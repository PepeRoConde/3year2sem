{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "57knM8jrYZ2t"
   },
   "source": [
    "# Notebook 4: Modelos generativos\n",
    "\n",
    "## Pre-requisitos\n",
    "\n",
    "### Instalar paquetes\n",
    "\n",
    "Si la práctica requiere algún paquete de Python, habrá que incluir una celda en la que se instalen. Si usamos un paquete que se ha utilizado en prácticas anteriores, podríamos dar por supuesto que está instalado pero no cuesta nada satisfacer todas las dependencias en la propia práctica para reducir las dependencias entre ellas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "LkaimNJfYZ2w"
   },
   "outputs": [],
   "source": [
    "# Ejemplo de instalación de tensorflow 2.0\n",
    "#%tensorflow_version 2.x\n",
    "# !pip3 install tensorflow  # NECESARIO SOLO SI SE EJECUTA EN LOCAL\n",
    "import tensorflow as tf\n",
    "\n",
    "# Hacemos los imports que sean necesarios\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SOch-CnwQttl"
   },
   "source": [
    "# Modelos generativos sobre MNIST\n",
    "\n",
    "Lo primero que tenemos que hacer es cargar el dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "1gXdWDBIEKel"
   },
   "outputs": [],
   "source": [
    "labeled_data = 0.01 # Vamos a usar el etiquetado de sólo el 1% de los datos\n",
    "np.random.seed(42)\n",
    "\n",
    "(x_train, y_train), (x_test, y_test), = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "indexes = np.arange(len(x_train))\n",
    "np.random.shuffle(indexes)\n",
    "ntrain_data = int(labeled_data*len(x_train))\n",
    "unlabeled_train = x_train[indexes[ntrain_data:]]\n",
    "x_train = x_train[indexes[:ntrain_data]] \n",
    "y_train = y_train[indexes[:ntrain_data]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "8XsZIqV8TmSc"
   },
   "outputs": [],
   "source": [
    "# TODO: Haz el preprocesado que necesites aquí (si lo necesitas)\n",
    "\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1]*x_train.shape[2])) \n",
    "x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1]*x_test.shape[2])) /255\n",
    "unlabeled_train = np.reshape(unlabeled_train, (unlabeled_train.shape[0], unlabeled_train.shape[1]*unlabeled_train.shape[2])) /255\n",
    "\n",
    "one_hot_train = np.zeros((y_train.size, len(set(y_train))), dtype=int)\n",
    "one_hot_train[np.arange(y_train.size), y_train ] = 1\n",
    "\n",
    "one_hot_test = np.zeros((y_test.size, len(set(y_test))), dtype=int)\n",
    "one_hot_test[np.arange(y_test.size), y_test ] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wkaCDOGapMyl"
   },
   "source": [
    "## Modelo generativo\n",
    "\n",
    "Vamos a crear nuestro propio modelo generativo. En clase de teoría has visto muchas versiones distintas:\n",
    "\n",
    "1. Mezcla de distribuciones de Gaussianas (GMM)\n",
    "1. Mezcla de distribuciones multinomiales (Naive Bayes)\n",
    "1. Modelos de Markov ocultos (HMM)\n",
    "\n",
    "Tal y como se os apunta en teoría, los modelos generativos abordan un problema más general, y aprenden realmente cómo se estructuran y distribuyen los datos de entrada. \n",
    "\n",
    "En nuestro caso, vamos a distribuír los datos de entrada mediante el uso de **Autoencoders**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pxf_lSC1HsYh"
   },
   "source": [
    "# Autoencoders\n",
    "\n",
    "El autoencoder es un tipo de red que se utiliza para aprender codificaciones eficientes de datos sin etiquetar (lo que se conoce como aprendizaje no supervisado). Es una red que tiene el mismo tamaño en la entrada como en la salida, puesto que el objetivo de la red es reconstruír la entrada con la menor pérdida posible.\n",
    "\n",
    "Si lo que hacemos es reconstruír la entrada, ¿qué sentido tiene el usar la red? Habitualmente, **la red consta, a su mitad, de una capa con menos elementos que los datos de entrada**. Por tanto, al reconstruír los datos de la entrada a la salida, en esa capa tendremos una versión *comprimida* de la entrada, que contendrá la mayor parte de su información.\n",
    "\n",
    "Por tanto, podemos dividir un autoencoder en 3 secciones diferentes, tal y como se ve en la siguiente figura:\n",
    "\n",
    "![autoencoder](https://drive.google.com/uc?export=view&id=1yxkKZV0J0YplQAGPGJxQ2Z80Ad6L94eu)\n",
    "\n",
    "\n",
    "1. **Encoder:** es la parte inicial de la red, encargada de comprimir los datos de la entrada.\n",
    "1. **Code:** es la salida del encoder, contiene la versión *comprimida* de los datos de entrada.\n",
    "1. **Decoder:** se encarga de, partiendo de la salida del *Encoder*, reconstruír la red."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7-mBCsDXJX3M"
   },
   "source": [
    "## Crea tu propio Autoencoder\n",
    "\n",
    "El diseño del autoencoder es libre (capas densas, convolucionales, ...), puedes crearlo como quieras. **El único requisito es que tiene que mantener los nombres (y parámetros) de las funciones descritas abajo.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "M95R6t1pJW3f"
   },
   "outputs": [],
   "source": [
    "# TODO: crea tu propio autoencoder\n",
    "\n",
    "\n",
    "class MiAutoencoder:\n",
    "\n",
    "    def __init__(self, input_shape):\n",
    "        \n",
    "        self.input_shape = input_shape\n",
    "        \n",
    "        self.encoder = models.Sequential()\n",
    "        self.encoder.add(layers.InputLayer(shape=self.input_shape))\n",
    "        self.encoder.add(layers.Dense(512, activation='relu'))\n",
    "        self.encoder.add(layers.Dense(128, activation='relu'))\n",
    "        self.encoder.add(layers.Dense(64, activation='relu'))\n",
    "        self.encoder.add(layers.Dense(32, activation='relu'))\n",
    "        self.encoder.add(layers.Dense(32, activation='relu'))  # Latent space\n",
    "\n",
    "        self.decoder = models.Sequential()\n",
    "        self.decoder.add(layers.InputLayer(shape=(32,)))\n",
    "        self.decoder.add(layers.Dense(32, activation='relu'))\n",
    "        self.decoder.add(layers.Dense(64, activation='relu'))\n",
    "        self.decoder.add(layers.Dense(128, activation='relu'))\n",
    "        self.decoder.add(layers.Dense(512, activation='relu'))\n",
    "        self.decoder.add(layers.Dense(self.input_shape[0], activation='sigmoid'))  # Output should match input\n",
    "\n",
    "        self.autoencoder = models.Sequential([self.encoder, self.decoder])\n",
    "\n",
    "        self.optimicer = tf.keras.optimizers.AdamW(\n",
    "            learning_rate=0.001,\n",
    "            clipnorm=1,\n",
    "        )\n",
    "\n",
    "\n",
    "        self.autoencoder.compile(optimizer=self.optimicer, loss='mse')\n",
    "    \n",
    "    def fit(self, X, y=None, sample_weight=None, batch_size=60_000, epochs=100):\n",
    "        # TODO: entrena el modelo. Escoge el tamaño de batch y el número de epochs que quieras\n",
    "        \n",
    "        self.autoencoder.fit(X, X, \n",
    "                             batch_size=batch_size, \n",
    "                             epochs=epochs, \n",
    "                             sample_weight=sample_weight)\n",
    "\n",
    "    def get_encoded_data(self, X):\n",
    "        # TODO: devuelve la salida del encoder (code)\n",
    "        return self.encoder.predict(X)\n",
    "\n",
    "\n",
    "    def __call__(self, X):\n",
    "        return self.autoencoder.predict(X)\n",
    "        \n",
    "    def __del__(self):\n",
    "        # elimina todos los modelos que hayas creado\n",
    "        tf.keras.backend.clear_session() # Necesario para liberar la memoria en GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6tt0L2yCMdmb"
   },
   "source": [
    "## Crea tu propio Clasificador\n",
    "\n",
    "El diseño del clasificador es libre, pero recuerda que tiene que ser simple (máximo dos capas). **El único requisito es que tiene que mantener los nombres (y parámetros) de las funciones descritas abajo.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "1mh0yzbKMuhk"
   },
   "outputs": [],
   "source": [
    "# TODO: crea tu propio clasificador\n",
    "\n",
    "class MiClasificador:\n",
    "\n",
    "    def __init__(self):\n",
    "        # TODO : define el modelo y compílalo\n",
    "        \n",
    "        self.input_shape = (32,)\n",
    "        \n",
    "        self.classifier = models.Sequential()\n",
    "        self.classifier.add(layers.InputLayer(shape=self.input_shape))\n",
    "        self.classifier.add(layers.Dense(32, activation='relu'))\n",
    "        self.classifier.add(layers.Dense(10, activation='sigmoid'))\n",
    "\n",
    "        self.optimicer = tf.keras.optimizers.AdamW(\n",
    "            learning_rate=0.001,\n",
    "            clipnorm=1,\n",
    "        )\n",
    "\n",
    "        self.classifier.compile(optimizer=self.optimicer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    def fit(self, X, y, sample_weight=None, batch_size=60_000, epochs=350):\n",
    "        # TODO: entrena el modelo. Escoge el tamaño de batch y el número de epochs que quieras\n",
    "        self.classifier.fit(X, y, \n",
    "                             batch_size=batch_size, \n",
    "                             epochs=epochs, \n",
    "                             sample_weight=sample_weight)\n",
    "\n",
    "    def predict(self, X):\n",
    "        # TODO: devuelve la clase ganadora\n",
    "\n",
    "        return np.argmax(self.predict_proba(X)) + 1\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \n",
    "        return self.classifier.predict(X)\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        \n",
    "        return self.classifier.evaluate(X, y)[1]\n",
    "\n",
    "    def __del__(self):\n",
    "        # elimina todos los modelos que hayas creado\n",
    "        tf.keras.backend.clear_session() # Necesario para liberar la memoria en GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w1-v4D6VH3Qq"
   },
   "source": [
    "### Entrenamiendo del modelo semisupervisado\n",
    "\n",
    "El entrenamiento del sistema semisupervisado se realiza en dos pasos.\n",
    "\n",
    "1. Se entrena el autoencoder con todos los datos (etiquetados y sin etiquetar).\n",
    "1. Se entrena un clasificador simple (una o dos capas), teniendo como entrada la salida del encoder (**code**) de los datos etiquetados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vqT2nuCspfE_"
   },
   "source": [
    "<font color='red'>NOTA:</font> para entrenar (y predecir) vamos a utilizar los nombres de las funciones que hemos definido en el autoencoder y en el clasificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "5xjcLa21EKen"
   },
   "outputs": [],
   "source": [
    "# TODO: implementa el algoritmo semisupervised_training.\n",
    "\n",
    "def semisupervised_training(autoencoder, classifier, x_train, y_train, unlabeled_data):\n",
    "\n",
    "    all_x = np.vstack((x_train, unlabeled_train))\n",
    "    autoencoder.fit(all_x)\n",
    "    x_coded = autoencoder.get_encoded_data(x_train)\n",
    "    classifier.fit(x_coded, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qjFXe6EiYfRg"
   },
   "source": [
    "### Entrenamos nuestro modelo\n",
    "\n",
    "Usa lo hecho anteriormente para entrenar tu clasificador de una manera semi-supervisada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "lNC1s2Wmqx4x"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-31 23:36:17.458837: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1\n",
      "2025-03-31 23:36:17.458919: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 8.00 GB\n",
      "2025-03-31 23:36:17.458948: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 2.67 GB\n",
      "2025-03-31 23:36:17.458987: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-03-31 23:36:17.459016: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "# Crea tu autoencoder y tu clasificador\n",
    "\n",
    "autoencoder = MiAutoencoder(input_shape=x_train[0].shape)\n",
    "classifier = MiClasificador()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "hN2zd3DEYnKI",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-31 23:36:21.935447: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - loss: 71.5394\n",
      "Epoch 2/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 796ms/step - loss: 71.4639\n",
      "Epoch 3/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500ms/step - loss: 71.3724\n",
      "Epoch 4/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445ms/step - loss: 71.2990\n",
      "Epoch 5/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 443ms/step - loss: 71.2545\n",
      "Epoch 6/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 430ms/step - loss: 71.2296\n",
      "Epoch 7/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425ms/step - loss: 71.2136\n",
      "Epoch 8/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 438ms/step - loss: 71.2041\n",
      "Epoch 9/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473ms/step - loss: 71.1965\n",
      "Epoch 10/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 545ms/step - loss: 71.1943\n",
      "Epoch 11/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480ms/step - loss: 71.1877\n",
      "Epoch 12/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 442ms/step - loss: 71.1811\n",
      "Epoch 13/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 437ms/step - loss: 71.1793\n",
      "Epoch 14/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 435ms/step - loss: 71.1788\n",
      "Epoch 15/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491ms/step - loss: 71.1721\n",
      "Epoch 16/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 504ms/step - loss: 71.1700\n",
      "Epoch 17/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 519ms/step - loss: 71.1677\n",
      "Epoch 18/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 518ms/step - loss: 71.1656\n",
      "Epoch 19/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487ms/step - loss: 71.1636\n",
      "Epoch 20/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449ms/step - loss: 71.1611\n",
      "Epoch 21/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451ms/step - loss: 71.1581\n",
      "Epoch 22/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 426ms/step - loss: 71.1562\n",
      "Epoch 23/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 423ms/step - loss: 71.1537\n",
      "Epoch 24/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 443ms/step - loss: 71.1512\n",
      "Epoch 25/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486ms/step - loss: 71.1479\n",
      "Epoch 26/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 516ms/step - loss: 71.1449\n",
      "Epoch 27/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475ms/step - loss: 71.1440\n",
      "Epoch 28/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 505ms/step - loss: 71.1438\n",
      "Epoch 29/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 512ms/step - loss: 71.1426\n",
      "Epoch 30/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456ms/step - loss: 71.1388\n",
      "Epoch 31/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 440ms/step - loss: 71.1377\n",
      "Epoch 32/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 427ms/step - loss: 71.1359\n",
      "Epoch 33/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 422ms/step - loss: 71.1338\n",
      "Epoch 34/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 443ms/step - loss: 71.1320\n",
      "Epoch 35/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446ms/step - loss: 71.1302\n",
      "Epoch 36/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420ms/step - loss: 71.1284\n",
      "Epoch 37/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 423ms/step - loss: 71.1264\n",
      "Epoch 38/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 428ms/step - loss: 71.1237\n",
      "Epoch 39/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 432ms/step - loss: 71.1221\n",
      "Epoch 40/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462ms/step - loss: 71.1233\n",
      "Epoch 41/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474ms/step - loss: 71.1197\n",
      "Epoch 42/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460ms/step - loss: 71.1189\n",
      "Epoch 43/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449ms/step - loss: 71.1186\n",
      "Epoch 44/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 430ms/step - loss: 71.1176\n",
      "Epoch 45/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 444ms/step - loss: 71.1164\n",
      "Epoch 46/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 427ms/step - loss: 71.1146\n",
      "Epoch 47/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462ms/step - loss: 71.1127\n",
      "Epoch 48/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 541ms/step - loss: 71.1108\n",
      "Epoch 49/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 517ms/step - loss: 71.1091\n",
      "Epoch 50/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 437ms/step - loss: 71.1086\n",
      "Epoch 51/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474ms/step - loss: 71.1074\n",
      "Epoch 52/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477ms/step - loss: 71.1063\n",
      "Epoch 53/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496ms/step - loss: 71.1047\n",
      "Epoch 54/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466ms/step - loss: 71.1042\n",
      "Epoch 55/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 428ms/step - loss: 71.1038\n",
      "Epoch 56/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 436ms/step - loss: 71.1022\n",
      "Epoch 57/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446ms/step - loss: 71.1014\n",
      "Epoch 58/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452ms/step - loss: 71.0993\n",
      "Epoch 59/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425ms/step - loss: 71.0984\n",
      "Epoch 60/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 432ms/step - loss: 71.0976\n",
      "Epoch 61/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 436ms/step - loss: 71.0974\n",
      "Epoch 62/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 444ms/step - loss: 71.0952\n",
      "Epoch 63/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479ms/step - loss: 71.0947\n",
      "Epoch 64/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 500ms/step - loss: 71.0925\n",
      "Epoch 65/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472ms/step - loss: 71.0918\n",
      "Epoch 66/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 432ms/step - loss: 71.0915\n",
      "Epoch 67/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 435ms/step - loss: 71.0911\n",
      "Epoch 68/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 429ms/step - loss: 71.0890\n",
      "Epoch 69/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 429ms/step - loss: 71.0875\n",
      "Epoch 70/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 442ms/step - loss: 71.0872\n",
      "Epoch 71/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 424ms/step - loss: 71.0866\n",
      "Epoch 72/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425ms/step - loss: 71.0853\n",
      "Epoch 73/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 431ms/step - loss: 71.0870\n",
      "Epoch 74/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 432ms/step - loss: 71.0825\n",
      "Epoch 75/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 426ms/step - loss: 71.0806\n",
      "Epoch 76/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454ms/step - loss: 71.0823\n",
      "Epoch 77/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 555ms/step - loss: 71.0823\n",
      "Epoch 78/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 647ms/step - loss: 71.0784\n",
      "Epoch 79/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 512ms/step - loss: 71.0980\n",
      "Epoch 80/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459ms/step - loss: 71.1099\n",
      "Epoch 81/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - loss: 71.1481\n",
      "Epoch 82/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 468ms/step - loss: 71.1524\n",
      "Epoch 83/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 529ms/step - loss: 71.1339\n",
      "Epoch 84/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 521ms/step - loss: 71.1024\n",
      "Epoch 85/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455ms/step - loss: 71.0957\n",
      "Epoch 86/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 521ms/step - loss: 71.1196\n",
      "Epoch 87/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473ms/step - loss: 71.0819\n",
      "Epoch 88/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 432ms/step - loss: 71.0751\n",
      "Epoch 89/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 424ms/step - loss: 71.0780\n",
      "Epoch 90/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 429ms/step - loss: 71.0807\n",
      "Epoch 91/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 426ms/step - loss: 71.0805\n",
      "Epoch 92/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 429ms/step - loss: 71.0779\n",
      "Epoch 93/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463ms/step - loss: 71.0753\n",
      "Epoch 94/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 434ms/step - loss: 71.0738\n",
      "Epoch 95/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457ms/step - loss: 71.0722\n",
      "Epoch 96/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 507ms/step - loss: 71.0698\n",
      "Epoch 97/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 535ms/step - loss: 71.0667\n",
      "Epoch 98/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 587ms/step - loss: 71.0644\n",
      "Epoch 99/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 631ms/step - loss: 71.0630\n",
      "Epoch 100/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490ms/step - loss: 71.0617\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step  \n",
      "Epoch 1/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.0900 - loss: 1397.1637\n",
      "Epoch 2/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.0867 - loss: 1312.1133\n",
      "Epoch 3/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.0867 - loss: 1239.3304\n",
      "Epoch 4/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.0833 - loss: 1178.6244\n",
      "Epoch 5/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.0783 - loss: 1121.1644\n",
      "Epoch 6/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.0783 - loss: 1063.4427\n",
      "Epoch 7/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.0700 - loss: 1006.2294\n",
      "Epoch 8/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.0633 - loss: 953.2740\n",
      "Epoch 9/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.0683 - loss: 910.8041\n",
      "Epoch 10/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.0650 - loss: 882.3644\n",
      "Epoch 11/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.0650 - loss: 860.1843\n",
      "Epoch 12/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.0650 - loss: 833.6529\n",
      "Epoch 13/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.0650 - loss: 802.7247\n",
      "Epoch 14/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.0800 - loss: 768.9641\n",
      "Epoch 15/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.0783 - loss: 735.1561\n",
      "Epoch 16/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.0917 - loss: 704.6005\n",
      "Epoch 17/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.0983 - loss: 678.5394\n",
      "Epoch 18/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.1000 - loss: 655.8394\n",
      "Epoch 19/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.1017 - loss: 635.6038\n",
      "Epoch 20/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.1067 - loss: 616.7831\n",
      "Epoch 21/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.1050 - loss: 598.8525\n",
      "Epoch 22/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.1050 - loss: 581.7367\n",
      "Epoch 23/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.1050 - loss: 565.5253\n",
      "Epoch 24/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.1050 - loss: 549.8178\n",
      "Epoch 25/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.1067 - loss: 534.0887\n",
      "Epoch 26/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.1067 - loss: 518.3021\n",
      "Epoch 27/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.1067 - loss: 501.9050\n",
      "Epoch 28/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.1067 - loss: 485.0006\n",
      "Epoch 29/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.1067 - loss: 467.9550\n",
      "Epoch 30/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.1067 - loss: 450.8593\n",
      "Epoch 31/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.1067 - loss: 434.6382\n",
      "Epoch 32/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.1067 - loss: 420.0388\n",
      "Epoch 33/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.1067 - loss: 407.3231\n",
      "Epoch 34/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.1033 - loss: 395.3228\n",
      "Epoch 35/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.1050 - loss: 383.9630\n",
      "Epoch 36/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.1017 - loss: 373.9183\n",
      "Epoch 37/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.1017 - loss: 365.1388\n",
      "Epoch 38/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.1017 - loss: 357.1755\n",
      "Epoch 39/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.1050 - loss: 348.9270\n",
      "Epoch 40/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.1050 - loss: 340.0301\n",
      "Epoch 41/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.1100 - loss: 330.3871\n",
      "Epoch 42/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.1117 - loss: 320.2466\n",
      "Epoch 43/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.1117 - loss: 310.1669\n",
      "Epoch 44/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.1117 - loss: 300.1450\n",
      "Epoch 45/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.1133 - loss: 290.2730\n",
      "Epoch 46/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.1100 - loss: 280.9395\n",
      "Epoch 47/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.1100 - loss: 271.8476\n",
      "Epoch 48/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.1100 - loss: 263.2164\n",
      "Epoch 49/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.1100 - loss: 254.2491\n",
      "Epoch 50/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.1100 - loss: 244.6761\n",
      "Epoch 51/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.1133 - loss: 234.8632\n",
      "Epoch 52/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.1133 - loss: 225.2551\n",
      "Epoch 53/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.1133 - loss: 216.4288\n",
      "Epoch 54/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.1133 - loss: 208.2012\n",
      "Epoch 55/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.1150 - loss: 199.9703\n",
      "Epoch 56/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.1183 - loss: 191.5226\n",
      "Epoch 57/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.1183 - loss: 182.9550\n",
      "Epoch 58/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.1200 - loss: 174.4214\n",
      "Epoch 59/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.1200 - loss: 166.1586\n",
      "Epoch 60/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.1417 - loss: 158.1679\n",
      "Epoch 61/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.1483 - loss: 150.1083\n",
      "Epoch 62/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.1583 - loss: 142.1428\n",
      "Epoch 63/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.1750 - loss: 134.5576\n",
      "Epoch 64/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.1967 - loss: 127.7906\n",
      "Epoch 65/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.2133 - loss: 123.3092\n",
      "Epoch 66/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.2150 - loss: 121.7706\n",
      "Epoch 67/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.2167 - loss: 123.5678\n",
      "Epoch 68/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.2150 - loss: 126.4221\n",
      "Epoch 69/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.2150 - loss: 128.1565\n",
      "Epoch 70/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2150 - loss: 127.7648\n",
      "Epoch 71/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2150 - loss: 125.3009\n",
      "Epoch 72/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.2150 - loss: 121.2925\n",
      "Epoch 73/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2183 - loss: 116.6105\n",
      "Epoch 74/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.2167 - loss: 112.2967\n",
      "Epoch 75/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2200 - loss: 108.7276\n",
      "Epoch 76/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2200 - loss: 105.6469\n",
      "Epoch 77/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.2200 - loss: 103.6558\n",
      "Epoch 78/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.2267 - loss: 102.5159\n",
      "Epoch 79/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2217 - loss: 101.7107\n",
      "Epoch 80/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2217 - loss: 100.8819\n",
      "Epoch 81/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2167 - loss: 99.6066\n",
      "Epoch 82/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.2200 - loss: 97.9844\n",
      "Epoch 83/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2217 - loss: 96.1599\n",
      "Epoch 84/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.2250 - loss: 94.2487\n",
      "Epoch 85/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2250 - loss: 92.0945\n",
      "Epoch 86/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.2250 - loss: 90.0061\n",
      "Epoch 87/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2233 - loss: 88.1209\n",
      "Epoch 88/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2233 - loss: 86.7598\n",
      "Epoch 89/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.2233 - loss: 85.3461\n",
      "Epoch 90/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.2233 - loss: 83.8426\n",
      "Epoch 91/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.2233 - loss: 82.2456\n",
      "Epoch 92/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2217 - loss: 80.5239\n",
      "Epoch 93/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.2217 - loss: 78.7241\n",
      "Epoch 94/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2250 - loss: 77.1031\n",
      "Epoch 95/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2233 - loss: 75.5967\n",
      "Epoch 96/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2250 - loss: 74.1812\n",
      "Epoch 97/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.2250 - loss: 72.7884\n",
      "Epoch 98/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2250 - loss: 71.2772\n",
      "Epoch 99/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.2250 - loss: 69.7087\n",
      "Epoch 100/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.2250 - loss: 68.2616\n",
      "Epoch 101/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2250 - loss: 66.8501\n",
      "Epoch 102/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2217 - loss: 65.4966\n",
      "Epoch 103/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2217 - loss: 64.1624\n",
      "Epoch 104/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2233 - loss: 62.8392\n",
      "Epoch 105/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.2233 - loss: 61.4947\n",
      "Epoch 106/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2233 - loss: 60.1399\n",
      "Epoch 107/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2250 - loss: 58.8092\n",
      "Epoch 108/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2233 - loss: 57.5827\n",
      "Epoch 109/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2267 - loss: 56.3071\n",
      "Epoch 110/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2283 - loss: 55.0856\n",
      "Epoch 111/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.2267 - loss: 53.8238\n",
      "Epoch 112/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2300 - loss: 52.6494\n",
      "Epoch 113/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2300 - loss: 51.4790\n",
      "Epoch 114/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2300 - loss: 50.3373\n",
      "Epoch 115/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2300 - loss: 49.2575\n",
      "Epoch 116/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2300 - loss: 48.1960\n",
      "Epoch 117/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.2350 - loss: 47.1449\n",
      "Epoch 118/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2350 - loss: 46.1493\n",
      "Epoch 119/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2333 - loss: 45.1475\n",
      "Epoch 120/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2350 - loss: 44.2187\n",
      "Epoch 121/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2433 - loss: 43.2935\n",
      "Epoch 122/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2450 - loss: 42.3978\n",
      "Epoch 123/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.2467 - loss: 41.5844\n",
      "Epoch 124/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2450 - loss: 40.8245\n",
      "Epoch 125/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2450 - loss: 40.0006\n",
      "Epoch 126/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.2433 - loss: 39.3672\n",
      "Epoch 127/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2467 - loss: 38.5192\n",
      "Epoch 128/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2483 - loss: 37.9087\n",
      "Epoch 129/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2517 - loss: 37.2305\n",
      "Epoch 130/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.2450 - loss: 36.6722\n",
      "Epoch 131/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.2450 - loss: 36.1184\n",
      "Epoch 132/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2450 - loss: 35.4777\n",
      "Epoch 133/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2500 - loss: 35.0148\n",
      "Epoch 134/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.2500 - loss: 34.5866\n",
      "Epoch 135/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.2517 - loss: 33.9731\n",
      "Epoch 136/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.2550 - loss: 33.6356\n",
      "Epoch 137/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.2550 - loss: 33.1713\n",
      "Epoch 138/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2567 - loss: 32.6611\n",
      "Epoch 139/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.2533 - loss: 32.2761\n",
      "Epoch 140/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.2550 - loss: 31.8787\n",
      "Epoch 141/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.2533 - loss: 31.3972\n",
      "Epoch 142/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.2517 - loss: 31.1246\n",
      "Epoch 143/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2517 - loss: 30.7451\n",
      "Epoch 144/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2567 - loss: 30.3848\n",
      "Epoch 145/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.2533 - loss: 30.0485\n",
      "Epoch 146/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2533 - loss: 29.6290\n",
      "Epoch 147/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2533 - loss: 29.4569\n",
      "Epoch 148/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2533 - loss: 29.1332\n",
      "Epoch 149/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.2467 - loss: 28.6565\n",
      "Epoch 150/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2483 - loss: 28.4068\n",
      "Epoch 151/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.2500 - loss: 28.1597\n",
      "Epoch 152/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.2500 - loss: 27.7607\n",
      "Epoch 153/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2433 - loss: 27.4944\n",
      "Epoch 154/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2433 - loss: 27.1453\n",
      "Epoch 155/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2483 - loss: 26.9573\n",
      "Epoch 156/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2467 - loss: 26.6682\n",
      "Epoch 157/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2450 - loss: 26.3853\n",
      "Epoch 158/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2450 - loss: 26.0957\n",
      "Epoch 159/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2450 - loss: 25.8163\n",
      "Epoch 160/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.2433 - loss: 25.5216\n",
      "Epoch 161/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.2433 - loss: 25.3747\n",
      "Epoch 162/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2433 - loss: 25.1192\n",
      "Epoch 163/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2450 - loss: 24.7865\n",
      "Epoch 164/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2450 - loss: 24.5588\n",
      "Epoch 165/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.2467 - loss: 24.3543\n",
      "Epoch 166/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.2450 - loss: 24.0717\n",
      "Epoch 167/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.2467 - loss: 23.9761\n",
      "Epoch 168/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.2467 - loss: 23.7365\n",
      "Epoch 169/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.2467 - loss: 23.4295\n",
      "Epoch 170/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.2500 - loss: 23.2151\n",
      "Epoch 171/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.2467 - loss: 23.0181\n",
      "Epoch 172/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2450 - loss: 22.7622\n",
      "Epoch 173/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2450 - loss: 22.7494\n",
      "Epoch 174/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2450 - loss: 22.5273\n",
      "Epoch 175/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2433 - loss: 22.1816\n",
      "Epoch 176/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.2483 - loss: 22.0003\n",
      "Epoch 177/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2450 - loss: 21.8756\n",
      "Epoch 178/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2433 - loss: 21.6246\n",
      "Epoch 179/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2483 - loss: 21.6421\n",
      "Epoch 180/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.2483 - loss: 21.4663\n",
      "Epoch 181/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.2450 - loss: 21.0903\n",
      "Epoch 182/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.2383 - loss: 20.9720\n",
      "Epoch 183/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2433 - loss: 20.8105\n",
      "Epoch 184/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2433 - loss: 20.6121\n",
      "Epoch 185/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.2383 - loss: 20.5823\n",
      "Epoch 186/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.2383 - loss: 20.3157\n",
      "Epoch 187/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2433 - loss: 20.4168\n",
      "Epoch 188/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.2433 - loss: 20.2776\n",
      "Epoch 189/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2417 - loss: 19.9485\n",
      "Epoch 190/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2400 - loss: 19.8510\n",
      "Epoch 191/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.2367 - loss: 19.7210\n",
      "Epoch 192/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.2383 - loss: 19.5642\n",
      "Epoch 193/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.2417 - loss: 19.4483\n",
      "Epoch 194/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.2433 - loss: 19.2793\n",
      "Epoch 195/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.2417 - loss: 19.2570\n",
      "Epoch 196/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.2383 - loss: 19.0735\n",
      "Epoch 197/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.2417 - loss: 18.9878\n",
      "Epoch 198/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.2417 - loss: 18.8196\n",
      "Epoch 199/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.2433 - loss: 18.7765\n",
      "Epoch 200/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.2417 - loss: 18.5793\n",
      "Epoch 201/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2400 - loss: 18.5459\n",
      "Epoch 202/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.2400 - loss: 18.4379\n",
      "Epoch 203/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.2417 - loss: 18.1947\n",
      "Epoch 204/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2417 - loss: 18.1045\n",
      "Epoch 205/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.2400 - loss: 18.0287\n",
      "Epoch 206/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.2400 - loss: 17.8648\n",
      "Epoch 207/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.2383 - loss: 17.9765\n",
      "Epoch 208/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2400 - loss: 17.8608\n",
      "Epoch 209/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2433 - loss: 17.5162\n",
      "Epoch 210/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.2400 - loss: 17.4078\n",
      "Epoch 211/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.2400 - loss: 17.3675\n",
      "Epoch 212/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2367 - loss: 17.1992\n",
      "Epoch 213/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.2383 - loss: 17.2805\n",
      "Epoch 214/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.2367 - loss: 17.1582\n",
      "Epoch 215/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.2400 - loss: 16.9292\n",
      "Epoch 216/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.2383 - loss: 16.8754\n",
      "Epoch 217/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.2333 - loss: 16.7291\n",
      "Epoch 218/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.2333 - loss: 16.6552\n",
      "Epoch 219/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.2350 - loss: 16.5399\n",
      "Epoch 220/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2350 - loss: 16.4289\n",
      "Epoch 221/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2333 - loss: 16.4261\n",
      "Epoch 222/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2317 - loss: 16.2503\n",
      "Epoch 223/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2267 - loss: 16.3290\n",
      "Epoch 224/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2317 - loss: 16.2637\n",
      "Epoch 225/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.2350 - loss: 16.0120\n",
      "Epoch 226/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.2333 - loss: 15.8955\n",
      "Epoch 227/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.2283 - loss: 15.8825\n",
      "Epoch 228/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.2283 - loss: 15.7975\n",
      "Epoch 229/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.2300 - loss: 15.7159\n",
      "Epoch 230/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.2300 - loss: 15.6060\n",
      "Epoch 231/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.2283 - loss: 15.4917\n",
      "Epoch 232/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2300 - loss: 15.4160\n",
      "Epoch 233/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.2283 - loss: 15.2969\n",
      "Epoch 234/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.2317 - loss: 15.2550\n",
      "Epoch 235/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.2300 - loss: 15.1798\n",
      "Epoch 236/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.2317 - loss: 15.0163\n",
      "Epoch 237/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2250 - loss: 15.1729\n",
      "Epoch 238/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2233 - loss: 15.0179\n",
      "Epoch 239/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2267 - loss: 14.9578\n",
      "Epoch 240/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2283 - loss: 14.8130\n",
      "Epoch 241/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2233 - loss: 14.9528\n",
      "Epoch 242/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2217 - loss: 14.7978\n",
      "Epoch 243/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.2250 - loss: 14.7178\n",
      "Epoch 244/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.2267 - loss: 14.6227\n",
      "Epoch 245/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2250 - loss: 14.5463\n",
      "Epoch 246/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2233 - loss: 14.4410\n",
      "Epoch 247/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2250 - loss: 14.4574\n",
      "Epoch 248/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.2250 - loss: 14.2787\n",
      "Epoch 249/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2250 - loss: 14.4994\n",
      "Epoch 250/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2250 - loss: 14.4748\n",
      "Epoch 251/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2250 - loss: 14.0993\n",
      "Epoch 252/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2267 - loss: 14.0837\n",
      "Epoch 253/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2250 - loss: 14.0990\n",
      "Epoch 254/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.2233 - loss: 13.9797\n",
      "Epoch 255/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.2250 - loss: 14.0142\n",
      "Epoch 256/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.2250 - loss: 13.9158\n",
      "Epoch 257/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.2250 - loss: 13.9286\n",
      "Epoch 258/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.2233 - loss: 13.8551\n",
      "Epoch 259/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2233 - loss: 13.7212\n",
      "Epoch 260/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.2233 - loss: 13.6621\n",
      "Epoch 261/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.2233 - loss: 13.6973\n",
      "Epoch 262/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.2233 - loss: 13.5897\n",
      "Epoch 263/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.2233 - loss: 13.5647\n",
      "Epoch 264/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.2233 - loss: 13.4779\n",
      "Epoch 265/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.2233 - loss: 13.4878\n",
      "Epoch 266/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.2233 - loss: 13.3989\n",
      "Epoch 267/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.2250 - loss: 13.3621\n",
      "Epoch 268/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.2250 - loss: 13.2906\n",
      "Epoch 269/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.2233 - loss: 13.2754\n",
      "Epoch 270/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.2233 - loss: 13.1893\n",
      "Epoch 271/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.2250 - loss: 13.1904\n",
      "Epoch 272/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.2233 - loss: 13.1107\n",
      "Epoch 273/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.2233 - loss: 13.1124\n",
      "Epoch 274/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.2233 - loss: 13.0343\n",
      "Epoch 275/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.2233 - loss: 12.9671\n",
      "Epoch 276/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2233 - loss: 12.8793\n",
      "Epoch 277/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.2217 - loss: 13.0044\n",
      "Epoch 278/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2217 - loss: 12.9071\n",
      "Epoch 279/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2233 - loss: 12.7907\n",
      "Epoch 280/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2200 - loss: 12.7224\n",
      "Epoch 281/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2200 - loss: 12.7725\n",
      "Epoch 282/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.2217 - loss: 12.6562\n",
      "Epoch 283/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.2233 - loss: 12.7213\n",
      "Epoch 284/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.2200 - loss: 12.6471\n",
      "Epoch 285/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2183 - loss: 12.5263\n",
      "Epoch 286/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2200 - loss: 12.4444\n",
      "Epoch 287/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2217 - loss: 12.5132\n",
      "Epoch 288/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2183 - loss: 12.3946\n",
      "Epoch 289/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2167 - loss: 12.5066\n",
      "Epoch 290/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2167 - loss: 12.4388\n",
      "Epoch 291/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.2200 - loss: 12.2556\n",
      "Epoch 292/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.2183 - loss: 12.1830\n",
      "Epoch 293/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.2167 - loss: 12.3560\n",
      "Epoch 294/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2167 - loss: 12.2076\n",
      "Epoch 295/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2183 - loss: 12.1841\n",
      "Epoch 296/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2183 - loss: 12.1377\n",
      "Epoch 297/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2167 - loss: 12.0426\n",
      "Epoch 298/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2167 - loss: 11.9679\n",
      "Epoch 299/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2183 - loss: 12.0161\n",
      "Epoch 300/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.2183 - loss: 11.9066\n",
      "Epoch 301/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2150 - loss: 12.0691\n",
      "Epoch 302/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2167 - loss: 12.0169\n",
      "Epoch 303/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2183 - loss: 11.7705\n",
      "Epoch 304/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2183 - loss: 11.7281\n",
      "Epoch 305/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.2167 - loss: 11.8314\n",
      "Epoch 306/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.2167 - loss: 11.6590\n",
      "Epoch 307/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.2183 - loss: 11.8393\n",
      "Epoch 308/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2183 - loss: 11.8097\n",
      "Epoch 309/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.2167 - loss: 11.5649\n",
      "Epoch 310/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.2167 - loss: 11.6209\n",
      "Epoch 311/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2167 - loss: 11.5886\n",
      "Epoch 312/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2167 - loss: 11.4764\n",
      "Epoch 313/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2150 - loss: 11.5760\n",
      "Epoch 314/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.2167 - loss: 11.3990\n",
      "Epoch 315/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.2183 - loss: 11.5172\n",
      "Epoch 316/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.2167 - loss: 11.4049\n",
      "Epoch 317/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.2150 - loss: 11.5616\n",
      "Epoch 318/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.2167 - loss: 11.4937\n",
      "Epoch 319/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2167 - loss: 11.2516\n",
      "Epoch 320/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2150 - loss: 11.2548\n",
      "Epoch 321/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2150 - loss: 11.2561\n",
      "Epoch 322/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.2150 - loss: 11.1093\n",
      "Epoch 323/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.2183 - loss: 11.2739\n",
      "Epoch 324/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.2183 - loss: 11.2532\n",
      "Epoch 325/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.2167 - loss: 10.9334\n",
      "Epoch 326/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.2167 - loss: 10.9941\n",
      "Epoch 327/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.2167 - loss: 10.9385\n",
      "Epoch 328/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.2167 - loss: 10.8586\n",
      "Epoch 329/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2167 - loss: 10.8210\n",
      "Epoch 330/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2167 - loss: 10.8114\n",
      "Epoch 331/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2167 - loss: 10.7501\n",
      "Epoch 332/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.2167 - loss: 10.6548\n",
      "Epoch 333/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.2183 - loss: 10.6673\n",
      "Epoch 334/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.2167 - loss: 10.6374\n",
      "Epoch 335/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.2150 - loss: 10.5625\n",
      "Epoch 336/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.2150 - loss: 10.5494\n",
      "Epoch 337/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2150 - loss: 10.4419\n",
      "Epoch 338/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2150 - loss: 10.5415\n",
      "Epoch 339/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2150 - loss: 10.3497\n",
      "Epoch 340/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.2167 - loss: 10.8243\n",
      "Epoch 341/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.2133 - loss: 10.9033\n",
      "Epoch 342/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.2150 - loss: 10.6539\n",
      "Epoch 343/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2150 - loss: 10.3203\n",
      "Epoch 344/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2117 - loss: 10.5433\n",
      "Epoch 345/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2117 - loss: 10.5541\n",
      "Epoch 346/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2133 - loss: 10.1657\n",
      "Epoch 347/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2150 - loss: 10.2368\n",
      "Epoch 348/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2150 - loss: 10.3565\n",
      "Epoch 349/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2133 - loss: 10.0140\n",
      "Epoch 350/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2133 - loss: 10.4854\n"
     ]
    }
   ],
   "source": [
    "# TODO: Entrena tu modelo\n",
    "\n",
    "semisupervised_training(autoencoder=autoencoder, classifier=classifier, x_train=x_train, y_train=one_hot_train, unlabeled_data=unlabeled_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "id": "n5tS8_SKOngm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7033 - loss: 0.9042\n",
      "Test accuracy : 0.730400025844574\n"
     ]
    }
   ],
   "source": [
    "# TODO: Obtén la precisión sobre el conjunto de test\n",
    "pred_data = autoencoder.get_encoded_data(x_test)\n",
    "print('Test accuracy :', classifier.score(pred_data, one_hot_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "index = 1\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "axes[0].imshow(x_test[index].reshape(28, 28), cmap='gray')\n",
    "axes[0].set_title(\"Original Image\")\n",
    "axes[0].axis('off') \n",
    "\n",
    "# Get the reconstructed image from the autoencoder\n",
    "reconstructed_image = autoencoder(x_test[index].reshape(1, 784)).reshape(28, 28)\n",
    "\n",
    "# Plot the reconstructed image on the right\n",
    "axes[1].imshow(reconstructed_image, cmap='gray')\n",
    "axes[1].set_title(\"Reconstructed Image\")\n",
    "axes[1].axis('off')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MbUKp14pPsrp"
   },
   "source": [
    "## Mejorando el código\n",
    "\n",
    "nuestro modelo actual requiere de dos pasos para entrenarse, pero podría realizarse en un único paso si **creamos un modelo con las dos salidas (autoencoder y clasificador)**. \n",
    "\n",
    "Para ello, hay que tener en cuenta que, en los datos sin etiquetar, su contribución al clasificador debería ser nula.\n",
    "\n",
    "\n",
    "### TRABAJO: Crea el nuevo modelo y modifica la función semisupervised_training para tener en cuenta todos los puntos mencionados anteriormente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "id": "xS3JLE37SqrG"
   },
   "outputs": [],
   "source": [
    "# TODO: crea el nuevo modelo\n",
    "\n",
    "# TODO: crea tu propio clasificador\n",
    "\n",
    "class MiClasificadorSemisupervisado:\n",
    "\n",
    "    def __init__(self, input_shape):\n",
    "        # TODO : define el modelo y compílalo\n",
    "        \n",
    "        self.input_shape = input_shape\n",
    "        self.num_classes = 10\n",
    "        \n",
    "        input_layer = layers.Input(shape=self.input_shape)\n",
    "        \n",
    "        # Encoder part (shared for both autoencoder and classifier)\n",
    "        encoded = layers.Dense(128, activation='relu')(input_layer)\n",
    "        encoded = layers.Dense(64, activation='relu')(encoded)\n",
    "        encoded = layers.Dense(16, activation='relu', kernel_regularizer='l2')(encoded)\n",
    "        \n",
    "        # Decoder for autoencoder part\n",
    "        decoded = layers.Dense(64, activation='relu')(encoded)\n",
    "        decoded = layers.Dense(128, activation='relu')(decoded)\n",
    "        decoded = layers.Dense(self.input_shape[0], activation='sigmoid',name='autoencoder')(decoded)\n",
    "\n",
    "        # Classifier part\n",
    "        classifier = layers.Dense(32, activation='relu')(encoded)\n",
    "        classifier = layers.Dense(16, activation='relu')(classifier)\n",
    "        classifier_output = layers.Dense(self.num_classes, activation='softmax',name='classifier')(classifier)\n",
    "\n",
    "        # Autoencoder model (for reconstructing input)\n",
    "        self.autoencoder = models.Model(input_layer, decoded)\n",
    "        #self.autoencoder.compile(optimizer='adam', loss='mse')\n",
    "        \n",
    "        # Classifier model (for predicting class labels)\n",
    "        self.classifier = models.Model(input_layer, classifier_output)\n",
    "        #self.classifier.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        \n",
    "        \n",
    "        # Combined model with two outputs: one for autoencoder (reconstruction) and one for classifier (classification)\n",
    "        self.model = models.Model(input_layer, \n",
    "                                  [decoded, classifier_output])\n",
    "                                  #classifier_output)\n",
    "\n",
    "        self.optimicer = tf.keras.optimizers.AdamW(\n",
    "            learning_rate=0.0001,\n",
    "            clipnorm=1,\n",
    "        )\n",
    "        \n",
    "        self.model.compile(optimizer=self.optimicer,\n",
    "                           loss=['mse', 'categorical_crossentropy'],\n",
    "                           #loss='categorical_crossentropy',\n",
    "                           loss_weights=[.8, 1.2],  # Adjust loss weights if needed\n",
    "                           metrics=['accuracy', 'accuracy'])\n",
    "    \n",
    "    def fit(self, X, y, unlabeled_data, batch_size,  epochs):\n",
    "        # TODO: entrena el modelo. Escoge el tamaño de batch y el número de epochs que quieras, y define bien el sample_weight\n",
    "\n",
    "        all_x = np.vstack((X, unlabeled_train))\n",
    "        y_zeros = np.zeros((unlabeled_data.shape[0],y.shape[1]))\n",
    "        all_y = np.vstack((y,y_zeros))\n",
    "        weight_autoencoder = np.ones(len(all_x))\n",
    "        weight_classifier = np.array([1]*len(X) + [0]*len(unlabeled_data))\n",
    "        \n",
    "        h = self.model.fit(all_x, \n",
    "                       [all_x, all_y], \n",
    "                       #all_y,\n",
    "                       sample_weight=[weight_autoencoder, weight_classifier], \n",
    "                       #sample_weight=sample_weight,\n",
    "                       epochs=epochs, \n",
    "                       batch_size=batch_size, \n",
    "                       verbose=1)\n",
    "        return h\n",
    "\n",
    "    def predict(self, X):\n",
    "        # TODO: devuelve la clase ganadora del clasificador\n",
    "        _, predictions = self.model.predict(X)\n",
    "        return predictions.argmax(axis=1)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        # TODO: devuelve la probabilidad del clasificador\n",
    "        _, predictions = self.model.predict(X)\n",
    "        return predictions\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        y_pred = self.predict(X)\n",
    "        return accuracy_score(y, y_pred)\n",
    "\n",
    "    def __call__(self, X):\n",
    "        return self.autoencoder.predict(X), self.classifier.predict(X)\n",
    "\n",
    "    def __del__(self):\n",
    "        # elimina todos los modelos que hayas creado\n",
    "        tf.keras.backend.clear_session() # Necesario para liberar la memoria en GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "id": "7eF_9LMeZ2J2"
   },
   "outputs": [],
   "source": [
    "# TODO: reescribe la función semisupervised_training para incorporar las mejoras mencionadas anteriormente\n",
    "\n",
    "model = MiClasificadorSemisupervisado(input_shape=x_train[0].shape)\n",
    "\n",
    "def semisupervised_training_v2(model, x_train, y_train, unlabeled_data):\n",
    "    h = model.fit(x_train, y_train, unlabeled_data, batch_size=60_000, epochs = 1000)\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "id": "YbqC0inexwHp",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - autoencoder_accuracy: 0.0017 - autoencoder_loss: 0.2327 - classifier_accuracy: 0.0037 - classifier_loss: 0.0247 - loss: 0.4767\n",
      "Epoch 2/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 535ms/step - autoencoder_accuracy: 0.0018 - autoencoder_loss: 0.2324 - classifier_accuracy: 0.0038 - classifier_loss: 0.0246 - loss: 0.4761\n",
      "Epoch 3/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376ms/step - autoencoder_accuracy: 0.0017 - autoencoder_loss: 0.2320 - classifier_accuracy: 0.0039 - classifier_loss: 0.0245 - loss: 0.4754\n",
      "Epoch 4/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 439ms/step - autoencoder_accuracy: 0.0018 - autoencoder_loss: 0.2317 - classifier_accuracy: 0.0036 - classifier_loss: 0.0244 - loss: 0.4748\n",
      "Epoch 5/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389ms/step - autoencoder_accuracy: 0.0019 - autoencoder_loss: 0.2314 - classifier_accuracy: 0.0037 - classifier_loss: 0.0244 - loss: 0.4742\n",
      "Epoch 6/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462ms/step - autoencoder_accuracy: 0.0018 - autoencoder_loss: 0.2311 - classifier_accuracy: 0.0033 - classifier_loss: 0.0243 - loss: 0.4736\n",
      "Epoch 7/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458ms/step - autoencoder_accuracy: 0.0018 - autoencoder_loss: 0.2308 - classifier_accuracy: 0.0032 - classifier_loss: 0.0243 - loss: 0.4730\n",
      "Epoch 8/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355ms/step - autoencoder_accuracy: 0.0018 - autoencoder_loss: 0.2305 - classifier_accuracy: 0.0032 - classifier_loss: 0.0242 - loss: 0.4724\n",
      "Epoch 9/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 434ms/step - autoencoder_accuracy: 0.0017 - autoencoder_loss: 0.2301 - classifier_accuracy: 0.0030 - classifier_loss: 0.0242 - loss: 0.4718\n",
      "Epoch 10/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461ms/step - autoencoder_accuracy: 0.0017 - autoencoder_loss: 0.2298 - classifier_accuracy: 0.0030 - classifier_loss: 0.0241 - loss: 0.4712\n",
      "Epoch 11/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 363ms/step - autoencoder_accuracy: 0.0016 - autoencoder_loss: 0.2294 - classifier_accuracy: 0.0030 - classifier_loss: 0.0241 - loss: 0.4705\n",
      "Epoch 12/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 540ms/step - autoencoder_accuracy: 0.0016 - autoencoder_loss: 0.2290 - classifier_accuracy: 0.0031 - classifier_loss: 0.0240 - loss: 0.4699\n",
      "Epoch 13/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459ms/step - autoencoder_accuracy: 0.0017 - autoencoder_loss: 0.2286 - classifier_accuracy: 0.0033 - classifier_loss: 0.0240 - loss: 0.4692\n",
      "Epoch 14/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 510ms/step - autoencoder_accuracy: 0.0016 - autoencoder_loss: 0.2282 - classifier_accuracy: 0.0033 - classifier_loss: 0.0239 - loss: 0.4685\n",
      "Epoch 15/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 442ms/step - autoencoder_accuracy: 0.0015 - autoencoder_loss: 0.2277 - classifier_accuracy: 0.0034 - classifier_loss: 0.0238 - loss: 0.4678\n",
      "Epoch 16/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 354ms/step - autoencoder_accuracy: 0.0015 - autoencoder_loss: 0.2273 - classifier_accuracy: 0.0036 - classifier_loss: 0.0238 - loss: 0.4671\n",
      "Epoch 17/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 343ms/step - autoencoder_accuracy: 0.0014 - autoencoder_loss: 0.2267 - classifier_accuracy: 0.0037 - classifier_loss: 0.0237 - loss: 0.4664\n",
      "Epoch 18/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 357ms/step - autoencoder_accuracy: 0.0014 - autoencoder_loss: 0.2262 - classifier_accuracy: 0.0038 - classifier_loss: 0.0237 - loss: 0.4656\n",
      "Epoch 19/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 343ms/step - autoencoder_accuracy: 0.0014 - autoencoder_loss: 0.2256 - classifier_accuracy: 0.0039 - classifier_loss: 0.0237 - loss: 0.4648\n",
      "Epoch 20/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 346ms/step - autoencoder_accuracy: 0.0014 - autoencoder_loss: 0.2250 - classifier_accuracy: 0.0038 - classifier_loss: 0.0236 - loss: 0.4640\n",
      "Epoch 21/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333ms/step - autoencoder_accuracy: 0.0014 - autoencoder_loss: 0.2244 - classifier_accuracy: 0.0039 - classifier_loss: 0.0236 - loss: 0.4632\n",
      "Epoch 22/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 348ms/step - autoencoder_accuracy: 0.0015 - autoencoder_loss: 0.2237 - classifier_accuracy: 0.0038 - classifier_loss: 0.0236 - loss: 0.4623\n",
      "Epoch 23/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 340ms/step - autoencoder_accuracy: 0.0015 - autoencoder_loss: 0.2230 - classifier_accuracy: 0.0038 - classifier_loss: 0.0235 - loss: 0.4614\n",
      "Epoch 24/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 342ms/step - autoencoder_accuracy: 0.0015 - autoencoder_loss: 0.2222 - classifier_accuracy: 0.0038 - classifier_loss: 0.0235 - loss: 0.4605\n",
      "Epoch 25/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 343ms/step - autoencoder_accuracy: 0.0016 - autoencoder_loss: 0.2214 - classifier_accuracy: 0.0037 - classifier_loss: 0.0235 - loss: 0.4596\n",
      "Epoch 26/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 344ms/step - autoencoder_accuracy: 0.0016 - autoencoder_loss: 0.2205 - classifier_accuracy: 0.0036 - classifier_loss: 0.0235 - loss: 0.4586\n",
      "Epoch 27/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 352ms/step - autoencoder_accuracy: 0.0016 - autoencoder_loss: 0.2196 - classifier_accuracy: 0.0035 - classifier_loss: 0.0235 - loss: 0.4576\n",
      "Epoch 28/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463ms/step - autoencoder_accuracy: 0.0016 - autoencoder_loss: 0.2187 - classifier_accuracy: 0.0033 - classifier_loss: 0.0235 - loss: 0.4565\n",
      "Epoch 29/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470ms/step - autoencoder_accuracy: 0.0017 - autoencoder_loss: 0.2176 - classifier_accuracy: 0.0032 - classifier_loss: 0.0235 - loss: 0.4554\n",
      "Epoch 30/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 357ms/step - autoencoder_accuracy: 0.0016 - autoencoder_loss: 0.2166 - classifier_accuracy: 0.0030 - classifier_loss: 0.0235 - loss: 0.4543\n",
      "Epoch 31/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 351ms/step - autoencoder_accuracy: 0.0017 - autoencoder_loss: 0.2154 - classifier_accuracy: 0.0028 - classifier_loss: 0.0235 - loss: 0.4531\n",
      "Epoch 32/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329ms/step - autoencoder_accuracy: 0.0017 - autoencoder_loss: 0.2142 - classifier_accuracy: 0.0026 - classifier_loss: 0.0235 - loss: 0.4519\n",
      "Epoch 33/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333ms/step - autoencoder_accuracy: 0.0018 - autoencoder_loss: 0.2130 - classifier_accuracy: 0.0025 - classifier_loss: 0.0235 - loss: 0.4506\n",
      "Epoch 34/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 346ms/step - autoencoder_accuracy: 0.0019 - autoencoder_loss: 0.2117 - classifier_accuracy: 0.0024 - classifier_loss: 0.0235 - loss: 0.4493\n",
      "Epoch 35/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331ms/step - autoencoder_accuracy: 0.0019 - autoencoder_loss: 0.2103 - classifier_accuracy: 0.0022 - classifier_loss: 0.0235 - loss: 0.4480\n",
      "Epoch 36/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 327ms/step - autoencoder_accuracy: 0.0020 - autoencoder_loss: 0.2089 - classifier_accuracy: 0.0021 - classifier_loss: 0.0235 - loss: 0.4465\n",
      "Epoch 37/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 350ms/step - autoencoder_accuracy: 0.0020 - autoencoder_loss: 0.2074 - classifier_accuracy: 0.0020 - classifier_loss: 0.0236 - loss: 0.4451\n",
      "Epoch 38/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329ms/step - autoencoder_accuracy: 0.0022 - autoencoder_loss: 0.2058 - classifier_accuracy: 0.0020 - classifier_loss: 0.0236 - loss: 0.4436\n",
      "Epoch 39/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330ms/step - autoencoder_accuracy: 0.0023 - autoencoder_loss: 0.2041 - classifier_accuracy: 0.0019 - classifier_loss: 0.0236 - loss: 0.4420\n",
      "Epoch 40/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329ms/step - autoencoder_accuracy: 0.0023 - autoencoder_loss: 0.2024 - classifier_accuracy: 0.0019 - classifier_loss: 0.0236 - loss: 0.4404\n",
      "Epoch 41/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 342ms/step - autoencoder_accuracy: 0.0024 - autoencoder_loss: 0.2006 - classifier_accuracy: 0.0018 - classifier_loss: 0.0237 - loss: 0.4388\n",
      "Epoch 42/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 357ms/step - autoencoder_accuracy: 0.0025 - autoencoder_loss: 0.1988 - classifier_accuracy: 0.0018 - classifier_loss: 0.0237 - loss: 0.4370\n",
      "Epoch 43/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392ms/step - autoencoder_accuracy: 0.0025 - autoencoder_loss: 0.1969 - classifier_accuracy: 0.0018 - classifier_loss: 0.0237 - loss: 0.4353\n",
      "Epoch 44/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 504ms/step - autoencoder_accuracy: 0.0026 - autoencoder_loss: 0.1949 - classifier_accuracy: 0.0018 - classifier_loss: 0.0238 - loss: 0.4334\n",
      "Epoch 45/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387ms/step - autoencoder_accuracy: 0.0027 - autoencoder_loss: 0.1928 - classifier_accuracy: 0.0017 - classifier_loss: 0.0238 - loss: 0.4315\n",
      "Epoch 46/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 370ms/step - autoencoder_accuracy: 0.0028 - autoencoder_loss: 0.1907 - classifier_accuracy: 0.0017 - classifier_loss: 0.0238 - loss: 0.4296\n",
      "Epoch 47/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 352ms/step - autoencoder_accuracy: 0.0029 - autoencoder_loss: 0.1885 - classifier_accuracy: 0.0018 - classifier_loss: 0.0238 - loss: 0.4276\n",
      "Epoch 48/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 360ms/step - autoencoder_accuracy: 0.0030 - autoencoder_loss: 0.1863 - classifier_accuracy: 0.0018 - classifier_loss: 0.0239 - loss: 0.4256\n",
      "Epoch 49/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 342ms/step - autoencoder_accuracy: 0.0031 - autoencoder_loss: 0.1839 - classifier_accuracy: 0.0018 - classifier_loss: 0.0239 - loss: 0.4235\n",
      "Epoch 50/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 348ms/step - autoencoder_accuracy: 0.0032 - autoencoder_loss: 0.1816 - classifier_accuracy: 0.0018 - classifier_loss: 0.0239 - loss: 0.4214\n",
      "Epoch 51/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 336ms/step - autoencoder_accuracy: 0.0032 - autoencoder_loss: 0.1791 - classifier_accuracy: 0.0018 - classifier_loss: 0.0240 - loss: 0.4192\n",
      "Epoch 52/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 341ms/step - autoencoder_accuracy: 0.0032 - autoencoder_loss: 0.1766 - classifier_accuracy: 0.0019 - classifier_loss: 0.0240 - loss: 0.4170\n",
      "Epoch 53/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 340ms/step - autoencoder_accuracy: 0.0034 - autoencoder_loss: 0.1741 - classifier_accuracy: 0.0018 - classifier_loss: 0.0240 - loss: 0.4147\n",
      "Epoch 54/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330ms/step - autoencoder_accuracy: 0.0034 - autoencoder_loss: 0.1715 - classifier_accuracy: 0.0019 - classifier_loss: 0.0241 - loss: 0.4124\n",
      "Epoch 55/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 339ms/step - autoencoder_accuracy: 0.0035 - autoencoder_loss: 0.1689 - classifier_accuracy: 0.0019 - classifier_loss: 0.0241 - loss: 0.4100\n",
      "Epoch 56/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 344ms/step - autoencoder_accuracy: 0.0036 - autoencoder_loss: 0.1662 - classifier_accuracy: 0.0019 - classifier_loss: 0.0241 - loss: 0.4077\n",
      "Epoch 57/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 336ms/step - autoencoder_accuracy: 0.0036 - autoencoder_loss: 0.1635 - classifier_accuracy: 0.0019 - classifier_loss: 0.0241 - loss: 0.4053\n",
      "Epoch 58/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 347ms/step - autoencoder_accuracy: 0.0037 - autoencoder_loss: 0.1607 - classifier_accuracy: 0.0019 - classifier_loss: 0.0241 - loss: 0.4028\n",
      "Epoch 59/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334ms/step - autoencoder_accuracy: 0.0038 - autoencoder_loss: 0.1580 - classifier_accuracy: 0.0019 - classifier_loss: 0.0242 - loss: 0.4004\n",
      "Epoch 60/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333ms/step - autoencoder_accuracy: 0.0038 - autoencoder_loss: 0.1552 - classifier_accuracy: 0.0021 - classifier_loss: 0.0242 - loss: 0.3979\n",
      "Epoch 61/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 348ms/step - autoencoder_accuracy: 0.0038 - autoencoder_loss: 0.1524 - classifier_accuracy: 0.0021 - classifier_loss: 0.0242 - loss: 0.3954\n",
      "Epoch 62/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 337ms/step - autoencoder_accuracy: 0.0038 - autoencoder_loss: 0.1496 - classifier_accuracy: 0.0022 - classifier_loss: 0.0242 - loss: 0.3930\n",
      "Epoch 63/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 324ms/step - autoencoder_accuracy: 0.0038 - autoencoder_loss: 0.1469 - classifier_accuracy: 0.0023 - classifier_loss: 0.0242 - loss: 0.3905\n",
      "Epoch 64/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 338ms/step - autoencoder_accuracy: 0.0038 - autoencoder_loss: 0.1441 - classifier_accuracy: 0.0023 - classifier_loss: 0.0242 - loss: 0.3880\n",
      "Epoch 65/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 343ms/step - autoencoder_accuracy: 0.0038 - autoencoder_loss: 0.1414 - classifier_accuracy: 0.0025 - classifier_loss: 0.0242 - loss: 0.3855\n",
      "Epoch 66/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333ms/step - autoencoder_accuracy: 0.0038 - autoencoder_loss: 0.1387 - classifier_accuracy: 0.0029 - classifier_loss: 0.0242 - loss: 0.3831\n",
      "Epoch 67/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332ms/step - autoencoder_accuracy: 0.0038 - autoencoder_loss: 0.1360 - classifier_accuracy: 0.0031 - classifier_loss: 0.0242 - loss: 0.3807\n",
      "Epoch 68/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 336ms/step - autoencoder_accuracy: 0.0038 - autoencoder_loss: 0.1333 - classifier_accuracy: 0.0034 - classifier_loss: 0.0242 - loss: 0.3783\n",
      "Epoch 69/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 336ms/step - autoencoder_accuracy: 0.0040 - autoencoder_loss: 0.1307 - classifier_accuracy: 0.0040 - classifier_loss: 0.0241 - loss: 0.3759\n",
      "Epoch 70/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 340ms/step - autoencoder_accuracy: 0.0040 - autoencoder_loss: 0.1282 - classifier_accuracy: 0.0044 - classifier_loss: 0.0241 - loss: 0.3736\n",
      "Epoch 71/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 337ms/step - autoencoder_accuracy: 0.0039 - autoencoder_loss: 0.1256 - classifier_accuracy: 0.0051 - classifier_loss: 0.0241 - loss: 0.3713\n",
      "Epoch 72/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 348ms/step - autoencoder_accuracy: 0.0039 - autoencoder_loss: 0.1232 - classifier_accuracy: 0.0063 - classifier_loss: 0.0241 - loss: 0.3690\n",
      "Epoch 73/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 350ms/step - autoencoder_accuracy: 0.0040 - autoencoder_loss: 0.1208 - classifier_accuracy: 0.0077 - classifier_loss: 0.0241 - loss: 0.3668\n",
      "Epoch 74/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 346ms/step - autoencoder_accuracy: 0.0040 - autoencoder_loss: 0.1185 - classifier_accuracy: 0.0095 - classifier_loss: 0.0240 - loss: 0.3647\n",
      "Epoch 75/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 502ms/step - autoencoder_accuracy: 0.0040 - autoencoder_loss: 0.1162 - classifier_accuracy: 0.0121 - classifier_loss: 0.0240 - loss: 0.3626\n",
      "Epoch 76/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461ms/step - autoencoder_accuracy: 0.0040 - autoencoder_loss: 0.1140 - classifier_accuracy: 0.0148 - classifier_loss: 0.0240 - loss: 0.3605\n",
      "Epoch 77/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 348ms/step - autoencoder_accuracy: 0.0039 - autoencoder_loss: 0.1119 - classifier_accuracy: 0.0188 - classifier_loss: 0.0239 - loss: 0.3585\n",
      "Epoch 78/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 341ms/step - autoencoder_accuracy: 0.0038 - autoencoder_loss: 0.1099 - classifier_accuracy: 0.0239 - classifier_loss: 0.0239 - loss: 0.3566\n",
      "Epoch 79/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 349ms/step - autoencoder_accuracy: 0.0038 - autoencoder_loss: 0.1079 - classifier_accuracy: 0.0310 - classifier_loss: 0.0239 - loss: 0.3547\n",
      "Epoch 80/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 341ms/step - autoencoder_accuracy: 0.0038 - autoencoder_loss: 0.1060 - classifier_accuracy: 0.0388 - classifier_loss: 0.0238 - loss: 0.3529\n",
      "Epoch 81/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 337ms/step - autoencoder_accuracy: 0.0039 - autoencoder_loss: 0.1042 - classifier_accuracy: 0.0476 - classifier_loss: 0.0238 - loss: 0.3512\n",
      "Epoch 82/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331ms/step - autoencoder_accuracy: 0.0039 - autoencoder_loss: 0.1025 - classifier_accuracy: 0.0575 - classifier_loss: 0.0237 - loss: 0.3495\n",
      "Epoch 83/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328ms/step - autoencoder_accuracy: 0.0040 - autoencoder_loss: 0.1009 - classifier_accuracy: 0.0679 - classifier_loss: 0.0237 - loss: 0.3479\n",
      "Epoch 84/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334ms/step - autoencoder_accuracy: 0.0039 - autoencoder_loss: 0.0993 - classifier_accuracy: 0.0795 - classifier_loss: 0.0236 - loss: 0.3463\n",
      "Epoch 85/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 343ms/step - autoencoder_accuracy: 0.0039 - autoencoder_loss: 0.0979 - classifier_accuracy: 0.0912 - classifier_loss: 0.0236 - loss: 0.3448\n",
      "Epoch 86/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 341ms/step - autoencoder_accuracy: 0.0039 - autoencoder_loss: 0.0965 - classifier_accuracy: 0.1021 - classifier_loss: 0.0235 - loss: 0.3434\n",
      "Epoch 87/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 353ms/step - autoencoder_accuracy: 0.0039 - autoencoder_loss: 0.0952 - classifier_accuracy: 0.1131 - classifier_loss: 0.0235 - loss: 0.3420\n",
      "Epoch 88/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 358ms/step - autoencoder_accuracy: 0.0039 - autoencoder_loss: 0.0939 - classifier_accuracy: 0.1233 - classifier_loss: 0.0234 - loss: 0.3407\n",
      "Epoch 89/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 351ms/step - autoencoder_accuracy: 0.0039 - autoencoder_loss: 0.0928 - classifier_accuracy: 0.1335 - classifier_loss: 0.0233 - loss: 0.3394\n",
      "Epoch 90/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 339ms/step - autoencoder_accuracy: 0.0041 - autoencoder_loss: 0.0916 - classifier_accuracy: 0.1421 - classifier_loss: 0.0233 - loss: 0.3382\n",
      "Epoch 91/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 337ms/step - autoencoder_accuracy: 0.0042 - autoencoder_loss: 0.0906 - classifier_accuracy: 0.1503 - classifier_loss: 0.0232 - loss: 0.3370\n",
      "Epoch 92/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 371ms/step - autoencoder_accuracy: 0.0045 - autoencoder_loss: 0.0896 - classifier_accuracy: 0.1569 - classifier_loss: 0.0231 - loss: 0.3358\n",
      "Epoch 93/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472ms/step - autoencoder_accuracy: 0.0046 - autoencoder_loss: 0.0887 - classifier_accuracy: 0.1622 - classifier_loss: 0.0230 - loss: 0.3348\n",
      "Epoch 94/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 437ms/step - autoencoder_accuracy: 0.0050 - autoencoder_loss: 0.0878 - classifier_accuracy: 0.1669 - classifier_loss: 0.0230 - loss: 0.3337\n",
      "Epoch 95/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 357ms/step - autoencoder_accuracy: 0.0052 - autoencoder_loss: 0.0870 - classifier_accuracy: 0.1709 - classifier_loss: 0.0229 - loss: 0.3327\n",
      "Epoch 96/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 345ms/step - autoencoder_accuracy: 0.0055 - autoencoder_loss: 0.0863 - classifier_accuracy: 0.1735 - classifier_loss: 0.0228 - loss: 0.3317\n",
      "Epoch 97/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445ms/step - autoencoder_accuracy: 0.0058 - autoencoder_loss: 0.0855 - classifier_accuracy: 0.1750 - classifier_loss: 0.0227 - loss: 0.3308\n",
      "Epoch 98/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 352ms/step - autoencoder_accuracy: 0.0062 - autoencoder_loss: 0.0849 - classifier_accuracy: 0.1756 - classifier_loss: 0.0226 - loss: 0.3299\n",
      "Epoch 99/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 339ms/step - autoencoder_accuracy: 0.0068 - autoencoder_loss: 0.0842 - classifier_accuracy: 0.1753 - classifier_loss: 0.0225 - loss: 0.3290\n",
      "Epoch 100/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 339ms/step - autoencoder_accuracy: 0.0071 - autoencoder_loss: 0.0836 - classifier_accuracy: 0.1742 - classifier_loss: 0.0224 - loss: 0.3282\n",
      "Epoch 101/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 350ms/step - autoencoder_accuracy: 0.0073 - autoencoder_loss: 0.0831 - classifier_accuracy: 0.1731 - classifier_loss: 0.0224 - loss: 0.3274\n",
      "Epoch 102/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355ms/step - autoencoder_accuracy: 0.0077 - autoencoder_loss: 0.0825 - classifier_accuracy: 0.1713 - classifier_loss: 0.0223 - loss: 0.3266\n",
      "Epoch 103/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 339ms/step - autoencoder_accuracy: 0.0080 - autoencoder_loss: 0.0820 - classifier_accuracy: 0.1693 - classifier_loss: 0.0222 - loss: 0.3259\n",
      "Epoch 104/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334ms/step - autoencoder_accuracy: 0.0080 - autoencoder_loss: 0.0816 - classifier_accuracy: 0.1674 - classifier_loss: 0.0221 - loss: 0.3251\n",
      "Epoch 105/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 341ms/step - autoencoder_accuracy: 0.0080 - autoencoder_loss: 0.0811 - classifier_accuracy: 0.1649 - classifier_loss: 0.0221 - loss: 0.3244\n",
      "Epoch 106/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 340ms/step - autoencoder_accuracy: 0.0083 - autoencoder_loss: 0.0807 - classifier_accuracy: 0.1628 - classifier_loss: 0.0220 - loss: 0.3237\n",
      "Epoch 107/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 345ms/step - autoencoder_accuracy: 0.0082 - autoencoder_loss: 0.0802 - classifier_accuracy: 0.1606 - classifier_loss: 0.0219 - loss: 0.3230\n",
      "Epoch 108/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 327ms/step - autoencoder_accuracy: 0.0083 - autoencoder_loss: 0.0798 - classifier_accuracy: 0.1591 - classifier_loss: 0.0219 - loss: 0.3224\n",
      "Epoch 109/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330ms/step - autoencoder_accuracy: 0.0083 - autoencoder_loss: 0.0794 - classifier_accuracy: 0.1566 - classifier_loss: 0.0218 - loss: 0.3217\n",
      "Epoch 110/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330ms/step - autoencoder_accuracy: 0.0083 - autoencoder_loss: 0.0790 - classifier_accuracy: 0.1547 - classifier_loss: 0.0217 - loss: 0.3211\n",
      "Epoch 111/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 344ms/step - autoencoder_accuracy: 0.0082 - autoencoder_loss: 0.0786 - classifier_accuracy: 0.1529 - classifier_loss: 0.0217 - loss: 0.3205\n",
      "Epoch 112/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 350ms/step - autoencoder_accuracy: 0.0082 - autoencoder_loss: 0.0783 - classifier_accuracy: 0.1511 - classifier_loss: 0.0217 - loss: 0.3199\n",
      "Epoch 113/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 344ms/step - autoencoder_accuracy: 0.0083 - autoencoder_loss: 0.0779 - classifier_accuracy: 0.1488 - classifier_loss: 0.0216 - loss: 0.3193\n",
      "Epoch 114/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388ms/step - autoencoder_accuracy: 0.0083 - autoencoder_loss: 0.0775 - classifier_accuracy: 0.1462 - classifier_loss: 0.0216 - loss: 0.3187\n",
      "Epoch 115/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 509ms/step - autoencoder_accuracy: 0.0084 - autoencoder_loss: 0.0772 - classifier_accuracy: 0.1437 - classifier_loss: 0.0215 - loss: 0.3181\n",
      "Epoch 116/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 464ms/step - autoencoder_accuracy: 0.0084 - autoencoder_loss: 0.0769 - classifier_accuracy: 0.1412 - classifier_loss: 0.0215 - loss: 0.3176\n",
      "Epoch 117/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 348ms/step - autoencoder_accuracy: 0.0084 - autoencoder_loss: 0.0766 - classifier_accuracy: 0.1390 - classifier_loss: 0.0214 - loss: 0.3170\n",
      "Epoch 118/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 336ms/step - autoencoder_accuracy: 0.0083 - autoencoder_loss: 0.0762 - classifier_accuracy: 0.1363 - classifier_loss: 0.0214 - loss: 0.3165\n",
      "Epoch 119/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 337ms/step - autoencoder_accuracy: 0.0083 - autoencoder_loss: 0.0759 - classifier_accuracy: 0.1338 - classifier_loss: 0.0214 - loss: 0.3159\n",
      "Epoch 120/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 339ms/step - autoencoder_accuracy: 0.0083 - autoencoder_loss: 0.0756 - classifier_accuracy: 0.1315 - classifier_loss: 0.0213 - loss: 0.3154\n",
      "Epoch 121/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334ms/step - autoencoder_accuracy: 0.0084 - autoencoder_loss: 0.0754 - classifier_accuracy: 0.1289 - classifier_loss: 0.0213 - loss: 0.3149\n",
      "Epoch 122/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 343ms/step - autoencoder_accuracy: 0.0084 - autoencoder_loss: 0.0751 - classifier_accuracy: 0.1266 - classifier_loss: 0.0212 - loss: 0.3143\n",
      "Epoch 123/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333ms/step - autoencoder_accuracy: 0.0085 - autoencoder_loss: 0.0748 - classifier_accuracy: 0.1245 - classifier_loss: 0.0212 - loss: 0.3138\n",
      "Epoch 124/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 337ms/step - autoencoder_accuracy: 0.0086 - autoencoder_loss: 0.0745 - classifier_accuracy: 0.1226 - classifier_loss: 0.0211 - loss: 0.3133\n",
      "Epoch 125/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 342ms/step - autoencoder_accuracy: 0.0086 - autoencoder_loss: 0.0743 - classifier_accuracy: 0.1205 - classifier_loss: 0.0211 - loss: 0.3128\n",
      "Epoch 126/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 336ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0740 - classifier_accuracy: 0.1188 - classifier_loss: 0.0210 - loss: 0.3123\n",
      "Epoch 127/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 338ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0738 - classifier_accuracy: 0.1171 - classifier_loss: 0.0210 - loss: 0.3118\n",
      "Epoch 128/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 338ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0736 - classifier_accuracy: 0.1159 - classifier_loss: 0.0209 - loss: 0.3113\n",
      "Epoch 129/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0733 - classifier_accuracy: 0.1145 - classifier_loss: 0.0209 - loss: 0.3108\n",
      "Epoch 130/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 341ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0731 - classifier_accuracy: 0.1138 - classifier_loss: 0.0208 - loss: 0.3103\n",
      "Epoch 131/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0729 - classifier_accuracy: 0.1129 - classifier_loss: 0.0208 - loss: 0.3098\n",
      "Epoch 132/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0727 - classifier_accuracy: 0.1126 - classifier_loss: 0.0207 - loss: 0.3093\n",
      "Epoch 133/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 356ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0725 - classifier_accuracy: 0.1125 - classifier_loss: 0.0207 - loss: 0.3088\n",
      "Epoch 134/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 370ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0723 - classifier_accuracy: 0.1126 - classifier_loss: 0.0206 - loss: 0.3084\n",
      "Epoch 135/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 352ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0721 - classifier_accuracy: 0.1128 - classifier_loss: 0.0206 - loss: 0.3079\n",
      "Epoch 136/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 347ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0719 - classifier_accuracy: 0.1132 - classifier_loss: 0.0205 - loss: 0.3075\n",
      "Epoch 137/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 343ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0717 - classifier_accuracy: 0.1140 - classifier_loss: 0.0205 - loss: 0.3070\n",
      "Epoch 138/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 349ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0715 - classifier_accuracy: 0.1147 - classifier_loss: 0.0204 - loss: 0.3065\n",
      "Epoch 139/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 361ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0713 - classifier_accuracy: 0.1153 - classifier_loss: 0.0204 - loss: 0.3061\n",
      "Epoch 140/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 365ms/step - autoencoder_accuracy: 0.0085 - autoencoder_loss: 0.0712 - classifier_accuracy: 0.1161 - classifier_loss: 0.0203 - loss: 0.3057\n",
      "Epoch 141/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 360ms/step - autoencoder_accuracy: 0.0085 - autoencoder_loss: 0.0710 - classifier_accuracy: 0.1170 - classifier_loss: 0.0203 - loss: 0.3052\n",
      "Epoch 142/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387ms/step - autoencoder_accuracy: 0.0086 - autoencoder_loss: 0.0708 - classifier_accuracy: 0.1179 - classifier_loss: 0.0202 - loss: 0.3048\n",
      "Epoch 143/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 438ms/step - autoencoder_accuracy: 0.0085 - autoencoder_loss: 0.0707 - classifier_accuracy: 0.1192 - classifier_loss: 0.0202 - loss: 0.3044\n",
      "Epoch 144/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476ms/step - autoencoder_accuracy: 0.0085 - autoencoder_loss: 0.0705 - classifier_accuracy: 0.1205 - classifier_loss: 0.0201 - loss: 0.3039\n",
      "Epoch 145/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 611ms/step - autoencoder_accuracy: 0.0086 - autoencoder_loss: 0.0704 - classifier_accuracy: 0.1221 - classifier_loss: 0.0201 - loss: 0.3035\n",
      "Epoch 146/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458ms/step - autoencoder_accuracy: 0.0086 - autoencoder_loss: 0.0702 - classifier_accuracy: 0.1237 - classifier_loss: 0.0201 - loss: 0.3031\n",
      "Epoch 147/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 467ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0701 - classifier_accuracy: 0.1252 - classifier_loss: 0.0200 - loss: 0.3027\n",
      "Epoch 148/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 352ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0699 - classifier_accuracy: 0.1268 - classifier_loss: 0.0200 - loss: 0.3022\n",
      "Epoch 149/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 358ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0698 - classifier_accuracy: 0.1285 - classifier_loss: 0.0199 - loss: 0.3018\n",
      "Epoch 150/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 465ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0696 - classifier_accuracy: 0.1303 - classifier_loss: 0.0199 - loss: 0.3014\n",
      "Epoch 151/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 504ms/step - autoencoder_accuracy: 0.0090 - autoencoder_loss: 0.0695 - classifier_accuracy: 0.1317 - classifier_loss: 0.0198 - loss: 0.3010\n",
      "Epoch 152/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 364ms/step - autoencoder_accuracy: 0.0090 - autoencoder_loss: 0.0694 - classifier_accuracy: 0.1327 - classifier_loss: 0.0198 - loss: 0.3006\n",
      "Epoch 153/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 351ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0692 - classifier_accuracy: 0.1340 - classifier_loss: 0.0197 - loss: 0.3002\n",
      "Epoch 154/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 356ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0691 - classifier_accuracy: 0.1348 - classifier_loss: 0.0197 - loss: 0.2998\n",
      "Epoch 155/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 353ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0690 - classifier_accuracy: 0.1356 - classifier_loss: 0.0196 - loss: 0.2994\n",
      "Epoch 156/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 362ms/step - autoencoder_accuracy: 0.0092 - autoencoder_loss: 0.0688 - classifier_accuracy: 0.1356 - classifier_loss: 0.0196 - loss: 0.2990\n",
      "Epoch 157/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0687 - classifier_accuracy: 0.1359 - classifier_loss: 0.0195 - loss: 0.2986\n",
      "Epoch 158/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 514ms/step - autoencoder_accuracy: 0.0092 - autoencoder_loss: 0.0686 - classifier_accuracy: 0.1356 - classifier_loss: 0.0195 - loss: 0.2982\n",
      "Epoch 159/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0685 - classifier_accuracy: 0.1353 - classifier_loss: 0.0194 - loss: 0.2978\n",
      "Epoch 160/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 345ms/step - autoencoder_accuracy: 0.0092 - autoencoder_loss: 0.0684 - classifier_accuracy: 0.1346 - classifier_loss: 0.0194 - loss: 0.2974\n",
      "Epoch 161/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 352ms/step - autoencoder_accuracy: 0.0092 - autoencoder_loss: 0.0682 - classifier_accuracy: 0.1337 - classifier_loss: 0.0193 - loss: 0.2970\n",
      "Epoch 162/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0681 - classifier_accuracy: 0.1325 - classifier_loss: 0.0193 - loss: 0.2966\n",
      "Epoch 163/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0680 - classifier_accuracy: 0.1315 - classifier_loss: 0.0192 - loss: 0.2962\n",
      "Epoch 164/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0679 - classifier_accuracy: 0.1304 - classifier_loss: 0.0192 - loss: 0.2958\n",
      "Epoch 165/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 357ms/step - autoencoder_accuracy: 0.0095 - autoencoder_loss: 0.0678 - classifier_accuracy: 0.1286 - classifier_loss: 0.0191 - loss: 0.2954\n",
      "Epoch 166/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0677 - classifier_accuracy: 0.1271 - classifier_loss: 0.0191 - loss: 0.2951\n",
      "Epoch 167/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 353ms/step - autoencoder_accuracy: 0.0095 - autoencoder_loss: 0.0676 - classifier_accuracy: 0.1255 - classifier_loss: 0.0190 - loss: 0.2947\n",
      "Epoch 168/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 345ms/step - autoencoder_accuracy: 0.0096 - autoencoder_loss: 0.0674 - classifier_accuracy: 0.1241 - classifier_loss: 0.0190 - loss: 0.2943\n",
      "Epoch 169/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376ms/step - autoencoder_accuracy: 0.0097 - autoencoder_loss: 0.0673 - classifier_accuracy: 0.1227 - classifier_loss: 0.0190 - loss: 0.2939\n",
      "Epoch 170/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 364ms/step - autoencoder_accuracy: 0.0098 - autoencoder_loss: 0.0672 - classifier_accuracy: 0.1212 - classifier_loss: 0.0189 - loss: 0.2936\n",
      "Epoch 171/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 347ms/step - autoencoder_accuracy: 0.0099 - autoencoder_loss: 0.0671 - classifier_accuracy: 0.1198 - classifier_loss: 0.0189 - loss: 0.2932\n",
      "Epoch 172/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 358ms/step - autoencoder_accuracy: 0.0098 - autoencoder_loss: 0.0670 - classifier_accuracy: 0.1189 - classifier_loss: 0.0189 - loss: 0.2928\n",
      "Epoch 173/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 369ms/step - autoencoder_accuracy: 0.0099 - autoencoder_loss: 0.0669 - classifier_accuracy: 0.1180 - classifier_loss: 0.0188 - loss: 0.2924\n",
      "Epoch 174/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 347ms/step - autoencoder_accuracy: 0.0097 - autoencoder_loss: 0.0668 - classifier_accuracy: 0.1173 - classifier_loss: 0.0188 - loss: 0.2921\n",
      "Epoch 175/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 353ms/step - autoencoder_accuracy: 0.0099 - autoencoder_loss: 0.0667 - classifier_accuracy: 0.1174 - classifier_loss: 0.0188 - loss: 0.2917\n",
      "Epoch 176/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403ms/step - autoencoder_accuracy: 0.0099 - autoencoder_loss: 0.0666 - classifier_accuracy: 0.1177 - classifier_loss: 0.0187 - loss: 0.2914\n",
      "Epoch 177/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386ms/step - autoencoder_accuracy: 0.0102 - autoencoder_loss: 0.0664 - classifier_accuracy: 0.1179 - classifier_loss: 0.0187 - loss: 0.2910\n",
      "Epoch 178/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402ms/step - autoencoder_accuracy: 0.0103 - autoencoder_loss: 0.0663 - classifier_accuracy: 0.1183 - classifier_loss: 0.0187 - loss: 0.2907\n",
      "Epoch 179/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376ms/step - autoencoder_accuracy: 0.0104 - autoencoder_loss: 0.0662 - classifier_accuracy: 0.1189 - classifier_loss: 0.0187 - loss: 0.2903\n",
      "Epoch 180/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366ms/step - autoencoder_accuracy: 0.0105 - autoencoder_loss: 0.0662 - classifier_accuracy: 0.1196 - classifier_loss: 0.0186 - loss: 0.2900\n",
      "Epoch 181/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 427ms/step - autoencoder_accuracy: 0.0105 - autoencoder_loss: 0.0661 - classifier_accuracy: 0.1200 - classifier_loss: 0.0186 - loss: 0.2896\n",
      "Epoch 182/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388ms/step - autoencoder_accuracy: 0.0105 - autoencoder_loss: 0.0660 - classifier_accuracy: 0.1202 - classifier_loss: 0.0186 - loss: 0.2893\n",
      "Epoch 183/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490ms/step - autoencoder_accuracy: 0.0106 - autoencoder_loss: 0.0659 - classifier_accuracy: 0.1203 - classifier_loss: 0.0186 - loss: 0.2890\n",
      "Epoch 184/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 358ms/step - autoencoder_accuracy: 0.0109 - autoencoder_loss: 0.0658 - classifier_accuracy: 0.1202 - classifier_loss: 0.0185 - loss: 0.2886\n",
      "Epoch 185/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 412ms/step - autoencoder_accuracy: 0.0110 - autoencoder_loss: 0.0657 - classifier_accuracy: 0.1196 - classifier_loss: 0.0185 - loss: 0.2883\n",
      "Epoch 186/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 360ms/step - autoencoder_accuracy: 0.0113 - autoencoder_loss: 0.0656 - classifier_accuracy: 0.1191 - classifier_loss: 0.0185 - loss: 0.2880\n",
      "Epoch 187/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 360ms/step - autoencoder_accuracy: 0.0114 - autoencoder_loss: 0.0655 - classifier_accuracy: 0.1185 - classifier_loss: 0.0184 - loss: 0.2876\n",
      "Epoch 188/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 364ms/step - autoencoder_accuracy: 0.0115 - autoencoder_loss: 0.0655 - classifier_accuracy: 0.1178 - classifier_loss: 0.0184 - loss: 0.2873\n",
      "Epoch 189/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 370ms/step - autoencoder_accuracy: 0.0115 - autoencoder_loss: 0.0654 - classifier_accuracy: 0.1170 - classifier_loss: 0.0184 - loss: 0.2869\n",
      "Epoch 190/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473ms/step - autoencoder_accuracy: 0.0115 - autoencoder_loss: 0.0653 - classifier_accuracy: 0.1160 - classifier_loss: 0.0184 - loss: 0.2866\n",
      "Epoch 191/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 440ms/step - autoencoder_accuracy: 0.0114 - autoencoder_loss: 0.0652 - classifier_accuracy: 0.1151 - classifier_loss: 0.0183 - loss: 0.2863\n",
      "Epoch 192/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494ms/step - autoencoder_accuracy: 0.0111 - autoencoder_loss: 0.0651 - classifier_accuracy: 0.1143 - classifier_loss: 0.0183 - loss: 0.2859\n",
      "Epoch 193/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 352ms/step - autoencoder_accuracy: 0.0109 - autoencoder_loss: 0.0650 - classifier_accuracy: 0.1138 - classifier_loss: 0.0183 - loss: 0.2856\n",
      "Epoch 194/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 347ms/step - autoencoder_accuracy: 0.0108 - autoencoder_loss: 0.0649 - classifier_accuracy: 0.1133 - classifier_loss: 0.0183 - loss: 0.2853\n",
      "Epoch 195/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 422ms/step - autoencoder_accuracy: 0.0107 - autoencoder_loss: 0.0648 - classifier_accuracy: 0.1127 - classifier_loss: 0.0183 - loss: 0.2849\n",
      "Epoch 196/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 549ms/step - autoencoder_accuracy: 0.0106 - autoencoder_loss: 0.0647 - classifier_accuracy: 0.1122 - classifier_loss: 0.0182 - loss: 0.2846\n",
      "Epoch 197/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 504ms/step - autoencoder_accuracy: 0.0106 - autoencoder_loss: 0.0646 - classifier_accuracy: 0.1116 - classifier_loss: 0.0182 - loss: 0.2843\n",
      "Epoch 198/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452ms/step - autoencoder_accuracy: 0.0106 - autoencoder_loss: 0.0645 - classifier_accuracy: 0.1114 - classifier_loss: 0.0182 - loss: 0.2840\n",
      "Epoch 199/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 572ms/step - autoencoder_accuracy: 0.0107 - autoencoder_loss: 0.0644 - classifier_accuracy: 0.1107 - classifier_loss: 0.0182 - loss: 0.2836\n",
      "Epoch 200/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476ms/step - autoencoder_accuracy: 0.0108 - autoencoder_loss: 0.0644 - classifier_accuracy: 0.1098 - classifier_loss: 0.0182 - loss: 0.2833\n",
      "Epoch 201/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454ms/step - autoencoder_accuracy: 0.0109 - autoencoder_loss: 0.0643 - classifier_accuracy: 0.1092 - classifier_loss: 0.0182 - loss: 0.2830\n",
      "Epoch 202/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 440ms/step - autoencoder_accuracy: 0.0109 - autoencoder_loss: 0.0642 - classifier_accuracy: 0.1086 - classifier_loss: 0.0181 - loss: 0.2827\n",
      "Epoch 203/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492ms/step - autoencoder_accuracy: 0.0112 - autoencoder_loss: 0.0641 - classifier_accuracy: 0.1082 - classifier_loss: 0.0181 - loss: 0.2824\n",
      "Epoch 204/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 528ms/step - autoencoder_accuracy: 0.0113 - autoencoder_loss: 0.0640 - classifier_accuracy: 0.1076 - classifier_loss: 0.0181 - loss: 0.2820\n",
      "Epoch 205/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 527ms/step - autoencoder_accuracy: 0.0114 - autoencoder_loss: 0.0639 - classifier_accuracy: 0.1069 - classifier_loss: 0.0181 - loss: 0.2817\n",
      "Epoch 206/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 469ms/step - autoencoder_accuracy: 0.0114 - autoencoder_loss: 0.0638 - classifier_accuracy: 0.1063 - classifier_loss: 0.0181 - loss: 0.2814\n",
      "Epoch 207/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407ms/step - autoencoder_accuracy: 0.0114 - autoencoder_loss: 0.0637 - classifier_accuracy: 0.1057 - classifier_loss: 0.0180 - loss: 0.2810\n",
      "Epoch 208/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 554ms/step - autoencoder_accuracy: 0.0114 - autoencoder_loss: 0.0637 - classifier_accuracy: 0.1050 - classifier_loss: 0.0180 - loss: 0.2807\n",
      "Epoch 209/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 427ms/step - autoencoder_accuracy: 0.0113 - autoencoder_loss: 0.0636 - classifier_accuracy: 0.1043 - classifier_loss: 0.0180 - loss: 0.2804\n",
      "Epoch 210/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398ms/step - autoencoder_accuracy: 0.0113 - autoencoder_loss: 0.0635 - classifier_accuracy: 0.1041 - classifier_loss: 0.0179 - loss: 0.2800\n",
      "Epoch 211/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 337ms/step - autoencoder_accuracy: 0.0112 - autoencoder_loss: 0.0634 - classifier_accuracy: 0.1042 - classifier_loss: 0.0179 - loss: 0.2797\n",
      "Epoch 212/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366ms/step - autoencoder_accuracy: 0.0110 - autoencoder_loss: 0.0633 - classifier_accuracy: 0.1043 - classifier_loss: 0.0179 - loss: 0.2794\n",
      "Epoch 213/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 442ms/step - autoencoder_accuracy: 0.0110 - autoencoder_loss: 0.0632 - classifier_accuracy: 0.1046 - classifier_loss: 0.0178 - loss: 0.2790\n",
      "Epoch 214/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479ms/step - autoencoder_accuracy: 0.0108 - autoencoder_loss: 0.0631 - classifier_accuracy: 0.1053 - classifier_loss: 0.0178 - loss: 0.2787\n",
      "Epoch 215/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445ms/step - autoencoder_accuracy: 0.0106 - autoencoder_loss: 0.0630 - classifier_accuracy: 0.1064 - classifier_loss: 0.0178 - loss: 0.2783\n",
      "Epoch 216/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 524ms/step - autoencoder_accuracy: 0.0104 - autoencoder_loss: 0.0629 - classifier_accuracy: 0.1072 - classifier_loss: 0.0178 - loss: 0.2780\n",
      "Epoch 217/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 514ms/step - autoencoder_accuracy: 0.0105 - autoencoder_loss: 0.0628 - classifier_accuracy: 0.1081 - classifier_loss: 0.0177 - loss: 0.2777\n",
      "Epoch 218/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 513ms/step - autoencoder_accuracy: 0.0104 - autoencoder_loss: 0.0627 - classifier_accuracy: 0.1093 - classifier_loss: 0.0177 - loss: 0.2773\n",
      "Epoch 219/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 353ms/step - autoencoder_accuracy: 0.0104 - autoencoder_loss: 0.0626 - classifier_accuracy: 0.1104 - classifier_loss: 0.0177 - loss: 0.2770\n",
      "Epoch 220/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 356ms/step - autoencoder_accuracy: 0.0104 - autoencoder_loss: 0.0625 - classifier_accuracy: 0.1116 - classifier_loss: 0.0176 - loss: 0.2766\n",
      "Epoch 221/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457ms/step - autoencoder_accuracy: 0.0104 - autoencoder_loss: 0.0625 - classifier_accuracy: 0.1128 - classifier_loss: 0.0176 - loss: 0.2763\n",
      "Epoch 222/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451ms/step - autoencoder_accuracy: 0.0103 - autoencoder_loss: 0.0624 - classifier_accuracy: 0.1141 - classifier_loss: 0.0175 - loss: 0.2759\n",
      "Epoch 223/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 435ms/step - autoencoder_accuracy: 0.0103 - autoencoder_loss: 0.0623 - classifier_accuracy: 0.1153 - classifier_loss: 0.0175 - loss: 0.2756\n",
      "Epoch 224/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384ms/step - autoencoder_accuracy: 0.0103 - autoencoder_loss: 0.0622 - classifier_accuracy: 0.1162 - classifier_loss: 0.0175 - loss: 0.2753\n",
      "Epoch 225/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 367ms/step - autoencoder_accuracy: 0.0102 - autoencoder_loss: 0.0621 - classifier_accuracy: 0.1172 - classifier_loss: 0.0174 - loss: 0.2749\n",
      "Epoch 226/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 515ms/step - autoencoder_accuracy: 0.0100 - autoencoder_loss: 0.0620 - classifier_accuracy: 0.1179 - classifier_loss: 0.0174 - loss: 0.2746\n",
      "Epoch 227/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 437ms/step - autoencoder_accuracy: 0.0099 - autoencoder_loss: 0.0619 - classifier_accuracy: 0.1190 - classifier_loss: 0.0173 - loss: 0.2742\n",
      "Epoch 228/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 364ms/step - autoencoder_accuracy: 0.0098 - autoencoder_loss: 0.0619 - classifier_accuracy: 0.1202 - classifier_loss: 0.0173 - loss: 0.2739\n",
      "Epoch 229/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397ms/step - autoencoder_accuracy: 0.0097 - autoencoder_loss: 0.0618 - classifier_accuracy: 0.1212 - classifier_loss: 0.0173 - loss: 0.2736\n",
      "Epoch 230/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0617 - classifier_accuracy: 0.1222 - classifier_loss: 0.0172 - loss: 0.2732\n",
      "Epoch 231/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 362ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0616 - classifier_accuracy: 0.1236 - classifier_loss: 0.0172 - loss: 0.2729\n",
      "Epoch 232/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0615 - classifier_accuracy: 0.1249 - classifier_loss: 0.0171 - loss: 0.2725\n",
      "Epoch 233/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 560ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0614 - classifier_accuracy: 0.1259 - classifier_loss: 0.0171 - loss: 0.2722\n",
      "Epoch 234/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 527ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0614 - classifier_accuracy: 0.1273 - classifier_loss: 0.0171 - loss: 0.2719\n",
      "Epoch 235/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 586ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0613 - classifier_accuracy: 0.1287 - classifier_loss: 0.0170 - loss: 0.2715\n",
      "Epoch 236/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 516ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0612 - classifier_accuracy: 0.1299 - classifier_loss: 0.0170 - loss: 0.2712\n",
      "Epoch 237/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 506ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0611 - classifier_accuracy: 0.1313 - classifier_loss: 0.0169 - loss: 0.2709\n",
      "Epoch 238/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0610 - classifier_accuracy: 0.1324 - classifier_loss: 0.0169 - loss: 0.2706\n",
      "Epoch 239/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0610 - classifier_accuracy: 0.1338 - classifier_loss: 0.0169 - loss: 0.2702\n",
      "Epoch 240/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0609 - classifier_accuracy: 0.1348 - classifier_loss: 0.0168 - loss: 0.2699\n",
      "Epoch 241/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 548ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0608 - classifier_accuracy: 0.1358 - classifier_loss: 0.0168 - loss: 0.2696\n",
      "Epoch 242/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 507ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0607 - classifier_accuracy: 0.1368 - classifier_loss: 0.0167 - loss: 0.2692\n",
      "Epoch 243/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 592ms/step - autoencoder_accuracy: 0.0086 - autoencoder_loss: 0.0607 - classifier_accuracy: 0.1376 - classifier_loss: 0.0167 - loss: 0.2689\n",
      "Epoch 244/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 521ms/step - autoencoder_accuracy: 0.0086 - autoencoder_loss: 0.0606 - classifier_accuracy: 0.1383 - classifier_loss: 0.0167 - loss: 0.2686\n",
      "Epoch 245/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485ms/step - autoencoder_accuracy: 0.0086 - autoencoder_loss: 0.0605 - classifier_accuracy: 0.1392 - classifier_loss: 0.0166 - loss: 0.2683\n",
      "Epoch 246/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step - autoencoder_accuracy: 0.0084 - autoencoder_loss: 0.0604 - classifier_accuracy: 0.1403 - classifier_loss: 0.0166 - loss: 0.2679\n",
      "Epoch 247/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 535ms/step - autoencoder_accuracy: 0.0084 - autoencoder_loss: 0.0604 - classifier_accuracy: 0.1412 - classifier_loss: 0.0166 - loss: 0.2676\n",
      "Epoch 248/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 616ms/step - autoencoder_accuracy: 0.0083 - autoencoder_loss: 0.0603 - classifier_accuracy: 0.1426 - classifier_loss: 0.0165 - loss: 0.2673\n",
      "Epoch 249/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 634ms/step - autoencoder_accuracy: 0.0082 - autoencoder_loss: 0.0602 - classifier_accuracy: 0.1440 - classifier_loss: 0.0165 - loss: 0.2670\n",
      "Epoch 250/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 524ms/step - autoencoder_accuracy: 0.0081 - autoencoder_loss: 0.0601 - classifier_accuracy: 0.1454 - classifier_loss: 0.0164 - loss: 0.2666\n",
      "Epoch 251/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 648ms/step - autoencoder_accuracy: 0.0081 - autoencoder_loss: 0.0601 - classifier_accuracy: 0.1469 - classifier_loss: 0.0164 - loss: 0.2663\n",
      "Epoch 252/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 581ms/step - autoencoder_accuracy: 0.0081 - autoencoder_loss: 0.0600 - classifier_accuracy: 0.1482 - classifier_loss: 0.0164 - loss: 0.2660\n",
      "Epoch 253/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 519ms/step - autoencoder_accuracy: 0.0080 - autoencoder_loss: 0.0599 - classifier_accuracy: 0.1492 - classifier_loss: 0.0163 - loss: 0.2657\n",
      "Epoch 254/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496ms/step - autoencoder_accuracy: 0.0080 - autoencoder_loss: 0.0599 - classifier_accuracy: 0.1505 - classifier_loss: 0.0163 - loss: 0.2654\n",
      "Epoch 255/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 519ms/step - autoencoder_accuracy: 0.0080 - autoencoder_loss: 0.0598 - classifier_accuracy: 0.1514 - classifier_loss: 0.0163 - loss: 0.2651\n",
      "Epoch 256/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 549ms/step - autoencoder_accuracy: 0.0079 - autoencoder_loss: 0.0597 - classifier_accuracy: 0.1522 - classifier_loss: 0.0162 - loss: 0.2647\n",
      "Epoch 257/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 681ms/step - autoencoder_accuracy: 0.0079 - autoencoder_loss: 0.0597 - classifier_accuracy: 0.1530 - classifier_loss: 0.0162 - loss: 0.2644\n",
      "Epoch 258/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 660ms/step - autoencoder_accuracy: 0.0078 - autoencoder_loss: 0.0596 - classifier_accuracy: 0.1535 - classifier_loss: 0.0161 - loss: 0.2641\n",
      "Epoch 259/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 649ms/step - autoencoder_accuracy: 0.0079 - autoencoder_loss: 0.0595 - classifier_accuracy: 0.1539 - classifier_loss: 0.0161 - loss: 0.2638\n",
      "Epoch 260/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 620ms/step - autoencoder_accuracy: 0.0079 - autoencoder_loss: 0.0594 - classifier_accuracy: 0.1542 - classifier_loss: 0.0161 - loss: 0.2635\n",
      "Epoch 261/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 529ms/step - autoencoder_accuracy: 0.0078 - autoencoder_loss: 0.0594 - classifier_accuracy: 0.1547 - classifier_loss: 0.0160 - loss: 0.2631\n",
      "Epoch 262/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 368ms/step - autoencoder_accuracy: 0.0078 - autoencoder_loss: 0.0593 - classifier_accuracy: 0.1547 - classifier_loss: 0.0160 - loss: 0.2628\n",
      "Epoch 263/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 514ms/step - autoencoder_accuracy: 0.0078 - autoencoder_loss: 0.0592 - classifier_accuracy: 0.1547 - classifier_loss: 0.0159 - loss: 0.2625\n",
      "Epoch 264/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 405ms/step - autoencoder_accuracy: 0.0078 - autoencoder_loss: 0.0592 - classifier_accuracy: 0.1551 - classifier_loss: 0.0159 - loss: 0.2622\n",
      "Epoch 265/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379ms/step - autoencoder_accuracy: 0.0078 - autoencoder_loss: 0.0591 - classifier_accuracy: 0.1551 - classifier_loss: 0.0159 - loss: 0.2619\n",
      "Epoch 266/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382ms/step - autoencoder_accuracy: 0.0077 - autoencoder_loss: 0.0590 - classifier_accuracy: 0.1550 - classifier_loss: 0.0158 - loss: 0.2616\n",
      "Epoch 267/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393ms/step - autoencoder_accuracy: 0.0079 - autoencoder_loss: 0.0590 - classifier_accuracy: 0.1551 - classifier_loss: 0.0158 - loss: 0.2613\n",
      "Epoch 268/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 511ms/step - autoencoder_accuracy: 0.0080 - autoencoder_loss: 0.0589 - classifier_accuracy: 0.1551 - classifier_loss: 0.0158 - loss: 0.2609\n",
      "Epoch 269/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493ms/step - autoencoder_accuracy: 0.0080 - autoencoder_loss: 0.0588 - classifier_accuracy: 0.1551 - classifier_loss: 0.0157 - loss: 0.2606\n",
      "Epoch 270/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476ms/step - autoencoder_accuracy: 0.0079 - autoencoder_loss: 0.0588 - classifier_accuracy: 0.1552 - classifier_loss: 0.0157 - loss: 0.2603\n",
      "Epoch 271/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481ms/step - autoencoder_accuracy: 0.0078 - autoencoder_loss: 0.0587 - classifier_accuracy: 0.1553 - classifier_loss: 0.0156 - loss: 0.2600\n",
      "Epoch 272/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393ms/step - autoencoder_accuracy: 0.0079 - autoencoder_loss: 0.0586 - classifier_accuracy: 0.1553 - classifier_loss: 0.0156 - loss: 0.2597\n",
      "Epoch 273/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - autoencoder_accuracy: 0.0079 - autoencoder_loss: 0.0585 - classifier_accuracy: 0.1552 - classifier_loss: 0.0155 - loss: 0.2593\n",
      "Epoch 274/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492ms/step - autoencoder_accuracy: 0.0079 - autoencoder_loss: 0.0585 - classifier_accuracy: 0.1552 - classifier_loss: 0.0155 - loss: 0.2590\n",
      "Epoch 275/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455ms/step - autoencoder_accuracy: 0.0078 - autoencoder_loss: 0.0584 - classifier_accuracy: 0.1553 - classifier_loss: 0.0155 - loss: 0.2587\n",
      "Epoch 276/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473ms/step - autoencoder_accuracy: 0.0079 - autoencoder_loss: 0.0583 - classifier_accuracy: 0.1556 - classifier_loss: 0.0154 - loss: 0.2584\n",
      "Epoch 277/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484ms/step - autoencoder_accuracy: 0.0079 - autoencoder_loss: 0.0583 - classifier_accuracy: 0.1559 - classifier_loss: 0.0154 - loss: 0.2581\n",
      "Epoch 278/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 505ms/step - autoencoder_accuracy: 0.0080 - autoencoder_loss: 0.0582 - classifier_accuracy: 0.1562 - classifier_loss: 0.0154 - loss: 0.2578\n",
      "Epoch 279/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 627ms/step - autoencoder_accuracy: 0.0080 - autoencoder_loss: 0.0581 - classifier_accuracy: 0.1567 - classifier_loss: 0.0153 - loss: 0.2574\n",
      "Epoch 280/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 358ms/step - autoencoder_accuracy: 0.0080 - autoencoder_loss: 0.0580 - classifier_accuracy: 0.1570 - classifier_loss: 0.0153 - loss: 0.2571\n",
      "Epoch 281/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451ms/step - autoencoder_accuracy: 0.0081 - autoencoder_loss: 0.0580 - classifier_accuracy: 0.1572 - classifier_loss: 0.0153 - loss: 0.2568\n",
      "Epoch 282/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466ms/step - autoencoder_accuracy: 0.0081 - autoencoder_loss: 0.0579 - classifier_accuracy: 0.1572 - classifier_loss: 0.0152 - loss: 0.2565\n",
      "Epoch 283/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384ms/step - autoencoder_accuracy: 0.0082 - autoencoder_loss: 0.0578 - classifier_accuracy: 0.1574 - classifier_loss: 0.0152 - loss: 0.2562\n",
      "Epoch 284/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388ms/step - autoencoder_accuracy: 0.0082 - autoencoder_loss: 0.0577 - classifier_accuracy: 0.1578 - classifier_loss: 0.0152 - loss: 0.2559\n",
      "Epoch 285/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377ms/step - autoencoder_accuracy: 0.0082 - autoencoder_loss: 0.0577 - classifier_accuracy: 0.1577 - classifier_loss: 0.0151 - loss: 0.2556\n",
      "Epoch 286/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355ms/step - autoencoder_accuracy: 0.0083 - autoencoder_loss: 0.0576 - classifier_accuracy: 0.1576 - classifier_loss: 0.0151 - loss: 0.2553\n",
      "Epoch 287/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457ms/step - autoencoder_accuracy: 0.0084 - autoencoder_loss: 0.0575 - classifier_accuracy: 0.1574 - classifier_loss: 0.0151 - loss: 0.2550\n",
      "Epoch 288/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 522ms/step - autoencoder_accuracy: 0.0085 - autoencoder_loss: 0.0575 - classifier_accuracy: 0.1571 - classifier_loss: 0.0150 - loss: 0.2547\n",
      "Epoch 289/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 536ms/step - autoencoder_accuracy: 0.0084 - autoencoder_loss: 0.0574 - classifier_accuracy: 0.1565 - classifier_loss: 0.0150 - loss: 0.2544\n",
      "Epoch 290/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448ms/step - autoencoder_accuracy: 0.0084 - autoencoder_loss: 0.0573 - classifier_accuracy: 0.1559 - classifier_loss: 0.0150 - loss: 0.2541\n",
      "Epoch 291/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0572 - classifier_accuracy: 0.1555 - classifier_loss: 0.0149 - loss: 0.2537\n",
      "Epoch 292/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0572 - classifier_accuracy: 0.1549 - classifier_loss: 0.0149 - loss: 0.2534\n",
      "Epoch 293/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0571 - classifier_accuracy: 0.1541 - classifier_loss: 0.0148 - loss: 0.2531\n",
      "Epoch 294/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0570 - classifier_accuracy: 0.1533 - classifier_loss: 0.0148 - loss: 0.2528\n",
      "Epoch 295/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0570 - classifier_accuracy: 0.1527 - classifier_loss: 0.0148 - loss: 0.2525\n",
      "Epoch 296/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 440ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0569 - classifier_accuracy: 0.1523 - classifier_loss: 0.0147 - loss: 0.2522\n",
      "Epoch 297/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0568 - classifier_accuracy: 0.1517 - classifier_loss: 0.0147 - loss: 0.2519\n",
      "Epoch 298/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0568 - classifier_accuracy: 0.1512 - classifier_loss: 0.0146 - loss: 0.2516\n",
      "Epoch 299/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 357ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0567 - classifier_accuracy: 0.1507 - classifier_loss: 0.0146 - loss: 0.2513\n",
      "Epoch 300/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 344ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0566 - classifier_accuracy: 0.1505 - classifier_loss: 0.0146 - loss: 0.2509\n",
      "Epoch 301/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 347ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0566 - classifier_accuracy: 0.1503 - classifier_loss: 0.0145 - loss: 0.2506\n",
      "Epoch 302/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0565 - classifier_accuracy: 0.1502 - classifier_loss: 0.0145 - loss: 0.2503\n",
      "Epoch 303/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 371ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0564 - classifier_accuracy: 0.1499 - classifier_loss: 0.0144 - loss: 0.2500\n",
      "Epoch 304/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 367ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0563 - classifier_accuracy: 0.1499 - classifier_loss: 0.0144 - loss: 0.2497\n",
      "Epoch 305/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 435ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0563 - classifier_accuracy: 0.1500 - classifier_loss: 0.0143 - loss: 0.2494\n",
      "Epoch 306/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0562 - classifier_accuracy: 0.1500 - classifier_loss: 0.0143 - loss: 0.2491\n",
      "Epoch 307/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0562 - classifier_accuracy: 0.1498 - classifier_loss: 0.0143 - loss: 0.2488\n",
      "Epoch 308/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 360ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0561 - classifier_accuracy: 0.1492 - classifier_loss: 0.0142 - loss: 0.2485\n",
      "Epoch 309/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0560 - classifier_accuracy: 0.1489 - classifier_loss: 0.0142 - loss: 0.2482\n",
      "Epoch 310/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 341ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0560 - classifier_accuracy: 0.1484 - classifier_loss: 0.0141 - loss: 0.2478\n",
      "Epoch 311/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 365ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0559 - classifier_accuracy: 0.1477 - classifier_loss: 0.0141 - loss: 0.2475\n",
      "Epoch 312/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0558 - classifier_accuracy: 0.1468 - classifier_loss: 0.0140 - loss: 0.2472\n",
      "Epoch 313/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0558 - classifier_accuracy: 0.1460 - classifier_loss: 0.0140 - loss: 0.2469\n",
      "Epoch 314/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0557 - classifier_accuracy: 0.1452 - classifier_loss: 0.0139 - loss: 0.2466\n",
      "Epoch 315/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 504ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0557 - classifier_accuracy: 0.1444 - classifier_loss: 0.0139 - loss: 0.2463\n",
      "Epoch 316/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402ms/step - autoencoder_accuracy: 0.0090 - autoencoder_loss: 0.0556 - classifier_accuracy: 0.1435 - classifier_loss: 0.0138 - loss: 0.2460\n",
      "Epoch 317/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384ms/step - autoencoder_accuracy: 0.0090 - autoencoder_loss: 0.0555 - classifier_accuracy: 0.1427 - classifier_loss: 0.0138 - loss: 0.2456\n",
      "Epoch 318/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0555 - classifier_accuracy: 0.1421 - classifier_loss: 0.0137 - loss: 0.2453\n",
      "Epoch 319/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382ms/step - autoencoder_accuracy: 0.0090 - autoencoder_loss: 0.0554 - classifier_accuracy: 0.1414 - classifier_loss: 0.0137 - loss: 0.2450\n",
      "Epoch 320/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0554 - classifier_accuracy: 0.1408 - classifier_loss: 0.0136 - loss: 0.2447\n",
      "Epoch 321/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460ms/step - autoencoder_accuracy: 0.0092 - autoencoder_loss: 0.0553 - classifier_accuracy: 0.1402 - classifier_loss: 0.0136 - loss: 0.2444\n",
      "Epoch 322/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 426ms/step - autoencoder_accuracy: 0.0092 - autoencoder_loss: 0.0552 - classifier_accuracy: 0.1398 - classifier_loss: 0.0135 - loss: 0.2441\n",
      "Epoch 323/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 348ms/step - autoencoder_accuracy: 0.0092 - autoencoder_loss: 0.0552 - classifier_accuracy: 0.1393 - classifier_loss: 0.0135 - loss: 0.2438\n",
      "Epoch 324/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 370ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0551 - classifier_accuracy: 0.1389 - classifier_loss: 0.0134 - loss: 0.2434\n",
      "Epoch 325/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0550 - classifier_accuracy: 0.1384 - classifier_loss: 0.0134 - loss: 0.2431\n",
      "Epoch 326/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 351ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0550 - classifier_accuracy: 0.1378 - classifier_loss: 0.0133 - loss: 0.2428\n",
      "Epoch 327/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 363ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0549 - classifier_accuracy: 0.1370 - classifier_loss: 0.0133 - loss: 0.2425\n",
      "Epoch 328/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 361ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0548 - classifier_accuracy: 0.1364 - classifier_loss: 0.0132 - loss: 0.2422\n",
      "Epoch 329/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0548 - classifier_accuracy: 0.1357 - classifier_loss: 0.0132 - loss: 0.2419\n",
      "Epoch 330/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0547 - classifier_accuracy: 0.1348 - classifier_loss: 0.0131 - loss: 0.2416\n",
      "Epoch 331/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0547 - classifier_accuracy: 0.1340 - classifier_loss: 0.0131 - loss: 0.2413\n",
      "Epoch 332/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 356ms/step - autoencoder_accuracy: 0.0095 - autoencoder_loss: 0.0546 - classifier_accuracy: 0.1332 - classifier_loss: 0.0130 - loss: 0.2409\n",
      "Epoch 333/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 345ms/step - autoencoder_accuracy: 0.0095 - autoencoder_loss: 0.0545 - classifier_accuracy: 0.1325 - classifier_loss: 0.0130 - loss: 0.2406\n",
      "Epoch 334/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 412ms/step - autoencoder_accuracy: 0.0095 - autoencoder_loss: 0.0545 - classifier_accuracy: 0.1316 - classifier_loss: 0.0129 - loss: 0.2403\n",
      "Epoch 335/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 423ms/step - autoencoder_accuracy: 0.0095 - autoencoder_loss: 0.0544 - classifier_accuracy: 0.1308 - classifier_loss: 0.0129 - loss: 0.2400\n",
      "Epoch 336/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 471ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0544 - classifier_accuracy: 0.1302 - classifier_loss: 0.0128 - loss: 0.2397\n",
      "Epoch 337/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0543 - classifier_accuracy: 0.1295 - classifier_loss: 0.0128 - loss: 0.2394\n",
      "Epoch 338/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477ms/step - autoencoder_accuracy: 0.0095 - autoencoder_loss: 0.0542 - classifier_accuracy: 0.1290 - classifier_loss: 0.0127 - loss: 0.2391\n",
      "Epoch 339/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 567ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0542 - classifier_accuracy: 0.1285 - classifier_loss: 0.0127 - loss: 0.2388\n",
      "Epoch 340/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 541ms/step - autoencoder_accuracy: 0.0096 - autoencoder_loss: 0.0541 - classifier_accuracy: 0.1280 - classifier_loss: 0.0126 - loss: 0.2385\n",
      "Epoch 341/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 521ms/step - autoencoder_accuracy: 0.0096 - autoencoder_loss: 0.0540 - classifier_accuracy: 0.1276 - classifier_loss: 0.0126 - loss: 0.2382\n",
      "Epoch 342/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 519ms/step - autoencoder_accuracy: 0.0097 - autoencoder_loss: 0.0540 - classifier_accuracy: 0.1270 - classifier_loss: 0.0125 - loss: 0.2379\n",
      "Epoch 343/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486ms/step - autoencoder_accuracy: 0.0098 - autoencoder_loss: 0.0539 - classifier_accuracy: 0.1263 - classifier_loss: 0.0125 - loss: 0.2376\n",
      "Epoch 344/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 421ms/step - autoencoder_accuracy: 0.0097 - autoencoder_loss: 0.0539 - classifier_accuracy: 0.1259 - classifier_loss: 0.0124 - loss: 0.2372\n",
      "Epoch 345/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 569ms/step - autoencoder_accuracy: 0.0097 - autoencoder_loss: 0.0538 - classifier_accuracy: 0.1255 - classifier_loss: 0.0124 - loss: 0.2369\n",
      "Epoch 346/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490ms/step - autoencoder_accuracy: 0.0096 - autoencoder_loss: 0.0537 - classifier_accuracy: 0.1250 - classifier_loss: 0.0123 - loss: 0.2366\n",
      "Epoch 347/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 540ms/step - autoencoder_accuracy: 0.0095 - autoencoder_loss: 0.0537 - classifier_accuracy: 0.1247 - classifier_loss: 0.0123 - loss: 0.2363\n",
      "Epoch 348/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470ms/step - autoencoder_accuracy: 0.0095 - autoencoder_loss: 0.0536 - classifier_accuracy: 0.1245 - classifier_loss: 0.0122 - loss: 0.2360\n",
      "Epoch 349/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 508ms/step - autoencoder_accuracy: 0.0096 - autoencoder_loss: 0.0535 - classifier_accuracy: 0.1244 - classifier_loss: 0.0122 - loss: 0.2357\n",
      "Epoch 350/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 529ms/step - autoencoder_accuracy: 0.0096 - autoencoder_loss: 0.0535 - classifier_accuracy: 0.1239 - classifier_loss: 0.0121 - loss: 0.2354\n",
      "Epoch 351/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 522ms/step - autoencoder_accuracy: 0.0095 - autoencoder_loss: 0.0534 - classifier_accuracy: 0.1236 - classifier_loss: 0.0121 - loss: 0.2351\n",
      "Epoch 352/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 543ms/step - autoencoder_accuracy: 0.0096 - autoencoder_loss: 0.0534 - classifier_accuracy: 0.1232 - classifier_loss: 0.0120 - loss: 0.2348\n",
      "Epoch 353/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493ms/step - autoencoder_accuracy: 0.0096 - autoencoder_loss: 0.0533 - classifier_accuracy: 0.1229 - classifier_loss: 0.0120 - loss: 0.2345\n",
      "Epoch 354/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 365ms/step - autoencoder_accuracy: 0.0095 - autoencoder_loss: 0.0532 - classifier_accuracy: 0.1224 - classifier_loss: 0.0119 - loss: 0.2342\n",
      "Epoch 355/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377ms/step - autoencoder_accuracy: 0.0095 - autoencoder_loss: 0.0532 - classifier_accuracy: 0.1217 - classifier_loss: 0.0119 - loss: 0.2339\n",
      "Epoch 356/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401ms/step - autoencoder_accuracy: 0.0095 - autoencoder_loss: 0.0531 - classifier_accuracy: 0.1211 - classifier_loss: 0.0118 - loss: 0.2336\n",
      "Epoch 357/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366ms/step - autoencoder_accuracy: 0.0095 - autoencoder_loss: 0.0531 - classifier_accuracy: 0.1204 - classifier_loss: 0.0118 - loss: 0.2333\n",
      "Epoch 358/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 371ms/step - autoencoder_accuracy: 0.0096 - autoencoder_loss: 0.0530 - classifier_accuracy: 0.1197 - classifier_loss: 0.0117 - loss: 0.2330\n",
      "Epoch 359/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477ms/step - autoencoder_accuracy: 0.0097 - autoencoder_loss: 0.0529 - classifier_accuracy: 0.1190 - classifier_loss: 0.0117 - loss: 0.2327\n",
      "Epoch 360/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496ms/step - autoencoder_accuracy: 0.0095 - autoencoder_loss: 0.0529 - classifier_accuracy: 0.1183 - classifier_loss: 0.0116 - loss: 0.2324\n",
      "Epoch 361/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 441ms/step - autoencoder_accuracy: 0.0096 - autoencoder_loss: 0.0528 - classifier_accuracy: 0.1177 - classifier_loss: 0.0116 - loss: 0.2321\n",
      "Epoch 362/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 352ms/step - autoencoder_accuracy: 0.0095 - autoencoder_loss: 0.0528 - classifier_accuracy: 0.1172 - classifier_loss: 0.0115 - loss: 0.2318\n",
      "Epoch 363/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 352ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0527 - classifier_accuracy: 0.1166 - classifier_loss: 0.0115 - loss: 0.2315\n",
      "Epoch 364/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 427ms/step - autoencoder_accuracy: 0.0095 - autoencoder_loss: 0.0526 - classifier_accuracy: 0.1161 - classifier_loss: 0.0114 - loss: 0.2312\n",
      "Epoch 365/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 501ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0526 - classifier_accuracy: 0.1158 - classifier_loss: 0.0114 - loss: 0.2308\n",
      "Epoch 366/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 545ms/step - autoencoder_accuracy: 0.0095 - autoencoder_loss: 0.0525 - classifier_accuracy: 0.1154 - classifier_loss: 0.0113 - loss: 0.2305\n",
      "Epoch 367/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 518ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0525 - classifier_accuracy: 0.1151 - classifier_loss: 0.0113 - loss: 0.2302\n",
      "Epoch 368/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0524 - classifier_accuracy: 0.1151 - classifier_loss: 0.0112 - loss: 0.2299\n",
      "Epoch 369/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 364ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0524 - classifier_accuracy: 0.1150 - classifier_loss: 0.0112 - loss: 0.2296\n",
      "Epoch 370/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 365ms/step - autoencoder_accuracy: 0.0095 - autoencoder_loss: 0.0523 - classifier_accuracy: 0.1151 - classifier_loss: 0.0111 - loss: 0.2293\n",
      "Epoch 371/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 351ms/step - autoencoder_accuracy: 0.0095 - autoencoder_loss: 0.0522 - classifier_accuracy: 0.1149 - classifier_loss: 0.0111 - loss: 0.2290\n",
      "Epoch 372/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 368ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0522 - classifier_accuracy: 0.1148 - classifier_loss: 0.0110 - loss: 0.2288\n",
      "Epoch 373/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 536ms/step - autoencoder_accuracy: 0.0095 - autoencoder_loss: 0.0521 - classifier_accuracy: 0.1149 - classifier_loss: 0.0110 - loss: 0.2285\n",
      "Epoch 374/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0521 - classifier_accuracy: 0.1149 - classifier_loss: 0.0109 - loss: 0.2282\n",
      "Epoch 375/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0520 - classifier_accuracy: 0.1150 - classifier_loss: 0.0109 - loss: 0.2279\n",
      "Epoch 376/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0520 - classifier_accuracy: 0.1151 - classifier_loss: 0.0108 - loss: 0.2276\n",
      "Epoch 377/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 729ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0519 - classifier_accuracy: 0.1152 - classifier_loss: 0.0108 - loss: 0.2273\n",
      "Epoch 378/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 651ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0519 - classifier_accuracy: 0.1150 - classifier_loss: 0.0108 - loss: 0.2270\n",
      "Epoch 379/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 657ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0518 - classifier_accuracy: 0.1147 - classifier_loss: 0.0107 - loss: 0.2267\n",
      "Epoch 380/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 690ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0518 - classifier_accuracy: 0.1144 - classifier_loss: 0.0107 - loss: 0.2264\n",
      "Epoch 381/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 727ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0517 - classifier_accuracy: 0.1139 - classifier_loss: 0.0106 - loss: 0.2262\n",
      "Epoch 382/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 627ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0517 - classifier_accuracy: 0.1133 - classifier_loss: 0.0106 - loss: 0.2259\n",
      "Epoch 383/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 605ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0516 - classifier_accuracy: 0.1130 - classifier_loss: 0.0105 - loss: 0.2256\n",
      "Epoch 384/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 639ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0516 - classifier_accuracy: 0.1128 - classifier_loss: 0.0105 - loss: 0.2253\n",
      "Epoch 385/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 573ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0515 - classifier_accuracy: 0.1125 - classifier_loss: 0.0104 - loss: 0.2250\n",
      "Epoch 386/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0515 - classifier_accuracy: 0.1122 - classifier_loss: 0.0104 - loss: 0.2247\n",
      "Epoch 387/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0514 - classifier_accuracy: 0.1119 - classifier_loss: 0.0104 - loss: 0.2245\n",
      "Epoch 388/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 483ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0514 - classifier_accuracy: 0.1116 - classifier_loss: 0.0103 - loss: 0.2242\n",
      "Epoch 389/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 635ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0513 - classifier_accuracy: 0.1113 - classifier_loss: 0.0103 - loss: 0.2239\n",
      "Epoch 390/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 546ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0513 - classifier_accuracy: 0.1110 - classifier_loss: 0.0102 - loss: 0.2236\n",
      "Epoch 391/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 416ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0512 - classifier_accuracy: 0.1106 - classifier_loss: 0.0102 - loss: 0.2233\n",
      "Epoch 392/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 358ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0512 - classifier_accuracy: 0.1103 - classifier_loss: 0.0102 - loss: 0.2231\n",
      "Epoch 393/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0511 - classifier_accuracy: 0.1100 - classifier_loss: 0.0101 - loss: 0.2228\n",
      "Epoch 394/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 517ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0511 - classifier_accuracy: 0.1098 - classifier_loss: 0.0101 - loss: 0.2225\n",
      "Epoch 395/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 432ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0511 - classifier_accuracy: 0.1097 - classifier_loss: 0.0100 - loss: 0.2222\n",
      "Epoch 396/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0510 - classifier_accuracy: 0.1095 - classifier_loss: 0.0100 - loss: 0.2219\n",
      "Epoch 397/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 352ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0510 - classifier_accuracy: 0.1095 - classifier_loss: 0.0099 - loss: 0.2217\n",
      "Epoch 398/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 371ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0509 - classifier_accuracy: 0.1095 - classifier_loss: 0.0099 - loss: 0.2214\n",
      "Epoch 399/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 603ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0509 - classifier_accuracy: 0.1094 - classifier_loss: 0.0099 - loss: 0.2211\n",
      "Epoch 400/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0508 - classifier_accuracy: 0.1093 - classifier_loss: 0.0098 - loss: 0.2209\n",
      "Epoch 401/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 369ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0508 - classifier_accuracy: 0.1091 - classifier_loss: 0.0098 - loss: 0.2206\n",
      "Epoch 402/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0507 - classifier_accuracy: 0.1089 - classifier_loss: 0.0097 - loss: 0.2203\n",
      "Epoch 403/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0507 - classifier_accuracy: 0.1088 - classifier_loss: 0.0097 - loss: 0.2200\n",
      "Epoch 404/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 547ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0506 - classifier_accuracy: 0.1085 - classifier_loss: 0.0097 - loss: 0.2198\n",
      "Epoch 405/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 514ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0506 - classifier_accuracy: 0.1084 - classifier_loss: 0.0096 - loss: 0.2195\n",
      "Epoch 406/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0506 - classifier_accuracy: 0.1082 - classifier_loss: 0.0096 - loss: 0.2192\n",
      "Epoch 407/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0505 - classifier_accuracy: 0.1080 - classifier_loss: 0.0096 - loss: 0.2190\n",
      "Epoch 408/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0505 - classifier_accuracy: 0.1081 - classifier_loss: 0.0095 - loss: 0.2187\n",
      "Epoch 409/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 521ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0504 - classifier_accuracy: 0.1082 - classifier_loss: 0.0095 - loss: 0.2185\n",
      "Epoch 410/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 503ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0504 - classifier_accuracy: 0.1081 - classifier_loss: 0.0095 - loss: 0.2182\n",
      "Epoch 411/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0503 - classifier_accuracy: 0.1080 - classifier_loss: 0.0094 - loss: 0.2179\n",
      "Epoch 412/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 359ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0503 - classifier_accuracy: 0.1079 - classifier_loss: 0.0094 - loss: 0.2177\n",
      "Epoch 413/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0503 - classifier_accuracy: 0.1079 - classifier_loss: 0.0094 - loss: 0.2174\n",
      "Epoch 414/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 558ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0502 - classifier_accuracy: 0.1078 - classifier_loss: 0.0093 - loss: 0.2171\n",
      "Epoch 415/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 468ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0502 - classifier_accuracy: 0.1078 - classifier_loss: 0.0093 - loss: 0.2169\n",
      "Epoch 416/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0501 - classifier_accuracy: 0.1076 - classifier_loss: 0.0093 - loss: 0.2166\n",
      "Epoch 417/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 436ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0501 - classifier_accuracy: 0.1076 - classifier_loss: 0.0092 - loss: 0.2164\n",
      "Epoch 418/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0501 - classifier_accuracy: 0.1074 - classifier_loss: 0.0092 - loss: 0.2161\n",
      "Epoch 419/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 526ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0500 - classifier_accuracy: 0.1073 - classifier_loss: 0.0092 - loss: 0.2158\n",
      "Epoch 420/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0500 - classifier_accuracy: 0.1072 - classifier_loss: 0.0091 - loss: 0.2156\n",
      "Epoch 421/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 561ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0499 - classifier_accuracy: 0.1071 - classifier_loss: 0.0091 - loss: 0.2153\n",
      "Epoch 422/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 495ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0499 - classifier_accuracy: 0.1069 - classifier_loss: 0.0091 - loss: 0.2151\n",
      "Epoch 423/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0499 - classifier_accuracy: 0.1067 - classifier_loss: 0.0090 - loss: 0.2148\n",
      "Epoch 424/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 548ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0498 - classifier_accuracy: 0.1065 - classifier_loss: 0.0090 - loss: 0.2146\n",
      "Epoch 425/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 495ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0498 - classifier_accuracy: 0.1062 - classifier_loss: 0.0090 - loss: 0.2143\n",
      "Epoch 426/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0497 - classifier_accuracy: 0.1060 - classifier_loss: 0.0089 - loss: 0.2141\n",
      "Epoch 427/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0497 - classifier_accuracy: 0.1058 - classifier_loss: 0.0089 - loss: 0.2138\n",
      "Epoch 428/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 369ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0497 - classifier_accuracy: 0.1055 - classifier_loss: 0.0089 - loss: 0.2136\n",
      "Epoch 429/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 363ms/step - autoencoder_accuracy: 0.0092 - autoencoder_loss: 0.0496 - classifier_accuracy: 0.1052 - classifier_loss: 0.0089 - loss: 0.2133\n",
      "Epoch 430/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 535ms/step - autoencoder_accuracy: 0.0092 - autoencoder_loss: 0.0496 - classifier_accuracy: 0.1050 - classifier_loss: 0.0088 - loss: 0.2131\n",
      "Epoch 431/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0495 - classifier_accuracy: 0.1048 - classifier_loss: 0.0088 - loss: 0.2128\n",
      "Epoch 432/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 367ms/step - autoencoder_accuracy: 0.0092 - autoencoder_loss: 0.0495 - classifier_accuracy: 0.1048 - classifier_loss: 0.0088 - loss: 0.2126\n",
      "Epoch 433/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 364ms/step - autoencoder_accuracy: 0.0092 - autoencoder_loss: 0.0495 - classifier_accuracy: 0.1047 - classifier_loss: 0.0087 - loss: 0.2123\n",
      "Epoch 434/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0494 - classifier_accuracy: 0.1046 - classifier_loss: 0.0087 - loss: 0.2121\n",
      "Epoch 435/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 522ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0494 - classifier_accuracy: 0.1045 - classifier_loss: 0.0087 - loss: 0.2118\n",
      "Epoch 436/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 427ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0493 - classifier_accuracy: 0.1045 - classifier_loss: 0.0087 - loss: 0.2116\n",
      "Epoch 437/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386ms/step - autoencoder_accuracy: 0.0092 - autoencoder_loss: 0.0493 - classifier_accuracy: 0.1044 - classifier_loss: 0.0086 - loss: 0.2113\n",
      "Epoch 438/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388ms/step - autoencoder_accuracy: 0.0092 - autoencoder_loss: 0.0493 - classifier_accuracy: 0.1044 - classifier_loss: 0.0086 - loss: 0.2111\n",
      "Epoch 439/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0492 - classifier_accuracy: 0.1044 - classifier_loss: 0.0086 - loss: 0.2108\n",
      "Epoch 440/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0492 - classifier_accuracy: 0.1043 - classifier_loss: 0.0085 - loss: 0.2106\n",
      "Epoch 441/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379ms/step - autoencoder_accuracy: 0.0092 - autoencoder_loss: 0.0492 - classifier_accuracy: 0.1042 - classifier_loss: 0.0085 - loss: 0.2104\n",
      "Epoch 442/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 580ms/step - autoencoder_accuracy: 0.0092 - autoencoder_loss: 0.0491 - classifier_accuracy: 0.1040 - classifier_loss: 0.0085 - loss: 0.2101\n",
      "Epoch 443/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 519ms/step - autoencoder_accuracy: 0.0092 - autoencoder_loss: 0.0491 - classifier_accuracy: 0.1037 - classifier_loss: 0.0085 - loss: 0.2099\n",
      "Epoch 444/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 370ms/step - autoencoder_accuracy: 0.0092 - autoencoder_loss: 0.0491 - classifier_accuracy: 0.1034 - classifier_loss: 0.0084 - loss: 0.2096\n",
      "Epoch 445/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0490 - classifier_accuracy: 0.1032 - classifier_loss: 0.0084 - loss: 0.2094\n",
      "Epoch 446/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 551ms/step - autoencoder_accuracy: 0.0092 - autoencoder_loss: 0.0490 - classifier_accuracy: 0.1028 - classifier_loss: 0.0084 - loss: 0.2091\n",
      "Epoch 447/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0490 - classifier_accuracy: 0.1025 - classifier_loss: 0.0084 - loss: 0.2089\n",
      "Epoch 448/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394ms/step - autoencoder_accuracy: 0.0092 - autoencoder_loss: 0.0489 - classifier_accuracy: 0.1024 - classifier_loss: 0.0083 - loss: 0.2087\n",
      "Epoch 449/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0489 - classifier_accuracy: 0.1022 - classifier_loss: 0.0083 - loss: 0.2084\n",
      "Epoch 450/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 553ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0489 - classifier_accuracy: 0.1022 - classifier_loss: 0.0083 - loss: 0.2082\n",
      "Epoch 451/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 467ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0488 - classifier_accuracy: 0.1019 - classifier_loss: 0.0083 - loss: 0.2080\n",
      "Epoch 452/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 369ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0488 - classifier_accuracy: 0.1017 - classifier_loss: 0.0082 - loss: 0.2077\n",
      "Epoch 453/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 441ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0488 - classifier_accuracy: 0.1016 - classifier_loss: 0.0082 - loss: 0.2075\n",
      "Epoch 454/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 539ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0487 - classifier_accuracy: 0.1015 - classifier_loss: 0.0082 - loss: 0.2073\n",
      "Epoch 455/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0487 - classifier_accuracy: 0.1015 - classifier_loss: 0.0082 - loss: 0.2070\n",
      "Epoch 456/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391ms/step - autoencoder_accuracy: 0.0092 - autoencoder_loss: 0.0487 - classifier_accuracy: 0.1014 - classifier_loss: 0.0081 - loss: 0.2068\n",
      "Epoch 457/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366ms/step - autoencoder_accuracy: 0.0092 - autoencoder_loss: 0.0486 - classifier_accuracy: 0.1013 - classifier_loss: 0.0081 - loss: 0.2066\n",
      "Epoch 458/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494ms/step - autoencoder_accuracy: 0.0092 - autoencoder_loss: 0.0486 - classifier_accuracy: 0.1012 - classifier_loss: 0.0081 - loss: 0.2063\n",
      "Epoch 459/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 505ms/step - autoencoder_accuracy: 0.0092 - autoencoder_loss: 0.0486 - classifier_accuracy: 0.1012 - classifier_loss: 0.0081 - loss: 0.2061\n",
      "Epoch 460/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397ms/step - autoencoder_accuracy: 0.0092 - autoencoder_loss: 0.0486 - classifier_accuracy: 0.1010 - classifier_loss: 0.0080 - loss: 0.2059\n",
      "Epoch 461/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0485 - classifier_accuracy: 0.1009 - classifier_loss: 0.0080 - loss: 0.2056\n",
      "Epoch 462/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 556ms/step - autoencoder_accuracy: 0.0092 - autoencoder_loss: 0.0485 - classifier_accuracy: 0.1006 - classifier_loss: 0.0080 - loss: 0.2054\n",
      "Epoch 463/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491ms/step - autoencoder_accuracy: 0.0092 - autoencoder_loss: 0.0485 - classifier_accuracy: 0.1004 - classifier_loss: 0.0080 - loss: 0.2052\n",
      "Epoch 464/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 356ms/step - autoencoder_accuracy: 0.0092 - autoencoder_loss: 0.0484 - classifier_accuracy: 0.1001 - classifier_loss: 0.0079 - loss: 0.2049\n",
      "Epoch 465/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 344ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0484 - classifier_accuracy: 0.0999 - classifier_loss: 0.0079 - loss: 0.2047\n",
      "Epoch 466/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 507ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0484 - classifier_accuracy: 0.0997 - classifier_loss: 0.0079 - loss: 0.2045\n",
      "Epoch 467/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 497ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0483 - classifier_accuracy: 0.0997 - classifier_loss: 0.0079 - loss: 0.2042\n",
      "Epoch 468/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0483 - classifier_accuracy: 0.0995 - classifier_loss: 0.0078 - loss: 0.2040\n",
      "Epoch 469/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0483 - classifier_accuracy: 0.0995 - classifier_loss: 0.0078 - loss: 0.2038\n",
      "Epoch 470/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 560ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0483 - classifier_accuracy: 0.0995 - classifier_loss: 0.0078 - loss: 0.2035\n",
      "Epoch 471/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0482 - classifier_accuracy: 0.0994 - classifier_loss: 0.0078 - loss: 0.2033\n",
      "Epoch 472/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408ms/step - autoencoder_accuracy: 0.0092 - autoencoder_loss: 0.0482 - classifier_accuracy: 0.0994 - classifier_loss: 0.0077 - loss: 0.2031\n",
      "Epoch 473/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388ms/step - autoencoder_accuracy: 0.0092 - autoencoder_loss: 0.0482 - classifier_accuracy: 0.0993 - classifier_loss: 0.0077 - loss: 0.2029\n",
      "Epoch 474/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 538ms/step - autoencoder_accuracy: 0.0092 - autoencoder_loss: 0.0481 - classifier_accuracy: 0.0992 - classifier_loss: 0.0077 - loss: 0.2026\n",
      "Epoch 475/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0481 - classifier_accuracy: 0.0992 - classifier_loss: 0.0077 - loss: 0.2024\n",
      "Epoch 476/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0481 - classifier_accuracy: 0.0991 - classifier_loss: 0.0076 - loss: 0.2022\n",
      "Epoch 477/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0481 - classifier_accuracy: 0.0989 - classifier_loss: 0.0076 - loss: 0.2020\n",
      "Epoch 478/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 517ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0480 - classifier_accuracy: 0.0988 - classifier_loss: 0.0076 - loss: 0.2017\n",
      "Epoch 479/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 441ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0480 - classifier_accuracy: 0.0987 - classifier_loss: 0.0076 - loss: 0.2015\n",
      "Epoch 480/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 372ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0480 - classifier_accuracy: 0.0985 - classifier_loss: 0.0076 - loss: 0.2013\n",
      "Epoch 481/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0480 - classifier_accuracy: 0.0984 - classifier_loss: 0.0075 - loss: 0.2011\n",
      "Epoch 482/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 530ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0479 - classifier_accuracy: 0.0984 - classifier_loss: 0.0075 - loss: 0.2008\n",
      "Epoch 483/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0479 - classifier_accuracy: 0.0983 - classifier_loss: 0.0075 - loss: 0.2006\n",
      "Epoch 484/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 369ms/step - autoencoder_accuracy: 0.0092 - autoencoder_loss: 0.0479 - classifier_accuracy: 0.0982 - classifier_loss: 0.0075 - loss: 0.2004\n",
      "Epoch 485/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375ms/step - autoencoder_accuracy: 0.0092 - autoencoder_loss: 0.0479 - classifier_accuracy: 0.0981 - classifier_loss: 0.0074 - loss: 0.2002\n",
      "Epoch 486/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 508ms/step - autoencoder_accuracy: 0.0092 - autoencoder_loss: 0.0478 - classifier_accuracy: 0.0980 - classifier_loss: 0.0074 - loss: 0.1999\n",
      "Epoch 487/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 429ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0478 - classifier_accuracy: 0.0978 - classifier_loss: 0.0074 - loss: 0.1997\n",
      "Epoch 488/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 426ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0478 - classifier_accuracy: 0.0977 - classifier_loss: 0.0074 - loss: 0.1995\n",
      "Epoch 489/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 371ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0477 - classifier_accuracy: 0.0977 - classifier_loss: 0.0074 - loss: 0.1993\n",
      "Epoch 490/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0477 - classifier_accuracy: 0.0977 - classifier_loss: 0.0073 - loss: 0.1991\n",
      "Epoch 491/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0477 - classifier_accuracy: 0.0976 - classifier_loss: 0.0073 - loss: 0.1988\n",
      "Epoch 492/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0477 - classifier_accuracy: 0.0976 - classifier_loss: 0.0073 - loss: 0.1986\n",
      "Epoch 493/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 546ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0476 - classifier_accuracy: 0.0977 - classifier_loss: 0.0073 - loss: 0.1984\n",
      "Epoch 494/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0476 - classifier_accuracy: 0.0977 - classifier_loss: 0.0072 - loss: 0.1982\n",
      "Epoch 495/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449ms/step - autoencoder_accuracy: 0.0090 - autoencoder_loss: 0.0476 - classifier_accuracy: 0.0977 - classifier_loss: 0.0072 - loss: 0.1980\n",
      "Epoch 496/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411ms/step - autoencoder_accuracy: 0.0090 - autoencoder_loss: 0.0476 - classifier_accuracy: 0.0978 - classifier_loss: 0.0072 - loss: 0.1977\n",
      "Epoch 497/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 547ms/step - autoencoder_accuracy: 0.0090 - autoencoder_loss: 0.0475 - classifier_accuracy: 0.0978 - classifier_loss: 0.0072 - loss: 0.1975\n",
      "Epoch 498/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 426ms/step - autoencoder_accuracy: 0.0090 - autoencoder_loss: 0.0475 - classifier_accuracy: 0.0979 - classifier_loss: 0.0072 - loss: 0.1973\n",
      "Epoch 499/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382ms/step - autoencoder_accuracy: 0.0090 - autoencoder_loss: 0.0475 - classifier_accuracy: 0.0980 - classifier_loss: 0.0071 - loss: 0.1971\n",
      "Epoch 500/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486ms/step - autoencoder_accuracy: 0.0090 - autoencoder_loss: 0.0475 - classifier_accuracy: 0.0980 - classifier_loss: 0.0071 - loss: 0.1969\n",
      "Epoch 501/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466ms/step - autoencoder_accuracy: 0.0090 - autoencoder_loss: 0.0474 - classifier_accuracy: 0.0981 - classifier_loss: 0.0071 - loss: 0.1967\n",
      "Epoch 502/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 513ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0474 - classifier_accuracy: 0.0982 - classifier_loss: 0.0071 - loss: 0.1964\n",
      "Epoch 503/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475ms/step - autoencoder_accuracy: 0.0090 - autoencoder_loss: 0.0474 - classifier_accuracy: 0.0983 - classifier_loss: 0.0071 - loss: 0.1962\n",
      "Epoch 504/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - autoencoder_accuracy: 0.0090 - autoencoder_loss: 0.0474 - classifier_accuracy: 0.0983 - classifier_loss: 0.0070 - loss: 0.1960\n",
      "Epoch 505/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 421ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0473 - classifier_accuracy: 0.0984 - classifier_loss: 0.0070 - loss: 0.1958\n",
      "Epoch 506/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 532ms/step - autoencoder_accuracy: 0.0090 - autoencoder_loss: 0.0473 - classifier_accuracy: 0.0984 - classifier_loss: 0.0070 - loss: 0.1956\n",
      "Epoch 507/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 431ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0473 - classifier_accuracy: 0.0984 - classifier_loss: 0.0070 - loss: 0.1954\n",
      "Epoch 508/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0473 - classifier_accuracy: 0.0984 - classifier_loss: 0.0069 - loss: 0.1951\n",
      "Epoch 509/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 405ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0472 - classifier_accuracy: 0.0983 - classifier_loss: 0.0069 - loss: 0.1949\n",
      "Epoch 510/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0472 - classifier_accuracy: 0.0983 - classifier_loss: 0.0069 - loss: 0.1947\n",
      "Epoch 511/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0472 - classifier_accuracy: 0.0982 - classifier_loss: 0.0069 - loss: 0.1945\n",
      "Epoch 512/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 438ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0472 - classifier_accuracy: 0.0981 - classifier_loss: 0.0069 - loss: 0.1943\n",
      "Epoch 513/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 503ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0471 - classifier_accuracy: 0.0981 - classifier_loss: 0.0068 - loss: 0.1941\n",
      "Epoch 514/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0471 - classifier_accuracy: 0.0981 - classifier_loss: 0.0068 - loss: 0.1939\n",
      "Epoch 515/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 505ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0471 - classifier_accuracy: 0.0981 - classifier_loss: 0.0068 - loss: 0.1936\n",
      "Epoch 516/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 560ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0471 - classifier_accuracy: 0.0979 - classifier_loss: 0.0068 - loss: 0.1934\n",
      "Epoch 517/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0471 - classifier_accuracy: 0.0978 - classifier_loss: 0.0068 - loss: 0.1932\n",
      "Epoch 518/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0470 - classifier_accuracy: 0.0978 - classifier_loss: 0.0067 - loss: 0.1930\n",
      "Epoch 519/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0470 - classifier_accuracy: 0.0976 - classifier_loss: 0.0067 - loss: 0.1928\n",
      "Epoch 520/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 540ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0470 - classifier_accuracy: 0.0975 - classifier_loss: 0.0067 - loss: 0.1926\n",
      "Epoch 521/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0470 - classifier_accuracy: 0.0974 - classifier_loss: 0.0067 - loss: 0.1924\n",
      "Epoch 522/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0469 - classifier_accuracy: 0.0973 - classifier_loss: 0.0067 - loss: 0.1922\n",
      "Epoch 523/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0469 - classifier_accuracy: 0.0973 - classifier_loss: 0.0066 - loss: 0.1919\n",
      "Epoch 524/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 526ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0469 - classifier_accuracy: 0.0972 - classifier_loss: 0.0066 - loss: 0.1917\n",
      "Epoch 525/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 502ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0469 - classifier_accuracy: 0.0972 - classifier_loss: 0.0066 - loss: 0.1915\n",
      "Epoch 526/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 372ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0469 - classifier_accuracy: 0.0971 - classifier_loss: 0.0066 - loss: 0.1913\n",
      "Epoch 527/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0468 - classifier_accuracy: 0.0971 - classifier_loss: 0.0065 - loss: 0.1911\n",
      "Epoch 528/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 551ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0468 - classifier_accuracy: 0.0972 - classifier_loss: 0.0065 - loss: 0.1909\n",
      "Epoch 529/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 502ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0468 - classifier_accuracy: 0.0972 - classifier_loss: 0.0065 - loss: 0.1907\n",
      "Epoch 530/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0468 - classifier_accuracy: 0.0972 - classifier_loss: 0.0065 - loss: 0.1905\n",
      "Epoch 531/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0467 - classifier_accuracy: 0.0973 - classifier_loss: 0.0065 - loss: 0.1903\n",
      "Epoch 532/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 568ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0467 - classifier_accuracy: 0.0972 - classifier_loss: 0.0064 - loss: 0.1901\n",
      "Epoch 533/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 518ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0467 - classifier_accuracy: 0.0972 - classifier_loss: 0.0064 - loss: 0.1898\n",
      "Epoch 534/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 465ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0467 - classifier_accuracy: 0.0972 - classifier_loss: 0.0064 - loss: 0.1896\n",
      "Epoch 535/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 543ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0466 - classifier_accuracy: 0.0973 - classifier_loss: 0.0064 - loss: 0.1894\n",
      "Epoch 536/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 535ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0466 - classifier_accuracy: 0.0972 - classifier_loss: 0.0064 - loss: 0.1892\n",
      "Epoch 537/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0466 - classifier_accuracy: 0.0972 - classifier_loss: 0.0063 - loss: 0.1890\n",
      "Epoch 538/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 352ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0466 - classifier_accuracy: 0.0971 - classifier_loss: 0.0063 - loss: 0.1888\n",
      "Epoch 539/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 362ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0466 - classifier_accuracy: 0.0970 - classifier_loss: 0.0063 - loss: 0.1886\n",
      "Epoch 540/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 525ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0465 - classifier_accuracy: 0.0970 - classifier_loss: 0.0063 - loss: 0.1884\n",
      "Epoch 541/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0465 - classifier_accuracy: 0.0970 - classifier_loss: 0.0063 - loss: 0.1882\n",
      "Epoch 542/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 364ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0465 - classifier_accuracy: 0.0969 - classifier_loss: 0.0063 - loss: 0.1880\n",
      "Epoch 543/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 363ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0465 - classifier_accuracy: 0.0969 - classifier_loss: 0.0062 - loss: 0.1878\n",
      "Epoch 544/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0464 - classifier_accuracy: 0.0969 - classifier_loss: 0.0062 - loss: 0.1876\n",
      "Epoch 545/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0464 - classifier_accuracy: 0.0967 - classifier_loss: 0.0062 - loss: 0.1874\n",
      "Epoch 546/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 359ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0464 - classifier_accuracy: 0.0967 - classifier_loss: 0.0062 - loss: 0.1872\n",
      "Epoch 547/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0464 - classifier_accuracy: 0.0966 - classifier_loss: 0.0062 - loss: 0.1870\n",
      "Epoch 548/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0464 - classifier_accuracy: 0.0966 - classifier_loss: 0.0061 - loss: 0.1868\n",
      "Epoch 549/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 427ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0463 - classifier_accuracy: 0.0966 - classifier_loss: 0.0061 - loss: 0.1866\n",
      "Epoch 550/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 361ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0463 - classifier_accuracy: 0.0967 - classifier_loss: 0.0061 - loss: 0.1864\n",
      "Epoch 551/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0463 - classifier_accuracy: 0.0967 - classifier_loss: 0.0061 - loss: 0.1862\n",
      "Epoch 552/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 422ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0463 - classifier_accuracy: 0.0967 - classifier_loss: 0.0061 - loss: 0.1860\n",
      "Epoch 553/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 429ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0463 - classifier_accuracy: 0.0967 - classifier_loss: 0.0061 - loss: 0.1858\n",
      "Epoch 554/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0462 - classifier_accuracy: 0.0968 - classifier_loss: 0.0060 - loss: 0.1856\n",
      "Epoch 555/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 427ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0462 - classifier_accuracy: 0.0969 - classifier_loss: 0.0060 - loss: 0.1854\n",
      "Epoch 556/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0462 - classifier_accuracy: 0.0969 - classifier_loss: 0.0060 - loss: 0.1852\n",
      "Epoch 557/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0462 - classifier_accuracy: 0.0969 - classifier_loss: 0.0060 - loss: 0.1850\n",
      "Epoch 558/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0461 - classifier_accuracy: 0.0968 - classifier_loss: 0.0060 - loss: 0.1848\n",
      "Epoch 559/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0461 - classifier_accuracy: 0.0968 - classifier_loss: 0.0060 - loss: 0.1846\n",
      "Epoch 560/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0461 - classifier_accuracy: 0.0969 - classifier_loss: 0.0059 - loss: 0.1844\n",
      "Epoch 561/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 514ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0461 - classifier_accuracy: 0.0970 - classifier_loss: 0.0059 - loss: 0.1842\n",
      "Epoch 562/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0461 - classifier_accuracy: 0.0970 - classifier_loss: 0.0059 - loss: 0.1840\n",
      "Epoch 563/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0460 - classifier_accuracy: 0.0969 - classifier_loss: 0.0059 - loss: 0.1838\n",
      "Epoch 564/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 465ms/step - autoencoder_accuracy: 0.0090 - autoencoder_loss: 0.0460 - classifier_accuracy: 0.0969 - classifier_loss: 0.0059 - loss: 0.1836\n",
      "Epoch 565/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473ms/step - autoencoder_accuracy: 0.0090 - autoencoder_loss: 0.0460 - classifier_accuracy: 0.0969 - classifier_loss: 0.0059 - loss: 0.1834\n",
      "Epoch 566/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400ms/step - autoencoder_accuracy: 0.0090 - autoencoder_loss: 0.0460 - classifier_accuracy: 0.0970 - classifier_loss: 0.0058 - loss: 0.1832\n",
      "Epoch 567/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0460 - classifier_accuracy: 0.0970 - classifier_loss: 0.0058 - loss: 0.1830\n",
      "Epoch 568/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0459 - classifier_accuracy: 0.0970 - classifier_loss: 0.0058 - loss: 0.1828\n",
      "Epoch 569/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 344ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0459 - classifier_accuracy: 0.0971 - classifier_loss: 0.0058 - loss: 0.1826\n",
      "Epoch 570/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 512ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0459 - classifier_accuracy: 0.0971 - classifier_loss: 0.0058 - loss: 0.1824\n",
      "Epoch 571/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 438ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0459 - classifier_accuracy: 0.0972 - classifier_loss: 0.0058 - loss: 0.1822\n",
      "Epoch 572/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 367ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0459 - classifier_accuracy: 0.0972 - classifier_loss: 0.0057 - loss: 0.1820\n",
      "Epoch 573/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0458 - classifier_accuracy: 0.0973 - classifier_loss: 0.0057 - loss: 0.1818\n",
      "Epoch 574/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 441ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0458 - classifier_accuracy: 0.0973 - classifier_loss: 0.0057 - loss: 0.1816\n",
      "Epoch 575/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0458 - classifier_accuracy: 0.0973 - classifier_loss: 0.0057 - loss: 0.1814\n",
      "Epoch 576/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0458 - classifier_accuracy: 0.0973 - classifier_loss: 0.0057 - loss: 0.1812\n",
      "Epoch 577/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0458 - classifier_accuracy: 0.0973 - classifier_loss: 0.0057 - loss: 0.1810\n",
      "Epoch 578/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 368ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0457 - classifier_accuracy: 0.0974 - classifier_loss: 0.0056 - loss: 0.1808\n",
      "Epoch 579/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 517ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0457 - classifier_accuracy: 0.0974 - classifier_loss: 0.0056 - loss: 0.1806\n",
      "Epoch 580/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 502ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0457 - classifier_accuracy: 0.0974 - classifier_loss: 0.0056 - loss: 0.1804\n",
      "Epoch 581/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0457 - classifier_accuracy: 0.0973 - classifier_loss: 0.0056 - loss: 0.1802\n",
      "Epoch 582/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0457 - classifier_accuracy: 0.0974 - classifier_loss: 0.0056 - loss: 0.1800\n",
      "Epoch 583/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0456 - classifier_accuracy: 0.0974 - classifier_loss: 0.0056 - loss: 0.1799\n",
      "Epoch 584/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0456 - classifier_accuracy: 0.0974 - classifier_loss: 0.0056 - loss: 0.1797\n",
      "Epoch 585/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 412ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0456 - classifier_accuracy: 0.0973 - classifier_loss: 0.0055 - loss: 0.1795\n",
      "Epoch 586/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 437ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0456 - classifier_accuracy: 0.0973 - classifier_loss: 0.0055 - loss: 0.1793\n",
      "Epoch 587/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0455 - classifier_accuracy: 0.0974 - classifier_loss: 0.0055 - loss: 0.1791\n",
      "Epoch 588/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0455 - classifier_accuracy: 0.0974 - classifier_loss: 0.0055 - loss: 0.1789\n",
      "Epoch 589/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0455 - classifier_accuracy: 0.0975 - classifier_loss: 0.0055 - loss: 0.1787\n",
      "Epoch 590/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 524ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0455 - classifier_accuracy: 0.0975 - classifier_loss: 0.0055 - loss: 0.1785\n",
      "Epoch 591/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 467ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0455 - classifier_accuracy: 0.0975 - classifier_loss: 0.0054 - loss: 0.1783\n",
      "Epoch 592/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0454 - classifier_accuracy: 0.0975 - classifier_loss: 0.0054 - loss: 0.1781\n",
      "Epoch 593/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0454 - classifier_accuracy: 0.0975 - classifier_loss: 0.0054 - loss: 0.1779\n",
      "Epoch 594/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0454 - classifier_accuracy: 0.0976 - classifier_loss: 0.0054 - loss: 0.1777\n",
      "Epoch 595/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0454 - classifier_accuracy: 0.0976 - classifier_loss: 0.0054 - loss: 0.1775\n",
      "Epoch 596/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 468ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0454 - classifier_accuracy: 0.0976 - classifier_loss: 0.0054 - loss: 0.1774\n",
      "Epoch 597/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 544ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0453 - classifier_accuracy: 0.0977 - classifier_loss: 0.0054 - loss: 0.1772\n",
      "Epoch 598/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0453 - classifier_accuracy: 0.0978 - classifier_loss: 0.0053 - loss: 0.1770\n",
      "Epoch 599/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 372ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0453 - classifier_accuracy: 0.0979 - classifier_loss: 0.0053 - loss: 0.1768\n",
      "Epoch 600/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 426ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0453 - classifier_accuracy: 0.0979 - classifier_loss: 0.0053 - loss: 0.1766\n",
      "Epoch 601/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0453 - classifier_accuracy: 0.0980 - classifier_loss: 0.0053 - loss: 0.1764\n",
      "Epoch 602/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 357ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0452 - classifier_accuracy: 0.0981 - classifier_loss: 0.0053 - loss: 0.1762\n",
      "Epoch 603/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0452 - classifier_accuracy: 0.0982 - classifier_loss: 0.0053 - loss: 0.1760\n",
      "Epoch 604/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 436ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0452 - classifier_accuracy: 0.0983 - classifier_loss: 0.0053 - loss: 0.1758\n",
      "Epoch 605/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0452 - classifier_accuracy: 0.0983 - classifier_loss: 0.0052 - loss: 0.1757\n",
      "Epoch 606/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 344ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0452 - classifier_accuracy: 0.0984 - classifier_loss: 0.0052 - loss: 0.1755\n",
      "Epoch 607/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 354ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0451 - classifier_accuracy: 0.0984 - classifier_loss: 0.0052 - loss: 0.1753\n",
      "Epoch 608/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 370ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0451 - classifier_accuracy: 0.0984 - classifier_loss: 0.0052 - loss: 0.1751\n",
      "Epoch 609/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0451 - classifier_accuracy: 0.0984 - classifier_loss: 0.0052 - loss: 0.1749\n",
      "Epoch 610/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 369ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0451 - classifier_accuracy: 0.0984 - classifier_loss: 0.0052 - loss: 0.1747\n",
      "Epoch 611/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 362ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0451 - classifier_accuracy: 0.0984 - classifier_loss: 0.0051 - loss: 0.1745\n",
      "Epoch 612/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0450 - classifier_accuracy: 0.0984 - classifier_loss: 0.0051 - loss: 0.1743\n",
      "Epoch 613/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379ms/step - autoencoder_accuracy: 0.0090 - autoencoder_loss: 0.0450 - classifier_accuracy: 0.0984 - classifier_loss: 0.0051 - loss: 0.1742\n",
      "Epoch 614/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 359ms/step - autoencoder_accuracy: 0.0090 - autoencoder_loss: 0.0450 - classifier_accuracy: 0.0984 - classifier_loss: 0.0051 - loss: 0.1740\n",
      "Epoch 615/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366ms/step - autoencoder_accuracy: 0.0090 - autoencoder_loss: 0.0450 - classifier_accuracy: 0.0984 - classifier_loss: 0.0051 - loss: 0.1738\n",
      "Epoch 616/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 369ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0450 - classifier_accuracy: 0.0985 - classifier_loss: 0.0051 - loss: 0.1736\n",
      "Epoch 617/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 405ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0449 - classifier_accuracy: 0.0985 - classifier_loss: 0.0051 - loss: 0.1734\n",
      "Epoch 618/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456ms/step - autoencoder_accuracy: 0.0090 - autoencoder_loss: 0.0449 - classifier_accuracy: 0.0985 - classifier_loss: 0.0051 - loss: 0.1732\n",
      "Epoch 619/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0449 - classifier_accuracy: 0.0984 - classifier_loss: 0.0050 - loss: 0.1730\n",
      "Epoch 620/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 424ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0449 - classifier_accuracy: 0.0984 - classifier_loss: 0.0050 - loss: 0.1728\n",
      "Epoch 621/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0449 - classifier_accuracy: 0.0985 - classifier_loss: 0.0050 - loss: 0.1727\n",
      "Epoch 622/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0448 - classifier_accuracy: 0.0985 - classifier_loss: 0.0050 - loss: 0.1725\n",
      "Epoch 623/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 358ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0448 - classifier_accuracy: 0.0985 - classifier_loss: 0.0050 - loss: 0.1723\n",
      "Epoch 624/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 439ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0448 - classifier_accuracy: 0.0985 - classifier_loss: 0.0050 - loss: 0.1721\n",
      "Epoch 625/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0448 - classifier_accuracy: 0.0985 - classifier_loss: 0.0050 - loss: 0.1719\n",
      "Epoch 626/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 438ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0447 - classifier_accuracy: 0.0985 - classifier_loss: 0.0049 - loss: 0.1717\n",
      "Epoch 627/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0447 - classifier_accuracy: 0.0985 - classifier_loss: 0.0049 - loss: 0.1716\n",
      "Epoch 628/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 468ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0447 - classifier_accuracy: 0.0985 - classifier_loss: 0.0049 - loss: 0.1714\n",
      "Epoch 629/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 467ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0447 - classifier_accuracy: 0.0985 - classifier_loss: 0.0049 - loss: 0.1712\n",
      "Epoch 630/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 519ms/step - autoencoder_accuracy: 0.0090 - autoencoder_loss: 0.0447 - classifier_accuracy: 0.0985 - classifier_loss: 0.0049 - loss: 0.1710\n",
      "Epoch 631/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425ms/step - autoencoder_accuracy: 0.0090 - autoencoder_loss: 0.0446 - classifier_accuracy: 0.0984 - classifier_loss: 0.0049 - loss: 0.1708\n",
      "Epoch 632/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0446 - classifier_accuracy: 0.0985 - classifier_loss: 0.0049 - loss: 0.1706\n",
      "Epoch 633/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0446 - classifier_accuracy: 0.0984 - classifier_loss: 0.0048 - loss: 0.1704\n",
      "Epoch 634/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0446 - classifier_accuracy: 0.0985 - classifier_loss: 0.0048 - loss: 0.1703\n",
      "Epoch 635/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 525ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0446 - classifier_accuracy: 0.0985 - classifier_loss: 0.0048 - loss: 0.1701\n",
      "Epoch 636/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 662ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0445 - classifier_accuracy: 0.0984 - classifier_loss: 0.0048 - loss: 0.1699\n",
      "Epoch 637/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 563ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0445 - classifier_accuracy: 0.0984 - classifier_loss: 0.0048 - loss: 0.1697\n",
      "Epoch 638/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 537ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0445 - classifier_accuracy: 0.0984 - classifier_loss: 0.0048 - loss: 0.1695\n",
      "Epoch 639/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 567ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0445 - classifier_accuracy: 0.0984 - classifier_loss: 0.0048 - loss: 0.1693\n",
      "Epoch 640/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 579ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0444 - classifier_accuracy: 0.0984 - classifier_loss: 0.0048 - loss: 0.1692\n",
      "Epoch 641/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 530ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0444 - classifier_accuracy: 0.0985 - classifier_loss: 0.0047 - loss: 0.1690\n",
      "Epoch 642/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 598ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0444 - classifier_accuracy: 0.0986 - classifier_loss: 0.0047 - loss: 0.1688\n",
      "Epoch 643/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 587ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0444 - classifier_accuracy: 0.0985 - classifier_loss: 0.0047 - loss: 0.1686\n",
      "Epoch 644/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 471ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0444 - classifier_accuracy: 0.0985 - classifier_loss: 0.0047 - loss: 0.1684\n",
      "Epoch 645/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 662ms/step - autoencoder_accuracy: 0.0090 - autoencoder_loss: 0.0443 - classifier_accuracy: 0.0984 - classifier_loss: 0.0047 - loss: 0.1683\n",
      "Epoch 646/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 516ms/step - autoencoder_accuracy: 0.0090 - autoencoder_loss: 0.0443 - classifier_accuracy: 0.0984 - classifier_loss: 0.0047 - loss: 0.1681\n",
      "Epoch 647/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478ms/step - autoencoder_accuracy: 0.0090 - autoencoder_loss: 0.0443 - classifier_accuracy: 0.0985 - classifier_loss: 0.0047 - loss: 0.1679\n",
      "Epoch 648/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 660ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0443 - classifier_accuracy: 0.0985 - classifier_loss: 0.0047 - loss: 0.1677\n",
      "Epoch 649/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 558ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0443 - classifier_accuracy: 0.0986 - classifier_loss: 0.0046 - loss: 0.1675\n",
      "Epoch 650/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 469ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0442 - classifier_accuracy: 0.0986 - classifier_loss: 0.0046 - loss: 0.1674\n",
      "Epoch 651/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 607ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0442 - classifier_accuracy: 0.0986 - classifier_loss: 0.0046 - loss: 0.1672\n",
      "Epoch 652/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 516ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0442 - classifier_accuracy: 0.0987 - classifier_loss: 0.0046 - loss: 0.1670\n",
      "Epoch 653/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0442 - classifier_accuracy: 0.0987 - classifier_loss: 0.0046 - loss: 0.1668\n",
      "Epoch 654/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 653ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0441 - classifier_accuracy: 0.0988 - classifier_loss: 0.0046 - loss: 0.1667\n",
      "Epoch 655/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 527ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0441 - classifier_accuracy: 0.0989 - classifier_loss: 0.0046 - loss: 0.1665\n",
      "Epoch 656/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 483ms/step - autoencoder_accuracy: 0.0090 - autoencoder_loss: 0.0441 - classifier_accuracy: 0.0989 - classifier_loss: 0.0046 - loss: 0.1663\n",
      "Epoch 657/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 642ms/step - autoencoder_accuracy: 0.0090 - autoencoder_loss: 0.0441 - classifier_accuracy: 0.0990 - classifier_loss: 0.0046 - loss: 0.1661\n",
      "Epoch 658/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 529ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0441 - classifier_accuracy: 0.0990 - classifier_loss: 0.0045 - loss: 0.1659\n",
      "Epoch 659/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 534ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0440 - classifier_accuracy: 0.0991 - classifier_loss: 0.0045 - loss: 0.1658\n",
      "Epoch 660/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 636ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0440 - classifier_accuracy: 0.0992 - classifier_loss: 0.0045 - loss: 0.1656\n",
      "Epoch 661/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 552ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0440 - classifier_accuracy: 0.0993 - classifier_loss: 0.0045 - loss: 0.1654\n",
      "Epoch 662/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 599ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0440 - classifier_accuracy: 0.0994 - classifier_loss: 0.0045 - loss: 0.1652\n",
      "Epoch 663/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 538ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0440 - classifier_accuracy: 0.0995 - classifier_loss: 0.0045 - loss: 0.1651\n",
      "Epoch 664/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0439 - classifier_accuracy: 0.0995 - classifier_loss: 0.0045 - loss: 0.1649\n",
      "Epoch 665/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 561ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0439 - classifier_accuracy: 0.0995 - classifier_loss: 0.0045 - loss: 0.1647\n",
      "Epoch 666/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 515ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0439 - classifier_accuracy: 0.0996 - classifier_loss: 0.0045 - loss: 0.1645\n",
      "Epoch 667/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 517ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0439 - classifier_accuracy: 0.0997 - classifier_loss: 0.0044 - loss: 0.1644\n",
      "Epoch 668/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 531ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0438 - classifier_accuracy: 0.0997 - classifier_loss: 0.0044 - loss: 0.1642\n",
      "Epoch 669/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 495ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0438 - classifier_accuracy: 0.0997 - classifier_loss: 0.0044 - loss: 0.1640\n",
      "Epoch 670/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0438 - classifier_accuracy: 0.0997 - classifier_loss: 0.0044 - loss: 0.1638\n",
      "Epoch 671/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0438 - classifier_accuracy: 0.0997 - classifier_loss: 0.0044 - loss: 0.1637\n",
      "Epoch 672/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 510ms/step - autoencoder_accuracy: 0.0090 - autoencoder_loss: 0.0438 - classifier_accuracy: 0.0997 - classifier_loss: 0.0044 - loss: 0.1635\n",
      "Epoch 673/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 599ms/step - autoencoder_accuracy: 0.0090 - autoencoder_loss: 0.0437 - classifier_accuracy: 0.0997 - classifier_loss: 0.0044 - loss: 0.1633\n",
      "Epoch 674/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482ms/step - autoencoder_accuracy: 0.0090 - autoencoder_loss: 0.0437 - classifier_accuracy: 0.0997 - classifier_loss: 0.0044 - loss: 0.1631\n",
      "Epoch 675/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0437 - classifier_accuracy: 0.0997 - classifier_loss: 0.0044 - loss: 0.1630\n",
      "Epoch 676/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 637ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0437 - classifier_accuracy: 0.0997 - classifier_loss: 0.0043 - loss: 0.1628\n",
      "Epoch 677/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 544ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0436 - classifier_accuracy: 0.0997 - classifier_loss: 0.0043 - loss: 0.1626\n",
      "Epoch 678/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 464ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0436 - classifier_accuracy: 0.0997 - classifier_loss: 0.0043 - loss: 0.1624\n",
      "Epoch 679/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 601ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0436 - classifier_accuracy: 0.0997 - classifier_loss: 0.0043 - loss: 0.1623\n",
      "Epoch 680/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475ms/step - autoencoder_accuracy: 0.0090 - autoencoder_loss: 0.0436 - classifier_accuracy: 0.0998 - classifier_loss: 0.0043 - loss: 0.1621\n",
      "Epoch 681/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485ms/step - autoencoder_accuracy: 0.0090 - autoencoder_loss: 0.0436 - classifier_accuracy: 0.0997 - classifier_loss: 0.0043 - loss: 0.1619\n",
      "Epoch 682/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 606ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0435 - classifier_accuracy: 0.0998 - classifier_loss: 0.0043 - loss: 0.1617\n",
      "Epoch 683/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 500ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0435 - classifier_accuracy: 0.0998 - classifier_loss: 0.0043 - loss: 0.1616\n",
      "Epoch 684/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479ms/step - autoencoder_accuracy: 0.0090 - autoencoder_loss: 0.0435 - classifier_accuracy: 0.0998 - classifier_loss: 0.0043 - loss: 0.1614\n",
      "Epoch 685/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 595ms/step - autoencoder_accuracy: 0.0090 - autoencoder_loss: 0.0435 - classifier_accuracy: 0.0999 - classifier_loss: 0.0043 - loss: 0.1612\n",
      "Epoch 686/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 504ms/step - autoencoder_accuracy: 0.0090 - autoencoder_loss: 0.0434 - classifier_accuracy: 0.0998 - classifier_loss: 0.0042 - loss: 0.1611\n",
      "Epoch 687/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 517ms/step - autoencoder_accuracy: 0.0090 - autoencoder_loss: 0.0434 - classifier_accuracy: 0.0998 - classifier_loss: 0.0042 - loss: 0.1609\n",
      "Epoch 688/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 586ms/step - autoencoder_accuracy: 0.0090 - autoencoder_loss: 0.0434 - classifier_accuracy: 0.0998 - classifier_loss: 0.0042 - loss: 0.1607\n",
      "Epoch 689/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0434 - classifier_accuracy: 0.0999 - classifier_loss: 0.0042 - loss: 0.1605\n",
      "Epoch 690/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 515ms/step - autoencoder_accuracy: 0.0092 - autoencoder_loss: 0.0434 - classifier_accuracy: 0.1000 - classifier_loss: 0.0042 - loss: 0.1604\n",
      "Epoch 691/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 585ms/step - autoencoder_accuracy: 0.0092 - autoencoder_loss: 0.0433 - classifier_accuracy: 0.1000 - classifier_loss: 0.0042 - loss: 0.1602\n",
      "Epoch 692/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0433 - classifier_accuracy: 0.1000 - classifier_loss: 0.0042 - loss: 0.1600\n",
      "Epoch 693/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 579ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0433 - classifier_accuracy: 0.1001 - classifier_loss: 0.0042 - loss: 0.1599\n",
      "Epoch 694/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 438ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0433 - classifier_accuracy: 0.1001 - classifier_loss: 0.0042 - loss: 0.1597\n",
      "Epoch 695/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0432 - classifier_accuracy: 0.1001 - classifier_loss: 0.0042 - loss: 0.1595\n",
      "Epoch 696/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 521ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0432 - classifier_accuracy: 0.1002 - classifier_loss: 0.0042 - loss: 0.1593\n",
      "Epoch 697/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 468ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0432 - classifier_accuracy: 0.1002 - classifier_loss: 0.0041 - loss: 0.1592\n",
      "Epoch 698/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0432 - classifier_accuracy: 0.1002 - classifier_loss: 0.0041 - loss: 0.1590\n",
      "Epoch 699/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0432 - classifier_accuracy: 0.1003 - classifier_loss: 0.0041 - loss: 0.1588\n",
      "Epoch 700/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0431 - classifier_accuracy: 0.1003 - classifier_loss: 0.0041 - loss: 0.1587\n",
      "Epoch 701/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 521ms/step - autoencoder_accuracy: 0.0092 - autoencoder_loss: 0.0431 - classifier_accuracy: 0.1003 - classifier_loss: 0.0041 - loss: 0.1585\n",
      "Epoch 702/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475ms/step - autoencoder_accuracy: 0.0092 - autoencoder_loss: 0.0431 - classifier_accuracy: 0.1003 - classifier_loss: 0.0041 - loss: 0.1583\n",
      "Epoch 703/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 546ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0431 - classifier_accuracy: 0.1004 - classifier_loss: 0.0041 - loss: 0.1582\n",
      "Epoch 704/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 563ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0430 - classifier_accuracy: 0.1003 - classifier_loss: 0.0041 - loss: 0.1580\n",
      "Epoch 705/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0430 - classifier_accuracy: 0.1003 - classifier_loss: 0.0041 - loss: 0.1578\n",
      "Epoch 706/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 594ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0430 - classifier_accuracy: 0.1003 - classifier_loss: 0.0041 - loss: 0.1577\n",
      "Epoch 707/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 519ms/step - autoencoder_accuracy: 0.0092 - autoencoder_loss: 0.0430 - classifier_accuracy: 0.1003 - classifier_loss: 0.0041 - loss: 0.1575\n",
      "Epoch 708/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478ms/step - autoencoder_accuracy: 0.0092 - autoencoder_loss: 0.0430 - classifier_accuracy: 0.1003 - classifier_loss: 0.0040 - loss: 0.1573\n",
      "Epoch 709/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 693ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0429 - classifier_accuracy: 0.1004 - classifier_loss: 0.0040 - loss: 0.1572\n",
      "Epoch 710/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 601ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0429 - classifier_accuracy: 0.1003 - classifier_loss: 0.0040 - loss: 0.1570\n",
      "Epoch 711/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 621ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0429 - classifier_accuracy: 0.1003 - classifier_loss: 0.0040 - loss: 0.1568\n",
      "Epoch 712/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 568ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0429 - classifier_accuracy: 0.1003 - classifier_loss: 0.0040 - loss: 0.1567\n",
      "Epoch 713/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 534ms/step - autoencoder_accuracy: 0.0092 - autoencoder_loss: 0.0428 - classifier_accuracy: 0.1002 - classifier_loss: 0.0040 - loss: 0.1565\n",
      "Epoch 714/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0428 - classifier_accuracy: 0.1003 - classifier_loss: 0.0040 - loss: 0.1563\n",
      "Epoch 715/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 593ms/step - autoencoder_accuracy: 0.0092 - autoencoder_loss: 0.0428 - classifier_accuracy: 0.1003 - classifier_loss: 0.0040 - loss: 0.1562\n",
      "Epoch 716/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 509ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0428 - classifier_accuracy: 0.1003 - classifier_loss: 0.0040 - loss: 0.1560\n",
      "Epoch 717/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0428 - classifier_accuracy: 0.1003 - classifier_loss: 0.0040 - loss: 0.1558\n",
      "Epoch 718/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 635ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0427 - classifier_accuracy: 0.1003 - classifier_loss: 0.0040 - loss: 0.1557\n",
      "Epoch 719/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 426ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0427 - classifier_accuracy: 0.1003 - classifier_loss: 0.0040 - loss: 0.1555\n",
      "Epoch 720/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0427 - classifier_accuracy: 0.1003 - classifier_loss: 0.0039 - loss: 0.1553\n",
      "Epoch 721/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 522ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0427 - classifier_accuracy: 0.1004 - classifier_loss: 0.0039 - loss: 0.1552\n",
      "Epoch 722/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0426 - classifier_accuracy: 0.1004 - classifier_loss: 0.0039 - loss: 0.1550\n",
      "Epoch 723/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 497ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0426 - classifier_accuracy: 0.1004 - classifier_loss: 0.0039 - loss: 0.1549\n",
      "Epoch 724/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 581ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0426 - classifier_accuracy: 0.1004 - classifier_loss: 0.0039 - loss: 0.1547\n",
      "Epoch 725/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0426 - classifier_accuracy: 0.1004 - classifier_loss: 0.0039 - loss: 0.1545\n",
      "Epoch 726/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 568ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0426 - classifier_accuracy: 0.1005 - classifier_loss: 0.0039 - loss: 0.1544\n",
      "Epoch 727/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 510ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0425 - classifier_accuracy: 0.1006 - classifier_loss: 0.0039 - loss: 0.1542\n",
      "Epoch 728/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 599ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0425 - classifier_accuracy: 0.1006 - classifier_loss: 0.0039 - loss: 0.1540\n",
      "Epoch 729/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0425 - classifier_accuracy: 0.1006 - classifier_loss: 0.0039 - loss: 0.1539\n",
      "Epoch 730/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488ms/step - autoencoder_accuracy: 0.0092 - autoencoder_loss: 0.0425 - classifier_accuracy: 0.1006 - classifier_loss: 0.0039 - loss: 0.1537\n",
      "Epoch 731/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477ms/step - autoencoder_accuracy: 0.0092 - autoencoder_loss: 0.0425 - classifier_accuracy: 0.1007 - classifier_loss: 0.0039 - loss: 0.1536\n",
      "Epoch 732/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 524ms/step - autoencoder_accuracy: 0.0092 - autoencoder_loss: 0.0424 - classifier_accuracy: 0.1007 - classifier_loss: 0.0038 - loss: 0.1534\n",
      "Epoch 733/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473ms/step - autoencoder_accuracy: 0.0092 - autoencoder_loss: 0.0424 - classifier_accuracy: 0.1008 - classifier_loss: 0.0038 - loss: 0.1532\n",
      "Epoch 734/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 471ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0424 - classifier_accuracy: 0.1008 - classifier_loss: 0.0038 - loss: 0.1531\n",
      "Epoch 735/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 558ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0424 - classifier_accuracy: 0.1008 - classifier_loss: 0.0038 - loss: 0.1529\n",
      "Epoch 736/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 431ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0424 - classifier_accuracy: 0.1007 - classifier_loss: 0.0038 - loss: 0.1527\n",
      "Epoch 737/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 430ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0423 - classifier_accuracy: 0.1007 - classifier_loss: 0.0038 - loss: 0.1526\n",
      "Epoch 738/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0423 - classifier_accuracy: 0.1007 - classifier_loss: 0.0038 - loss: 0.1524\n",
      "Epoch 739/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 358ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0423 - classifier_accuracy: 0.1006 - classifier_loss: 0.0038 - loss: 0.1523\n",
      "Epoch 740/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 571ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0423 - classifier_accuracy: 0.1006 - classifier_loss: 0.0038 - loss: 0.1521\n",
      "Epoch 741/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0423 - classifier_accuracy: 0.1007 - classifier_loss: 0.0038 - loss: 0.1519\n",
      "Epoch 742/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0422 - classifier_accuracy: 0.1007 - classifier_loss: 0.0038 - loss: 0.1518\n",
      "Epoch 743/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 503ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0422 - classifier_accuracy: 0.1007 - classifier_loss: 0.0038 - loss: 0.1516\n",
      "Epoch 744/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0422 - classifier_accuracy: 0.1007 - classifier_loss: 0.0038 - loss: 0.1515\n",
      "Epoch 745/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 574ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0422 - classifier_accuracy: 0.1007 - classifier_loss: 0.0037 - loss: 0.1513\n",
      "Epoch 746/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 622ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0422 - classifier_accuracy: 0.1007 - classifier_loss: 0.0037 - loss: 0.1512\n",
      "Epoch 747/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 520ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0421 - classifier_accuracy: 0.1007 - classifier_loss: 0.0037 - loss: 0.1510\n",
      "Epoch 748/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 586ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0421 - classifier_accuracy: 0.1007 - classifier_loss: 0.0037 - loss: 0.1508\n",
      "Epoch 749/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 500ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0421 - classifier_accuracy: 0.1008 - classifier_loss: 0.0037 - loss: 0.1507\n",
      "Epoch 750/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0421 - classifier_accuracy: 0.1008 - classifier_loss: 0.0037 - loss: 0.1505\n",
      "Epoch 751/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 613ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0421 - classifier_accuracy: 0.1007 - classifier_loss: 0.0037 - loss: 0.1504\n",
      "Epoch 752/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 540ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0421 - classifier_accuracy: 0.1008 - classifier_loss: 0.0037 - loss: 0.1502\n",
      "Epoch 753/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0420 - classifier_accuracy: 0.1007 - classifier_loss: 0.0037 - loss: 0.1501\n",
      "Epoch 754/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479ms/step - autoencoder_accuracy: 0.0095 - autoencoder_loss: 0.0420 - classifier_accuracy: 0.1008 - classifier_loss: 0.0037 - loss: 0.1499\n",
      "Epoch 755/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 510ms/step - autoencoder_accuracy: 0.0095 - autoencoder_loss: 0.0420 - classifier_accuracy: 0.1008 - classifier_loss: 0.0037 - loss: 0.1497\n",
      "Epoch 756/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 553ms/step - autoencoder_accuracy: 0.0095 - autoencoder_loss: 0.0420 - classifier_accuracy: 0.1008 - classifier_loss: 0.0037 - loss: 0.1496\n",
      "Epoch 757/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 516ms/step - autoencoder_accuracy: 0.0095 - autoencoder_loss: 0.0420 - classifier_accuracy: 0.1007 - classifier_loss: 0.0037 - loss: 0.1494\n",
      "Epoch 758/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 568ms/step - autoencoder_accuracy: 0.0095 - autoencoder_loss: 0.0419 - classifier_accuracy: 0.1007 - classifier_loss: 0.0037 - loss: 0.1493\n",
      "Epoch 759/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 527ms/step - autoencoder_accuracy: 0.0095 - autoencoder_loss: 0.0419 - classifier_accuracy: 0.1007 - classifier_loss: 0.0036 - loss: 0.1491\n",
      "Epoch 760/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 371ms/step - autoencoder_accuracy: 0.0095 - autoencoder_loss: 0.0419 - classifier_accuracy: 0.1007 - classifier_loss: 0.0036 - loss: 0.1490\n",
      "Epoch 761/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 506ms/step - autoencoder_accuracy: 0.0095 - autoencoder_loss: 0.0419 - classifier_accuracy: 0.1007 - classifier_loss: 0.0036 - loss: 0.1488\n",
      "Epoch 762/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453ms/step - autoencoder_accuracy: 0.0095 - autoencoder_loss: 0.0419 - classifier_accuracy: 0.1006 - classifier_loss: 0.0036 - loss: 0.1487\n",
      "Epoch 763/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 517ms/step - autoencoder_accuracy: 0.0095 - autoencoder_loss: 0.0419 - classifier_accuracy: 0.1006 - classifier_loss: 0.0036 - loss: 0.1485\n",
      "Epoch 764/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 532ms/step - autoencoder_accuracy: 0.0095 - autoencoder_loss: 0.0418 - classifier_accuracy: 0.1006 - classifier_loss: 0.0036 - loss: 0.1484\n",
      "Epoch 765/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488ms/step - autoencoder_accuracy: 0.0096 - autoencoder_loss: 0.0418 - classifier_accuracy: 0.1006 - classifier_loss: 0.0036 - loss: 0.1482\n",
      "Epoch 766/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 624ms/step - autoencoder_accuracy: 0.0097 - autoencoder_loss: 0.0418 - classifier_accuracy: 0.1006 - classifier_loss: 0.0036 - loss: 0.1480\n",
      "Epoch 767/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473ms/step - autoencoder_accuracy: 0.0096 - autoencoder_loss: 0.0418 - classifier_accuracy: 0.1006 - classifier_loss: 0.0036 - loss: 0.1479\n",
      "Epoch 768/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491ms/step - autoencoder_accuracy: 0.0097 - autoencoder_loss: 0.0418 - classifier_accuracy: 0.1006 - classifier_loss: 0.0036 - loss: 0.1477\n",
      "Epoch 769/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 641ms/step - autoencoder_accuracy: 0.0097 - autoencoder_loss: 0.0417 - classifier_accuracy: 0.1007 - classifier_loss: 0.0036 - loss: 0.1476\n",
      "Epoch 770/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 519ms/step - autoencoder_accuracy: 0.0097 - autoencoder_loss: 0.0417 - classifier_accuracy: 0.1007 - classifier_loss: 0.0036 - loss: 0.1474\n",
      "Epoch 771/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484ms/step - autoencoder_accuracy: 0.0097 - autoencoder_loss: 0.0417 - classifier_accuracy: 0.1006 - classifier_loss: 0.0036 - loss: 0.1473\n",
      "Epoch 772/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 554ms/step - autoencoder_accuracy: 0.0097 - autoencoder_loss: 0.0417 - classifier_accuracy: 0.1006 - classifier_loss: 0.0036 - loss: 0.1471\n",
      "Epoch 773/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452ms/step - autoencoder_accuracy: 0.0098 - autoencoder_loss: 0.0417 - classifier_accuracy: 0.1006 - classifier_loss: 0.0036 - loss: 0.1470\n",
      "Epoch 774/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452ms/step - autoencoder_accuracy: 0.0098 - autoencoder_loss: 0.0417 - classifier_accuracy: 0.1005 - classifier_loss: 0.0035 - loss: 0.1468\n",
      "Epoch 775/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 518ms/step - autoencoder_accuracy: 0.0098 - autoencoder_loss: 0.0416 - classifier_accuracy: 0.1005 - classifier_loss: 0.0035 - loss: 0.1467\n",
      "Epoch 776/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384ms/step - autoencoder_accuracy: 0.0098 - autoencoder_loss: 0.0416 - classifier_accuracy: 0.1005 - classifier_loss: 0.0035 - loss: 0.1465\n",
      "Epoch 777/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 548ms/step - autoencoder_accuracy: 0.0098 - autoencoder_loss: 0.0416 - classifier_accuracy: 0.1005 - classifier_loss: 0.0035 - loss: 0.1464\n",
      "Epoch 778/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455ms/step - autoencoder_accuracy: 0.0098 - autoencoder_loss: 0.0416 - classifier_accuracy: 0.1006 - classifier_loss: 0.0035 - loss: 0.1462\n",
      "Epoch 779/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 565ms/step - autoencoder_accuracy: 0.0098 - autoencoder_loss: 0.0416 - classifier_accuracy: 0.1007 - classifier_loss: 0.0035 - loss: 0.1461\n",
      "Epoch 780/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 502ms/step - autoencoder_accuracy: 0.0098 - autoencoder_loss: 0.0416 - classifier_accuracy: 0.1007 - classifier_loss: 0.0035 - loss: 0.1459\n",
      "Epoch 781/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 508ms/step - autoencoder_accuracy: 0.0098 - autoencoder_loss: 0.0415 - classifier_accuracy: 0.1008 - classifier_loss: 0.0035 - loss: 0.1458\n",
      "Epoch 782/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 590ms/step - autoencoder_accuracy: 0.0098 - autoencoder_loss: 0.0415 - classifier_accuracy: 0.1007 - classifier_loss: 0.0035 - loss: 0.1456\n",
      "Epoch 783/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 442ms/step - autoencoder_accuracy: 0.0098 - autoencoder_loss: 0.0415 - classifier_accuracy: 0.1008 - classifier_loss: 0.0035 - loss: 0.1455\n",
      "Epoch 784/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 531ms/step - autoencoder_accuracy: 0.0098 - autoencoder_loss: 0.0415 - classifier_accuracy: 0.1008 - classifier_loss: 0.0035 - loss: 0.1453\n",
      "Epoch 785/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402ms/step - autoencoder_accuracy: 0.0098 - autoencoder_loss: 0.0415 - classifier_accuracy: 0.1008 - classifier_loss: 0.0035 - loss: 0.1452\n",
      "Epoch 786/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 429ms/step - autoencoder_accuracy: 0.0098 - autoencoder_loss: 0.0415 - classifier_accuracy: 0.1009 - classifier_loss: 0.0035 - loss: 0.1450\n",
      "Epoch 787/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 527ms/step - autoencoder_accuracy: 0.0098 - autoencoder_loss: 0.0414 - classifier_accuracy: 0.1009 - classifier_loss: 0.0035 - loss: 0.1449\n",
      "Epoch 788/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 467ms/step - autoencoder_accuracy: 0.0098 - autoencoder_loss: 0.0414 - classifier_accuracy: 0.1009 - classifier_loss: 0.0035 - loss: 0.1447\n",
      "Epoch 789/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389ms/step - autoencoder_accuracy: 0.0098 - autoencoder_loss: 0.0414 - classifier_accuracy: 0.1009 - classifier_loss: 0.0034 - loss: 0.1446\n",
      "Epoch 790/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 365ms/step - autoencoder_accuracy: 0.0098 - autoencoder_loss: 0.0414 - classifier_accuracy: 0.1009 - classifier_loss: 0.0034 - loss: 0.1444\n",
      "Epoch 791/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490ms/step - autoencoder_accuracy: 0.0098 - autoencoder_loss: 0.0414 - classifier_accuracy: 0.1009 - classifier_loss: 0.0034 - loss: 0.1443\n",
      "Epoch 792/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498ms/step - autoencoder_accuracy: 0.0098 - autoencoder_loss: 0.0414 - classifier_accuracy: 0.1009 - classifier_loss: 0.0034 - loss: 0.1441\n",
      "Epoch 793/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484ms/step - autoencoder_accuracy: 0.0098 - autoencoder_loss: 0.0413 - classifier_accuracy: 0.1010 - classifier_loss: 0.0034 - loss: 0.1440\n",
      "Epoch 794/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384ms/step - autoencoder_accuracy: 0.0097 - autoencoder_loss: 0.0413 - classifier_accuracy: 0.1010 - classifier_loss: 0.0034 - loss: 0.1438\n",
      "Epoch 795/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480ms/step - autoencoder_accuracy: 0.0097 - autoencoder_loss: 0.0413 - classifier_accuracy: 0.1010 - classifier_loss: 0.0034 - loss: 0.1437\n",
      "Epoch 796/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461ms/step - autoencoder_accuracy: 0.0097 - autoencoder_loss: 0.0413 - classifier_accuracy: 0.1010 - classifier_loss: 0.0034 - loss: 0.1435\n",
      "Epoch 797/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 540ms/step - autoencoder_accuracy: 0.0097 - autoencoder_loss: 0.0413 - classifier_accuracy: 0.1010 - classifier_loss: 0.0034 - loss: 0.1434\n",
      "Epoch 798/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481ms/step - autoencoder_accuracy: 0.0098 - autoencoder_loss: 0.0413 - classifier_accuracy: 0.1010 - classifier_loss: 0.0034 - loss: 0.1432\n",
      "Epoch 799/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420ms/step - autoencoder_accuracy: 0.0098 - autoencoder_loss: 0.0412 - classifier_accuracy: 0.1010 - classifier_loss: 0.0034 - loss: 0.1431\n",
      "Epoch 800/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 537ms/step - autoencoder_accuracy: 0.0098 - autoencoder_loss: 0.0412 - classifier_accuracy: 0.1010 - classifier_loss: 0.0034 - loss: 0.1429\n",
      "Epoch 801/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473ms/step - autoencoder_accuracy: 0.0098 - autoencoder_loss: 0.0412 - classifier_accuracy: 0.1010 - classifier_loss: 0.0034 - loss: 0.1428\n",
      "Epoch 802/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394ms/step - autoencoder_accuracy: 0.0097 - autoencoder_loss: 0.0412 - classifier_accuracy: 0.1011 - classifier_loss: 0.0034 - loss: 0.1426\n",
      "Epoch 803/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 520ms/step - autoencoder_accuracy: 0.0097 - autoencoder_loss: 0.0412 - classifier_accuracy: 0.1011 - classifier_loss: 0.0034 - loss: 0.1425\n",
      "Epoch 804/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499ms/step - autoencoder_accuracy: 0.0097 - autoencoder_loss: 0.0412 - classifier_accuracy: 0.1011 - classifier_loss: 0.0033 - loss: 0.1424\n",
      "Epoch 805/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454ms/step - autoencoder_accuracy: 0.0097 - autoencoder_loss: 0.0411 - classifier_accuracy: 0.1012 - classifier_loss: 0.0033 - loss: 0.1422\n",
      "Epoch 806/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 442ms/step - autoencoder_accuracy: 0.0097 - autoencoder_loss: 0.0411 - classifier_accuracy: 0.1012 - classifier_loss: 0.0033 - loss: 0.1421\n",
      "Epoch 807/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 526ms/step - autoencoder_accuracy: 0.0098 - autoencoder_loss: 0.0411 - classifier_accuracy: 0.1012 - classifier_loss: 0.0033 - loss: 0.1419\n",
      "Epoch 808/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 623ms/step - autoencoder_accuracy: 0.0097 - autoencoder_loss: 0.0411 - classifier_accuracy: 0.1013 - classifier_loss: 0.0033 - loss: 0.1418\n",
      "Epoch 809/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491ms/step - autoencoder_accuracy: 0.0097 - autoencoder_loss: 0.0411 - classifier_accuracy: 0.1013 - classifier_loss: 0.0033 - loss: 0.1416\n",
      "Epoch 810/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 563ms/step - autoencoder_accuracy: 0.0098 - autoencoder_loss: 0.0411 - classifier_accuracy: 0.1014 - classifier_loss: 0.0033 - loss: 0.1415\n",
      "Epoch 811/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 518ms/step - autoencoder_accuracy: 0.0097 - autoencoder_loss: 0.0411 - classifier_accuracy: 0.1015 - classifier_loss: 0.0033 - loss: 0.1413\n",
      "Epoch 812/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 608ms/step - autoencoder_accuracy: 0.0098 - autoencoder_loss: 0.0410 - classifier_accuracy: 0.1015 - classifier_loss: 0.0033 - loss: 0.1412\n",
      "Epoch 813/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 654ms/step - autoencoder_accuracy: 0.0098 - autoencoder_loss: 0.0410 - classifier_accuracy: 0.1015 - classifier_loss: 0.0033 - loss: 0.1411\n",
      "Epoch 814/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 540ms/step - autoencoder_accuracy: 0.0098 - autoencoder_loss: 0.0410 - classifier_accuracy: 0.1015 - classifier_loss: 0.0033 - loss: 0.1409\n",
      "Epoch 815/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 501ms/step - autoencoder_accuracy: 0.0098 - autoencoder_loss: 0.0410 - classifier_accuracy: 0.1016 - classifier_loss: 0.0033 - loss: 0.1408\n",
      "Epoch 816/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 526ms/step - autoencoder_accuracy: 0.0097 - autoencoder_loss: 0.0410 - classifier_accuracy: 0.1017 - classifier_loss: 0.0033 - loss: 0.1406\n",
      "Epoch 817/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 535ms/step - autoencoder_accuracy: 0.0097 - autoencoder_loss: 0.0410 - classifier_accuracy: 0.1018 - classifier_loss: 0.0033 - loss: 0.1405\n",
      "Epoch 818/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 603ms/step - autoencoder_accuracy: 0.0097 - autoencoder_loss: 0.0409 - classifier_accuracy: 0.1019 - classifier_loss: 0.0033 - loss: 0.1403\n",
      "Epoch 819/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 523ms/step - autoencoder_accuracy: 0.0097 - autoencoder_loss: 0.0409 - classifier_accuracy: 0.1020 - classifier_loss: 0.0033 - loss: 0.1402\n",
      "Epoch 820/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 527ms/step - autoencoder_accuracy: 0.0097 - autoencoder_loss: 0.0409 - classifier_accuracy: 0.1020 - classifier_loss: 0.0033 - loss: 0.1401\n",
      "Epoch 821/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 543ms/step - autoencoder_accuracy: 0.0097 - autoencoder_loss: 0.0409 - classifier_accuracy: 0.1021 - classifier_loss: 0.0033 - loss: 0.1399\n",
      "Epoch 822/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 615ms/step - autoencoder_accuracy: 0.0096 - autoencoder_loss: 0.0409 - classifier_accuracy: 0.1021 - classifier_loss: 0.0032 - loss: 0.1398\n",
      "Epoch 823/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 584ms/step - autoencoder_accuracy: 0.0096 - autoencoder_loss: 0.0409 - classifier_accuracy: 0.1022 - classifier_loss: 0.0032 - loss: 0.1396\n",
      "Epoch 824/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 536ms/step - autoencoder_accuracy: 0.0096 - autoencoder_loss: 0.0408 - classifier_accuracy: 0.1022 - classifier_loss: 0.0032 - loss: 0.1395\n",
      "Epoch 825/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445ms/step - autoencoder_accuracy: 0.0096 - autoencoder_loss: 0.0408 - classifier_accuracy: 0.1023 - classifier_loss: 0.0032 - loss: 0.1393\n",
      "Epoch 826/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 633ms/step - autoencoder_accuracy: 0.0096 - autoencoder_loss: 0.0408 - classifier_accuracy: 0.1023 - classifier_loss: 0.0032 - loss: 0.1392\n",
      "Epoch 827/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 687ms/step - autoencoder_accuracy: 0.0096 - autoencoder_loss: 0.0408 - classifier_accuracy: 0.1024 - classifier_loss: 0.0032 - loss: 0.1391\n",
      "Epoch 828/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 713ms/step - autoencoder_accuracy: 0.0096 - autoencoder_loss: 0.0408 - classifier_accuracy: 0.1024 - classifier_loss: 0.0032 - loss: 0.1389\n",
      "Epoch 829/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 638ms/step - autoencoder_accuracy: 0.0096 - autoencoder_loss: 0.0408 - classifier_accuracy: 0.1026 - classifier_loss: 0.0032 - loss: 0.1388\n",
      "Epoch 830/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 539ms/step - autoencoder_accuracy: 0.0096 - autoencoder_loss: 0.0408 - classifier_accuracy: 0.1027 - classifier_loss: 0.0032 - loss: 0.1386\n",
      "Epoch 831/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 622ms/step - autoencoder_accuracy: 0.0096 - autoencoder_loss: 0.0407 - classifier_accuracy: 0.1027 - classifier_loss: 0.0032 - loss: 0.1385\n",
      "Epoch 832/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 629ms/step - autoencoder_accuracy: 0.0096 - autoencoder_loss: 0.0407 - classifier_accuracy: 0.1027 - classifier_loss: 0.0032 - loss: 0.1384\n",
      "Epoch 833/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 504ms/step - autoencoder_accuracy: 0.0096 - autoencoder_loss: 0.0407 - classifier_accuracy: 0.1025 - classifier_loss: 0.0032 - loss: 0.1382\n",
      "Epoch 834/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 563ms/step - autoencoder_accuracy: 0.0096 - autoencoder_loss: 0.0407 - classifier_accuracy: 0.1025 - classifier_loss: 0.0032 - loss: 0.1381\n",
      "Epoch 835/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 501ms/step - autoencoder_accuracy: 0.0096 - autoencoder_loss: 0.0407 - classifier_accuracy: 0.1025 - classifier_loss: 0.0032 - loss: 0.1379\n",
      "Epoch 836/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448ms/step - autoencoder_accuracy: 0.0095 - autoencoder_loss: 0.0407 - classifier_accuracy: 0.1025 - classifier_loss: 0.0032 - loss: 0.1378\n",
      "Epoch 837/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 631ms/step - autoencoder_accuracy: 0.0095 - autoencoder_loss: 0.0407 - classifier_accuracy: 0.1025 - classifier_loss: 0.0032 - loss: 0.1377\n",
      "Epoch 838/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 556ms/step - autoencoder_accuracy: 0.0096 - autoencoder_loss: 0.0406 - classifier_accuracy: 0.1025 - classifier_loss: 0.0032 - loss: 0.1375\n",
      "Epoch 839/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496ms/step - autoencoder_accuracy: 0.0096 - autoencoder_loss: 0.0406 - classifier_accuracy: 0.1025 - classifier_loss: 0.0032 - loss: 0.1374\n",
      "Epoch 840/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 587ms/step - autoencoder_accuracy: 0.0096 - autoencoder_loss: 0.0406 - classifier_accuracy: 0.1025 - classifier_loss: 0.0032 - loss: 0.1372\n",
      "Epoch 841/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481ms/step - autoencoder_accuracy: 0.0096 - autoencoder_loss: 0.0406 - classifier_accuracy: 0.1025 - classifier_loss: 0.0031 - loss: 0.1371\n",
      "Epoch 842/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463ms/step - autoencoder_accuracy: 0.0095 - autoencoder_loss: 0.0406 - classifier_accuracy: 0.1024 - classifier_loss: 0.0031 - loss: 0.1370\n",
      "Epoch 843/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 471ms/step - autoencoder_accuracy: 0.0095 - autoencoder_loss: 0.0406 - classifier_accuracy: 0.1024 - classifier_loss: 0.0031 - loss: 0.1368\n",
      "Epoch 844/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384ms/step - autoencoder_accuracy: 0.0095 - autoencoder_loss: 0.0405 - classifier_accuracy: 0.1024 - classifier_loss: 0.0031 - loss: 0.1367\n",
      "Epoch 845/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 497ms/step - autoencoder_accuracy: 0.0095 - autoencoder_loss: 0.0405 - classifier_accuracy: 0.1024 - classifier_loss: 0.0031 - loss: 0.1365\n",
      "Epoch 846/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487ms/step - autoencoder_accuracy: 0.0096 - autoencoder_loss: 0.0405 - classifier_accuracy: 0.1025 - classifier_loss: 0.0031 - loss: 0.1364\n",
      "Epoch 847/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400ms/step - autoencoder_accuracy: 0.0096 - autoencoder_loss: 0.0405 - classifier_accuracy: 0.1024 - classifier_loss: 0.0031 - loss: 0.1363\n",
      "Epoch 848/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 510ms/step - autoencoder_accuracy: 0.0096 - autoencoder_loss: 0.0405 - classifier_accuracy: 0.1023 - classifier_loss: 0.0031 - loss: 0.1361\n",
      "Epoch 849/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499ms/step - autoencoder_accuracy: 0.0096 - autoencoder_loss: 0.0405 - classifier_accuracy: 0.1024 - classifier_loss: 0.0031 - loss: 0.1360\n",
      "Epoch 850/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 351ms/step - autoencoder_accuracy: 0.0096 - autoencoder_loss: 0.0405 - classifier_accuracy: 0.1025 - classifier_loss: 0.0031 - loss: 0.1358\n",
      "Epoch 851/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 511ms/step - autoencoder_accuracy: 0.0095 - autoencoder_loss: 0.0404 - classifier_accuracy: 0.1025 - classifier_loss: 0.0031 - loss: 0.1357\n",
      "Epoch 852/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 508ms/step - autoencoder_accuracy: 0.0095 - autoencoder_loss: 0.0404 - classifier_accuracy: 0.1026 - classifier_loss: 0.0031 - loss: 0.1356\n",
      "Epoch 853/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 361ms/step - autoencoder_accuracy: 0.0095 - autoencoder_loss: 0.0404 - classifier_accuracy: 0.1026 - classifier_loss: 0.0031 - loss: 0.1354\n",
      "Epoch 854/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409ms/step - autoencoder_accuracy: 0.0095 - autoencoder_loss: 0.0404 - classifier_accuracy: 0.1026 - classifier_loss: 0.0031 - loss: 0.1353\n",
      "Epoch 855/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0404 - classifier_accuracy: 0.1026 - classifier_loss: 0.0031 - loss: 0.1352\n",
      "Epoch 856/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 468ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0404 - classifier_accuracy: 0.1026 - classifier_loss: 0.0031 - loss: 0.1350\n",
      "Epoch 857/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 500ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0404 - classifier_accuracy: 0.1026 - classifier_loss: 0.0031 - loss: 0.1349\n",
      "Epoch 858/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 545ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0403 - classifier_accuracy: 0.1027 - classifier_loss: 0.0031 - loss: 0.1348\n",
      "Epoch 859/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 523ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0403 - classifier_accuracy: 0.1026 - classifier_loss: 0.0031 - loss: 0.1346\n",
      "Epoch 860/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 505ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0403 - classifier_accuracy: 0.1026 - classifier_loss: 0.0031 - loss: 0.1345\n",
      "Epoch 861/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 667ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0403 - classifier_accuracy: 0.1025 - classifier_loss: 0.0031 - loss: 0.1343\n",
      "Epoch 862/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 588ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0403 - classifier_accuracy: 0.1025 - classifier_loss: 0.0030 - loss: 0.1342\n",
      "Epoch 863/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 568ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0403 - classifier_accuracy: 0.1025 - classifier_loss: 0.0030 - loss: 0.1341\n",
      "Epoch 864/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 653ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0403 - classifier_accuracy: 0.1025 - classifier_loss: 0.0030 - loss: 0.1339\n",
      "Epoch 865/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 525ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0402 - classifier_accuracy: 0.1025 - classifier_loss: 0.0030 - loss: 0.1338\n",
      "Epoch 866/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0402 - classifier_accuracy: 0.1025 - classifier_loss: 0.0030 - loss: 0.1337\n",
      "Epoch 867/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 608ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0402 - classifier_accuracy: 0.1024 - classifier_loss: 0.0030 - loss: 0.1335\n",
      "Epoch 868/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 512ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0402 - classifier_accuracy: 0.1024 - classifier_loss: 0.0030 - loss: 0.1334\n",
      "Epoch 869/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393ms/step - autoencoder_accuracy: 0.0092 - autoencoder_loss: 0.0402 - classifier_accuracy: 0.1025 - classifier_loss: 0.0030 - loss: 0.1333\n",
      "Epoch 870/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 560ms/step - autoencoder_accuracy: 0.0092 - autoencoder_loss: 0.0402 - classifier_accuracy: 0.1025 - classifier_loss: 0.0030 - loss: 0.1331\n",
      "Epoch 871/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 501ms/step - autoencoder_accuracy: 0.0092 - autoencoder_loss: 0.0402 - classifier_accuracy: 0.1024 - classifier_loss: 0.0030 - loss: 0.1330\n",
      "Epoch 872/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374ms/step - autoencoder_accuracy: 0.0092 - autoencoder_loss: 0.0401 - classifier_accuracy: 0.1023 - classifier_loss: 0.0030 - loss: 0.1329\n",
      "Epoch 873/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 551ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0401 - classifier_accuracy: 0.1025 - classifier_loss: 0.0030 - loss: 0.1327\n",
      "Epoch 874/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 554ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0401 - classifier_accuracy: 0.1025 - classifier_loss: 0.0030 - loss: 0.1326\n",
      "Epoch 875/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 598ms/step - autoencoder_accuracy: 0.0092 - autoencoder_loss: 0.0401 - classifier_accuracy: 0.1025 - classifier_loss: 0.0030 - loss: 0.1325\n",
      "Epoch 876/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493ms/step - autoencoder_accuracy: 0.0092 - autoencoder_loss: 0.0401 - classifier_accuracy: 0.1024 - classifier_loss: 0.0030 - loss: 0.1323\n",
      "Epoch 877/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 467ms/step - autoencoder_accuracy: 0.0092 - autoencoder_loss: 0.0401 - classifier_accuracy: 0.1024 - classifier_loss: 0.0030 - loss: 0.1322\n",
      "Epoch 878/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459ms/step - autoencoder_accuracy: 0.0092 - autoencoder_loss: 0.0401 - classifier_accuracy: 0.1024 - classifier_loss: 0.0030 - loss: 0.1321\n",
      "Epoch 879/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 503ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0400 - classifier_accuracy: 0.1025 - classifier_loss: 0.0030 - loss: 0.1319\n",
      "Epoch 880/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 545ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0400 - classifier_accuracy: 0.1025 - classifier_loss: 0.0030 - loss: 0.1318\n",
      "Epoch 881/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 524ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0400 - classifier_accuracy: 0.1024 - classifier_loss: 0.0030 - loss: 0.1317\n",
      "Epoch 882/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0400 - classifier_accuracy: 0.1024 - classifier_loss: 0.0030 - loss: 0.1315\n",
      "Epoch 883/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 552ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0400 - classifier_accuracy: 0.1024 - classifier_loss: 0.0030 - loss: 0.1314\n",
      "Epoch 884/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 515ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0400 - classifier_accuracy: 0.1023 - classifier_loss: 0.0029 - loss: 0.1313\n",
      "Epoch 885/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0400 - classifier_accuracy: 0.1023 - classifier_loss: 0.0029 - loss: 0.1311\n",
      "Epoch 886/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 502ms/step - autoencoder_accuracy: 0.0090 - autoencoder_loss: 0.0399 - classifier_accuracy: 0.1023 - classifier_loss: 0.0029 - loss: 0.1310\n",
      "Epoch 887/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496ms/step - autoencoder_accuracy: 0.0090 - autoencoder_loss: 0.0399 - classifier_accuracy: 0.1023 - classifier_loss: 0.0029 - loss: 0.1309\n",
      "Epoch 888/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 417ms/step - autoencoder_accuracy: 0.0090 - autoencoder_loss: 0.0399 - classifier_accuracy: 0.1023 - classifier_loss: 0.0029 - loss: 0.1307\n",
      "Epoch 889/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 551ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0399 - classifier_accuracy: 0.1022 - classifier_loss: 0.0029 - loss: 0.1306\n",
      "Epoch 890/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 508ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0399 - classifier_accuracy: 0.1022 - classifier_loss: 0.0029 - loss: 0.1305\n",
      "Epoch 891/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 527ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0399 - classifier_accuracy: 0.1023 - classifier_loss: 0.0029 - loss: 0.1303\n",
      "Epoch 892/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 571ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0399 - classifier_accuracy: 0.1022 - classifier_loss: 0.0029 - loss: 0.1302\n",
      "Epoch 893/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 635ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0398 - classifier_accuracy: 0.1023 - classifier_loss: 0.0029 - loss: 0.1301\n",
      "Epoch 894/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0398 - classifier_accuracy: 0.1023 - classifier_loss: 0.0029 - loss: 0.1300\n",
      "Epoch 895/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 553ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0398 - classifier_accuracy: 0.1024 - classifier_loss: 0.0029 - loss: 0.1298\n",
      "Epoch 896/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 526ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0398 - classifier_accuracy: 0.1022 - classifier_loss: 0.0029 - loss: 0.1297\n",
      "Epoch 897/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0398 - classifier_accuracy: 0.1023 - classifier_loss: 0.0029 - loss: 0.1296\n",
      "Epoch 898/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0398 - classifier_accuracy: 0.1024 - classifier_loss: 0.0029 - loss: 0.1294\n",
      "Epoch 899/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0398 - classifier_accuracy: 0.1025 - classifier_loss: 0.0029 - loss: 0.1293\n",
      "Epoch 900/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 528ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0397 - classifier_accuracy: 0.1025 - classifier_loss: 0.0029 - loss: 0.1292\n",
      "Epoch 901/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 647ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0397 - classifier_accuracy: 0.1025 - classifier_loss: 0.0029 - loss: 0.1290\n",
      "Epoch 902/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 580ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0397 - classifier_accuracy: 0.1025 - classifier_loss: 0.0029 - loss: 0.1289\n",
      "Epoch 903/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 605ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0397 - classifier_accuracy: 0.1025 - classifier_loss: 0.0029 - loss: 0.1288\n",
      "Epoch 904/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 568ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0397 - classifier_accuracy: 0.1026 - classifier_loss: 0.0029 - loss: 0.1287\n",
      "Epoch 905/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 597ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0397 - classifier_accuracy: 0.1025 - classifier_loss: 0.0029 - loss: 0.1285\n",
      "Epoch 906/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 593ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0397 - classifier_accuracy: 0.1025 - classifier_loss: 0.0029 - loss: 0.1284\n",
      "Epoch 907/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 534ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0397 - classifier_accuracy: 0.1026 - classifier_loss: 0.0029 - loss: 0.1283\n",
      "Epoch 908/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 617ms/step - autoencoder_accuracy: 0.0086 - autoencoder_loss: 0.0396 - classifier_accuracy: 0.1027 - classifier_loss: 0.0029 - loss: 0.1281\n",
      "Epoch 909/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 543ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0396 - classifier_accuracy: 0.1027 - classifier_loss: 0.0029 - loss: 0.1280\n",
      "Epoch 910/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 368ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0396 - classifier_accuracy: 0.1027 - classifier_loss: 0.0029 - loss: 0.1279\n",
      "Epoch 911/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 595ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0396 - classifier_accuracy: 0.1027 - classifier_loss: 0.0028 - loss: 0.1278\n",
      "Epoch 912/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 516ms/step - autoencoder_accuracy: 0.0086 - autoencoder_loss: 0.0396 - classifier_accuracy: 0.1027 - classifier_loss: 0.0028 - loss: 0.1276\n",
      "Epoch 913/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0396 - classifier_accuracy: 0.1027 - classifier_loss: 0.0028 - loss: 0.1275\n",
      "Epoch 914/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 602ms/step - autoencoder_accuracy: 0.0086 - autoencoder_loss: 0.0396 - classifier_accuracy: 0.1028 - classifier_loss: 0.0028 - loss: 0.1274\n",
      "Epoch 915/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411ms/step - autoencoder_accuracy: 0.0086 - autoencoder_loss: 0.0395 - classifier_accuracy: 0.1027 - classifier_loss: 0.0028 - loss: 0.1273\n",
      "Epoch 916/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 596ms/step - autoencoder_accuracy: 0.0086 - autoencoder_loss: 0.0395 - classifier_accuracy: 0.1027 - classifier_loss: 0.0028 - loss: 0.1271\n",
      "Epoch 917/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409ms/step - autoencoder_accuracy: 0.0086 - autoencoder_loss: 0.0395 - classifier_accuracy: 0.1026 - classifier_loss: 0.0028 - loss: 0.1270\n",
      "Epoch 918/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 569ms/step - autoencoder_accuracy: 0.0086 - autoencoder_loss: 0.0395 - classifier_accuracy: 0.1025 - classifier_loss: 0.0028 - loss: 0.1269\n",
      "Epoch 919/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484ms/step - autoencoder_accuracy: 0.0086 - autoencoder_loss: 0.0395 - classifier_accuracy: 0.1025 - classifier_loss: 0.0028 - loss: 0.1267\n",
      "Epoch 920/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487ms/step - autoencoder_accuracy: 0.0086 - autoencoder_loss: 0.0395 - classifier_accuracy: 0.1026 - classifier_loss: 0.0028 - loss: 0.1266\n",
      "Epoch 921/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 577ms/step - autoencoder_accuracy: 0.0086 - autoencoder_loss: 0.0395 - classifier_accuracy: 0.1026 - classifier_loss: 0.0028 - loss: 0.1265\n",
      "Epoch 922/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 542ms/step - autoencoder_accuracy: 0.0086 - autoencoder_loss: 0.0395 - classifier_accuracy: 0.1026 - classifier_loss: 0.0028 - loss: 0.1264\n",
      "Epoch 923/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 440ms/step - autoencoder_accuracy: 0.0086 - autoencoder_loss: 0.0394 - classifier_accuracy: 0.1026 - classifier_loss: 0.0028 - loss: 0.1262\n",
      "Epoch 924/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 542ms/step - autoencoder_accuracy: 0.0086 - autoencoder_loss: 0.0394 - classifier_accuracy: 0.1025 - classifier_loss: 0.0028 - loss: 0.1261\n",
      "Epoch 925/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456ms/step - autoencoder_accuracy: 0.0086 - autoencoder_loss: 0.0394 - classifier_accuracy: 0.1025 - classifier_loss: 0.0028 - loss: 0.1260\n",
      "Epoch 926/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 584ms/step - autoencoder_accuracy: 0.0086 - autoencoder_loss: 0.0394 - classifier_accuracy: 0.1024 - classifier_loss: 0.0028 - loss: 0.1258\n",
      "Epoch 927/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420ms/step - autoencoder_accuracy: 0.0086 - autoencoder_loss: 0.0394 - classifier_accuracy: 0.1023 - classifier_loss: 0.0028 - loss: 0.1257\n",
      "Epoch 928/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 586ms/step - autoencoder_accuracy: 0.0086 - autoencoder_loss: 0.0394 - classifier_accuracy: 0.1023 - classifier_loss: 0.0028 - loss: 0.1256\n",
      "Epoch 929/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466ms/step - autoencoder_accuracy: 0.0085 - autoencoder_loss: 0.0394 - classifier_accuracy: 0.1024 - classifier_loss: 0.0028 - loss: 0.1255\n",
      "Epoch 930/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 517ms/step - autoencoder_accuracy: 0.0086 - autoencoder_loss: 0.0393 - classifier_accuracy: 0.1025 - classifier_loss: 0.0028 - loss: 0.1253\n",
      "Epoch 931/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 500ms/step - autoencoder_accuracy: 0.0085 - autoencoder_loss: 0.0393 - classifier_accuracy: 0.1027 - classifier_loss: 0.0028 - loss: 0.1252\n",
      "Epoch 932/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 529ms/step - autoencoder_accuracy: 0.0086 - autoencoder_loss: 0.0393 - classifier_accuracy: 0.1027 - classifier_loss: 0.0028 - loss: 0.1251\n",
      "Epoch 933/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 580ms/step - autoencoder_accuracy: 0.0085 - autoencoder_loss: 0.0393 - classifier_accuracy: 0.1026 - classifier_loss: 0.0028 - loss: 0.1250\n",
      "Epoch 934/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480ms/step - autoencoder_accuracy: 0.0085 - autoencoder_loss: 0.0393 - classifier_accuracy: 0.1025 - classifier_loss: 0.0027 - loss: 0.1248\n",
      "Epoch 935/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 662ms/step - autoencoder_accuracy: 0.0085 - autoencoder_loss: 0.0393 - classifier_accuracy: 0.1025 - classifier_loss: 0.0027 - loss: 0.1247\n",
      "Epoch 936/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 583ms/step - autoencoder_accuracy: 0.0086 - autoencoder_loss: 0.0393 - classifier_accuracy: 0.1025 - classifier_loss: 0.0027 - loss: 0.1246\n",
      "Epoch 937/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492ms/step - autoencoder_accuracy: 0.0086 - autoencoder_loss: 0.0393 - classifier_accuracy: 0.1025 - classifier_loss: 0.0027 - loss: 0.1245\n",
      "Epoch 938/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 538ms/step - autoencoder_accuracy: 0.0086 - autoencoder_loss: 0.0392 - classifier_accuracy: 0.1025 - classifier_loss: 0.0027 - loss: 0.1243\n",
      "Epoch 939/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 511ms/step - autoencoder_accuracy: 0.0085 - autoencoder_loss: 0.0392 - classifier_accuracy: 0.1024 - classifier_loss: 0.0027 - loss: 0.1242\n",
      "Epoch 940/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 559ms/step - autoencoder_accuracy: 0.0085 - autoencoder_loss: 0.0392 - classifier_accuracy: 0.1024 - classifier_loss: 0.0027 - loss: 0.1241\n",
      "Epoch 941/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474ms/step - autoencoder_accuracy: 0.0085 - autoencoder_loss: 0.0392 - classifier_accuracy: 0.1024 - classifier_loss: 0.0027 - loss: 0.1240\n",
      "Epoch 942/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388ms/step - autoencoder_accuracy: 0.0086 - autoencoder_loss: 0.0392 - classifier_accuracy: 0.1024 - classifier_loss: 0.0027 - loss: 0.1238\n",
      "Epoch 943/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 574ms/step - autoencoder_accuracy: 0.0086 - autoencoder_loss: 0.0392 - classifier_accuracy: 0.1024 - classifier_loss: 0.0027 - loss: 0.1237\n",
      "Epoch 944/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490ms/step - autoencoder_accuracy: 0.0086 - autoencoder_loss: 0.0392 - classifier_accuracy: 0.1024 - classifier_loss: 0.0027 - loss: 0.1236\n",
      "Epoch 945/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 501ms/step - autoencoder_accuracy: 0.0086 - autoencoder_loss: 0.0391 - classifier_accuracy: 0.1024 - classifier_loss: 0.0027 - loss: 0.1235\n",
      "Epoch 946/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 524ms/step - autoencoder_accuracy: 0.0086 - autoencoder_loss: 0.0391 - classifier_accuracy: 0.1023 - classifier_loss: 0.0027 - loss: 0.1233\n",
      "Epoch 947/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 501ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0391 - classifier_accuracy: 0.1023 - classifier_loss: 0.0027 - loss: 0.1232\n",
      "Epoch 948/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 544ms/step - autoencoder_accuracy: 0.0086 - autoencoder_loss: 0.0391 - classifier_accuracy: 0.1023 - classifier_loss: 0.0027 - loss: 0.1231\n",
      "Epoch 949/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 561ms/step - autoencoder_accuracy: 0.0086 - autoencoder_loss: 0.0391 - classifier_accuracy: 0.1023 - classifier_loss: 0.0027 - loss: 0.1230\n",
      "Epoch 950/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473ms/step - autoencoder_accuracy: 0.0086 - autoencoder_loss: 0.0391 - classifier_accuracy: 0.1023 - classifier_loss: 0.0027 - loss: 0.1229\n",
      "Epoch 951/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 549ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0391 - classifier_accuracy: 0.1023 - classifier_loss: 0.0027 - loss: 0.1227\n",
      "Epoch 952/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 573ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0391 - classifier_accuracy: 0.1023 - classifier_loss: 0.0027 - loss: 0.1226\n",
      "Epoch 953/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0390 - classifier_accuracy: 0.1023 - classifier_loss: 0.0027 - loss: 0.1225\n",
      "Epoch 954/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 405ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0390 - classifier_accuracy: 0.1023 - classifier_loss: 0.0027 - loss: 0.1224\n",
      "Epoch 955/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 554ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0390 - classifier_accuracy: 0.1023 - classifier_loss: 0.0027 - loss: 0.1222\n",
      "Epoch 956/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0390 - classifier_accuracy: 0.1023 - classifier_loss: 0.0027 - loss: 0.1221\n",
      "Epoch 957/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 522ms/step - autoencoder_accuracy: 0.0086 - autoencoder_loss: 0.0390 - classifier_accuracy: 0.1023 - classifier_loss: 0.0027 - loss: 0.1220\n",
      "Epoch 958/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 603ms/step - autoencoder_accuracy: 0.0086 - autoencoder_loss: 0.0390 - classifier_accuracy: 0.1024 - classifier_loss: 0.0027 - loss: 0.1219\n",
      "Epoch 959/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 529ms/step - autoencoder_accuracy: 0.0086 - autoencoder_loss: 0.0390 - classifier_accuracy: 0.1023 - classifier_loss: 0.0027 - loss: 0.1218\n",
      "Epoch 960/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 468ms/step - autoencoder_accuracy: 0.0086 - autoencoder_loss: 0.0389 - classifier_accuracy: 0.1023 - classifier_loss: 0.0026 - loss: 0.1216\n",
      "Epoch 961/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 560ms/step - autoencoder_accuracy: 0.0086 - autoencoder_loss: 0.0389 - classifier_accuracy: 0.1023 - classifier_loss: 0.0026 - loss: 0.1215\n",
      "Epoch 962/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 612ms/step - autoencoder_accuracy: 0.0086 - autoencoder_loss: 0.0389 - classifier_accuracy: 0.1023 - classifier_loss: 0.0026 - loss: 0.1214\n",
      "Epoch 963/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 523ms/step - autoencoder_accuracy: 0.0086 - autoencoder_loss: 0.0389 - classifier_accuracy: 0.1023 - classifier_loss: 0.0026 - loss: 0.1213\n",
      "Epoch 964/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 610ms/step - autoencoder_accuracy: 0.0086 - autoencoder_loss: 0.0389 - classifier_accuracy: 0.1023 - classifier_loss: 0.0026 - loss: 0.1211\n",
      "Epoch 965/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 542ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0389 - classifier_accuracy: 0.1023 - classifier_loss: 0.0026 - loss: 0.1210\n",
      "Epoch 966/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 590ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0389 - classifier_accuracy: 0.1023 - classifier_loss: 0.0026 - loss: 0.1209\n",
      "Epoch 967/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 546ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0389 - classifier_accuracy: 0.1023 - classifier_loss: 0.0026 - loss: 0.1208\n",
      "Epoch 968/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 437ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0388 - classifier_accuracy: 0.1022 - classifier_loss: 0.0026 - loss: 0.1207\n",
      "Epoch 969/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0388 - classifier_accuracy: 0.1022 - classifier_loss: 0.0026 - loss: 0.1205\n",
      "Epoch 970/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 543ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0388 - classifier_accuracy: 0.1022 - classifier_loss: 0.0026 - loss: 0.1204\n",
      "Epoch 971/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 567ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0388 - classifier_accuracy: 0.1022 - classifier_loss: 0.0026 - loss: 0.1203\n",
      "Epoch 972/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 510ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0388 - classifier_accuracy: 0.1022 - classifier_loss: 0.0026 - loss: 0.1202\n",
      "Epoch 973/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 619ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0388 - classifier_accuracy: 0.1022 - classifier_loss: 0.0026 - loss: 0.1201\n",
      "Epoch 974/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 639ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0388 - classifier_accuracy: 0.1021 - classifier_loss: 0.0026 - loss: 0.1199\n",
      "Epoch 975/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 566ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0387 - classifier_accuracy: 0.1021 - classifier_loss: 0.0026 - loss: 0.1198\n",
      "Epoch 976/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 575ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0387 - classifier_accuracy: 0.1021 - classifier_loss: 0.0026 - loss: 0.1197\n",
      "Epoch 977/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 557ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0387 - classifier_accuracy: 0.1022 - classifier_loss: 0.0026 - loss: 0.1196\n",
      "Epoch 978/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 576ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0387 - classifier_accuracy: 0.1022 - classifier_loss: 0.0026 - loss: 0.1195\n",
      "Epoch 979/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 529ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0387 - classifier_accuracy: 0.1022 - classifier_loss: 0.0026 - loss: 0.1193\n",
      "Epoch 980/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 539ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0387 - classifier_accuracy: 0.1022 - classifier_loss: 0.0026 - loss: 0.1192\n",
      "Epoch 981/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 558ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0387 - classifier_accuracy: 0.1022 - classifier_loss: 0.0026 - loss: 0.1191\n",
      "Epoch 982/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 514ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0387 - classifier_accuracy: 0.1021 - classifier_loss: 0.0026 - loss: 0.1190\n",
      "Epoch 983/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 525ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0386 - classifier_accuracy: 0.1021 - classifier_loss: 0.0026 - loss: 0.1189\n",
      "Epoch 984/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 538ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0386 - classifier_accuracy: 0.1021 - classifier_loss: 0.0026 - loss: 0.1188\n",
      "Epoch 985/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0386 - classifier_accuracy: 0.1020 - classifier_loss: 0.0026 - loss: 0.1186\n",
      "Epoch 986/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 513ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0386 - classifier_accuracy: 0.1020 - classifier_loss: 0.0026 - loss: 0.1185\n",
      "Epoch 987/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0386 - classifier_accuracy: 0.1020 - classifier_loss: 0.0026 - loss: 0.1184\n",
      "Epoch 988/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 592ms/step - autoencoder_accuracy: 0.0086 - autoencoder_loss: 0.0386 - classifier_accuracy: 0.1020 - classifier_loss: 0.0026 - loss: 0.1183\n",
      "Epoch 989/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 533ms/step - autoencoder_accuracy: 0.0086 - autoencoder_loss: 0.0386 - classifier_accuracy: 0.1021 - classifier_loss: 0.0026 - loss: 0.1182\n",
      "Epoch 990/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 435ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0385 - classifier_accuracy: 0.1021 - classifier_loss: 0.0025 - loss: 0.1180\n",
      "Epoch 991/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 566ms/step - autoencoder_accuracy: 0.0086 - autoencoder_loss: 0.0385 - classifier_accuracy: 0.1021 - classifier_loss: 0.0025 - loss: 0.1179\n",
      "Epoch 992/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 535ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0385 - classifier_accuracy: 0.1021 - classifier_loss: 0.0025 - loss: 0.1178\n",
      "Epoch 993/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 570ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0385 - classifier_accuracy: 0.1021 - classifier_loss: 0.0025 - loss: 0.1177\n",
      "Epoch 994/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 514ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0385 - classifier_accuracy: 0.1022 - classifier_loss: 0.0025 - loss: 0.1176\n",
      "Epoch 995/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0385 - classifier_accuracy: 0.1022 - classifier_loss: 0.0025 - loss: 0.1175\n",
      "Epoch 996/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 552ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0385 - classifier_accuracy: 0.1022 - classifier_loss: 0.0025 - loss: 0.1173\n",
      "Epoch 997/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 501ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0385 - classifier_accuracy: 0.1022 - classifier_loss: 0.0025 - loss: 0.1172\n",
      "Epoch 998/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 581ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0384 - classifier_accuracy: 0.1022 - classifier_loss: 0.0025 - loss: 0.1171\n",
      "Epoch 999/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 637ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0384 - classifier_accuracy: 0.1022 - classifier_loss: 0.0025 - loss: 0.1170\n",
      "Epoch 1000/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 524ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0384 - classifier_accuracy: 0.1022 - classifier_loss: 0.0025 - loss: 0.1169\n"
     ]
    }
   ],
   "source": [
    "# TODO: Crea y entrena tu clasificador\n",
    "\n",
    "model = MiClasificadorSemisupervisado(input_shape=x_train[0].shape)\n",
    "\n",
    "h = semisupervised_training_v2(model, x_train, one_hot_train, unlabeled_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "id": "JSVVW8fZXWGs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 318 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x345c25d00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n",
      "Test accuracy : 0.816\n"
     ]
    }
   ],
   "source": [
    "# TODO: Obtén la precisión sobre el conjunto de test\n",
    "print('Test accuracy :', model.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "index = 32\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "axes[0].imshow(x_test[index].reshape(28, 28), cmap='gray')\n",
    "axes[0].set_title(\"Original Image\")\n",
    "axes[0].axis('off') \n",
    "\n",
    "# Get the reconstructed image from the autoencoder\n",
    "reconstructed_image, label = model(x_test[index].reshape(1, 784))\n",
    "\n",
    "# Plot the reconstructed image on the right\n",
    "axes[1].imshow(reconstructed_image.reshape(28, 28), cmap='gray')\n",
    "axes[1].set_title(f\"Reconstructed Image, predicted {np.argmax(label)}\")\n",
    "axes[1].axis('off')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(h.history['classifier_accuracy'], label='Classifier Accuracy')\n",
    "plt.plot(h.history['autoencoder_accuracy'], label='Autoencoder Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mPGRXmHXptYW"
   },
   "source": [
    "# Hay vida más allá del autoencoder\n",
    "\n",
    "¿Has probado a utilizar otro método distinto del autoencoder para obtener una respresentación similar a la salida del encoder? La idea es la siguiente:\n",
    "\n",
    "1. Define un modelo $model$ convolucional similar al encoder de un autoencoder (la entrada es el tamaño de la imagen, la salida el vector de representación)\n",
    "1. Define una capa de salida $cluster$ que, partiendo de la salida de model, nos devuelva una salida con el mismo número de clases que el dataset a utilizar (la entrada es el vector de representación), usando softmax como activación de salida\n",
    "1. Para cada batch de entrenamiento $X$:  # Usa un batch alto, mínimo 128\n",
    "  1. Modifica las imágenes de entrada con [data_augmentation](https://www.tensorflow.org/tutorials/images/data_augmentation?hl=es-419), llámala $augX_1$.\n",
    "  1. Modifica otra vez las imágenes de entrada con [data_augmentation_2](https://www.tensorflow.org/tutorials/images/data_augmentation?hl=es-419), llámala $augX_2$.\n",
    "  1. $augX_{1comp} \\leftarrow model(augX_1)$\n",
    "  1. $augX_{2comp} \\leftarrow model(augX_2)$\n",
    "  1. $cX_{1comp} \\leftarrow cluster(augX_{1comp})$\n",
    "  1. $cX_{2comp} \\leftarrow cluster(augX_{2comp})$\n",
    "  1. $M \\leftarrow augX_{1comp} ~ augX_{2comp}^T$\n",
    "  1. $loss_C \\leftarrow cX_{1comp}(1 - cX_{1comp}) + cX_{2comp}(1 - cX_{2comp})$ # Puede que tengas que crear tu [propia función de coste](https://keras.io/api/losses/#creating-custom-losses)\n",
    "  1. $loss_M \\leftarrow crossentropy(I, softmax(M/\\tau, axis=1)))$ # Puede que tengas que crear tu [propia función de coste](https://keras.io/api/losses/#creating-custom-losses)\n",
    "  1. $\\tau$ es un hiperparámetro que se suele definir a 5.0\n",
    "  1. $loss \\leftarrow loss_M + \\lambda~loss_C$\n",
    "    1. $\\lambda$ es un hiperparámetro (puedes probar con 0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "7cXegrUWtiFW"
   },
   "outputs": [],
   "source": [
    "# Escribe aquí la solución. Crea tantos bloques de código como necesites. Puedes utilizar la siguiente red para generar distorsiones\n",
    "\n",
    "\n",
    "class ContrastiveLoss():\n",
    "    def __init__(self, temperature=0.5):\n",
    "        self.temperature = temperature\n",
    "        \n",
    "    def __call__(self, M):\n",
    "        # y_true es la matriz identidad (no la usamos directamente)\n",
    "        # y_pred es la matriz de similitud M\n",
    "        \n",
    "        # Aplicamos softmax con temperatura\n",
    "        logits = M / self.temperature\n",
    "        logits_max = tf.reduce_max(logits, axis=1, keepdims=True)\n",
    "        logits = logits - logits_max\n",
    "        exp_logits = tf.exp(logits)\n",
    "        exp_logits_sum = tf.reduce_sum(exp_logits, axis=1, keepdims=True)\n",
    "        probs = exp_logits / exp_logits_sum # softmax\n",
    "        \n",
    "        # Creamos matriz identidad como objetivo\n",
    "        batch_size = tf.shape(M)[0]\n",
    "        I = tf.eye(batch_size)\n",
    "\n",
    "        # Seleccionamos las probabilidades de la clase correcta (diagonal de y_true)\n",
    "        correct_class_probs = tf.matmul(I, probs)   \n",
    "        # Calculamos entropia cruzada\n",
    "        loss = -tf.reduce_mean(tf.math.log(correct_class_probs + 1e-10))\n",
    "        \n",
    "        return loss\n",
    "\n",
    "# Función de pérdida para el clustering\n",
    "class ClusteringLoss():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def __call__(self, cX_1comp, cX_2comp):\n",
    "\n",
    "        # loss_C = cX_1comp(1 - cX_1comp) + cX_2comp(1 - cX_2comp)\n",
    "        loss_1 = tf.reduce_mean(cX_1comp * (1 - cX_1comp))\n",
    "        loss_2 = tf.reduce_mean(cX_2comp * (1 - cX_2comp))\n",
    "        \n",
    "        return loss_1 + loss_2\n",
    "\n",
    "\n",
    "class ContrastiveModel():\n",
    "    def __init__(self, input_shape, lambda_param = 0.5, temperature = 0.5, learning_rate=0.0005):\n",
    "\n",
    "        self.lambda_param = lambda_param\n",
    "        self.contrastive_loss = ContrastiveLoss(temperature=temperature)\n",
    "        self.clustering_loss = ClusteringLoss()\n",
    "        self.optimicer = tf.keras.optimizers.AdamW(\n",
    "            learning_rate=learning_rate,\n",
    "            clipnorm=1,\n",
    "        )\n",
    "\n",
    "        self.data_augmentation_1 = tf.keras.models.Sequential([\n",
    "                # tf.keras.layers.RandomFlip(\"horizontal\"),  # Puede ser util en otros casos\n",
    "                tf.keras.layers.RandomRotation(0.05),\n",
    "                tf.keras.layers.RandomTranslation(0.15, 0.15),\n",
    "                tf.keras.layers.RandomZoom(.15),\n",
    "            ])\n",
    "    \n",
    "        self.data_augmentation_2 = tf.keras.models.Sequential([\n",
    "                # tf.keras.layers.RandomFlip(\"horizontal\"),  # Puede ser util en otros casos\n",
    "                tf.keras.layers.RandomTranslation(0.15, 0.15),\n",
    "                tf.keras.layers.RandomRotation(.2)\n",
    "                #tf.keras.layers.Resizing(40, 40), # para CIFAR, para MNIST usar 40 en lugar de 48\n",
    "                #tf.keras.layers.RandomCrop(28, 28), # para CIFAR, para MNIST usar 28 en lugar de 32\n",
    "            ])\n",
    "            \n",
    "        # Definir modelo convolucional\n",
    "        input_layer = tf.keras.layers.Input(batch_shape=(None, 28, 28,1))  # Tamaño de imagen\n",
    "        conv_layer = tf.keras.layers.Conv2D(8, (3, 3), activation='relu')(input_layer)\n",
    "        conv_layer = tf.keras.layers.Conv2D(8, (3, 3), activation='relu')(conv_layer)\n",
    "        conv_layer = tf.keras.layers.Conv2D(8, (3, 3), activation='relu')(conv_layer)\n",
    "        conv_layer = tf.keras.layers.Conv2D(16, (3, 3), activation='relu')(conv_layer)\n",
    "        conv_layer = tf.keras.layers.Conv2D(32, (3, 3), activation='relu')(conv_layer)\n",
    "        flatten_layer = tf.keras.layers.Flatten()(conv_layer)\n",
    "        \n",
    "        # Capa de clustering\n",
    "        cluster_layer = tf.keras.layers.Dense(10, activation='softmax')(flatten_layer)\n",
    "        \n",
    "        # Modelo final\n",
    "        self.encoder = tf.keras.Model(input_layer, outputs=flatten_layer)\n",
    "        self.cluster = tf.keras.Model(flatten_layer, outputs=cluster_layer)\n",
    "        \n",
    "        #model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    \n",
    "    def train_step(self, data):\n",
    "        if isinstance(data, tuple):\n",
    "            X = data[0]\n",
    "        else:\n",
    "            X = data\n",
    "            \n",
    "        batch_size = tf.shape(X)[0]\n",
    "        \n",
    "        # Aplicar las dos transformaciones de data augmentation\n",
    "        augX_1 = self.data_augmentation_1(X)\n",
    "        augX_2 = self.data_augmentation_2(X)\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            #print(f'< 1 {augX_1.shape}, 2 {augX_2.shape}')\n",
    "            # Obtener representaciones del encoder\n",
    "            augX_1comp = self.encoder(augX_1)\n",
    "            #augX_1comp = self.encoder(X)\n",
    "            augX_2comp = self.encoder(augX_2)\n",
    "            #augX_2comp = self.encoder(X)\n",
    "            #print(f'<< 1 {augX_1comp.shape}, 2 {augX_2comp.shape}')\n",
    "            # Obtener salidas del clustering\n",
    "            #augX_1comp = tf.keras.layers.Flatten('channels_last')(augX_1comp)\n",
    "            cX_1comp = self.cluster(augX_1comp)\n",
    "            cX_2comp = self.cluster(augX_2comp)\n",
    "\n",
    "            \n",
    "            # Calcular matriz de similitud M\n",
    "            M = tf.matmul(augX_1comp, augX_2comp, transpose_b=True)\n",
    "            #print(f'm {M.shape}, 1 {augX_1comp.shape}, 2 {augX_2comp.shape}')\n",
    "            \n",
    "            plt.imshow(M.numpy())\n",
    "            \n",
    "            # Calcular pérdida de contraste\n",
    "            loss_M = self.contrastive_loss(M)\n",
    "            \n",
    "            # Calcular pérdida de clustering\n",
    "            loss_C = self.clustering_loss(cX_1comp, cX_2comp)\n",
    "            \n",
    "            # Pérdida total\n",
    "            total_loss = loss_M + self.lambda_param * loss_C\n",
    "            \n",
    "        # Calcular gradientes y actualizar pesos\n",
    "        gradients = tape.gradient(total_loss, self.cluster.trainable_variables)\n",
    "        self.optimicer.apply_gradients(zip(gradients, self.cluster.trainable_variables))\n",
    "        \n",
    "        return {\"loss\": total_loss, \"contrastive_loss\": loss_M, \"clustering_loss\": loss_C}\n",
    "\n",
    "    def mini_batches(self, X, batch_size):\n",
    "        for start in range(0, X.shape[0], batch_size):\n",
    "            # Yield each mini-batch\n",
    "            end = min(start + batch_size, X.shape[0])\n",
    "            yield X[start:end]\n",
    "\n",
    "    def train(self, dataset, epochs=10, batch_size=128):\n",
    "        for epoch in range(epochs):\n",
    "            total_loss = 0\n",
    "            for data in self.mini_batches(dataset, batch_size=batch_size):\n",
    "                loss_dict = self.train_step(data)\n",
    "                total_loss += loss_dict[\"loss\"]\n",
    "            \n",
    "           \n",
    "            print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss_dict[\"loss\"]}\")\n",
    "\n",
    "    def __call__(self, X):\n",
    "        return self.encoder.predict(X), self.clusters.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastiveLoss():\n",
    "    def __init__(self, temperature=0.5):\n",
    "        self.temperature = temperature\n",
    "        \n",
    "    def __call__(self, M):\n",
    "        # y_true es la matriz identidad (no la usamos directamente)\n",
    "        # y_pred es la matriz de similitud M\n",
    "        \n",
    "        # Aplicamos softmax con temperatura\n",
    "        logits = M / self.temperature\n",
    "        logits_max = tf.reduce_max(logits, axis=1, keepdims=True)\n",
    "        logits = logits - logits_max\n",
    "        exp_logits = tf.exp(logits)\n",
    "        exp_logits_sum = tf.reduce_sum(exp_logits, axis=1, keepdims=True)\n",
    "        probs = exp_logits / exp_logits_sum # softmax\n",
    "        \n",
    "        # Creamos matriz identidad como objetivo\n",
    "        batch_size = tf.shape(M)[0]\n",
    "        I = tf.eye(batch_size)\n",
    "        # Seleccionamos las probabilidades de la clase correcta (diagonal de y_true)\n",
    "        correct_class_probs = tf.matmul(I, probs)   \n",
    "        # Calculamos entropia cruzada\n",
    "        loss = -tf.reduce_mean(tf.math.log(correct_class_probs + 1e-10))\n",
    "        \n",
    "        return loss\n",
    "\n",
    "# Función de pérdida para el clustering\n",
    "class ClusteringLoss():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def __call__(self, cX_1comp, cX_2comp):\n",
    "        # loss_C = cX_1comp(1 - cX_1comp) + cX_2comp(1 - cX_2comp)\n",
    "        loss_1 = tf.reduce_mean(cX_1comp * (1 - cX_1comp))\n",
    "        loss_2 = tf.reduce_mean(cX_2comp * (1 - cX_2comp))\n",
    "        \n",
    "        return loss_1 + loss_2\n",
    "\n",
    "class ContrastiveModel():\n",
    "    def __init__(self, input_shape, lambda_param = 0.5, temperature = 0.5, learning_rate=0.0005):\n",
    "        self.lambda_param = lambda_param\n",
    "        self.contrastive_loss = ContrastiveLoss(temperature=temperature)\n",
    "        self.clustering_loss = ClusteringLoss()\n",
    "        self.optimicer = tf.keras.optimizers.AdamW(\n",
    "            learning_rate=learning_rate,\n",
    "            clipnorm=1,\n",
    "        )\n",
    "        self.data_augmentation_1 = tf.keras.models.Sequential([\n",
    "                # tf.keras.layers.RandomFlip(\"horizontal\"),  # Puede ser util en otros casos\n",
    "                tf.keras.layers.RandomRotation(0.05),\n",
    "                tf.keras.layers.RandomTranslation(0.15, 0.15),\n",
    "                tf.keras.layers.RandomZoom(.15),\n",
    "            ])\n",
    "    \n",
    "        self.data_augmentation_2 = tf.keras.models.Sequential([\n",
    "                # tf.keras.layers.RandomFlip(\"horizontal\"),  # Puede ser util en otros casos\n",
    "                tf.keras.layers.RandomTranslation(0.15, 0.15),\n",
    "                tf.keras.layers.RandomRotation(.2),\n",
    "                tf.keras.layers.Resizing(40, 40), # para CIFAR, para MNIST usar 40 en lugar de 48\n",
    "                tf.keras.layers.RandomCrop(28, 28), # para CIFAR, para MNIST usar 28 en lugar de 32\n",
    "            ])\n",
    "            \n",
    "        # Definir modelo convolucional\n",
    "        input_layer = tf.keras.layers.Input(batch_shape=(None, 28, 28,1))  # Tamaño de imagen\n",
    "        conv_layer = tf.keras.layers.Conv2D(8, (3, 3), activation='relu')(input_layer)\n",
    "        conv_layer = tf.keras.layers.Conv2D(8, (3, 3), activation='relu')(conv_layer)\n",
    "        conv_layer = tf.keras.layers.Conv2D(8, (3, 3), activation='relu')(conv_layer)\n",
    "        conv_layer = tf.keras.layers.Conv2D(16, (3, 3), activation='relu')(conv_layer)\n",
    "        conv_layer = tf.keras.layers.Conv2D(32, (3, 3), activation='relu')(conv_layer)\n",
    "        flatten_layer = tf.keras.layers.Flatten()(conv_layer)\n",
    "        \n",
    "        # Capa de clustering\n",
    "        cluster_layer = tf.keras.layers.Dense(10, activation='softmax')(flatten_layer)\n",
    "        \n",
    "        # Modelo final\n",
    "        self.encoder = tf.keras.Model(input_layer, outputs=flatten_layer)\n",
    "        self.cluster = tf.keras.Model(flatten_layer, outputs=cluster_layer)\n",
    "        \n",
    "        # Historial de pérdidas para graficar\n",
    "        self.loss_history = {\n",
    "            'total_loss': [],\n",
    "            'contrastive_loss': [],\n",
    "            'clustering_loss': []\n",
    "        }\n",
    "        \n",
    "        #model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    def train_step(self, data):\n",
    "        if isinstance(data, tuple):\n",
    "            X = data[0]\n",
    "        else:\n",
    "            X = data\n",
    "            \n",
    "        batch_size = tf.shape(X)[0]\n",
    "        \n",
    "        # Aplicar las dos transformaciones de data augmentation\n",
    "        augX_1 = self.data_augmentation_1(X)\n",
    "        augX_2 = self.data_augmentation_2(X)\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            #print(f'< 1 {augX_1.shape}, 2 {augX_2.shape}')\n",
    "            # Obtener representaciones del encoder\n",
    "            augX_1comp = self.encoder(augX_1)\n",
    "            #augX_1comp = self.encoder(X)\n",
    "            augX_2comp = self.encoder(augX_2)\n",
    "            #augX_2comp = self.encoder(X)\n",
    "            #print(f'<< 1 {augX_1comp.shape}, 2 {augX_2comp.shape}')\n",
    "            # Obtener salidas del clustering\n",
    "            #augX_1comp = tf.keras.layers.Flatten('channels_last')(augX_1comp)\n",
    "            cX_1comp = self.cluster(augX_1comp)\n",
    "            cX_2comp = self.cluster(augX_2comp)\n",
    "            \n",
    "            # Calcular matriz de similitud M\n",
    "            M = tf.matmul(augX_1comp, augX_2comp, transpose_b=True)\n",
    "            #print(f'm {M.shape}, 1 {augX_1comp.shape}, 2 {augX_2comp.shape}')\n",
    "            \n",
    "            # Calcular pérdida de contraste\n",
    "            loss_M = self.contrastive_loss(M)\n",
    "            \n",
    "            # Calcular pérdida de clustering\n",
    "            loss_C = self.clustering_loss(cX_1comp, cX_2comp)\n",
    "            \n",
    "            # Pérdida total\n",
    "            total_loss = loss_M + self.lambda_param * loss_C\n",
    "            \n",
    "        # Calcular gradientes y actualizar pesos\n",
    "        gradients = tape.gradient(total_loss, self.encoder.trainable_variables + self.cluster.trainable_variables)\n",
    "        self.optimicer.apply_gradients(zip(gradients, self.encoder.trainable_variables + self.cluster.trainable_variables))\n",
    "        \n",
    "        return {\"loss\": total_loss, \"contrastive_loss\": loss_M, \"clustering_loss\": loss_C}\n",
    "    \n",
    "    def mini_batches(self, X, batch_size):\n",
    "        for start in range(0, X.shape[0], batch_size):\n",
    "            # Yield each mini-batch\n",
    "            end = min(start + batch_size, X.shape[0])\n",
    "            yield X[start:end]\n",
    "    \n",
    "    def train(self, dataset, epochs=10, batch_size=128):\n",
    "        # Reiniciar el historial de pérdida si comenzamos un nuevo entrenamiento\n",
    "        self.loss_history = {\n",
    "            'total_loss': [],\n",
    "            'contrastive_loss': [],\n",
    "            'clustering_loss': []\n",
    "        }\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            epoch_total_loss = 0\n",
    "            epoch_contrastive_loss = 0\n",
    "            epoch_clustering_loss = 0\n",
    "            batch_count = 0\n",
    "            \n",
    "            for data in self.mini_batches(dataset, batch_size=batch_size):\n",
    "                loss_dict = self.train_step(data)\n",
    "                epoch_total_loss += loss_dict[\"loss\"]\n",
    "                epoch_contrastive_loss += loss_dict[\"contrastive_loss\"]\n",
    "                epoch_clustering_loss += loss_dict[\"clustering_loss\"]\n",
    "                batch_count += 1\n",
    "            \n",
    "            # Calcular promedios para la época\n",
    "            avg_total_loss = epoch_total_loss / batch_count\n",
    "            avg_contrastive_loss = epoch_contrastive_loss / batch_count\n",
    "            avg_clustering_loss = epoch_clustering_loss / batch_count\n",
    "            \n",
    "            # Guardar en el historial\n",
    "            self.loss_history['total_loss'].append(avg_total_loss.numpy())\n",
    "            self.loss_history['contrastive_loss'].append(avg_contrastive_loss.numpy())\n",
    "            self.loss_history['clustering_loss'].append(avg_clustering_loss.numpy())\n",
    "            \n",
    "            print(f\"Epoch {epoch+1}/{epochs}, Total Loss: {avg_total_loss:.4f}, \"\n",
    "                  f\"Contrastive Loss: {avg_contrastive_loss:.4f}, \"\n",
    "                  f\"Clustering Loss: {avg_clustering_loss:.4f}\")\n",
    "    \n",
    "    def plot_training_history(self, figsize=(12, 6)):\n",
    "        \"\"\"\n",
    "        Visualiza el historial de pérdidas durante el entrenamiento.\n",
    "        \"\"\"\n",
    "        import matplotlib.pyplot as plt\n",
    "        \n",
    "        epochs = range(1, len(self.loss_history['total_loss']) + 1)\n",
    "        \n",
    "        plt.figure(figsize=figsize)\n",
    "        \n",
    "        # Gráfico de pérdida total\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(epochs, self.loss_history['total_loss'], 'b-', label='Total Loss')\n",
    "        plt.title('Total Loss')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        \n",
    "        # Gráfico comparativo de pérdidas\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(epochs, self.loss_history['contrastive_loss'], 'r-', label='Contrastive Loss')\n",
    "        plt.plot(epochs, self.loss_history['clustering_loss'], 'g-', label='Clustering Loss')\n",
    "        plt.title('Component Losses')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def __call__(self, X):\n",
    "        features = self.encoder(X)\n",
    "        clusters = self.cluster(features)\n",
    "        return features, clusters\n",
    "\n",
    "    def plot_similarity_matrix(self, X, n_samples=10):\n",
    "        \"\"\"\n",
    "        Visualiza la matriz de similitud para un conjunto de muestras.\n",
    "        \"\"\"\n",
    "        import matplotlib.pyplot as plt\n",
    "        import numpy as np\n",
    "        \n",
    "        # Seleccionar n_samples aleatorias\n",
    "        if n_samples < X.shape[0]:\n",
    "            indices = np.random.choice(X.shape[0], n_samples, replace=False)\n",
    "            samples = X[indices]\n",
    "        else:\n",
    "            samples = X\n",
    "            \n",
    "        # Aplicar data augmentation\n",
    "        augX_1 = self.data_augmentation_1(samples)\n",
    "        augX_2 = self.data_augmentation_2(samples)\n",
    "        \n",
    "        # Obtener representaciones\n",
    "        augX_1comp = self.encoder(augX_1)\n",
    "        augX_2comp = self.encoder(augX_2)\n",
    "        \n",
    "        # Calcular matriz de similitud\n",
    "        M = tf.matmul(augX_1comp, augX_2comp, transpose_b=True).numpy()\n",
    "        \n",
    "        # Visualizar\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.imshow(M, cmap='viridis')\n",
    "        plt.colorbar()\n",
    "        plt.title('Similarity Matrix')\n",
    "        plt.xlabel('Augmentation 2')\n",
    "        plt.ylabel('Augmentation 1')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_data = 0.01 # Vamos a usar el etiquetado de sólo el 1% de los datos\n",
    "np.random.seed(42)\n",
    "\n",
    "(x_train, y_train), (x_test, y_test), = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "indexes = np.arange(len(x_train))\n",
    "np.random.shuffle(indexes)\n",
    "ntrain_data = int(labeled_data*len(x_train))\n",
    "unlabeled_train = x_train[indexes[ntrain_data:]]\n",
    "x_train = x_train[indexes[:ntrain_data]] \n",
    "y_train = y_train[indexes[:ntrain_data]]\n",
    "\n",
    "\n",
    "# TODO: Haz el preprocesado que necesites aquí (si lo necesitas)\n",
    "\n",
    "x_train = x_train /255\n",
    "x_test = x_test /255\n",
    "unlabeled_train = unlabeled_train /255\n",
    "\n",
    "one_hot_train = np.zeros((y_train.size, len(set(y_train))), dtype=int)\n",
    "one_hot_train[np.arange(y_train.size), y_train ] = 1\n",
    "\n",
    "one_hot_test = np.zeros((y_test.size, len(set(y_test))), dtype=int)\n",
    "one_hot_test[np.arange(y_test.size), y_test ] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Total Loss: 12.3638, Contrastive Loss: 3.3655, Clustering Loss: 0.1800\n",
      "Epoch 2/20, Total Loss: 12.3147, Contrastive Loss: 3.3334, Clustering Loss: 0.1796\n",
      "Epoch 3/20, Total Loss: 11.9474, Contrastive Loss: 3.3784, Clustering Loss: 0.1714\n",
      "Epoch 4/20, Total Loss: 11.1642, Contrastive Loss: 3.3793, Clustering Loss: 0.1557\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[32m/var/folders/1l/sdrz_tw104ld922_w0xnl5840000gn/T/ipykernel_17635/2097438596.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      1\u001b[39m cModel = ContrastiveModel(unlabeled_train[\u001b[32m0\u001b[39m].shape, learning_rate=\u001b[32m0.0001\u001b[39m, lambda_param=\u001b[32m50\u001b[39m)\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m#unlabeled_train = np.expand_dims(unlabeled_train, axis=-1)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m cModel.train(unlabeled_train, epochs=\u001b[32m20\u001b[39m, batch_size=\u001b[32m2048\u001b[39m)\n\u001b[32m      4\u001b[39m cModel.plot_training_history()\n",
      "\u001b[32m/var/folders/1l/sdrz_tw104ld922_w0xnl5840000gn/T/ipykernel_17635/898483491.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, dataset, epochs, batch_size)\u001b[39m\n\u001b[32m    148\u001b[39m             epoch_clustering_loss = \u001b[32m0\u001b[39m\n\u001b[32m    149\u001b[39m             batch_count = \u001b[32m0\u001b[39m\n\u001b[32m    150\u001b[39m \n\u001b[32m    151\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;28;01min\u001b[39;00m self.mini_batches(dataset, batch_size=batch_size):\n\u001b[32m--> \u001b[39m\u001b[32m152\u001b[39m                 loss_dict = self.train_step(data)\n\u001b[32m    153\u001b[39m                 epoch_total_loss += loss_dict[\u001b[33m\"loss\"\u001b[39m]\n\u001b[32m    154\u001b[39m                 epoch_contrastive_loss += loss_dict[\u001b[33m\"contrastive_loss\"\u001b[39m]\n\u001b[32m    155\u001b[39m                 epoch_clustering_loss += loss_dict[\u001b[33m\"clustering_loss\"\u001b[39m]\n",
      "\u001b[32m/var/folders/1l/sdrz_tw104ld922_w0xnl5840000gn/T/ipykernel_17635/898483491.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m     93\u001b[39m         batch_size = tf.shape(X)[\u001b[32m0\u001b[39m]\n\u001b[32m     94\u001b[39m \n\u001b[32m     95\u001b[39m         \u001b[38;5;66;03m# Aplicar las dos transformaciones de data augmentation\u001b[39;00m\n\u001b[32m     96\u001b[39m         augX_1 = self.data_augmentation_1(X)\n\u001b[32m---> \u001b[39m\u001b[32m97\u001b[39m         augX_2 = self.data_augmentation_2(X)\n\u001b[32m     98\u001b[39m \n\u001b[32m     99\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m tf.GradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[32m    100\u001b[39m             \u001b[38;5;66;03m#print(f'< 1 {augX_1.shape}, 2 {augX_2.shape}')\u001b[39;00m\n",
      "\u001b[32m~/carrera/3/2/ma2/ma2Python12/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    120\u001b[39m             \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m             \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m    122\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m         \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m             \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[32m~/carrera/3/2/ma2/ma2Python12/lib/python3.12/site-packages/keras/src/layers/layer.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    944\u001b[39m                     \u001b[33m\"layers will not see the mask.\"\u001b[39m\n\u001b[32m    945\u001b[39m                 )\n\u001b[32m    946\u001b[39m         \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    947\u001b[39m             \u001b[38;5;66;03m# Destroy call context if we created it\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m948\u001b[39m             self._maybe_reset_call_context()\n\u001b[32m    949\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "\u001b[32m~/carrera/3/2/ma2/ma2Python12/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    120\u001b[39m             \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m             \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m    122\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m         \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m             \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[32m~/carrera/3/2/ma2/ma2Python12/lib/python3.12/site-packages/keras/src/ops/operation.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     48\u001b[39m             call_fn = traceback_utils.inject_argument_info_in_traceback(\n\u001b[32m     49\u001b[39m                 call_fn,\n\u001b[32m     50\u001b[39m                 object_name=(f\"{self.__class__.__name__}.call()\"),\n\u001b[32m     51\u001b[39m             )\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m call_fn(*args, **kwargs)\n\u001b[32m     53\u001b[39m \n\u001b[32m     54\u001b[39m         \u001b[38;5;66;03m# Plain flow.\u001b[39;00m\n\u001b[32m     55\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m any_symbolic_tensors(args, kwargs):\n",
      "\u001b[32m~/carrera/3/2/ma2/ma2Python12/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    213\u001b[39m                 new_e = e\n\u001b[32m    214\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m new_e.with_traceback(e.__traceback__) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    215\u001b[39m         \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    216\u001b[39m             \u001b[38;5;28;01mdel\u001b[39;00m signature\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m             \u001b[38;5;28;01mdel\u001b[39;00m bound_signature\n",
      "\u001b[32m~/carrera/3/2/ma2/ma2Python12/lib/python3.12/site-packages/keras/src/models/sequential.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, inputs, training, mask)\u001b[39m\n\u001b[32m    219\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m call(self, inputs, training=\u001b[38;5;28;01mNone\u001b[39;00m, mask=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    220\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m self._functional:\n\u001b[32m--> \u001b[39m\u001b[32m221\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m self._functional.call(inputs, training=training, mask=mask)\n\u001b[32m    222\u001b[39m \n\u001b[32m    223\u001b[39m         \u001b[38;5;66;03m# Fallback: Just apply the layer sequence.\u001b[39;00m\n\u001b[32m    224\u001b[39m         \u001b[38;5;66;03m# This typically happens if `inputs` is a nested struct.\u001b[39;00m\n",
      "\u001b[32m~/carrera/3/2/ma2/ma2Python12/lib/python3.12/site-packages/keras/src/models/functional.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, inputs, training, mask)\u001b[39m\n\u001b[32m    179\u001b[39m             masks = tree.flatten(mask)\n\u001b[32m    180\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m x, mask \u001b[38;5;28;01min\u001b[39;00m zip(inputs, masks):\n\u001b[32m    181\u001b[39m                 \u001b[38;5;28;01mif\u001b[39;00m mask \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    182\u001b[39m                     backend.set_keras_mask(x, mask)\n\u001b[32m--> \u001b[39m\u001b[32m183\u001b[39m         outputs = self._run_through_graph(\n\u001b[32m    184\u001b[39m             inputs, operation_fn=\u001b[38;5;28;01mlambda\u001b[39;00m op: operation_fn(op, training=training)\n\u001b[32m    185\u001b[39m         )\n\u001b[32m    186\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m unpack_singleton(outputs)\n",
      "\u001b[32m~/carrera/3/2/ma2/ma2Python12/lib/python3.12/site-packages/keras/src/ops/function.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, inputs, operation_fn, call_fn)\u001b[39m\n\u001b[32m    167\u001b[39m                 op = operation_fn(node.operation)\n\u001b[32m    168\u001b[39m                 \u001b[38;5;28;01mif\u001b[39;00m call_fn \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    169\u001b[39m                     outputs = call_fn(op, *args, **kwargs)\n\u001b[32m    170\u001b[39m                 \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m171\u001b[39m                     outputs = op(*args, **kwargs)\n\u001b[32m    172\u001b[39m \n\u001b[32m    173\u001b[39m                 \u001b[38;5;66;03m# Update tensor_dict.\u001b[39;00m\n\u001b[32m    174\u001b[39m                 \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;28;01min\u001b[39;00m zip(node.outputs, tree.flatten(outputs)):\n",
      "\u001b[32m~/carrera/3/2/ma2/ma2Python12/lib/python3.12/site-packages/keras/src/models/functional.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    639\u001b[39m             \u001b[38;5;28;01mand\u001b[39;00m operation._call_has_training_arg\n\u001b[32m    640\u001b[39m             \u001b[38;5;28;01mand\u001b[39;00m training \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    641\u001b[39m         ):\n\u001b[32m    642\u001b[39m             kwargs[\u001b[33m\"training\"\u001b[39m] = training\n\u001b[32m--> \u001b[39m\u001b[32m643\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m operation(*args, **kwargs)\n",
      "\u001b[32m~/carrera/3/2/ma2/ma2Python12/lib/python3.12/site-packages/keras/src/layers/preprocessing/tf_data_layer.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, inputs, **kwargs)\u001b[39m\n\u001b[32m     45\u001b[39m                 self.backend.reset()\n\u001b[32m     46\u001b[39m                 \u001b[38;5;28;01mif\u001b[39;00m switch_convert_input_args:\n\u001b[32m     47\u001b[39m                     self._convert_input_args = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     48\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m super().__call__(inputs, **kwargs)\n",
      "\u001b[32m~/carrera/3/2/ma2/ma2Python12/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    120\u001b[39m             \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m             \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m    122\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m         \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m             \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[32m~/carrera/3/2/ma2/ma2Python12/lib/python3.12/site-packages/keras/src/layers/layer.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    944\u001b[39m                     \u001b[33m\"layers will not see the mask.\"\u001b[39m\n\u001b[32m    945\u001b[39m                 )\n\u001b[32m    946\u001b[39m         \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    947\u001b[39m             \u001b[38;5;66;03m# Destroy call context if we created it\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m948\u001b[39m             self._maybe_reset_call_context()\n\u001b[32m    949\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "\u001b[32m~/carrera/3/2/ma2/ma2Python12/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    120\u001b[39m             \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m             \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m    122\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m         \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m             \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[32m~/carrera/3/2/ma2/ma2Python12/lib/python3.12/site-packages/keras/src/ops/operation.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     48\u001b[39m             call_fn = traceback_utils.inject_argument_info_in_traceback(\n\u001b[32m     49\u001b[39m                 call_fn,\n\u001b[32m     50\u001b[39m                 object_name=(f\"{self.__class__.__name__}.call()\"),\n\u001b[32m     51\u001b[39m             )\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m call_fn(*args, **kwargs)\n\u001b[32m     53\u001b[39m \n\u001b[32m     54\u001b[39m         \u001b[38;5;66;03m# Plain flow.\u001b[39;00m\n\u001b[32m     55\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m any_symbolic_tensors(args, kwargs):\n",
      "\u001b[32m~/carrera/3/2/ma2/ma2Python12/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    213\u001b[39m                 new_e = e\n\u001b[32m    214\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m new_e.with_traceback(e.__traceback__) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    215\u001b[39m         \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    216\u001b[39m             \u001b[38;5;28;01mdel\u001b[39;00m signature\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m             \u001b[38;5;28;01mdel\u001b[39;00m bound_signature\n",
      "\u001b[32m~/carrera/3/2/ma2/ma2Python12/lib/python3.12/site-packages/keras/src/layers/preprocessing/image_preprocessing/base_image_preprocessing_layer.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, data, training)\u001b[39m\n\u001b[32m    131\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m call(self, data, training=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m132\u001b[39m         transformation = self.get_random_transformation(data, training=training)\n\u001b[32m    133\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m isinstance(data, dict):\n\u001b[32m    134\u001b[39m             is_batched = self._is_batched(data[\u001b[33m\"images\"\u001b[39m])\n\u001b[32m    135\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m is_batched:\n",
      "\u001b[32m~/carrera/3/2/ma2/ma2Python12/lib/python3.12/site-packages/keras/src/layers/preprocessing/image_preprocessing/random_rotation.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, data, training, seed)\u001b[39m\n\u001b[32m    216\u001b[39m             translate_x=ops.numpy.zeros([batch_size]),\n\u001b[32m    217\u001b[39m             translate_y=ops.numpy.zeros([batch_size]),\n\u001b[32m    218\u001b[39m             scale=ops.numpy.ones([batch_size]),\n\u001b[32m    219\u001b[39m             shear_x=ops.numpy.zeros([batch_size]),\n\u001b[32m--> \u001b[39m\u001b[32m220\u001b[39m             shear_y=ops.numpy.zeros([batch_size]),\n\u001b[32m    221\u001b[39m             height=image_height,\n\u001b[32m    222\u001b[39m             width=image_width,\n\u001b[32m    223\u001b[39m         )\n",
      "\u001b[32m~/carrera/3/2/ma2/ma2Python12/lib/python3.12/site-packages/keras/src/backend/tensorflow/numpy.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(shape, dtype)\u001b[39m\n\u001b[32m    707\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m zeros(shape, dtype=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    708\u001b[39m     dtype = dtype \u001b[38;5;28;01mor\u001b[39;00m config.floatx()\n\u001b[32m--> \u001b[39m\u001b[32m709\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m tf.zeros(shape, dtype=dtype)\n",
      "\u001b[32m~/carrera/3/2/ma2/ma2Python12/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    151\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m Exception \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m       filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    153\u001b[39m       \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    154\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m       \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[32m~/carrera/3/2/ma2/ma2Python12/lib/python3.12/site-packages/tensorflow/python/util/dispatch.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   1257\u001b[39m \n\u001b[32m   1258\u001b[39m       \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[32m   1259\u001b[39m       \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1260\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m dispatch_target(*args, **kwargs)\n\u001b[32m-> \u001b[39m\u001b[32m1261\u001b[39m       \u001b[38;5;28;01mexcept\u001b[39;00m (TypeError, ValueError):\n\u001b[32m   1262\u001b[39m         \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[32m   1263\u001b[39m         \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[32m   1264\u001b[39m         result = dispatch(op_dispatch_handler, args, kwargs)\n",
      "\u001b[32m~/carrera/3/2/ma2/ma2Python12/lib/python3.12/site-packages/tensorflow/python/ops/array_ops.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   2557\u001b[39m   \u001b[38;5;28;01mdef\u001b[39;00m wrapped(*args, **kwargs):\n\u001b[32m-> \u001b[39m\u001b[32m2558\u001b[39m     tensor = fun(*args, **kwargs)\n\u001b[32m   2559\u001b[39m     tensor._is_zeros_tensor = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   2560\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m tensor\n",
      "\u001b[32m~/carrera/3/2/ma2/ma2Python12/lib/python3.12/site-packages/tensorflow/python/ops/array_ops.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(shape, dtype, name, layout)\u001b[39m\n\u001b[32m   2618\u001b[39m         \u001b[38;5;66;03m# Happens when shape is a list with tensor elements\u001b[39;00m\n\u001b[32m   2619\u001b[39m         shape = ops.convert_to_tensor(shape, dtype=dtypes.int32)\n\u001b[32m   2620\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m shape._shape_tuple():\n\u001b[32m   2621\u001b[39m       shape = reshape(shape, [-\u001b[32m1\u001b[39m])  \u001b[38;5;66;03m# Ensure it's a vector\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2622\u001b[39m     output = fill(shape, constant(zero, dtype=dtype), name=name, layout=layout)\n\u001b[32m   2623\u001b[39m   \u001b[38;5;28;01massert\u001b[39;00m output.dtype.base_dtype == dtype\n\u001b[32m   2624\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "\u001b[32m~/carrera/3/2/ma2/ma2Python12/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    151\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m Exception \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m       filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    153\u001b[39m       \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    154\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m       \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[32m~/carrera/3/2/ma2/ma2Python12/lib/python3.12/site-packages/tensorflow/python/util/dispatch.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   1257\u001b[39m \n\u001b[32m   1258\u001b[39m       \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[32m   1259\u001b[39m       \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1260\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m dispatch_target(*args, **kwargs)\n\u001b[32m-> \u001b[39m\u001b[32m1261\u001b[39m       \u001b[38;5;28;01mexcept\u001b[39;00m (TypeError, ValueError):\n\u001b[32m   1262\u001b[39m         \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[32m   1263\u001b[39m         \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[32m   1264\u001b[39m         result = dispatch(op_dispatch_handler, args, kwargs)\n",
      "\u001b[32m~/carrera/3/2/ma2/ma2Python12/lib/python3.12/site-packages/tensorflow/python/ops/array_ops.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(dims, value, name, layout)\u001b[39m\n\u001b[32m    242\u001b[39m   number argument \u001b[38;5;28;01mas\u001b[39;00m the shape (`np.full(\u001b[32m5\u001b[39m, value)`) \u001b[38;5;28;01mis\u001b[39;00m valid \u001b[38;5;28;01min\u001b[39;00m `numpy` \u001b[38;5;28;01mfor\u001b[39;00m\n\u001b[32m    243\u001b[39m   specifying a \u001b[32m1\u001b[39m-D shaped result, \u001b[38;5;28;01mwhile\u001b[39;00m TensorFlow does \u001b[38;5;28;01mnot\u001b[39;00m support this syntax.\n\u001b[32m    244\u001b[39m   @end_compatibility\n\u001b[32m    245\u001b[39m   \"\"\"\n\u001b[32m--> \u001b[39m\u001b[32m246\u001b[39m   result = d_api.call_with_layout(\n\u001b[32m    247\u001b[39m       gen_array_ops.fill, layout=layout, dims=dims, value=value, name=name\n\u001b[32m    248\u001b[39m   )\n\u001b[32m    249\u001b[39m   shape_util.maybe_set_static_shape(result, dims)\n",
      "\u001b[32m~/carrera/3/2/ma2/ma2Python12/lib/python3.12/site-packages/tensorflow/dtensor/python/api.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(fn, layout, *args, **kwargs)\u001b[39m\n\u001b[32m     60\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m _dtensor_device()._default_layout(layout):  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[32m     61\u001b[39m           \u001b[38;5;28;01mreturn\u001b[39;00m fn(*args, **kwargs)\n\u001b[32m     62\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     63\u001b[39m       \u001b[38;5;28;01mreturn\u001b[39;00m relayout(fn(*args, **kwargs), layout)\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(*args, **kwargs)\n",
      "\u001b[32m~/carrera/3/2/ma2/ma2Python12/lib/python3.12/site-packages/tensorflow/python/ops/gen_array_ops.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(dims, value, name)\u001b[39m\n\u001b[32m   3601\u001b[39m         _ctx, \u001b[33m\"Fill\"\u001b[39m, name, dims, value)\n\u001b[32m   3602\u001b[39m       \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[32m   3603\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m _core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   3604\u001b[39m       _ops.raise_from_not_ok_status(e, name)\n\u001b[32m-> \u001b[39m\u001b[32m3605\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m _core._FallbackException:\n\u001b[32m   3606\u001b[39m       \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m   3607\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   3608\u001b[39m       return fill_eager_fallback(\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "cModel = ContrastiveModel(unlabeled_train[0].shape, learning_rate=0.0001, lambda_param=50)\n",
    "#unlabeled_train = np.expand_dims(unlabeled_train, axis=-1)\n",
    "cModel.train(unlabeled_train, epochs=20, batch_size=2048)\n",
    "cModel.plot_training_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 100\n",
    "test_samples = x_test[:n_samples].reshape(n_samples,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cModel.plot_similarity_matrix(test_samples, n_samples=n_samples);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vEZfd7iVX94s"
   },
   "source": [
    "# Trabajo extra\n",
    "\n",
    "¿Has probado a hacer el autoencoder totalmente convolucional? Para el *decoder* puedes usar las funciones [UpSampling2D](https://www.tensorflow.org/api_docs/python/tf/keras/layers/UpSampling2D) o [Conv2DTranspose](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2DTranspose)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: crea el nuevo modelo\n",
    "\n",
    "# TODO: crea tu propio clasificador\n",
    "\n",
    "class MiClasificadorSemisupervisado:\n",
    "\n",
    "    def __init__(self, input_shape):\n",
    "        # TODO : define el modelo y compílalo\n",
    "        \n",
    "        self.input_shape = (28,28,1)\n",
    "        self.num_classes = 10\n",
    "        \n",
    "        input_layer = layers.Input(shape=self.input_shape)\n",
    "        \n",
    "        # Encoder part (shared for both autoencoder and classifier)\n",
    "        # Convolutional layers instead of dense layers\n",
    "        x = layers.Conv2D(32, (3, 3), activation='relu')(input_layer)\n",
    "        x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "        x = layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
    "        x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "        x = layers.Conv2D(128, (3, 3), activation='relu')(x)\n",
    "        x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "        \n",
    "        # Encoder output (encoded features for classifier)\n",
    "        encoded = layers.Flatten()(x)\n",
    "        encoded = layers.Dense(64, activation='relu', kernel_regularizer='l2')(encoded)\n",
    "        \n",
    "        # Decoder for autoencoder part (using Conv2DTranspose layers)\n",
    "        decoded = layers.Dense(8 * 8 * 128, activation='relu', kernel_regularizer='l2')(encoded)\n",
    "        decoded = layers.Reshape((8, 8, 128))(decoded)\n",
    "        decoded = layers.Conv2DTranspose(128, (3, 3), activation='relu')(decoded)\n",
    "        decoded = layers.UpSampling2D((2, 2))(decoded)\n",
    "        decoded = layers.Conv2DTranspose(64, (3, 3), activation='relu')(decoded)\n",
    "        #decoded = layers.UpSampling2D((2, 2))(decoded)\n",
    "        decoded = layers.Conv2DTranspose(32, (3, 3), activation='relu', padding=(1,1))(decoded)\n",
    "        #decoded = layers.UpSampling2D((2, 2))(decoded)\n",
    "        decoded = layers.Conv2DTranspose(self.input_shape[2], (3, 3), activation='sigmoid', name='autoencoder')(decoded)\n",
    "\n",
    "\n",
    "        # Classifier part\n",
    "        classifier = layers.Dense(64, activation='relu', kernel_regularizer='l2')(encoded)\n",
    "        classifier = layers.Dense(32, activation='relu', kernel_regularizer='l2')(classifier)\n",
    "        classifier_output = layers.Dense(self.num_classes, activation='softmax',name='classifier')(classifier)\n",
    "\n",
    "        # Autoencoder model (for reconstructing input)\n",
    "        self.autoencoder = models.Model(input_layer, decoded)\n",
    "        self.autoencoder.compile(optimizer='adam', loss='mse')\n",
    "        \n",
    "        # Classifier model (for predicting class labels)\n",
    "        self.classifier = models.Model(input_layer, classifier_output)\n",
    "        self.classifier.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        # Combined model with two outputs: one for autoencoder (reconstruction) and one for classifier (classification)\n",
    "        self.model = models.Model(input_layer, \n",
    "                                  [decoded, classifier_output])\n",
    "                                  #classifier_output)\n",
    "        self.model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "                           loss=['mse', 'categorical_crossentropy'],\n",
    "                           #loss='categorical_crossentropy',\n",
    "                           loss_weights=[.5, 1.5],  # Adjust loss weights if needed\n",
    "                           metrics=['accuracy', 'accuracy'])\n",
    "    \n",
    "    def fit(self, X, y, unlabeled_data, batch_size,  epochs):\n",
    "        # TODO: entrena el modelo. Escoge el tamaño de batch y el número de epochs que quieras, y define bien el sample_weight\n",
    "\n",
    "        all_x = np.vstack((X, unlabeled_train))\n",
    "        y_zeros = np.zeros((unlabeled_data.shape[0],y.shape[1]))\n",
    "        all_y = np.vstack((y,y_zeros))\n",
    "        weight_autoencoder = np.ones(len(all_x))\n",
    "        weight_classifier = np.array([1]*len(X) + [0]*len(unlabeled_data))\n",
    "        \n",
    "        h = self.model.fit(all_x, \n",
    "                       [all_x, all_y], \n",
    "                       #all_y,\n",
    "                       sample_weight=[weight_autoencoder, weight_classifier], \n",
    "                       #sample_weight=sample_weight,\n",
    "                       epochs=epochs, \n",
    "                       batch_size=batch_size, \n",
    "                       verbose=1)\n",
    "        return h\n",
    "\n",
    "    def predict(self, X):\n",
    "        # TODO: devuelve la clase ganadora del clasificador\n",
    "        _, predictions = self.model.predict(X)\n",
    "        return predictions.argmax(axis=1)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        # TODO: devuelve la probabilidad del clasificador\n",
    "        _, predictions = self.model.predict(X)\n",
    "        return predictions\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        y_pred = self.predict(X)\n",
    "        return accuracy_score(y, y_pred)\n",
    "\n",
    "    def __del__(self):\n",
    "        # elimina todos los modelos que hayas creado\n",
    "        tf.keras.backend.clear_session() # Necesario para liberar la memoria en GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Exception encountered when calling Conv2DTranspose.call().\n\n\u001b[1m'tuple' object has no attribute 'lower'\u001b[0m\n\nArguments received by Conv2DTranspose.call():\n  • args=('<KerasTensor shape=(None, 22, 22, 64), dtype=float32, sparse=False, ragged=False, name=keras_tensor_163>',)\n  • kwargs=<class 'inspect._empty'>",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[243]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m model = \u001b[43mMiClasificadorSemisupervisado\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m=\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m h = model.fit(x_train, one_hot_train, unlabeled_train, batch_size=\u001b[32m60_000\u001b[39m, epochs = \u001b[32m100\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[242]\u001b[39m\u001b[32m, line 35\u001b[39m, in \u001b[36mMiClasificadorSemisupervisado.__init__\u001b[39m\u001b[34m(self, input_shape)\u001b[39m\n\u001b[32m     33\u001b[39m decoded = layers.Conv2DTranspose(\u001b[32m64\u001b[39m, (\u001b[32m3\u001b[39m, \u001b[32m3\u001b[39m), activation=\u001b[33m'\u001b[39m\u001b[33mrelu\u001b[39m\u001b[33m'\u001b[39m)(decoded)\n\u001b[32m     34\u001b[39m \u001b[38;5;66;03m#decoded = layers.UpSampling2D((2, 2))(decoded)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m decoded = \u001b[43mlayers\u001b[49m\u001b[43m.\u001b[49m\u001b[43mConv2DTranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrelu\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdecoded\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[38;5;66;03m#decoded = layers.UpSampling2D((2, 2))(decoded)\u001b[39;00m\n\u001b[32m     37\u001b[39m decoded = layers.Conv2DTranspose(\u001b[38;5;28mself\u001b[39m.input_shape[\u001b[32m2\u001b[39m], (\u001b[32m3\u001b[39m, \u001b[32m3\u001b[39m), activation=\u001b[33m'\u001b[39m\u001b[33msigmoid\u001b[39m\u001b[33m'\u001b[39m, name=\u001b[33m'\u001b[39m\u001b[33mautoencoder\u001b[39m\u001b[33m'\u001b[39m)(decoded)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/carrera/3/2/ma2/ma2Python12/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/carrera/3/2/ma2/ma2Python12/lib/python3.12/site-packages/keras/src/backend/common/backend_utils.py:196\u001b[39m, in \u001b[36m_get_output_shape_given_tf_padding\u001b[39m\u001b[34m(input_size, kernel_size, strides, padding, output_padding, dilation_rate)\u001b[39m\n\u001b[32m    193\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m input_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    194\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m196\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[43mpadding\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlower\u001b[49m() \u001b[38;5;129;01min\u001b[39;00m {\u001b[33m\"\u001b[39m\u001b[33mvalid\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33msame\u001b[39m\u001b[33m\"\u001b[39m}\n\u001b[32m    198\u001b[39m kernel_size = (kernel_size - \u001b[32m1\u001b[39m) * dilation_rate + \u001b[32m1\u001b[39m\n\u001b[32m    200\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m padding.lower() == \u001b[33m\"\u001b[39m\u001b[33mvalid\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[31mAttributeError\u001b[39m: Exception encountered when calling Conv2DTranspose.call().\n\n\u001b[1m'tuple' object has no attribute 'lower'\u001b[0m\n\nArguments received by Conv2DTranspose.call():\n  • args=('<KerasTensor shape=(None, 22, 22, 64), dtype=float32, sparse=False, ragged=False, name=keras_tensor_163>',)\n  • kwargs=<class 'inspect._empty'>"
     ]
    }
   ],
   "source": [
    "model = MiClasificadorSemisupervisado(input_shape=x_train[0].shape)\n",
    "h = model.fit(x_train, one_hot_train, unlabeled_train, batch_size=60_000, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(h.history['classifier_accuracy']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, losses\n",
    "import numpy as np\n",
    "\n",
    "# Hiperparámetros\n",
    "BATCH_SIZE = 128\n",
    "EMBEDDING_DIM = 128\n",
    "NUM_CLASSES = 10  # Ajustar según el dataset\n",
    "TEMPERATURE = 5.0\n",
    "LAMBDA = 0.5\n",
    "\n",
    "# Función para crear el modelo CNN (similar al encoder)\n",
    "def create_encoder_model(input_shape=(32, 32, 3)):\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(EMBEDDING_DIM)\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Función para crear la capa de cluster\n",
    "def create_cluster_model(embedding_dim=EMBEDDING_DIM, num_classes=NUM_CLASSES):\n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=(embedding_dim,)),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Data augmentation para imágenes\n",
    "def get_data_augmentation():\n",
    "    data_augmentation = keras.Sequential([\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomRotation(0.1),\n",
    "        layers.RandomZoom(0.1),\n",
    "    ])\n",
    "    return data_augmentation\n",
    "\n",
    "# Data augmentation diferente para segundo conjunto\n",
    "def get_data_augmentation_2():\n",
    "    data_augmentation = keras.Sequential([\n",
    "        layers.RandomFlip(\"vertical\"),\n",
    "        layers.RandomContrast(0.2),\n",
    "        layers.RandomTranslation(0.1, 0.1),\n",
    "    ])\n",
    "    return data_augmentation\n",
    "\n",
    "# Función de pérdida para la matriz de similitud\n",
    "class ContrastiveLoss():\n",
    "    def __init__(self, temperature=TEMPERATURE):\n",
    "        self.temperature = temperature\n",
    "        \n",
    "    def __call__(self, y_pred):\n",
    "        # y_true es la matriz identidad (no la usamos directamente)\n",
    "        # y_pred es la matriz de similitud M\n",
    "        \n",
    "        # Aplicamos softmax con temperatura\n",
    "        logits = y_pred / self.temperature\n",
    "        logits_max = tf.reduce_max(logits, axis=1, keepdims=True)\n",
    "        logits = logits - logits_max\n",
    "        exp_logits = tf.exp(logits)\n",
    "        exp_logits_sum = tf.reduce_sum(exp_logits, axis=1, keepdims=True)\n",
    "        probs = exp_logits / exp_logits_sum\n",
    "        \n",
    "        # Creamos matriz identidad como objetivo\n",
    "        batch_size = tf.shape(y_pred)[0]\n",
    "        y_true = tf.eye(batch_size)\n",
    "        \n",
    "        # Calculamos entropia cruzada\n",
    "        loss = -tf.reduce_sum(y_true * tf.math.log(probs + 1e-10)) / tf.cast(batch_size, tf.float32)\n",
    "        return loss\n",
    "\n",
    "# Función de pérdida para el clustering\n",
    "class ClusteringLoss():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def __call__(self, cX_1comp, cX_2comp):\n",
    "\n",
    "        # loss_C = cX_1comp(1 - cX_1comp) + cX_2comp(1 - cX_2comp)\n",
    "        loss_1 = tf.reduce_mean(cX_1comp * (1 - cX_1comp))\n",
    "        loss_2 = tf.reduce_mean(cX_2comp * (1 - cX_2comp))\n",
    "        \n",
    "        return loss_1 + loss_2\n",
    "\n",
    "# Modelo combinado para entrenamiento\n",
    "class ContrastiveModel(tf.keras.Model):\n",
    "    def __init__(self, input_shape=(32, 32, 3), embedding_dim=EMBEDDING_DIM, num_classes=NUM_CLASSES):\n",
    "        super(ContrastiveModel, self).__init__()\n",
    "        self.encoder = create_encoder_model(input_shape)\n",
    "        self.cluster = create_cluster_model(embedding_dim, num_classes)\n",
    "        self.data_aug1 = get_data_augmentation()\n",
    "        self.data_aug2 = get_data_augmentation_2()\n",
    "        self.contrastive_loss = ContrastiveLoss()\n",
    "        self.clustering_loss = ClusteringLoss()\n",
    "        self.lambda_param = LAMBDA\n",
    "        \n",
    "    def compile(self, optimizer):\n",
    "        super(ContrastiveModel, self).compile()\n",
    "        self.optimizer = optimizer\n",
    "        \n",
    "    def train_step(self, data):\n",
    "        # Desempaquetar los datos\n",
    "        if isinstance(data, tuple):\n",
    "            X = data[0]\n",
    "        else:\n",
    "            X = data\n",
    "            \n",
    "        batch_size = tf.shape(X)[0]\n",
    "        \n",
    "        # Aplicar las dos transformaciones de data augmentation\n",
    "        augX_1 = self.data_aug1(X)\n",
    "        augX_2 = self.data_aug2(X)\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            # Obtener representaciones del encoder\n",
    "            augX_1comp = self.encoder(augX_1)\n",
    "            augX_2comp = self.encoder(augX_2)\n",
    "            \n",
    "            # Obtener salidas del clustering\n",
    "            cX_1comp = self.cluster(augX_1comp)\n",
    "            cX_2comp = self.cluster(augX_2comp)\n",
    "            \n",
    "            # Calcular matriz de similitud M\n",
    "            M = tf.matmul(augX_1comp, augX_2comp, transpose_b=True)\n",
    "            \n",
    "            # Calcular pérdida de contraste\n",
    "            loss_M = self.contrastive_loss(M)\n",
    "            \n",
    "            # Calcular pérdida de clustering\n",
    "            loss_C = self.clustering_loss(cX_1comp, cX_2comp)\n",
    "            \n",
    "            # Pérdida total\n",
    "            total_loss = loss_M + self.lambda_param * loss_C\n",
    "            \n",
    "        # Calcular gradientes y actualizar pesos\n",
    "        gradients = tape.gradient(total_loss, self.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "        \n",
    "        return {\"loss\": total_loss, \"contrastive_loss\": loss_M, \"clustering_loss\": loss_C}\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        # Para inferencia, solo devolvemos la representación del encoder\n",
    "        return self.encoder(inputs)\n",
    "\n",
    "# Función de utilidad para cargar y preparar dataset (ej. CIFAR-10)\n",
    "def load_dataset():\n",
    "    (x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "    x_train = x_train.astype(\"float32\") / 255.0\n",
    "    x_test = x_test.astype(\"float32\") / 255.0\n",
    "    return (x_train, y_train), (x_test, y_test)\n",
    "\n",
    "def dummy_loss(y_true, y_pred):\n",
    "    return tf.constant(0.0)\n",
    "\n",
    "# Entrenamiento del modelo\n",
    "def train_model():\n",
    "    # Cargar dataset\n",
    "    (x_train, y_train), (x_test, y_test) = load_dataset()\n",
    "    \n",
    "    # Crear modelo\n",
    "    input_shape = x_train.shape[1:]\n",
    "    model = ContrastiveModel(input_shape=input_shape)\n",
    "    \n",
    "    # Compilar el modelo\n",
    "    model.compile(optimizer=keras.optimizers.Adam(1e-4))\n",
    "    \n",
    "    # Entrenar modelo\n",
    "    model.fit(\n",
    "        x_train,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        epochs=20,\n",
    "        validation_data=(x_test, None),\n",
    "        loss=dummy_loss\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Para usar el modelo entrenado para extraer representaciones:\n",
    "def extract_features(model, images):\n",
    "    return model.encoder(images).numpy()\n",
    "\n",
    "# Para clasificación, se puede entrenar un clasificador sobre las características extraídas\n",
    "def train_classifier(X_features, y_labels):\n",
    "    classifier = keras.Sequential([\n",
    "        layers.Input(shape=(EMBEDDING_DIM,)),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(NUM_CLASSES, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    classifier.compile(\n",
    "        optimizer=keras.optimizers.Adam(1e-3),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    classifier.fit(X_features, y_labels, batch_size=32, epochs=10, validation_split=0.1)\n",
    "    return classifier\n",
    "\n",
    "# Ejemplo de uso completo\n",
    "if __name__ == \"__main__\":\n",
    "    # Entrenar el modelo contrastivo\n",
    "    contrastive_model = train_model()\n",
    "    \n",
    "    # Cargar datos\n",
    "    (x_train, y_train), (x_test, y_test) = load_dataset()\n",
    "    \n",
    "    # Extraer características\n",
    "    train_features = extract_features(contrastive_model, x_train)\n",
    "    test_features = extract_features(contrastive_model, x_test)\n",
    "    \n",
    "    # Entrenar clasificador\n",
    "    classifier = train_classifier(train_features, y_train)\n",
    "    \n",
    "    # Evaluar\n",
    "    test_loss, test_acc = classifier.evaluate(test_features, y_test)\n",
    "    print(f\"Test accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabeled_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 1, 0])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_train[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ma2Python12",
   "language": "python",
   "name": "ma2python12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
