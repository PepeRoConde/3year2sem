{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "57knM8jrYZ2t"
   },
   "source": [
    "# Notebook 4: Modelos generativos\n",
    "\n",
    "## Pre-requisitos\n",
    "\n",
    "### Instalar paquetes\n",
    "\n",
    "Si la práctica requiere algún paquete de Python, habrá que incluir una celda en la que se instalen. Si usamos un paquete que se ha utilizado en prácticas anteriores, podríamos dar por supuesto que está instalado pero no cuesta nada satisfacer todas las dependencias en la propia práctica para reducir las dependencias entre ellas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "LkaimNJfYZ2w"
   },
   "outputs": [],
   "source": [
    "# Ejemplo de instalación de tensorflow 2.0\n",
    "#%tensorflow_version 2.x\n",
    "# !pip3 install tensorflow  # NECESARIO SOLO SI SE EJECUTA EN LOCAL\n",
    "import tensorflow as tf\n",
    "\n",
    "# Hacemos los imports que sean necesarios\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SOch-CnwQttl"
   },
   "source": [
    "# Modelos generativos sobre MNIST\n",
    "\n",
    "Lo primero que tenemos que hacer es cargar el dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "id": "1gXdWDBIEKel"
   },
   "outputs": [],
   "source": [
    "labeled_data = 0.01 # Vamos a usar el etiquetado de sólo el 1% de los datos\n",
    "np.random.seed(42)\n",
    "\n",
    "(x_train, y_train), (x_test, y_test), = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "indexes = np.arange(len(x_train))\n",
    "np.random.shuffle(indexes)\n",
    "ntrain_data = int(labeled_data*len(x_train))\n",
    "unlabeled_train = x_train[indexes[ntrain_data:]]\n",
    "x_train = x_train[indexes[:ntrain_data]]\n",
    "y_train = y_train[indexes[:ntrain_data]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "8XsZIqV8TmSc"
   },
   "outputs": [],
   "source": [
    "# TODO: Haz el preprocesado que necesites aquí (si lo necesitas)\n",
    "\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1]*x_train.shape[2]))\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1]*x_test.shape[2]))\n",
    "unlabeled_train = np.reshape(unlabeled_train, (unlabeled_train.shape[0], unlabeled_train.shape[1]*unlabeled_train.shape[2]))\n",
    "\n",
    "one_hot_train = np.zeros((y_train.size, len(set(y_train))), dtype=int)\n",
    "one_hot_train[np.arange(y_train.size), y_train ] = 1\n",
    "\n",
    "one_hot_test = np.zeros((y_test.size, len(set(y_test))), dtype=int)\n",
    "one_hot_test[np.arange(y_test.size), y_test ] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wkaCDOGapMyl"
   },
   "source": [
    "## Modelo generativo\n",
    "\n",
    "Vamos a crear nuestro propio modelo generativo. En clase de teoría has visto muchas versiones distintas:\n",
    "\n",
    "1. Mezcla de distribuciones de Gaussianas (GMM)\n",
    "1. Mezcla de distribuciones multinomiales (Naive Bayes)\n",
    "1. Modelos de Markov ocultos (HMM)\n",
    "\n",
    "Tal y como se os apunta en teoría, los modelos generativos abordan un problema más general, y aprenden realmente cómo se estructuran y distribuyen los datos de entrada. \n",
    "\n",
    "En nuestro caso, vamos a distribuír los datos de entrada mediante el uso de **Autoencoders**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pxf_lSC1HsYh"
   },
   "source": [
    "# Autoencoders\n",
    "\n",
    "El autoencoder es un tipo de red que se utiliza para aprender codificaciones eficientes de datos sin etiquetar (lo que se conoce como aprendizaje no supervisado). Es una red que tiene el mismo tamaño en la entrada como en la salida, puesto que el objetivo de la red es reconstruír la entrada con la menor pérdida posible.\n",
    "\n",
    "Si lo que hacemos es reconstruír la entrada, ¿qué sentido tiene el usar la red? Habitualmente, **la red consta, a su mitad, de una capa con menos elementos que los datos de entrada**. Por tanto, al reconstruír los datos de la entrada a la salida, en esa capa tendremos una versión *comprimida* de la entrada, que contendrá la mayor parte de su información.\n",
    "\n",
    "Por tanto, podemos dividir un autoencoder en 3 secciones diferentes, tal y como se ve en la siguiente figura:\n",
    "\n",
    "![autoencoder](https://drive.google.com/uc?export=view&id=1yxkKZV0J0YplQAGPGJxQ2Z80Ad6L94eu)\n",
    "\n",
    "\n",
    "1. **Encoder:** es la parte inicial de la red, encargada de comprimir los datos de la entrada.\n",
    "1. **Code:** es la salida del encoder, contiene la versión *comprimida* de los datos de entrada.\n",
    "1. **Decoder:** se encarga de, partiendo de la salida del *Encoder*, reconstruír la red."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7-mBCsDXJX3M"
   },
   "source": [
    "## Crea tu propio Autoencoder\n",
    "\n",
    "El diseño del autoencoder es libre (capas densas, convolucionales, ...), puedes crearlo como quieras. **El único requisito es que tiene que mantener los nombres (y parámetros) de las funciones descritas abajo.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M95R6t1pJW3f"
   },
   "outputs": [],
   "source": [
    "# TODO: crea tu propio autoencoder\n",
    "\n",
    "\n",
    "class MiAutoencoder:\n",
    "\n",
    "    def __init__(self, input_shape):\n",
    "        \n",
    "        self.input_shape = input_shape\n",
    "        \n",
    "        self.encoder = models.Sequential()\n",
    "        self.encoder.add(layers.InputLayer(shape=self.input_shape))\n",
    "        self.encoder.add(layers.Dense(512, activation='relu'))\n",
    "        self.encoder.add(layers.Dense(128, activation='relu'))\n",
    "        self.encoder.add(layers.Dense(64, activation='relu'))\n",
    "        self.encoder.add(layers.Dense(32, activation='relu'))\n",
    "        self.encoder.add(layers.Dense(32, activation='relu'))  # Latent space\n",
    "\n",
    "        self.decoder = models.Sequential()\n",
    "        self.decoder.add(layers.InputLayer(shape=(32,)))\n",
    "        self.decoder.add(layers.Dense(32, activation='relu'))\n",
    "        self.decoder.add(layers.Dense(64, activation='relu'))\n",
    "        self.decoder.add(layers.Dense(128, activation='relu'))\n",
    "        self.decoder.add(layers.Dense(512, activation='relu'))\n",
    "        self.decoder.add(layers.Dense(self.input_shape[0], activation='sigmoid'))  # Output should match input\n",
    "\n",
    "        self.autoencoder = models.Sequential([self.encoder, self.decoder])\n",
    "\n",
    "        self.autoencoder.compile(optimizer='adam', loss='mse')\n",
    "    \n",
    "    def fit(self, X, y=None, sample_weight=None, batch_size=60_000, epochs=20):\n",
    "        # TODO: entrena el modelo. Escoge el tamaño de batch y el número de epochs que quieras\n",
    "        \n",
    "        self.autoencoder.fit(X, X, \n",
    "                             batch_size=batch_size, \n",
    "                             epochs=epochs, \n",
    "                             sample_weight=sample_weight)\n",
    "\n",
    "    def get_encoded_data(self, X):\n",
    "        # TODO: devuelve la salida del encoder (code)\n",
    "        \n",
    "        return self.encoder.predict(X)\n",
    "        \n",
    "    def __del__(self):\n",
    "        # elimina todos los modelos que hayas creado\n",
    "        tf.keras.backend.clear_session() # Necesario para liberar la memoria en GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6tt0L2yCMdmb"
   },
   "source": [
    "## Crea tu propio Clasificador\n",
    "\n",
    "El diseño del clasificador es libre, pero recuerda que tiene que ser simple (máximo dos capas). **El único requisito es que tiene que mantener los nombres (y parámetros) de las funciones descritas abajo.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1mh0yzbKMuhk"
   },
   "outputs": [],
   "source": [
    "# TODO: crea tu propio clasificador\n",
    "\n",
    "class MiClasificador:\n",
    "\n",
    "    def __init__(self):\n",
    "        # TODO : define el modelo y compílalo\n",
    "        \n",
    "        self.input_shape = (32,)\n",
    "        \n",
    "        self.classifier = models.Sequential()\n",
    "        self.classifier.add(layers.InputLayer(shape=self.input_shape))\n",
    "        self.classifier.add(layers.Dense(32, activation='relu'))\n",
    "        self.classifier.add(layers.Dense(10, activation='sigmoid'))\n",
    "\n",
    "        self.classifier.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    def fit(self, X, y, sample_weight=None, batch_size=60_000, epochs=15):\n",
    "        # TODO: entrena el modelo. Escoge el tamaño de batch y el número de epochs que quieras\n",
    "        self.classifier.fit(X, y, \n",
    "                             batch_size=batch_size, \n",
    "                             epochs=epochs, \n",
    "                             sample_weight=sample_weight)\n",
    "\n",
    "    def predict(self, X):\n",
    "        # TODO: devuelve la clase ganadora\n",
    "\n",
    "        return np.argmax(self.predict_proba(X)) + 1\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \n",
    "        return self.classifier.predict(X)\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        \n",
    "        return self.classifier.evaluate(X, y)[1]\n",
    "\n",
    "    def __del__(self):\n",
    "        # elimina todos los modelos que hayas creado\n",
    "        tf.keras.backend.clear_session() # Necesario para liberar la memoria en GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w1-v4D6VH3Qq"
   },
   "source": [
    "### Entrenamiendo del modelo semisupervisado\n",
    "\n",
    "El entrenamiento del sistema semisupervisado se realiza en dos pasos.\n",
    "\n",
    "1. Se entrena el autoencoder con todos los datos (etiquetados y sin etiquetar).\n",
    "1. Se entrena un clasificador simple (una o dos capas), teniendo como entrada la salida del encoder (**code**) de los datos etiquetados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vqT2nuCspfE_"
   },
   "source": [
    "<font color='red'>NOTA:</font> para entrenar (y predecir) vamos a utilizar los nombres de las funciones que hemos definido en el autoencoder y en el clasificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5xjcLa21EKen"
   },
   "outputs": [],
   "source": [
    "# TODO: implementa el algoritmo semisupervised_training.\n",
    "\n",
    "def semisupervised_training(autoencoder, classifier, x_train, y_train, unlabeled_data):\n",
    "\n",
    "    all_x = np.vstack((x_train, unlabeled_train))\n",
    "    autoencoder.fit(all_x)\n",
    "    x_coded = autoencoder.get_encoded_data(x_train)\n",
    "    classifier.fit(x_coded, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qjFXe6EiYfRg"
   },
   "source": [
    "### Entrenamos nuestro modelo\n",
    "\n",
    "Usa lo hecho anteriormente para entrenar tu clasificador de una manera semi-supervisada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lNC1s2Wmqx4x"
   },
   "outputs": [],
   "source": [
    "# Crea tu autoencoder y tu clasificador\n",
    "\n",
    "autoencoder = MiAutoencoder(input_shape=x_train[0].shape)\n",
    "classifier = MiClasificador()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hN2zd3DEYnKI",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO: Entrena tu modelo\n",
    "\n",
    "semisupervised_training(autoencoder=autoencoder, classifier=classifier, x_train=x_train, y_train=one_hot_train, unlabeled_data=unlabeled_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n5tS8_SKOngm"
   },
   "outputs": [],
   "source": [
    "# TODO: Obtén la precisión sobre el conjunto de test\n",
    "pred_data = autoencoder.get_encoded_data(x_test)\n",
    "print('Test accuracy :', classifier.score(pred_data, one_hot_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MbUKp14pPsrp"
   },
   "source": [
    "## Mejorando el código\n",
    "\n",
    "nuestro modelo actual requiere de dos pasos para entrenarse, pero podría realizarse en un único paso si **creamos un modelo con las dos salidas (autoencoder y clasificador)**. \n",
    "\n",
    "Para ello, hay que tener en cuenta que, en los datos sin etiquetar, su contribución al clasificador debería ser nula.\n",
    "\n",
    "\n",
    "### TRABAJO: Crea el nuevo modelo y modifica la función semisupervised_training para tener en cuenta todos los puntos mencionados anteriormente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "xS3JLE37SqrG"
   },
   "outputs": [],
   "source": [
    "# TODO: crea el nuevo modelo\n",
    "\n",
    "# TODO: crea tu propio clasificador\n",
    "\n",
    "class MiClasificadorSemisupervisado:\n",
    "\n",
    "    def __init__(self, input_shape):\n",
    "        # TODO : define el modelo y compílalo\n",
    "        \n",
    "        self.input_shape = input_shape\n",
    "        self.num_classes = 10\n",
    "        \n",
    "        input_layer = layers.Input(shape=self.input_shape)\n",
    "        \n",
    "        # Encoder part (shared for both autoencoder and classifier)\n",
    "        encoded = layers.Dense(128, activation='relu', kernel_regularizer='l2')(input_layer)\n",
    "        encoded = layers.Dense(64, activation='relu', kernel_regularizer='l2')(encoded)\n",
    "        encoded = layers.Dense(16, activation='relu', kernel_regularizer='l2')(encoded)\n",
    "        \n",
    "        # Decoder for autoencoder part\n",
    "        decoded = layers.Dense(64, activation='relu', kernel_regularizer='l2')(encoded)\n",
    "        decoded = layers.Dense(128, activation='relu', kernel_regularizer='l2')(decoded)\n",
    "        decoded = layers.Dense(self.input_shape[0], activation='sigmoid',name='autoencoder')(decoded)\n",
    "\n",
    "        # Classifier part\n",
    "        classifier = layers.Dense(32, activation='relu', kernel_regularizer='l2')(encoded)\n",
    "        classifier = layers.Dense(16, activation='relu', kernel_regularizer='l2')(classifier)\n",
    "        classifier_output = layers.Dense(self.num_classes, activation='softmax',name='classifier')(classifier)\n",
    "\n",
    "        # Autoencoder model (for reconstructing input)\n",
    "        self.autoencoder = models.Model(input_layer, decoded)\n",
    "        self.autoencoder.compile(optimizer='adam', loss='mse')\n",
    "        \n",
    "        # Classifier model (for predicting class labels)\n",
    "        self.classifier = models.Model(input_layer, classifier_output)\n",
    "        self.classifier.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        # Combined model with two outputs: one for autoencoder (reconstruction) and one for classifier (classification)\n",
    "        self.model = models.Model(input_layer, \n",
    "                                  [decoded, classifier_output])\n",
    "                                  #classifier_output)\n",
    "        self.model.compile(optimizer='adam',\n",
    "                           loss=['mse', 'categorical_crossentropy'],\n",
    "                           #loss='categorical_crossentropy',\n",
    "                           loss_weights=[.5, 1.5],  # Adjust loss weights if needed\n",
    "                           metrics=['accuracy', 'accuracy'])\n",
    "    \n",
    "    def fit(self, X, y, unlabeled_data, batch_size,  epochs):\n",
    "        # TODO: entrena el modelo. Escoge el tamaño de batch y el número de epochs que quieras, y define bien el sample_weight\n",
    "\n",
    "        all_x = np.vstack((X, unlabeled_train))\n",
    "        y_zeros = np.zeros((unlabeled_data.shape[0],y.shape[1]))\n",
    "        all_y = np.vstack((y,y_zeros))\n",
    "        weight_autoencoder = np.ones(len(all_x))\n",
    "        weight_classifier = np.array([1]*len(X) + [0]*len(unlabeled_data))\n",
    "        \n",
    "        h = self.model.fit(all_x, \n",
    "                       [all_x, all_y], \n",
    "                       #all_y,\n",
    "                       sample_weight=[weight_autoencoder, weight_classifier], \n",
    "                       #sample_weight=sample_weight,\n",
    "                       epochs=epochs, \n",
    "                       batch_size=batch_size, \n",
    "                       verbose=1)\n",
    "        return h\n",
    "\n",
    "    def predict(self, X):\n",
    "        # TODO: devuelve la clase ganadora del clasificador\n",
    "        _, predictions = self.model.predict(X)\n",
    "        return predictions.argmax(axis=1)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        # TODO: devuelve la probabilidad del clasificador\n",
    "        _, predictions = self.model.predict(X)\n",
    "        return predictions\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        y_pred = self.predict(X)\n",
    "        return accuracy_score(y, y_pred)\n",
    "\n",
    "    def __del__(self):\n",
    "        # elimina todos los modelos que hayas creado\n",
    "        tf.keras.backend.clear_session() # Necesario para liberar la memoria en GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "7eF_9LMeZ2J2"
   },
   "outputs": [],
   "source": [
    "# TODO: reescribe la función semisupervised_training para incorporar las mejoras mencionadas anteriormente\n",
    "\n",
    "model = MiClasificadorSemisupervisado(input_shape=x_train[0].shape)\n",
    "\n",
    "def semisupervised_training_v2(model, x_train, y_train, unlabeled_data):\n",
    "    h = model.fit(x_train, y_train, unlabeled_data, batch_size=20_000, epochs = 100)\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "YbqC0inexwHp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 118ms/step - autoencoder_accuracy: 0.0000e+00 - autoencoder_loss: 7243.3516 - classifier_accuracy: 0.3744 - classifier_loss: 2.4426 - loss: 3630.1204\n",
      "Epoch 2/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - autoencoder_accuracy: 0.0000e+00 - autoencoder_loss: 7240.6069 - classifier_accuracy: 0.4751 - classifier_loss: 3.1635 - loss: 3629.6643 \n",
      "Epoch 3/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - autoencoder_accuracy: 0.0000e+00 - autoencoder_loss: 7228.4180 - classifier_accuracy: 0.4182 - classifier_loss: 3.0386 - loss: 3623.2192\n",
      "Epoch 4/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - autoencoder_accuracy: 0.0000e+00 - autoencoder_loss: 7228.4131 - classifier_accuracy: 0.3574 - classifier_loss: 2.5654 - loss: 3622.3499 \n",
      "Epoch 5/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - autoencoder_accuracy: 2.7083e-05 - autoencoder_loss: 7221.1025 - classifier_accuracy: 0.2211 - classifier_loss: 2.2998 - loss: 3618.1482 \n",
      "Epoch 6/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - autoencoder_accuracy: 2.2917e-05 - autoencoder_loss: 7214.8247 - classifier_accuracy: 0.0834 - classifier_loss: 2.1126 - loss: 3614.5896 \n",
      "Epoch 7/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - autoencoder_accuracy: 3.7500e-05 - autoencoder_loss: 7221.6367 - classifier_accuracy: 0.1092 - classifier_loss: 1.9051 - loss: 3617.5547 \n",
      "Epoch 8/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - autoencoder_accuracy: 2.5417e-04 - autoencoder_loss: 7227.4424 - classifier_accuracy: 0.2045 - classifier_loss: 1.8756 - loss: 3620.2905 \n",
      "Epoch 9/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - autoencoder_accuracy: 1.8542e-04 - autoencoder_loss: 7220.5181 - classifier_accuracy: 0.2599 - classifier_loss: 1.6852 - loss: 3616.4285 \n",
      "Epoch 10/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - autoencoder_accuracy: 1.9167e-04 - autoencoder_loss: 7214.8301 - classifier_accuracy: 0.1655 - classifier_loss: 1.6039 - loss: 3613.3567\n",
      "Epoch 11/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - autoencoder_accuracy: 2.3542e-04 - autoencoder_loss: 7213.8066 - classifier_accuracy: 0.0981 - classifier_loss: 1.5279 - loss: 3612.6333 \n",
      "Epoch 12/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - autoencoder_accuracy: 1.9167e-04 - autoencoder_loss: 7218.5659 - classifier_accuracy: 0.2191 - classifier_loss: 1.5618 - loss: 3614.9771 \n",
      "Epoch 13/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - autoencoder_accuracy: 1.0833e-04 - autoencoder_loss: 7213.4937 - classifier_accuracy: 0.2298 - classifier_loss: 1.6398 - loss: 3612.4822 \n",
      "Epoch 14/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - autoencoder_accuracy: 1.4167e-04 - autoencoder_loss: 7220.1543 - classifier_accuracy: 0.0619 - classifier_loss: 1.6487 - loss: 3615.7559 \n",
      "Epoch 15/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - autoencoder_accuracy: 1.0000e-04 - autoencoder_loss: 7217.3223 - classifier_accuracy: 0.0106 - classifier_loss: 1.6633 - loss: 3614.2974 \n",
      "Epoch 16/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - autoencoder_accuracy: 5.2083e-05 - autoencoder_loss: 7222.1777 - classifier_accuracy: 0.0063 - classifier_loss: 1.7404 - loss: 3616.7842 \n",
      "Epoch 17/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - autoencoder_accuracy: 1.1875e-04 - autoencoder_loss: 7217.8467 - classifier_accuracy: 0.0245 - classifier_loss: 1.3970 - loss: 3614.0542 \n",
      "Epoch 18/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - autoencoder_accuracy: 7.9167e-05 - autoencoder_loss: 7219.7446 - classifier_accuracy: 0.1745 - classifier_loss: 1.4072 - loss: 3614.9746 \n",
      "Epoch 19/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - autoencoder_accuracy: 1.5625e-04 - autoencoder_loss: 7207.6709 - classifier_accuracy: 0.2636 - classifier_loss: 1.5626 - loss: 3609.1270\n",
      "Epoch 20/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - autoencoder_accuracy: 3.1667e-04 - autoencoder_loss: 7210.1411 - classifier_accuracy: 0.1333 - classifier_loss: 1.4732 - loss: 3610.1860 \n",
      "Epoch 21/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - autoencoder_accuracy: 4.1250e-04 - autoencoder_loss: 7210.8057 - classifier_accuracy: 0.0609 - classifier_loss: 1.4860 - loss: 3610.4956 \n",
      "Epoch 22/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - autoencoder_accuracy: 4.0417e-04 - autoencoder_loss: 7207.6514 - classifier_accuracy: 0.0836 - classifier_loss: 1.4787 - loss: 3608.8682 \n",
      "Epoch 23/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - autoencoder_accuracy: 2.5000e-04 - autoencoder_loss: 7220.8037 - classifier_accuracy: 0.1190 - classifier_loss: 1.4935 - loss: 3615.4280\n",
      "Epoch 24/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - autoencoder_accuracy: 8.9583e-05 - autoencoder_loss: 7209.3345 - classifier_accuracy: 0.1348 - classifier_loss: 1.0910 - loss: 3609.0540 \n",
      "Epoch 25/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - autoencoder_accuracy: 5.4167e-05 - autoencoder_loss: 7216.9531 - classifier_accuracy: 0.0458 - classifier_loss: 0.8526 - loss: 3612.4712\n",
      "Epoch 26/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - autoencoder_accuracy: 2.2917e-05 - autoencoder_loss: 7218.8496 - classifier_accuracy: 0.1130 - classifier_loss: 0.8232 - loss: 3613.3438 \n",
      "Epoch 27/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - autoencoder_accuracy: 4.1667e-05 - autoencoder_loss: 7223.9321 - classifier_accuracy: 0.1631 - classifier_loss: 0.8006 - loss: 3615.8201 \n",
      "Epoch 28/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - autoencoder_accuracy: 2.9167e-05 - autoencoder_loss: 7220.9844 - classifier_accuracy: 0.1260 - classifier_loss: 0.8030 - loss: 3614.3191 \n",
      "Epoch 29/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - autoencoder_accuracy: 3.5417e-05 - autoencoder_loss: 7223.4199 - classifier_accuracy: 0.1472 - classifier_loss: 0.6767 - loss: 3615.3169 \n",
      "Epoch 30/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - autoencoder_accuracy: 3.7500e-05 - autoencoder_loss: 7221.2021 - classifier_accuracy: 0.1313 - classifier_loss: 0.6044 - loss: 3614.0703 \n",
      "Epoch 31/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - autoencoder_accuracy: 4.3750e-05 - autoencoder_loss: 7213.4326 - classifier_accuracy: 0.1365 - classifier_loss: 0.6796 - loss: 3610.2705 \n",
      "Epoch 32/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - autoencoder_accuracy: 1.2917e-04 - autoencoder_loss: 7217.4570 - classifier_accuracy: 0.1277 - classifier_loss: 0.6426 - loss: 3612.2000 \n",
      "Epoch 33/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - autoencoder_accuracy: 1.5417e-04 - autoencoder_loss: 7214.4053 - classifier_accuracy: 0.1263 - classifier_loss: 0.7575 - loss: 3610.8196\n",
      "Epoch 34/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - autoencoder_accuracy: 1.7292e-04 - autoencoder_loss: 7224.9062 - classifier_accuracy: 0.1514 - classifier_loss: 0.8207 - loss: 3616.1406 \n",
      "Epoch 35/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - autoencoder_accuracy: 1.3125e-04 - autoencoder_loss: 7219.5840 - classifier_accuracy: 0.1402 - classifier_loss: 0.6843 - loss: 3613.2517 \n",
      "Epoch 36/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - autoencoder_accuracy: 1.9375e-04 - autoencoder_loss: 7216.5596 - classifier_accuracy: 0.0932 - classifier_loss: 0.6272 - loss: 3611.6299\n",
      "Epoch 37/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - autoencoder_accuracy: 2.5000e-04 - autoencoder_loss: 7218.3516 - classifier_accuracy: 0.0852 - classifier_loss: 0.4593 - loss: 3612.2505\n",
      "Epoch 38/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 212ms/step - autoencoder_accuracy: 3.6250e-04 - autoencoder_loss: 7215.2407 - classifier_accuracy: 0.1161 - classifier_loss: 0.4475 - loss: 3610.6567\n",
      "Epoch 39/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - autoencoder_accuracy: 3.2708e-04 - autoencoder_loss: 7220.6440 - classifier_accuracy: 0.1351 - classifier_loss: 0.4358 - loss: 3613.3193\n",
      "Epoch 40/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - autoencoder_accuracy: 2.4375e-04 - autoencoder_loss: 7218.8667 - classifier_accuracy: 0.1440 - classifier_loss: 0.3546 - loss: 3612.2856\n",
      "Epoch 41/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - autoencoder_accuracy: 1.1458e-04 - autoencoder_loss: 7221.9331 - classifier_accuracy: 0.1180 - classifier_loss: 0.4381 - loss: 3613.9207 \n",
      "Epoch 42/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - autoencoder_accuracy: 7.9167e-05 - autoencoder_loss: 7223.8062 - classifier_accuracy: 0.0801 - classifier_loss: 0.3951 - loss: 3614.7708\n",
      "Epoch 43/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - autoencoder_accuracy: 7.2917e-05 - autoencoder_loss: 7219.2461 - classifier_accuracy: 0.1058 - classifier_loss: 0.3330 - loss: 3612.3772\n",
      "Epoch 44/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - autoencoder_accuracy: 4.1667e-05 - autoencoder_loss: 7217.4053 - classifier_accuracy: 0.1486 - classifier_loss: 0.2786 - loss: 3611.3528\n",
      "Epoch 45/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - autoencoder_accuracy: 7.2917e-05 - autoencoder_loss: 7225.4985 - classifier_accuracy: 0.1403 - classifier_loss: 0.3137 - loss: 3615.4282 \n",
      "Epoch 46/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - autoencoder_accuracy: 8.3333e-05 - autoencoder_loss: 7219.1646 - classifier_accuracy: 0.1088 - classifier_loss: 0.2948 - loss: 3612.2092 \n",
      "Epoch 47/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - autoencoder_accuracy: 1.4583e-04 - autoencoder_loss: 7213.2480 - classifier_accuracy: 0.0922 - classifier_loss: 0.2988 - loss: 3609.2334 \n",
      "Epoch 48/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - autoencoder_accuracy: 2.1458e-04 - autoencoder_loss: 7217.9404 - classifier_accuracy: 0.0912 - classifier_loss: 0.2936 - loss: 3611.5496 \n",
      "Epoch 49/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - autoencoder_accuracy: 2.3125e-04 - autoencoder_loss: 7214.4131 - classifier_accuracy: 0.1017 - classifier_loss: 0.2438 - loss: 3609.6899 \n",
      "Epoch 50/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - autoencoder_accuracy: 1.8750e-04 - autoencoder_loss: 7223.9453 - classifier_accuracy: 0.1114 - classifier_loss: 0.2547 - loss: 3614.4507\n",
      "Epoch 51/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - autoencoder_accuracy: 3.2292e-04 - autoencoder_loss: 7218.0200 - classifier_accuracy: 0.1076 - classifier_loss: 0.2120 - loss: 3611.4043\n",
      "Epoch 52/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - autoencoder_accuracy: 3.8125e-04 - autoencoder_loss: 7217.6992 - classifier_accuracy: 0.1052 - classifier_loss: 0.2325 - loss: 3611.2549\n",
      "Epoch 53/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - autoencoder_accuracy: 4.5625e-04 - autoencoder_loss: 7214.0679 - classifier_accuracy: 0.1066 - classifier_loss: 0.2077 - loss: 3609.3826\n",
      "Epoch 54/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - autoencoder_accuracy: 3.4792e-04 - autoencoder_loss: 7221.1069 - classifier_accuracy: 0.1065 - classifier_loss: 0.2035 - loss: 3612.8757 \n",
      "Epoch 55/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - autoencoder_accuracy: 2.5625e-04 - autoencoder_loss: 7216.2417 - classifier_accuracy: 0.1036 - classifier_loss: 0.1781 - loss: 3610.3848\n",
      "Epoch 56/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - autoencoder_accuracy: 2.5417e-04 - autoencoder_loss: 7218.1748 - classifier_accuracy: 0.1036 - classifier_loss: 0.1754 - loss: 3611.3267 \n",
      "Epoch 57/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - autoencoder_accuracy: 1.8542e-04 - autoencoder_loss: 7212.0483 - classifier_accuracy: 0.1019 - classifier_loss: 0.1506 - loss: 3608.2061 \n",
      "Epoch 58/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - autoencoder_accuracy: 1.0625e-04 - autoencoder_loss: 7217.8101 - classifier_accuracy: 0.1000 - classifier_loss: 0.1683 - loss: 3611.0938 \n",
      "Epoch 59/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - autoencoder_accuracy: 1.4792e-04 - autoencoder_loss: 7214.7705 - classifier_accuracy: 0.0977 - classifier_loss: 0.1805 - loss: 3609.5737 \n",
      "Epoch 60/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - autoencoder_accuracy: 2.2708e-04 - autoencoder_loss: 7221.0332 - classifier_accuracy: 0.1006 - classifier_loss: 0.2137 - loss: 3612.7375 \n",
      "Epoch 61/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - autoencoder_accuracy: 1.4792e-04 - autoencoder_loss: 7220.2412 - classifier_accuracy: 0.1121 - classifier_loss: 0.1941 - loss: 3612.2959 \n",
      "Epoch 62/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - autoencoder_accuracy: 3.0833e-04 - autoencoder_loss: 7213.6660 - classifier_accuracy: 0.1272 - classifier_loss: 0.2043 - loss: 3609.0085 \n",
      "Epoch 63/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - autoencoder_accuracy: 5.1250e-04 - autoencoder_loss: 7219.4648 - classifier_accuracy: 0.1404 - classifier_loss: 0.1815 - loss: 3611.8606 \n",
      "Epoch 64/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - autoencoder_accuracy: 4.5833e-04 - autoencoder_loss: 7216.6631 - classifier_accuracy: 0.1261 - classifier_loss: 0.1744 - loss: 3610.4353 \n",
      "Epoch 65/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - autoencoder_accuracy: 4.1875e-04 - autoencoder_loss: 7220.2158 - classifier_accuracy: 0.0992 - classifier_loss: 0.1851 - loss: 3612.2134\n",
      "Epoch 66/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - autoencoder_accuracy: 1.6458e-04 - autoencoder_loss: 7223.6016 - classifier_accuracy: 0.0957 - classifier_loss: 0.2098 - loss: 3613.9307\n",
      "Epoch 67/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - autoencoder_accuracy: 8.7500e-05 - autoencoder_loss: 7213.6562 - classifier_accuracy: 0.1099 - classifier_loss: 0.2137 - loss: 3608.9514 \n",
      "Epoch 68/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - autoencoder_accuracy: 3.4792e-04 - autoencoder_loss: 7215.7944 - classifier_accuracy: 0.1388 - classifier_loss: 0.2233 - loss: 3610.0229\n",
      "Epoch 69/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - autoencoder_accuracy: 4.2708e-04 - autoencoder_loss: 7211.1890 - classifier_accuracy: 0.1413 - classifier_loss: 0.2357 - loss: 3607.7285\n",
      "Epoch 70/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - autoencoder_accuracy: 3.9583e-04 - autoencoder_loss: 7215.3750 - classifier_accuracy: 0.1151 - classifier_loss: 0.3256 - loss: 3609.9482\n",
      "Epoch 71/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - autoencoder_accuracy: 1.5625e-04 - autoencoder_loss: 7217.0498 - classifier_accuracy: 0.0981 - classifier_loss: 0.3528 - loss: 3610.8201\n",
      "Epoch 72/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - autoencoder_accuracy: 2.3750e-04 - autoencoder_loss: 7224.0093 - classifier_accuracy: 0.1383 - classifier_loss: 0.3584 - loss: 3614.3027 \n",
      "Epoch 73/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - autoencoder_accuracy: 3.3125e-04 - autoencoder_loss: 7223.3496 - classifier_accuracy: 0.1351 - classifier_loss: 0.3981 - loss: 3614.0291 \n",
      "Epoch 74/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - autoencoder_accuracy: 4.7292e-04 - autoencoder_loss: 7211.3794 - classifier_accuracy: 0.1089 - classifier_loss: 0.4132 - loss: 3608.0657 \n",
      "Epoch 75/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - autoencoder_accuracy: 5.9375e-04 - autoencoder_loss: 7221.4502 - classifier_accuracy: 0.1179 - classifier_loss: 0.3409 - loss: 3612.9912 \n",
      "Epoch 76/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - autoencoder_accuracy: 3.8542e-04 - autoencoder_loss: 7220.4219 - classifier_accuracy: 0.1342 - classifier_loss: 0.3715 - loss: 3612.5205\n",
      "Epoch 77/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 182ms/step - autoencoder_accuracy: 1.0833e-04 - autoencoder_loss: 7218.5942 - classifier_accuracy: 0.1285 - classifier_loss: 0.4440 - loss: 3611.7144\n",
      "Epoch 78/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - autoencoder_accuracy: 1.1875e-04 - autoencoder_loss: 7223.7144 - classifier_accuracy: 0.1308 - classifier_loss: 0.3442 - loss: 3614.1211\n",
      "Epoch 79/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - autoencoder_accuracy: 1.5208e-04 - autoencoder_loss: 7219.1357 - classifier_accuracy: 0.1114 - classifier_loss: 0.3600 - loss: 3611.8535\n",
      "Epoch 80/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - autoencoder_accuracy: 1.2708e-04 - autoencoder_loss: 7221.6094 - classifier_accuracy: 0.0880 - classifier_loss: 0.3215 - loss: 3613.0337\n",
      "Epoch 81/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - autoencoder_accuracy: 2.5000e-05 - autoencoder_loss: 7221.1226 - classifier_accuracy: 0.0857 - classifier_loss: 0.4216 - loss: 3612.9380 \n",
      "Epoch 82/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - autoencoder_accuracy: 8.1250e-05 - autoencoder_loss: 7214.8545 - classifier_accuracy: 0.1054 - classifier_loss: 0.3753 - loss: 3609.7275\n",
      "Epoch 83/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - autoencoder_accuracy: 3.0417e-04 - autoencoder_loss: 7211.2808 - classifier_accuracy: 0.1291 - classifier_loss: 0.4519 - loss: 3608.0532 \n",
      "Epoch 84/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - autoencoder_accuracy: 3.0625e-04 - autoencoder_loss: 7212.5366 - classifier_accuracy: 0.1254 - classifier_loss: 0.4519 - loss: 3608.6826 \n",
      "Epoch 85/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - autoencoder_accuracy: 2.3958e-04 - autoencoder_loss: 7220.1309 - classifier_accuracy: 0.1025 - classifier_loss: 0.5090 - loss: 3612.5718 \n",
      "Epoch 86/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - autoencoder_accuracy: 3.4792e-04 - autoencoder_loss: 7214.3252 - classifier_accuracy: 0.0843 - classifier_loss: 0.6104 - loss: 3609.8262 \n",
      "Epoch 87/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - autoencoder_accuracy: 4.8750e-04 - autoencoder_loss: 7216.5747 - classifier_accuracy: 0.1083 - classifier_loss: 0.3587 - loss: 3610.5713\n",
      "Epoch 88/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - autoencoder_accuracy: 8.2917e-04 - autoencoder_loss: 7219.3438 - classifier_accuracy: 0.1285 - classifier_loss: 0.4383 - loss: 3612.0706 \n",
      "Epoch 89/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - autoencoder_accuracy: 6.3542e-04 - autoencoder_loss: 7213.3755 - classifier_accuracy: 0.1428 - classifier_loss: 0.4008 - loss: 3609.0305 \n",
      "Epoch 90/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - autoencoder_accuracy: 6.2917e-04 - autoencoder_loss: 7211.5962 - classifier_accuracy: 0.0946 - classifier_loss: 0.4524 - loss: 3608.2268 \n",
      "Epoch 91/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - autoencoder_accuracy: 2.7083e-04 - autoencoder_loss: 7222.1191 - classifier_accuracy: 0.1090 - classifier_loss: 0.4103 - loss: 3613.4331 \n",
      "Epoch 92/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - autoencoder_accuracy: 1.9792e-04 - autoencoder_loss: 7217.7051 - classifier_accuracy: 0.1506 - classifier_loss: 0.3751 - loss: 3611.1746 \n",
      "Epoch 93/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - autoencoder_accuracy: 2.0417e-04 - autoencoder_loss: 7210.2764 - classifier_accuracy: 0.0819 - classifier_loss: 0.3124 - loss: 3607.3618\n",
      "Epoch 94/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - autoencoder_accuracy: 2.5000e-04 - autoencoder_loss: 7218.7578 - classifier_accuracy: 0.1144 - classifier_loss: 0.2764 - loss: 3611.5461 \n",
      "Epoch 95/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - autoencoder_accuracy: 2.9375e-04 - autoencoder_loss: 7213.4917 - classifier_accuracy: 0.1261 - classifier_loss: 0.2080 - loss: 3608.8079 \n",
      "Epoch 96/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - autoencoder_accuracy: 3.1667e-04 - autoencoder_loss: 7202.2300 - classifier_accuracy: 0.1019 - classifier_loss: 0.2180 - loss: 3603.1877\n",
      "Epoch 97/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - autoencoder_accuracy: 2.9167e-04 - autoencoder_loss: 7211.0498 - classifier_accuracy: 0.0994 - classifier_loss: 0.2107 - loss: 3607.5815 \n",
      "Epoch 98/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - autoencoder_accuracy: 2.6042e-04 - autoencoder_loss: 7223.2476 - classifier_accuracy: 0.1156 - classifier_loss: 0.1829 - loss: 3613.6331\n",
      "Epoch 99/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - autoencoder_accuracy: 2.0833e-04 - autoencoder_loss: 7225.3062 - classifier_accuracy: 0.1139 - classifier_loss: 0.1782 - loss: 3614.6494\n",
      "Epoch 100/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - autoencoder_accuracy: 2.6875e-04 - autoencoder_loss: 7221.6318 - classifier_accuracy: 0.1144 - classifier_loss: 0.1807 - loss: 3612.8091\n"
     ]
    }
   ],
   "source": [
    "# TODO: Crea y entrena tu clasificador\n",
    "\n",
    "model = MiClasificadorSemisupervisado(input_shape=x_train[0].shape)\n",
    "\n",
    "h = semisupervised_training_v2(model, x_train, one_hot_train, unlabeled_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "JSVVW8fZXWGs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n",
      "Test accuracy : 0.72\n"
     ]
    }
   ],
   "source": [
    "# TODO: Obtén la precisión sobre el conjunto de test\n",
    "print('Test accuracy :', model.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(h.history['classifier_accuracy']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mPGRXmHXptYW"
   },
   "source": [
    "# Hay vida más allá del autoencoder\n",
    "\n",
    "¿Has probado a utilizar otro método distinto del autoencoder para obtener una respresentación similar a la salida del encoder? La idea es la siguiente:\n",
    "\n",
    "1. Define un modelo $model$ convolucional similar al encoder de un autoencoder (la entrada es el tamaño de la imagen, la salida el vector de representación)\n",
    "1. Define una capa de salida $cluster$ que, partiendo de la salida de model, nos devuelva una salida con el mismo número de clases que el dataset a utilizar (la entrada es el vector de representación), usando softmax como activación de salida\n",
    "1. Para cada batch de entrenamiento $X$:  # Usa un batch alto, mínimo 128\n",
    "  1. Modifica las imágenes de entrada con [data_augmentation](https://www.tensorflow.org/tutorials/images/data_augmentation?hl=es-419), llámala $augX_1$.\n",
    "  1. Modifica otra vez las imágenes de entrada con [data_augmentation_2](https://www.tensorflow.org/tutorials/images/data_augmentation?hl=es-419), llámala $augX_2$.\n",
    "  1. $augX_{1comp} \\leftarrow model(augX_1)$\n",
    "  1. $augX_{2comp} \\leftarrow model(augX_2)$\n",
    "  1. $cX_{1comp} \\leftarrow cluster(augX_{1comp})$\n",
    "  1. $cX_{2comp} \\leftarrow cluster(augX_{2comp})$\n",
    "  1. $M \\leftarrow augX_{1comp} ~ augX_{2comp}^T$\n",
    "  1. $loss_C \\leftarrow cX_{1comp}(1 - cX_{1comp}) + cX_{2comp}(1 - cX_{2comp})$ # Puede que tengas que crear tu [propia función de coste](https://keras.io/api/losses/#creating-custom-losses)\n",
    "  1. $loss_M \\leftarrow crossentropy(I, softmax(M/\\tau, axis=1)))$ # Puede que tengas que crear tu [propia función de coste](https://keras.io/api/losses/#creating-custom-losses)\n",
    "  1. $\\tau$ es un hiperparámetro que se suele definir a 5.0\n",
    "  1. $loss \\leftarrow loss_M + \\lambda~loss_C$\n",
    "    1. $\\lambda$ es un hiperparámetro (puedes probar con 0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "id": "7cXegrUWtiFW"
   },
   "outputs": [],
   "source": [
    "# Escribe aquí la solución. Crea tantos bloques de código como necesites. Puedes utilizar la siguiente red para generar distorsiones\n",
    "\n",
    "\n",
    "class ContrastiveLoss():\n",
    "    def __init__(self, temperature=TEMPERATURE):\n",
    "        self.temperature = temperature\n",
    "        \n",
    "    def __call__(self, y_pred):\n",
    "        # y_true es la matriz identidad (no la usamos directamente)\n",
    "        # y_pred es la matriz de similitud M\n",
    "        \n",
    "        # Aplicamos softmax con temperatura\n",
    "        logits = y_pred / self.temperature\n",
    "        logits_max = tf.reduce_max(logits, axis=1, keepdims=True)\n",
    "        logits = logits - logits_max\n",
    "        exp_logits = tf.exp(logits)\n",
    "        exp_logits_sum = tf.reduce_sum(exp_logits, axis=1, keepdims=True)\n",
    "        probs = exp_logits / exp_logits_sum\n",
    "        \n",
    "        # Creamos matriz identidad como objetivo\n",
    "        batch_size = tf.shape(y_pred)[0]\n",
    "        y_true = tf.eye(batch_size)\n",
    "        \n",
    "        # Calculamos entropia cruzada\n",
    "        loss = -tf.reduce_sum(y_true * tf.math.log(probs + 1e-10)) / tf.cast(batch_size, tf.float32)\n",
    "        return loss\n",
    "\n",
    "# Función de pérdida para el clustering\n",
    "class ClusteringLoss():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def __call__(self, cX_1comp, cX_2comp):\n",
    "\n",
    "        # loss_C = cX_1comp(1 - cX_1comp) + cX_2comp(1 - cX_2comp)\n",
    "        loss_1 = tf.reduce_mean(cX_1comp * (1 - cX_1comp))\n",
    "        loss_2 = tf.reduce_mean(cX_2comp * (1 - cX_2comp))\n",
    "        \n",
    "        return loss_1 + loss_2\n",
    "\n",
    "\n",
    "class ContrastiveModel():\n",
    "    def __init__(self, input_shape, lambda_param = 0.5):\n",
    "\n",
    "        self.lambda_param = lambda_param\n",
    "        self.contrastive_loss = ContrastiveLoss()\n",
    "        self.clustering_loss = ClusteringLoss()\n",
    "\n",
    "        self.data_augmentation_1 = tf.keras.models.Sequential([\n",
    "                # tf.keras.layers.RandomFlip(\"horizontal\"),  # Puede ser util en otros casos\n",
    "                tf.keras.layers.RandomRotation(0.05),\n",
    "                tf.keras.layers.RandomTranslation(0.15, 0.15),\n",
    "                tf.keras.layers.RandomZoom(.15),\n",
    "            ])\n",
    "    \n",
    "        self.data_augmentation_2 = tf.keras.models.Sequential([\n",
    "                # tf.keras.layers.RandomFlip(\"horizontal\"),  # Puede ser util en otros casos\n",
    "                tf.keras.layers.RandomTranslation(0.15, 0.15),\n",
    "                tf.keras.layers.Resizing(48, 48), # para CIFAR, para MNIST usar 40 en lugar de 48\n",
    "                tf.keras.layers.RandomCrop(32, 32), # para CIFAR, para MNIST usar 28 en lugar de 32\n",
    "            ])\n",
    "            \n",
    "        # Definir modelo convolucional\n",
    "        input_layer = tf.keras.layers.Input(batch_shape=(None, 28, 28,1))  # Tamaño de imagen\n",
    "        conv_layer = tf.keras.layers.Conv2D(4, (3, 3), activation='relu', padding='same')(input_layer)\n",
    "        conv_layer = tf.keras.layers.Conv2D(8, (3, 3), activation='relu', padding='same')(conv_layer)\n",
    "        conv_layer = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', padding='same')(conv_layer)\n",
    "        flatten_layer = tf.keras.layers.Flatten()(conv_layer)\n",
    "        \n",
    "        # Capa de clustering\n",
    "        cluster_layer = tf.keras.layers.Dense(10, activation='softmax')(conv_layer)\n",
    "        \n",
    "        # Modelo final\n",
    "        self.encoder = tf.keras.Model(input_layer, outputs=conv_layer)\n",
    "        self.cluster = tf.keras.Model(input_layer, outputs=cluster_layer)\n",
    "        \n",
    "        #model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    \n",
    "    def train_step(self, data):\n",
    "        if isinstance(data, tuple):\n",
    "            X = data[0]\n",
    "        else:\n",
    "            X = data\n",
    "            \n",
    "        batch_size = tf.shape(X)[0]\n",
    "        \n",
    "        # Aplicar las dos transformaciones de data augmentation\n",
    "        augX_1 = self.data_augmentation_1(X)\n",
    "        augX_2 = self.data_augmentation_2(X)\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            # Obtener representaciones del encoder\n",
    "            #augX_1comp = self.encoder(augX_1)\n",
    "            augX_1comp = self.encoder(X)\n",
    "            #augX_2comp = self.encoder(augX_2)\n",
    "            augX_2comp = self.encoder(X)\n",
    "            \n",
    "            # Obtener salidas del clustering\n",
    "            #augX_1comp = tf.keras.layers.Flatten('channels_last')(augX_1comp)\n",
    "            cX_1comp = self.cluster(X)\n",
    "            cX_2comp = self.cluster(X)\n",
    "            \n",
    "            # Calcular matriz de similitud M\n",
    "            M = tf.matmul(augX_1comp, augX_2comp, transpose_b=True)\n",
    "            \n",
    "            # Calcular pérdida de contraste\n",
    "            loss_M = self.contrastive_loss(M)\n",
    "            \n",
    "            # Calcular pérdida de clustering\n",
    "            loss_C = self.clustering_loss(cX_1comp, cX_2comp)\n",
    "            \n",
    "            # Pérdida total\n",
    "            total_loss = loss_M + self.lambda_param * loss_C\n",
    "            \n",
    "        # Calcular gradientes y actualizar pesos\n",
    "        gradients = tape.gradient(total_loss, self.cluster.trainable_variables)\n",
    "        tf.keras.optimizers.AdamW().apply_gradients(zip(gradients, self.cluster.trainable_variables))\n",
    "        \n",
    "        return {\"loss\": total_loss, \"contrastive_loss\": loss_M, \"clustering_loss\": loss_C}\n",
    "\n",
    "    def mini_batches(self, X, batch_size):\n",
    "        for start in range(0, X.shape[0], batch_size):\n",
    "            # Yield each mini-batch\n",
    "            end = min(start + batch_size, X.shape[0])\n",
    "            yield X[start:end]\n",
    "\n",
    "    def train(self, dataset, epochs=10):\n",
    "        for epoch in range(epochs):\n",
    "            total_loss = 0\n",
    "            for data in self.mini_batches(dataset, 10_000):\n",
    "                loss_dict = self.train_step(data)\n",
    "                total_loss += loss_dict[\"loss\"]\n",
    "            \n",
    "           \n",
    "            print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss_dict[\"loss\"]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-23 17:34:14.888490: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: INVALID_ARGUMENT: Incompatible shapes: [10000,10000] vs. [10000,28,28,28]\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__Mul_device_/job:localhost/replica:0/task:0/device:GPU:0}} Incompatible shapes: [10000,10000] vs. [10000,28,28,28] [Op:Mul] name: ",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mInvalidArgumentError\u001b[39m                      Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[256]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m cModel = ContrastiveModel(unlabeled_train[\u001b[32m0\u001b[39m].shape, \u001b[32m0.5\u001b[39m)\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m#unlabeled_train = np.expand_dims(unlabeled_train, axis=-1)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mcModel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43munlabeled_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m#unlabeled_train.shape\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[255]\u001b[39m\u001b[32m, line 131\u001b[39m, in \u001b[36mContrastiveModel.train\u001b[39m\u001b[34m(self, dataset, epochs)\u001b[39m\n\u001b[32m    129\u001b[39m total_loss = \u001b[32m0\u001b[39m\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.mini_batches(dataset, \u001b[32m10_000\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m     loss_dict = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    132\u001b[39m     total_loss += loss_dict[\u001b[33m\"\u001b[39m\u001b[33mloss\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    135\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss_dict[\u001b[33m\"\u001b[39m\u001b[33mloss\u001b[39m\u001b[33m\"\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[255]\u001b[39m\u001b[32m, line 107\u001b[39m, in \u001b[36mContrastiveModel.train_step\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m    104\u001b[39m M = tf.matmul(augX_1comp, augX_2comp, transpose_b=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    106\u001b[39m \u001b[38;5;66;03m# Calcular pérdida de contraste\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m107\u001b[39m loss_M = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcontrastive_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mM\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    109\u001b[39m \u001b[38;5;66;03m# Calcular pérdida de clustering\u001b[39;00m\n\u001b[32m    110\u001b[39m loss_C = \u001b[38;5;28mself\u001b[39m.clustering_loss(cX_1comp, cX_2comp)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[255]\u001b[39m\u001b[32m, line 25\u001b[39m, in \u001b[36mContrastiveLoss.__call__\u001b[39m\u001b[34m(self, y_pred)\u001b[39m\n\u001b[32m     22\u001b[39m y_true = tf.eye(batch_size)\n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m# Calculamos entropia cruzada\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m loss = -tf.reduce_sum(\u001b[43my_true\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43mtf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlog\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprobs\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1e-10\u001b[39;49m\u001b[43m)\u001b[49m) / tf.cast(batch_size, tf.float32)\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/carrera/3/2/ma2/ma2Python12/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    155\u001b[39m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/carrera/3/2/ma2/ma2Python12/lib/python3.12/site-packages/tensorflow/python/framework/ops.py:5983\u001b[39m, in \u001b[36mraise_from_not_ok_status\u001b[39m\u001b[34m(e, name)\u001b[39m\n\u001b[32m   5981\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mraise_from_not_ok_status\u001b[39m(e, name) -> NoReturn:\n\u001b[32m   5982\u001b[39m   e.message += (\u001b[33m\"\u001b[39m\u001b[33m name: \u001b[39m\u001b[33m\"\u001b[39m + \u001b[38;5;28mstr\u001b[39m(name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m-> \u001b[39m\u001b[32m5983\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m core._status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mInvalidArgumentError\u001b[39m: {{function_node __wrapped__Mul_device_/job:localhost/replica:0/task:0/device:GPU:0}} Incompatible shapes: [10000,10000] vs. [10000,28,28,28] [Op:Mul] name: "
     ]
    }
   ],
   "source": [
    "cModel = ContrastiveModel(unlabeled_train[0].shape, 0.5)\n",
    "#unlabeled_train = np.expand_dims(unlabeled_train, axis=-1)\n",
    "cModel.train(unlabeled_train)\n",
    "#unlabeled_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vEZfd7iVX94s"
   },
   "source": [
    "# Trabajo extra\n",
    "\n",
    "¿Has probado a hacer el autoencoder totalmente convolucional? Para el *decoder* puedes usar las funciones [UpSampling2D](https://www.tensorflow.org/api_docs/python/tf/keras/layers/UpSampling2D) o [Conv2DTranspose](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2DTranspose)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: crea el nuevo modelo\n",
    "\n",
    "# TODO: crea tu propio clasificador\n",
    "\n",
    "class MiClasificadorSemisupervisado:\n",
    "\n",
    "    def __init__(self, input_shape):\n",
    "        # TODO : define el modelo y compílalo\n",
    "        \n",
    "        self.input_shape = (28,28,1)\n",
    "        self.num_classes = 10\n",
    "        \n",
    "        input_layer = layers.Input(shape=self.input_shape)\n",
    "        \n",
    "        # Encoder part (shared for both autoencoder and classifier)\n",
    "        # Convolutional layers instead of dense layers\n",
    "        x = layers.Conv2D(32, (3, 3), activation='relu')(input_layer)\n",
    "        x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "        x = layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
    "        x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "        x = layers.Conv2D(128, (3, 3), activation='relu')(x)\n",
    "        x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "        \n",
    "        # Encoder output (encoded features for classifier)\n",
    "        encoded = layers.Flatten()(x)\n",
    "        encoded = layers.Dense(64, activation='relu', kernel_regularizer='l2')(encoded)\n",
    "        \n",
    "        # Decoder for autoencoder part (using Conv2DTranspose layers)\n",
    "        decoded = layers.Dense(8 * 8 * 128, activation='relu', kernel_regularizer='l2')(encoded)\n",
    "        decoded = layers.Reshape((8, 8, 128))(decoded)\n",
    "        decoded = layers.Conv2DTranspose(128, (3, 3), activation='relu')(decoded)\n",
    "        decoded = layers.UpSampling2D((2, 2))(decoded)\n",
    "        decoded = layers.Conv2DTranspose(64, (3, 3), activation='relu')(decoded)\n",
    "        #decoded = layers.UpSampling2D((2, 2))(decoded)\n",
    "        decoded = layers.Conv2DTranspose(32, (3, 3), activation='relu', padding=(1,1))(decoded)\n",
    "        #decoded = layers.UpSampling2D((2, 2))(decoded)\n",
    "        decoded = layers.Conv2DTranspose(self.input_shape[2], (3, 3), activation='sigmoid', name='autoencoder')(decoded)\n",
    "\n",
    "\n",
    "        # Classifier part\n",
    "        classifier = layers.Dense(64, activation='relu', kernel_regularizer='l2')(encoded)\n",
    "        classifier = layers.Dense(32, activation='relu', kernel_regularizer='l2')(classifier)\n",
    "        classifier_output = layers.Dense(self.num_classes, activation='softmax',name='classifier')(classifier)\n",
    "\n",
    "        # Autoencoder model (for reconstructing input)\n",
    "        self.autoencoder = models.Model(input_layer, decoded)\n",
    "        self.autoencoder.compile(optimizer='adam', loss='mse')\n",
    "        \n",
    "        # Classifier model (for predicting class labels)\n",
    "        self.classifier = models.Model(input_layer, classifier_output)\n",
    "        self.classifier.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        # Combined model with two outputs: one for autoencoder (reconstruction) and one for classifier (classification)\n",
    "        self.model = models.Model(input_layer, \n",
    "                                  [decoded, classifier_output])\n",
    "                                  #classifier_output)\n",
    "        self.model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "                           loss=['mse', 'categorical_crossentropy'],\n",
    "                           #loss='categorical_crossentropy',\n",
    "                           loss_weights=[.5, 1.5],  # Adjust loss weights if needed\n",
    "                           metrics=['accuracy', 'accuracy'])\n",
    "    \n",
    "    def fit(self, X, y, unlabeled_data, batch_size,  epochs):\n",
    "        # TODO: entrena el modelo. Escoge el tamaño de batch y el número de epochs que quieras, y define bien el sample_weight\n",
    "\n",
    "        all_x = np.vstack((X, unlabeled_train))\n",
    "        y_zeros = np.zeros((unlabeled_data.shape[0],y.shape[1]))\n",
    "        all_y = np.vstack((y,y_zeros))\n",
    "        weight_autoencoder = np.ones(len(all_x))\n",
    "        weight_classifier = np.array([1]*len(X) + [0]*len(unlabeled_data))\n",
    "        \n",
    "        h = self.model.fit(all_x, \n",
    "                       [all_x, all_y], \n",
    "                       #all_y,\n",
    "                       sample_weight=[weight_autoencoder, weight_classifier], \n",
    "                       #sample_weight=sample_weight,\n",
    "                       epochs=epochs, \n",
    "                       batch_size=batch_size, \n",
    "                       verbose=1)\n",
    "        return h\n",
    "\n",
    "    def predict(self, X):\n",
    "        # TODO: devuelve la clase ganadora del clasificador\n",
    "        _, predictions = self.model.predict(X)\n",
    "        return predictions.argmax(axis=1)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        # TODO: devuelve la probabilidad del clasificador\n",
    "        _, predictions = self.model.predict(X)\n",
    "        return predictions\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        y_pred = self.predict(X)\n",
    "        return accuracy_score(y, y_pred)\n",
    "\n",
    "    def __del__(self):\n",
    "        # elimina todos los modelos que hayas creado\n",
    "        tf.keras.backend.clear_session() # Necesario para liberar la memoria en GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Exception encountered when calling Conv2DTranspose.call().\n\n\u001b[1m'tuple' object has no attribute 'lower'\u001b[0m\n\nArguments received by Conv2DTranspose.call():\n  • args=('<KerasTensor shape=(None, 22, 22, 64), dtype=float32, sparse=False, ragged=False, name=keras_tensor_174>',)\n  • kwargs=<class 'inspect._empty'>",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[76]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m model = \u001b[43mMiClasificadorSemisupervisado\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m=\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m h = model.fit(x_train, one_hot_train, unlabeled_train, batch_size=\u001b[32m60_000\u001b[39m, epochs = \u001b[32m100\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[75]\u001b[39m\u001b[32m, line 35\u001b[39m, in \u001b[36mMiClasificadorSemisupervisado.__init__\u001b[39m\u001b[34m(self, input_shape)\u001b[39m\n\u001b[32m     33\u001b[39m decoded = layers.Conv2DTranspose(\u001b[32m64\u001b[39m, (\u001b[32m3\u001b[39m, \u001b[32m3\u001b[39m), activation=\u001b[33m'\u001b[39m\u001b[33mrelu\u001b[39m\u001b[33m'\u001b[39m)(decoded)\n\u001b[32m     34\u001b[39m \u001b[38;5;66;03m#decoded = layers.UpSampling2D((2, 2))(decoded)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m decoded = \u001b[43mlayers\u001b[49m\u001b[43m.\u001b[49m\u001b[43mConv2DTranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrelu\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdecoded\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[38;5;66;03m#decoded = layers.UpSampling2D((2, 2))(decoded)\u001b[39;00m\n\u001b[32m     37\u001b[39m decoded = layers.Conv2DTranspose(\u001b[38;5;28mself\u001b[39m.input_shape[\u001b[32m2\u001b[39m], (\u001b[32m3\u001b[39m, \u001b[32m3\u001b[39m), activation=\u001b[33m'\u001b[39m\u001b[33msigmoid\u001b[39m\u001b[33m'\u001b[39m, name=\u001b[33m'\u001b[39m\u001b[33mautoencoder\u001b[39m\u001b[33m'\u001b[39m)(decoded)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/carrera/3/2/ma2/ma2Python12/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/carrera/3/2/ma2/ma2Python12/lib/python3.12/site-packages/keras/src/backend/common/backend_utils.py:196\u001b[39m, in \u001b[36m_get_output_shape_given_tf_padding\u001b[39m\u001b[34m(input_size, kernel_size, strides, padding, output_padding, dilation_rate)\u001b[39m\n\u001b[32m    193\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m input_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    194\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m196\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[43mpadding\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlower\u001b[49m() \u001b[38;5;129;01min\u001b[39;00m {\u001b[33m\"\u001b[39m\u001b[33mvalid\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33msame\u001b[39m\u001b[33m\"\u001b[39m}\n\u001b[32m    198\u001b[39m kernel_size = (kernel_size - \u001b[32m1\u001b[39m) * dilation_rate + \u001b[32m1\u001b[39m\n\u001b[32m    200\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m padding.lower() == \u001b[33m\"\u001b[39m\u001b[33mvalid\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[31mAttributeError\u001b[39m: Exception encountered when calling Conv2DTranspose.call().\n\n\u001b[1m'tuple' object has no attribute 'lower'\u001b[0m\n\nArguments received by Conv2DTranspose.call():\n  • args=('<KerasTensor shape=(None, 22, 22, 64), dtype=float32, sparse=False, ragged=False, name=keras_tensor_174>',)\n  • kwargs=<class 'inspect._empty'>"
     ]
    }
   ],
   "source": [
    "model = MiClasificadorSemisupervisado(input_shape=x_train[0].shape)\n",
    "h = model.fit(x_train, one_hot_train, unlabeled_train, batch_size=60_000, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(h.history['classifier_accuracy']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pepe/carrera/3/2/ma2/ma2Python12/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "pop from empty list",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/carrera/3/2/ma2/ma2Python12/lib/python3.12/site-packages/keras/src/layers/layer.py:229\u001b[39m, in \u001b[36mLayer.__new__.<locals>.build_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    228\u001b[39m     obj._path = current_path()\n\u001b[32m--> \u001b[39m\u001b[32m229\u001b[39m     \u001b[43moriginal_build_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    230\u001b[39m \u001b[38;5;66;03m# Record build config.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/carrera/3/2/ma2/ma2Python12/lib/python3.12/site-packages/keras/src/models/sequential.py:195\u001b[39m, in \u001b[36mSequential.build\u001b[39m\u001b[34m(self, input_shape)\u001b[39m\n\u001b[32m    194\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m195\u001b[39m     x = \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    196\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n\u001b[32m    197\u001b[39m     \u001b[38;5;66;03m# Can happen if shape inference is not implemented.\u001b[39;00m\n\u001b[32m    198\u001b[39m     \u001b[38;5;66;03m# TODO: consider reverting inbound nodes on layers processed.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/carrera/3/2/ma2/ma2Python12/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/carrera/3/2/ma2/ma2Python12/lib/python3.12/site-packages/keras/src/backend/common/name_scope.py:61\u001b[39m, in \u001b[36mname_scope.__exit__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     58\u001b[39m name_scope_stack = global_state.get_global_attribute(\n\u001b[32m     59\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mname_scope_stack\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     60\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m61\u001b[39m \u001b[43mname_scope_stack\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mIndexError\u001b[39m: pop from empty list",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[91]\u001b[39m\u001b[32m, line 208\u001b[39m\n\u001b[32m    205\u001b[39m \u001b[38;5;66;03m# Ejemplo de uso completo\u001b[39;00m\n\u001b[32m    206\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    207\u001b[39m     \u001b[38;5;66;03m# Entrenar el modelo contrastivo\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m208\u001b[39m     contrastive_model = \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    210\u001b[39m     \u001b[38;5;66;03m# Cargar datos\u001b[39;00m\n\u001b[32m    211\u001b[39m     (x_train, y_train), (x_test, y_test) = load_dataset()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[91]\u001b[39m\u001b[32m, line 167\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    165\u001b[39m \u001b[38;5;66;03m# Crear modelo\u001b[39;00m\n\u001b[32m    166\u001b[39m input_shape = x_train.shape[\u001b[32m1\u001b[39m:]\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m model = \u001b[43mContrastiveModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[38;5;66;03m# Compilar el modelo\u001b[39;00m\n\u001b[32m    170\u001b[39m model.compile(optimizer=keras.optimizers.Adam(\u001b[32m1e-4\u001b[39m))\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[91]\u001b[39m\u001b[32m, line 94\u001b[39m, in \u001b[36mContrastiveModel.__init__\u001b[39m\u001b[34m(self, input_shape, embedding_dim, num_classes)\u001b[39m\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_shape=(\u001b[32m32\u001b[39m, \u001b[32m32\u001b[39m, \u001b[32m3\u001b[39m), embedding_dim=EMBEDDING_DIM, num_classes=NUM_CLASSES):\n\u001b[32m     93\u001b[39m     \u001b[38;5;28msuper\u001b[39m(ContrastiveModel, \u001b[38;5;28mself\u001b[39m).\u001b[34m__init__\u001b[39m()\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m     \u001b[38;5;28mself\u001b[39m.encoder = \u001b[43mcreate_encoder_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     95\u001b[39m     \u001b[38;5;28mself\u001b[39m.cluster = create_cluster_model(embedding_dim, num_classes)\n\u001b[32m     96\u001b[39m     \u001b[38;5;28mself\u001b[39m.data_aug1 = get_data_augmentation()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[91]\u001b[39m\u001b[32m, line 15\u001b[39m, in \u001b[36mcreate_encoder_model\u001b[39m\u001b[34m(input_shape)\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate_encoder_model\u001b[39m(input_shape=(\u001b[32m32\u001b[39m, \u001b[32m32\u001b[39m, \u001b[32m3\u001b[39m)):\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m     model = \u001b[43mmodels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mSequential\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlayers\u001b[49m\u001b[43m.\u001b[49m\u001b[43mConv2D\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrelu\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msame\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlayers\u001b[49m\u001b[43m.\u001b[49m\u001b[43mMaxPooling2D\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlayers\u001b[49m\u001b[43m.\u001b[49m\u001b[43mConv2D\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrelu\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msame\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlayers\u001b[49m\u001b[43m.\u001b[49m\u001b[43mMaxPooling2D\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlayers\u001b[49m\u001b[43m.\u001b[49m\u001b[43mConv2D\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrelu\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msame\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlayers\u001b[49m\u001b[43m.\u001b[49m\u001b[43mMaxPooling2D\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlayers\u001b[49m\u001b[43m.\u001b[49m\u001b[43mFlatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlayers\u001b[49m\u001b[43m.\u001b[49m\u001b[43mDense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mEMBEDDING_DIM\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/carrera/3/2/ma2/ma2Python12/lib/python3.12/site-packages/keras/src/models/sequential.py:76\u001b[39m, in \u001b[36mSequential.__init__\u001b[39m\u001b[34m(self, layers, trainable, name)\u001b[39m\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m layers:\n\u001b[32m     75\u001b[39m     \u001b[38;5;28mself\u001b[39m.add(layer, rebuild=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_maybe_rebuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/carrera/3/2/ma2/ma2Python12/lib/python3.12/site-packages/keras/src/models/sequential.py:149\u001b[39m, in \u001b[36mSequential._maybe_rebuild\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    147\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m._layers[\u001b[32m0\u001b[39m], InputLayer) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._layers) > \u001b[32m1\u001b[39m:\n\u001b[32m    148\u001b[39m     input_shape = \u001b[38;5;28mself\u001b[39m._layers[\u001b[32m0\u001b[39m].batch_shape\n\u001b[32m--> \u001b[39m\u001b[32m149\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    150\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m._layers[\u001b[32m0\u001b[39m], \u001b[33m\"\u001b[39m\u001b[33minput_shape\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._layers) > \u001b[32m1\u001b[39m:\n\u001b[32m    151\u001b[39m     \u001b[38;5;66;03m# We can build the Sequential model if the first layer has the\u001b[39;00m\n\u001b[32m    152\u001b[39m     \u001b[38;5;66;03m# `input_shape` property. This is most commonly found in Functional\u001b[39;00m\n\u001b[32m    153\u001b[39m     \u001b[38;5;66;03m# model.\u001b[39;00m\n\u001b[32m    154\u001b[39m     input_shape = \u001b[38;5;28mself\u001b[39m._layers[\u001b[32m0\u001b[39m].input_shape\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/carrera/3/2/ma2/ma2Python12/lib/python3.12/site-packages/keras/src/layers/layer.py:227\u001b[39m, in \u001b[36mLayer.__new__.<locals>.build_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    225\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(original_build_method)\n\u001b[32m    226\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbuild_wrapper\u001b[39m(*args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m227\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m obj._open_name_scope():\n\u001b[32m    228\u001b[39m         obj._path = current_path()\n\u001b[32m    229\u001b[39m         original_build_method(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/carrera/3/2/ma2/ma2Python12/lib/python3.12/site-packages/keras/src/backend/tensorflow/core.py:679\u001b[39m, in \u001b[36mname_scope.__exit__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    678\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m679\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__exit__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    680\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pop_on_exit:\n\u001b[32m    681\u001b[39m         \u001b[38;5;28mself\u001b[39m._tf_name_scope.\u001b[34m__exit__\u001b[39m(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/carrera/3/2/ma2/ma2Python12/lib/python3.12/site-packages/keras/src/backend/common/name_scope.py:61\u001b[39m, in \u001b[36mname_scope.__exit__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pop_on_exit:\n\u001b[32m     58\u001b[39m     name_scope_stack = global_state.get_global_attribute(\n\u001b[32m     59\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mname_scope_stack\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     60\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m61\u001b[39m     \u001b[43mname_scope_stack\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mIndexError\u001b[39m: pop from empty list"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, losses\n",
    "import numpy as np\n",
    "\n",
    "# Hiperparámetros\n",
    "BATCH_SIZE = 128\n",
    "EMBEDDING_DIM = 128\n",
    "NUM_CLASSES = 10  # Ajustar según el dataset\n",
    "TEMPERATURE = 5.0\n",
    "LAMBDA = 0.5\n",
    "\n",
    "# Función para crear el modelo CNN (similar al encoder)\n",
    "def create_encoder_model(input_shape=(32, 32, 3)):\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(EMBEDDING_DIM)\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Función para crear la capa de cluster\n",
    "def create_cluster_model(embedding_dim=EMBEDDING_DIM, num_classes=NUM_CLASSES):\n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=(embedding_dim,)),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Data augmentation para imágenes\n",
    "def get_data_augmentation():\n",
    "    data_augmentation = keras.Sequential([\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomRotation(0.1),\n",
    "        layers.RandomZoom(0.1),\n",
    "    ])\n",
    "    return data_augmentation\n",
    "\n",
    "# Data augmentation diferente para segundo conjunto\n",
    "def get_data_augmentation_2():\n",
    "    data_augmentation = keras.Sequential([\n",
    "        layers.RandomFlip(\"vertical\"),\n",
    "        layers.RandomContrast(0.2),\n",
    "        layers.RandomTranslation(0.1, 0.1),\n",
    "    ])\n",
    "    return data_augmentation\n",
    "\n",
    "# Función de pérdida para la matriz de similitud\n",
    "class ContrastiveLoss():\n",
    "    def __init__(self, temperature=TEMPERATURE):\n",
    "        self.temperature = temperature\n",
    "        \n",
    "    def __call__(self, y_pred):\n",
    "        # y_true es la matriz identidad (no la usamos directamente)\n",
    "        # y_pred es la matriz de similitud M\n",
    "        \n",
    "        # Aplicamos softmax con temperatura\n",
    "        logits = y_pred / self.temperature\n",
    "        logits_max = tf.reduce_max(logits, axis=1, keepdims=True)\n",
    "        logits = logits - logits_max\n",
    "        exp_logits = tf.exp(logits)\n",
    "        exp_logits_sum = tf.reduce_sum(exp_logits, axis=1, keepdims=True)\n",
    "        probs = exp_logits / exp_logits_sum\n",
    "        \n",
    "        # Creamos matriz identidad como objetivo\n",
    "        batch_size = tf.shape(y_pred)[0]\n",
    "        y_true = tf.eye(batch_size)\n",
    "        \n",
    "        # Calculamos entropia cruzada\n",
    "        loss = -tf.reduce_sum(y_true * tf.math.log(probs + 1e-10)) / tf.cast(batch_size, tf.float32)\n",
    "        return loss\n",
    "\n",
    "# Función de pérdida para el clustering\n",
    "class ClusteringLoss():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def __call__(self, cX_1comp, cX_2comp):\n",
    "\n",
    "        # loss_C = cX_1comp(1 - cX_1comp) + cX_2comp(1 - cX_2comp)\n",
    "        loss_1 = tf.reduce_mean(cX_1comp * (1 - cX_1comp))\n",
    "        loss_2 = tf.reduce_mean(cX_2comp * (1 - cX_2comp))\n",
    "        \n",
    "        return loss_1 + loss_2\n",
    "\n",
    "# Modelo combinado para entrenamiento\n",
    "class ContrastiveModel(tf.keras.Model):\n",
    "    def __init__(self, input_shape=(32, 32, 3), embedding_dim=EMBEDDING_DIM, num_classes=NUM_CLASSES):\n",
    "        super(ContrastiveModel, self).__init__()\n",
    "        self.encoder = create_encoder_model(input_shape)\n",
    "        self.cluster = create_cluster_model(embedding_dim, num_classes)\n",
    "        self.data_aug1 = get_data_augmentation()\n",
    "        self.data_aug2 = get_data_augmentation_2()\n",
    "        self.contrastive_loss = ContrastiveLoss()\n",
    "        self.clustering_loss = ClusteringLoss()\n",
    "        self.lambda_param = LAMBDA\n",
    "        \n",
    "    def compile(self, optimizer):\n",
    "        super(ContrastiveModel, self).compile()\n",
    "        self.optimizer = optimizer\n",
    "        \n",
    "    def train_step(self, data):\n",
    "        # Desempaquetar los datos\n",
    "        if isinstance(data, tuple):\n",
    "            X = data[0]\n",
    "        else:\n",
    "            X = data\n",
    "            \n",
    "        batch_size = tf.shape(X)[0]\n",
    "        \n",
    "        # Aplicar las dos transformaciones de data augmentation\n",
    "        augX_1 = self.data_aug1(X)\n",
    "        augX_2 = self.data_aug2(X)\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            # Obtener representaciones del encoder\n",
    "            augX_1comp = self.encoder(augX_1)\n",
    "            augX_2comp = self.encoder(augX_2)\n",
    "            \n",
    "            # Obtener salidas del clustering\n",
    "            cX_1comp = self.cluster(augX_1comp)\n",
    "            cX_2comp = self.cluster(augX_2comp)\n",
    "            \n",
    "            # Calcular matriz de similitud M\n",
    "            M = tf.matmul(augX_1comp, augX_2comp, transpose_b=True)\n",
    "            \n",
    "            # Calcular pérdida de contraste\n",
    "            loss_M = self.contrastive_loss(M)\n",
    "            \n",
    "            # Calcular pérdida de clustering\n",
    "            loss_C = self.clustering_loss(cX_1comp, cX_2comp)\n",
    "            \n",
    "            # Pérdida total\n",
    "            total_loss = loss_M + self.lambda_param * loss_C\n",
    "            \n",
    "        # Calcular gradientes y actualizar pesos\n",
    "        gradients = tape.gradient(total_loss, self.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "        \n",
    "        return {\"loss\": total_loss, \"contrastive_loss\": loss_M, \"clustering_loss\": loss_C}\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        # Para inferencia, solo devolvemos la representación del encoder\n",
    "        return self.encoder(inputs)\n",
    "\n",
    "# Función de utilidad para cargar y preparar dataset (ej. CIFAR-10)\n",
    "def load_dataset():\n",
    "    (x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "    x_train = x_train.astype(\"float32\") / 255.0\n",
    "    x_test = x_test.astype(\"float32\") / 255.0\n",
    "    return (x_train, y_train), (x_test, y_test)\n",
    "\n",
    "def dummy_loss(y_true, y_pred):\n",
    "    return tf.constant(0.0)\n",
    "\n",
    "# Entrenamiento del modelo\n",
    "def train_model():\n",
    "    # Cargar dataset\n",
    "    (x_train, y_train), (x_test, y_test) = load_dataset()\n",
    "    \n",
    "    # Crear modelo\n",
    "    input_shape = x_train.shape[1:]\n",
    "    model = ContrastiveModel(input_shape=input_shape)\n",
    "    \n",
    "    # Compilar el modelo\n",
    "    model.compile(optimizer=keras.optimizers.Adam(1e-4))\n",
    "    \n",
    "    # Entrenar modelo\n",
    "    model.fit(\n",
    "        x_train,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        epochs=20,\n",
    "        validation_data=(x_test, None),\n",
    "        loss=dummy_loss\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Para usar el modelo entrenado para extraer representaciones:\n",
    "def extract_features(model, images):\n",
    "    return model.encoder(images).numpy()\n",
    "\n",
    "# Para clasificación, se puede entrenar un clasificador sobre las características extraídas\n",
    "def train_classifier(X_features, y_labels):\n",
    "    classifier = keras.Sequential([\n",
    "        layers.Input(shape=(EMBEDDING_DIM,)),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(NUM_CLASSES, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    classifier.compile(\n",
    "        optimizer=keras.optimizers.Adam(1e-3),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    classifier.fit(X_features, y_labels, batch_size=32, epochs=10, validation_split=0.1)\n",
    "    return classifier\n",
    "\n",
    "# Ejemplo de uso completo\n",
    "if __name__ == \"__main__\":\n",
    "    # Entrenar el modelo contrastivo\n",
    "    contrastive_model = train_model()\n",
    "    \n",
    "    # Cargar datos\n",
    "    (x_train, y_train), (x_test, y_test) = load_dataset()\n",
    "    \n",
    "    # Extraer características\n",
    "    train_features = extract_features(contrastive_model, x_train)\n",
    "    test_features = extract_features(contrastive_model, x_test)\n",
    "    \n",
    "    # Entrenar clasificador\n",
    "    classifier = train_classifier(train_features, y_train)\n",
    "    \n",
    "    # Evaluar\n",
    "    test_loss, test_acc = classifier.evaluate(test_features, y_test)\n",
    "    print(f\"Test accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unlabeled_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
