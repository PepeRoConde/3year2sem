{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57knM8jrYZ2t"
      },
      "source": [
        "# Notebook 5: One Class Network\n",
        "\n",
        "## Pre-requisitos\n",
        "\n",
        "### Instalar paquetes\n",
        "\n",
        "Si la práctica requiere algún paquete de Python, habrá que incluir una celda en la que se instalen. Si usamos un paquete que se ha utilizado en prácticas anteriores, podríamos dar por supuesto que está instalado pero no cuesta nada satisfacer todas las dependencias en la propia práctica para reducir las dependencias entre ellas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LkaimNJfYZ2w"
      },
      "outputs": [],
      "source": [
        "# Ejemplo de instalación de tensorflow 2.0\n",
        "#%tensorflow_version 2.x\n",
        "# !pip3 install tensorflow  # NECESARIO SOLO SI SE EJECUTA EN LOCAL\n",
        "import tensorflow as tf\n",
        "\n",
        "# Hacemos los imports que sean necesarios\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SOch-CnwQttl"
      },
      "source": [
        "# One Class sobre datos artificiales\n",
        "\n",
        "Lo primero que tenemos que hacer es definir los datos a utilizar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1gXdWDBIEKel"
      },
      "outputs": [],
      "source": [
        "random_state = 42\n",
        "rng = np.random.RandomState(random_state)\n",
        "#  datos de entrenamiento\n",
        "X = 0.3 * rng.randn(5000, 2)\n",
        "x_train = np.r_[X + 2, X - 2]\n",
        "#  datos de test en la misma distribución que los datos de entrenamiento\n",
        "X = 0.3 * rng.randn(200, 2)\n",
        "x_test = np.r_[X + 2, X - 2]\n",
        "#  outliers\n",
        "x_outliers = rng.uniform(low=-4, high=4, size=(200, 2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(10000, 2) (400, 2) (200, 2)\n"
          ]
        }
      ],
      "source": [
        "print(x_train.shape, x_test.shape, x_outliers.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wkaCDOGapMyl"
      },
      "source": [
        "## Crea tu propia red para la detección de anomalías\n",
        "\n",
        "Vamos a crear nuestra propia red para la detección de anomalías. Para ello, vamos a definir una red cualquiera, que nos **transforme los datos de entrada en una salida de un único elemento**. Esta red va a cumplir una serie de características:\n",
        "\n",
        "* La capa anterior a la salida serán las llamadas **deep features**.\n",
        "* Todas las capas (incluyendo la última) deben incluir regularización.\n",
        "* La función de coste es $$L(y, \\tilde{y}) = \\dfrac{1}{2} \\| w^2 \\| + \\dfrac{1}{\\nu} \\dfrac{1}{N} \\sum_{i=1}^N \\max(0, r - \\tilde{y}) $$ donde $\\tilde{y}$ es la salida de la red, $\\nu$ es un hiperparámetro entre 0 y 1, y $r$ es un parámetro no entrenable, pero que va a ser modificado en cada epoch.\n",
        "* Al final del cada epoch, r va a ser modificado al valor del $\\nu$-cuantil de los datos de entrada (este valor será modificado gracias al Callback proporcionado a continuación).\n",
        "* Para la predicción, se considerará un dato típico si $\\tilde{y} > r$. En caso contrario, será un dato atípico."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_JM1GSLe8nXc"
      },
      "outputs": [],
      "source": [
        "class ChangeRCallback(tf.keras.callbacks.Callback):\n",
        "   def __init__(self, train_data, delta=.025, steps=3):\n",
        "       super().__init__()\n",
        "       self.train_data = train_data\n",
        "       self.delta = delta\n",
        "       self.steps = steps\n",
        "       self.cont = 0\n",
        "\n",
        "   def on_epoch_end(self, epoch, logs=None):\n",
        "       sorted_values = np.sort(self.model.predict(self.train_data).flatten())\n",
        "       new_value = sorted_values[int(len(sorted_values) * (1. - self.model.nu))]\n",
        "       old_value = self.model.r.numpy()\n",
        "       print('Cambiando r a', new_value, ', max:', sorted_values.max(), ', min:', sorted_values.min())\n",
        "       self.model.r.assign(new_value)\n",
        "       if np.abs(old_value - new_value) < self.delta:\n",
        "            self.cont += 1\n",
        "            if self.cont >= self.steps:\n",
        "                print('Convergencia obtenida. Finalizando el entrenamiento.')\n",
        "                self.model.stop_training = True\n",
        "       else:\n",
        "            self.cont = 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nroMok1bG9p0"
      },
      "source": [
        "Tu trabajo es crear el modelo y entrenarlo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5xjcLa21EKen"
      },
      "outputs": [],
      "source": [
        "# TODO: implementa la red de detección de anomalías\n",
        "\n",
        "class DetectorAnomalias:\n",
        "\n",
        "    def __init__(self, input_shape, nu=.5):\n",
        "        # TODO : define el modelo\n",
        "\n",
        "        self.model = tf.keras.models.Sequential([\n",
        "            tf.keras.layers.InputLayer(input_shape=input_shape),\n",
        "            tf.keras.layers.Dense(32, activation='relu'),\n",
        "            tf.keras.layers.Dense(16, activation='relu'),\n",
        "            # No usamos probabilidad usamos un escalar como salida\n",
        "            tf.keras.layers.Dense(1)\n",
        "        ])\n",
        "\n",
        "        self.model.r = tf.Variable(1.0, trainable=False, name='r', dtype=tf.float32)\n",
        "        self.model.nu = tf.Variable(nu, trainable=False, name='nu', dtype=tf.float32)\n",
        "        \n",
        "      \n",
        "    def loss_function(self, y_true, y_pred):\n",
        "        # TODO: crea la función de pérdida\n",
        "        w = ...\n",
        "        r = self.model.r\n",
        "        v = self.model.nu\n",
        "        loss = 1/2 * (w) + 1/self.model.nu * 1/len(y_true) * sum(max(0, r - v), len(y_true))\n",
        "        return loss\n",
        "    \n",
        "    def fit(self, X, y=None, sample_weight=None):\n",
        "        # TODO: entrena el modelo. Escoge el tamaño de batch y el número de epochs que quieras. No te olvides del callback.\n",
        "        dummy_y = np.zeros((len(X), 1)) # Necesario pasar como salida para que keras no de un error\n",
        "\n",
        "        self.model.compile(optimizer='adam', loss=self.loss_function)\n",
        "        self.model.fit(X, dummy_y, callbacks=[ChangeRCallback(X)], batch_size=64, epochs=5)\n",
        "        return self.model\n",
        "        \n",
        "    def predict(self, X):\n",
        "        # TODO: Devuelve la predicción del modelo\n",
        "        return self.model.predict(X)\n",
        "\n",
        "    def get_encoded_data(self, X):\n",
        "        # TODO: devuelve la salida del encoder (code)\n",
        "        return self.model.layers[1].predict(X)\n",
        "        \n",
        "    def __del__(self):\n",
        "        # TODO: borra el modelo\n",
        "        del self.model\n",
        "        tf.keras.backend.clear_session() # Necesario para liberar la memoria en GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjFXe6EiYfRg"
      },
      "source": [
        "### Entrena el modelo.\n",
        "\n",
        "Usa lo hecho anteriormente para entrenar tu modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lNC1s2Wmqx4x"
      },
      "outputs": [],
      "source": [
        "# TODO: Define el modelo\n",
        "def model_func():\n",
        "    model = DetectorAnomalias(input_shape=(2,))\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hN2zd3DEYnKI"
      },
      "outputs": [],
      "source": [
        "# TODO: Entrena tu modelo\n",
        "model = model_func()\n",
        "model.fit(x_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbUKp14pPsrp"
      },
      "source": [
        "## Evaluando el modelo\n",
        "\n",
        "Una vez entrenado, para evaluar el modelo sólo hay que tener en cuenta lo siguiente:\n",
        "\n",
        "  1. Si la salida es mayor que r, es un dato típico.\n",
        "  1. Si la salida es menor que r, es un dato atípico.\n",
        "\n",
        "### TRABAJO: Evalúa el modelo con los datos del conjunto de test, y con los outliers. Visualiza los datos típicos y atípicos con una gráfica."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7eF_9LMeZ2J2"
      },
      "outputs": [],
      "source": [
        "# TODO: Evalúa el modelo con los datos del conjunto de test. Indica el porcentaje de datos etiquetados como típicos, y visualiza los datos\n",
        "model.predict(x_test)\n",
        "print('Porcentaje de datos etiquetados como típicos:', ...)\n",
        "print('Datos de test:')\n",
        "print(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YbqC0inexwHp"
      },
      "outputs": [],
      "source": [
        "# TODO: Evalúa el modelo con los datos del conjunto de outliers. Indica el porcentaje de datos etiquetados como atípicos, y visualiza los datos en conjunto con los de test\n",
        "model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDWehV02UIpl"
      },
      "source": [
        "¿Qué resultados has obtenido? Si el número de outliers detectado es bajo (inferior al 30%), puedes estar cometiendo algún error, entre ellos:\n",
        "\n",
        "* Sobreentrenar el modelo. Prueba a usar un delta distinto en el callback.\n",
        "* Usar un valor de $\\nu$ demasiado alto.\n",
        "\n",
        "Prueba distintas configuraciones para ver su efecto."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "9_oneclass.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "maai_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
