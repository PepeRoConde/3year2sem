{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# practica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dudas miercoles:\n",
    " - articulo dbscan: '1. Since DBSCAN and CLARANS are clustering algorithms of different types, they have no common quantitative measure of the classification accuracy. Therefore, we evaluate the accuracy of both algorithms by visual inspection.'\n",
    " - autoencoder\n",
    " - numero de clusters es hiperparametro de modelo o algo más\n",
    " - atipicos\n",
    " - que deberiamos hacer con labels\n",
    "\n",
    "   ---\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "En esta práctica, se aplicarán técnicas de agrupamiento para analizar un conjunto de\n",
    "datos. El objetivo es explorar diferentes métodos de agrupamiento, determinar el\n",
    "número óptimo de grupos y evaluar la calidad de los resultados obtenidos.\n",
    "\n",
    "INSTRUCCIONES:\n",
    "1. Conjunto de datos: Se trabajará con el conjunto de datos proporcionado. Se\n",
    "recomienda hacer un análisis exploratorio inicial (revisión, resumen estadístico,\n",
    "visualización, identificación de valores atípicos, necesidad de transformación).\n",
    "2. Determinación del número de agrupamientos: Utiliza técnicas como el método del\n",
    "codo, la silueta o el análisis de la varianza para determinar el número adecuado de\n",
    "agrupamientos.\n",
    "3. Métodos de agrupamiento: Aplica al menos cuatro métodos de agrupamiento\n",
    "diferentes sobre el conjunto de datos. Se probarán distintos parámetros para cada uno\n",
    "de ellos.\n",
    "4. Evaluación de la calidad: Evalúa la calidad de los agrupamientos obtenidos.\n",
    "5. Razonamiento sobre resultados: Se incluirá un análisis crítico de los resultados\n",
    "obtenidos, las diferencias entre los métodos utilizados, la calidad de los agrupamientos\n",
    "y cualquier patrón interesante que hayas observado en los datos.\n",
    "\n",
    "ENTREGA\n",
    "\n",
    "Se entregarán el fichero del código Python y un informe razonado de resultados. Este\n",
    "informe contendrá la configuración de los métodos utilizados, los resultados de dichos\n",
    "métodos, visualizaciones de los agrupamientos y un razonamiento sobre los resultados.\n",
    "\n",
    "---\n",
    "\n",
    "- [ ] revision\n",
    "- [x] visualizacion (hacer plots de varios, util para evaluacion)\n",
    "- [ ] resumen estadistico\n",
    "- [ ] atipicos\n",
    "- [ ] necesidad de transformacion\n",
    "- [ ] transformacion\n",
    "- [ ] encontrar buen algoritmo y hiperparametros\n",
    "- [ ] evaluacion\n",
    "- [ ] analisis\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.mnist_reader import load_mnist\n",
    "#import p1utils\n",
    "import matplotlib.pyplot as plt\n",
    "from  sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering\n",
    "from sklearn.decomposition import PCA\n",
    "import sklearn.manifold\n",
    "from  sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "from time import time\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import tensor\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        \n",
    "        # Encoder\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3), \n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout(p=0.1), \n",
    "            nn.Conv2d(16, 4, kernel_size=3), \n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout(p=0.1),\n",
    "        )\n",
    "        \n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(4, 4, kernel_size=3), \n",
    "            nn.ReLU(),\n",
    "            nn.Upsample(2),\n",
    "            nn.Dropout(p=0.1), \n",
    "            nn.ConvTranspose2d(4, 16, kernel_size=3), \n",
    "            nn.ReLU(),\n",
    "            nn.Upsample(2),\n",
    "            nn.Dropout(p=0.1), \n",
    "            nn.ConvTranspose2d(16, 1, kernel_size=3), \n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "    def trainModel(self, train_loader):\n",
    "        criterion = nn.MSELoss()  # Mean Squared Error Loss\n",
    "        lr = 5e-2\n",
    "        optimizer = optim.Adam(self.parameters(), lr=lr, weight_decay=1e-5)\n",
    "        num_epochs = 2000\n",
    "        #device = torch.device(\"mps\")\n",
    "        #self.to(device)\n",
    "        losses = []\n",
    "        for epoch in range(num_epochs):\n",
    "            self.train()\n",
    "            running_loss = 0.0\n",
    "            for batch_idx, data in enumerate(train_loader):\n",
    "                # Forward pass\n",
    "                \n",
    "                #data = data.to(device)\n",
    "                output = self.forward(data)\n",
    "                loss = criterion(output, data)\n",
    "                \n",
    "                # Backward pass and optimization\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                running_loss += loss.item()\n",
    "                losses.append(loss.item)\n",
    "            #if epoch%50 == 0: optimizer = optim.Adam(self.parameters(), lr=lr*0.9)\n",
    "                print(f\">>minibatch [{batch_idx}], Loss: {running_loss/len(train_loader):.4f}\")\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n",
    "            \n",
    "        plt.plot(losses)\n",
    "        \n",
    "\n",
    "def toNNformat(x):\n",
    "    xformated = tensor(x).float() / 255.0\n",
    "    return xformated.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "exploración inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (50000, 784), y_train: (50000,)\n",
      "X_dev: (10000, 784), y_dev: (10000,)\n",
      "X_test: (10000, 784), y_test: (10000,)\n",
      "\n",
      "y_train: 9\n",
      "X_train:\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train, y_train = load_mnist('data/fashion', kind='train')\n",
    "X_test, y_test = load_mnist('data/fashion', kind='t10k')\n",
    "#X_train, X_dev = np.reshape(X_train[:50000],(50000,28,28)), np.reshape(X_train[50000:],(10000,28,28))\n",
    "X_train, X_dev = X_train[:50000], X_train[50000:]\n",
    "y_train, y_dev = y_train[:50000], y_train[50000:]\n",
    "\n",
    "print(f'X_train: {X_train.shape}, y_train: {y_train.shape}')\n",
    "print(f'X_dev: {X_dev.shape}, y_dev: {y_dev.shape}')\n",
    "print(f'X_test: {X_test.shape}, y_test: {y_test.shape}')\n",
    "\n",
    "#print('X_train:', X_train[0])\n",
    "print('\\ny_train:', y_train[0])\n",
    "print('X_train:')\n",
    "plt.imshow(np.reshape(X_train[0],(28,28)));\n",
    "#plt.imshow(X_train[0]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_embedded = sklearn.manifold.TSNE(n_components=3).fit_transform(X_train)\n",
    "# 2d plt.scatter(X_embedded[:,0],X_embedded[:,1],c=y_train);\n",
    "fig, ax = plt.subplots(subplot_kw={\"projection\": \"3d\"})\n",
    "ax.scatter(X_embedded[:,0], X_embedded[:,1], X_embedded[:,2],c=y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "primera clusterización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "km = KMeans(9)\n",
    "km.fit(X_train)\n",
    "labels_predict = km.predict(X_dev)\n",
    "adjusted_rand_score(y_dev, labels_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">140</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">889</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ up_sampling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">UpSampling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ up_sampling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">UpSampling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m14\u001b[0m)     │           \u001b[38;5;34m140\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m7\u001b[0m)      │           \u001b[38;5;34m889\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ up_sampling2d (\u001b[38;5;33mUpSampling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m7\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m7\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m)     │           \u001b[38;5;34m896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ up_sampling2d_1 (\u001b[38;5;33mUpSampling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m14\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m14\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │           \u001b[38;5;34m127\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,052</span> (8.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,052\u001b[0m (8.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,052</span> (8.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,052\u001b[0m (8.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nautoencoder = Autoencoder()\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Dense, Dropout, Conv2D, MaxPool2D, UpSampling2D, Activation\n",
    "\n",
    "autoencoder  = Sequential()\n",
    "autoencoder.add(Input((28,28,1)))\n",
    "autoencoder.add(Conv2D(14, kernel_size=3, padding='same', activation='relu'))\n",
    "autoencoder.add(MaxPool2D((2,2), padding='same'))\n",
    "autoencoder.add(Dropout(0.2))\n",
    "autoencoder.add(Conv2D(7, kernel_size=3, padding='same', activation='relu'))\n",
    "autoencoder.add(MaxPool2D((2,2), padding='same'))\n",
    "autoencoder.add(Dropout(0.2))\n",
    "autoencoder.add(UpSampling2D((2,2)))\n",
    "autoencoder.add(Dropout(0.2))\n",
    "autoencoder.add(Conv2D(14, kernel_size=3, padding='same', activation='relu'))\n",
    "autoencoder.add(UpSampling2D((2,2)))\n",
    "autoencoder.add(Dropout(0.2))\n",
    "autoencoder.add(Conv2D(1, kernel_size=3, padding='same', activation='relu'))\n",
    "autoencoder.compile(optimizer=SGD(0.01,0.9), loss=\"mse\", metrics=['accuracy'])\n",
    "autoencoder.summary()\n",
    "'''\n",
    "\n",
    "autoencoder = Autoencoder()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = Autoencoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = toNNformat(X_train)\n",
    "train_loader = DataLoader(X_train_tensor, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autoencoder(\n",
      "  (encoder): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Dropout(p=0.1, inplace=False)\n",
      "    (4): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (5): ReLU()\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (decoder): Sequential(\n",
      "    (0): ConvTranspose2d(4, 4, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): Upsample(size=2, mode='nearest')\n",
      "    (3): Dropout(p=0.1, inplace=False)\n",
      "    (4): ConvTranspose2d(4, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (5): ReLU()\n",
      "    (6): Upsample(size=2, mode='nearest')\n",
      "    (7): Dropout(p=0.1, inplace=False)\n",
      "    (8): ConvTranspose2d(16, 1, kernel_size=(3, 3), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(autoencoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x301323fb0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(np.resize(X_train_tensor[0][0].numpy(),(28,28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 50000, 784])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tensor.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pepe/carrera/3/2/ma2/ma2Python12/lib/python3.12/site-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([1, 50000, 784])) that is different to the input size (torch.Size([1, 12504, 4])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (4) must match the size of tensor b (784) at non-singleton dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mautoencoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrainModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 51\u001b[39m, in \u001b[36mAutoencoder.trainModel\u001b[39m\u001b[34m(self, train_loader)\u001b[39m\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[32m     47\u001b[39m     \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[32m     48\u001b[39m     \n\u001b[32m     49\u001b[39m     \u001b[38;5;66;03m#data = data.to(device)\u001b[39;00m\n\u001b[32m     50\u001b[39m     output = \u001b[38;5;28mself\u001b[39m.forward(data)\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m     loss = \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     53\u001b[39m     \u001b[38;5;66;03m# Backward pass and optimization\u001b[39;00m\n\u001b[32m     54\u001b[39m     optimizer.zero_grad()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/carrera/3/2/ma2/ma2Python12/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/carrera/3/2/ma2/ma2Python12/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/carrera/3/2/ma2/ma2Python12/lib/python3.12/site-packages/torch/nn/modules/loss.py:610\u001b[39m, in \u001b[36mMSELoss.forward\u001b[39m\u001b[34m(self, input, target)\u001b[39m\n\u001b[32m    609\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m610\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmse_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/carrera/3/2/ma2/ma2Python12/lib/python3.12/site-packages/torch/nn/functional.py:3884\u001b[39m, in \u001b[36mmse_loss\u001b[39m\u001b[34m(input, target, size_average, reduce, reduction, weight)\u001b[39m\n\u001b[32m   3881\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   3882\u001b[39m     reduction = _Reduction.legacy_get_string(size_average, reduce)\n\u001b[32m-> \u001b[39m\u001b[32m3884\u001b[39m expanded_input, expanded_target = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbroadcast_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3886\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   3887\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m weight.size() != \u001b[38;5;28minput\u001b[39m.size():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/carrera/3/2/ma2/ma2Python12/lib/python3.12/site-packages/torch/functional.py:76\u001b[39m, in \u001b[36mbroadcast_tensors\u001b[39m\u001b[34m(*tensors)\u001b[39m\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function(tensors):\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(broadcast_tensors, tensors, *tensors)\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbroadcast_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: The size of tensor a (4) must match the size of tensor b (784) at non-singleton dimension 2"
     ]
    }
   ],
   "source": [
    "autoencoder.trainModel(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder(toNNformat(X_test))[0][0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.eval\n",
    "autoencoder.to('cpu')\n",
    "\n",
    "plt.subplot(3,2,1)\n",
    "plt.imshow(np.reshape(autoencoder(toNNformat(X_train))[0][0].detach().numpy(),(28,28)))\n",
    "plt.subplot(3,2,2)\n",
    "plt.imshow(np.reshape(X_train[0],(28,28)))\n",
    "plt.subplot(3,2,3)\n",
    "plt.imshow(np.reshape(autoencoder(toNNformat(X_train))[0][1].detach().numpy(),(28,28)))\n",
    "plt.subplot(3,2,4)\n",
    "plt.imshow(np.reshape(X_train[1],(28,28)))\n",
    "plt.subplot(3,2,5)\n",
    "plt.imshow(np.reshape(autoencoder(toNNformat(X_train))[0][2].detach().numpy(),(28,28)))\n",
    "plt.subplot(3,2,6)\n",
    "plt.imshow(np.reshape(X_train[2],(28,28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 94ms/step - accuracy: 0.4808 - loss: 155946288412146240847872.0000 - val_accuracy: 0.4996 - val_loss: 13579.7988\n",
      "Epoch 2/10\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 94ms/step - accuracy: 0.5030 - loss: 13392.2979 - val_accuracy: 0.4996 - val_loss: 13579.7988\n",
      "Epoch 3/10\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 94ms/step - accuracy: 0.5025 - loss: 13397.3760 - val_accuracy: 0.4996 - val_loss: 13579.7988\n",
      "Epoch 4/10\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 91ms/step - accuracy: 0.5029 - loss: 13389.3760 - val_accuracy: 0.4996 - val_loss: 13579.7988\n",
      "Epoch 5/10\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 95ms/step - accuracy: 0.5016 - loss: 13430.7783 - val_accuracy: 0.4996 - val_loss: 13579.7988\n",
      "Epoch 6/10\n",
      "\u001b[1m 15/196\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 84ms/step - accuracy: 0.5099 - loss: 13190.2725"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[32m/var/folders/1l/sdrz_tw104ld922_w0xnl5840000gn/T/ipykernel_31434/1685592203.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m tensorflow \u001b[38;5;28;01mas\u001b[39;00m tf\n\u001b[32m      2\u001b[39m tf.config.run_functions_eagerly(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      3\u001b[39m tf.data.experimental.enable_debug_mode()\n\u001b[32m      4\u001b[39m \n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m history_AE=autoencoder.fit(X_train, X_train, epochs=\u001b[32m10\u001b[39m, batch_size=\u001b[32m256\u001b[39m, validation_data=(X_dev, X_dev), verbose=\u001b[32m1\u001b[39m)\n",
      "\u001b[32m~/carrera/3/2/ma2/ma2Python12/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    120\u001b[39m             \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m             \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m    122\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m         \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m             \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[32m~/carrera/3/2/ma2/ma2Python12/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    367\u001b[39m             callbacks.on_epoch_begin(epoch)\n\u001b[32m    368\u001b[39m             \u001b[38;5;28;01mwith\u001b[39;00m epoch_iterator.catch_stop_iteration():\n\u001b[32m    369\u001b[39m                 \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;28;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    370\u001b[39m                     callbacks.on_train_batch_begin(step)\n\u001b[32m--> \u001b[39m\u001b[32m371\u001b[39m                     logs = self.train_function(iterator)\n\u001b[32m    372\u001b[39m                     callbacks.on_train_batch_end(step, logs)\n\u001b[32m    373\u001b[39m                     \u001b[38;5;28;01mif\u001b[39;00m self.stop_training:\n\u001b[32m    374\u001b[39m                         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[32m~/carrera/3/2/ma2/ma2Python12/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    215\u001b[39m         \u001b[38;5;28;01mdef\u001b[39;00m function(iterator):\n\u001b[32m    216\u001b[39m             if isinstance(\n\u001b[32m    217\u001b[39m                 iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001b[32m    218\u001b[39m             ):\n\u001b[32m--> \u001b[39m\u001b[32m219\u001b[39m                 opt_outputs = multi_step_on_iterator(iterator)\n\u001b[32m    220\u001b[39m                 \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m opt_outputs.has_value():\n\u001b[32m    221\u001b[39m                     \u001b[38;5;28;01mraise\u001b[39;00m StopIteration\n\u001b[32m    222\u001b[39m                 \u001b[38;5;28;01mreturn\u001b[39;00m opt_outputs.get_value()\n",
      "\u001b[32m~/carrera/3/2/ma2/ma2Python12/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    151\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m Exception \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m       filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    153\u001b[39m       \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    154\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m       \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[32m~/carrera/3/2/ma2/ma2Python12/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    806\u001b[39m   \u001b[38;5;28;01mdef\u001b[39;00m __call__(self, *args, **kwds):\n\u001b[32m    807\u001b[39m     \u001b[38;5;66;03m# Implements PolymorphicFunction.__call__.\u001b[39;00m\n\u001b[32m    808\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m self._run_functions_eagerly:\n\u001b[32m    809\u001b[39m       \u001b[38;5;28;01mwith\u001b[39;00m trace.Trace(self._name, tf_function_call=\u001b[33m\"eager\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m810\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m self._python_function(*args, **kwds)\n\u001b[32m    811\u001b[39m \n\u001b[32m    812\u001b[39m     \u001b[38;5;66;03m# Only count the statistics the first time, before initialization took\u001b[39;00m\n\u001b[32m    813\u001b[39m     \u001b[38;5;66;03m# place.\u001b[39;00m\n",
      "\u001b[32m~/carrera/3/2/ma2/ma2Python12/lib/python3.12/site-packages/tensorflow/python/autograph/impl/api.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    641\u001b[39m   \u001b[38;5;28;01mdef\u001b[39;00m wrapper(*args, **kwargs):\n\u001b[32m    642\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):\n\u001b[32m--> \u001b[39m\u001b[32m643\u001b[39m       \u001b[38;5;28;01mreturn\u001b[39;00m func(*args, **kwargs)\n",
      "\u001b[32m~/carrera/3/2/ma2/ma2Python12/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    128\u001b[39m         @tf.autograph.experimental.do_not_convert\n\u001b[32m    129\u001b[39m         \u001b[38;5;28;01mdef\u001b[39;00m multi_step_on_iterator(iterator):\n\u001b[32m    130\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m self.steps_per_execution == \u001b[32m1\u001b[39m:\n\u001b[32m    131\u001b[39m                 return tf.experimental.Optional.from_value(\n\u001b[32m--> \u001b[39m\u001b[32m132\u001b[39m                     one_step_on_data(iterator.get_next())\n\u001b[32m    133\u001b[39m                 )\n\u001b[32m    134\u001b[39m \n\u001b[32m    135\u001b[39m             \u001b[38;5;66;03m# the spec is set lazily during the tracing of `tf.while_loop`\u001b[39;00m\n",
      "\u001b[32m~/carrera/3/2/ma2/ma2Python12/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    151\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m Exception \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m       filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    153\u001b[39m       \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    154\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m       \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[32m~/carrera/3/2/ma2/ma2Python12/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    806\u001b[39m   \u001b[38;5;28;01mdef\u001b[39;00m __call__(self, *args, **kwds):\n\u001b[32m    807\u001b[39m     \u001b[38;5;66;03m# Implements PolymorphicFunction.__call__.\u001b[39;00m\n\u001b[32m    808\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m self._run_functions_eagerly:\n\u001b[32m    809\u001b[39m       \u001b[38;5;28;01mwith\u001b[39;00m trace.Trace(self._name, tf_function_call=\u001b[33m\"eager\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m810\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m self._python_function(*args, **kwds)\n\u001b[32m    811\u001b[39m \n\u001b[32m    812\u001b[39m     \u001b[38;5;66;03m# Only count the statistics the first time, before initialization took\u001b[39;00m\n\u001b[32m    813\u001b[39m     \u001b[38;5;66;03m# place.\u001b[39;00m\n",
      "\u001b[32m~/carrera/3/2/ma2/ma2Python12/lib/python3.12/site-packages/tensorflow/python/autograph/impl/api.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    641\u001b[39m   \u001b[38;5;28;01mdef\u001b[39;00m wrapper(*args, **kwargs):\n\u001b[32m    642\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):\n\u001b[32m--> \u001b[39m\u001b[32m643\u001b[39m       \u001b[38;5;28;01mreturn\u001b[39;00m func(*args, **kwargs)\n",
      "\u001b[32m~/carrera/3/2/ma2/ma2Python12/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(data)\u001b[39m\n\u001b[32m    110\u001b[39m         @tf.autograph.experimental.do_not_convert\n\u001b[32m    111\u001b[39m         \u001b[38;5;28;01mdef\u001b[39;00m one_step_on_data(data):\n\u001b[32m    112\u001b[39m             \u001b[33m\"\"\"Runs a single training step on a batch of data.\"\"\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m113\u001b[39m             outputs = self.distribute_strategy.run(step_function, args=(data,))\n\u001b[32m    114\u001b[39m             outputs = reduce_per_replica(\n\u001b[32m    115\u001b[39m                 outputs,\n\u001b[32m    116\u001b[39m                 self.distribute_strategy,\n",
      "\u001b[32m~/carrera/3/2/ma2/ma2Python12/lib/python3.12/site-packages/tensorflow/python/distribute/distribute_lib.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m   1669\u001b[39m       \u001b[38;5;66;03m# tf.distribute supports Eager functions, so AutoGraph should not be\u001b[39;00m\n\u001b[32m   1670\u001b[39m       \u001b[38;5;66;03m# applied when the caller is also in Eager mode.\u001b[39;00m\n\u001b[32m   1671\u001b[39m       fn = autograph.tf_convert(\n\u001b[32m   1672\u001b[39m           fn, autograph_ctx.control_status_ctx(), convert_by_default=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m1673\u001b[39m       \u001b[38;5;28;01mreturn\u001b[39;00m self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n",
      "\u001b[32m~/carrera/3/2/ma2/ma2Python12/lib/python3.12/site-packages/tensorflow/python/distribute/distribute_lib.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, fn, args, kwargs)\u001b[39m\n\u001b[32m   3259\u001b[39m     _require_cross_replica_or_default_context_extended(self)\n\u001b[32m   3260\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   3261\u001b[39m       kwargs = {}\n\u001b[32m   3262\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m self._container_strategy().scope():\n\u001b[32m-> \u001b[39m\u001b[32m3263\u001b[39m       \u001b[38;5;28;01mreturn\u001b[39;00m self._call_for_each_replica(fn, args, kwargs)\n",
      "\u001b[32m~/carrera/3/2/ma2/ma2Python12/lib/python3.12/site-packages/tensorflow/python/distribute/distribute_lib.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, fn, args, kwargs)\u001b[39m\n\u001b[32m   4059\u001b[39m   \u001b[38;5;28;01mdef\u001b[39;00m _call_for_each_replica(self, fn, args, kwargs):\n\u001b[32m   4060\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ReplicaContext(self._container_strategy(), replica_id_in_sync_group=\u001b[32m0\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m4061\u001b[39m       \u001b[38;5;28;01mreturn\u001b[39;00m fn(*args, **kwargs)\n",
      "\u001b[32m~/carrera/3/2/ma2/ma2Python12/lib/python3.12/site-packages/tensorflow/python/autograph/impl/api.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    641\u001b[39m   \u001b[38;5;28;01mdef\u001b[39;00m wrapper(*args, **kwargs):\n\u001b[32m    642\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):\n\u001b[32m--> \u001b[39m\u001b[32m643\u001b[39m       \u001b[38;5;28;01mreturn\u001b[39;00m func(*args, **kwargs)\n",
      "\u001b[32m~/carrera/3/2/ma2/ma2Python12/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m     53\u001b[39m \n\u001b[32m     54\u001b[39m         \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[32m     55\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m tf.GradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[32m     56\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m self._call_has_training_arg:\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m                 y_pred = self(x, training=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     58\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     59\u001b[39m                 y_pred = self(x)\n\u001b[32m     60\u001b[39m             loss = self._compute_loss(\n",
      "\u001b[32m~/carrera/3/2/ma2/ma2Python12/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    120\u001b[39m             \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m             \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m    122\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m         \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m             \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[32m~/carrera/3/2/ma2/ma2Python12/lib/python3.12/site-packages/keras/src/layers/layer.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    944\u001b[39m                     \u001b[33m\"layers will not see the mask.\"\u001b[39m\n\u001b[32m    945\u001b[39m                 )\n\u001b[32m    946\u001b[39m         \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    947\u001b[39m             \u001b[38;5;66;03m# Destroy call context if we created it\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m948\u001b[39m             self._maybe_reset_call_context()\n\u001b[32m    949\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "\u001b[32m~/carrera/3/2/ma2/ma2Python12/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    120\u001b[39m             \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m             \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m    122\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m         \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m             \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[32m~/carrera/3/2/ma2/ma2Python12/lib/python3.12/site-packages/keras/src/ops/operation.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     48\u001b[39m             call_fn = traceback_utils.inject_argument_info_in_traceback(\n\u001b[32m     49\u001b[39m                 call_fn,\n\u001b[32m     50\u001b[39m                 object_name=(f\"{self.__class__.__name__}.call()\"),\n\u001b[32m     51\u001b[39m             )\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m call_fn(*args, **kwargs)\n\u001b[32m     53\u001b[39m \n\u001b[32m     54\u001b[39m         \u001b[38;5;66;03m# Plain flow.\u001b[39;00m\n\u001b[32m     55\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m any_symbolic_tensors(args, kwargs):\n",
      "\u001b[32m~/carrera/3/2/ma2/ma2Python12/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    213\u001b[39m                 new_e = e\n\u001b[32m    214\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m new_e.with_traceback(e.__traceback__) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    215\u001b[39m         \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    216\u001b[39m             \u001b[38;5;28;01mdel\u001b[39;00m signature\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m             \u001b[38;5;28;01mdel\u001b[39;00m bound_signature\n",
      "\u001b[32m~/carrera/3/2/ma2/ma2Python12/lib/python3.12/site-packages/keras/src/models/sequential.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, inputs, training, mask)\u001b[39m\n\u001b[32m    219\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m call(self, inputs, training=\u001b[38;5;28;01mNone\u001b[39;00m, mask=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    220\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m self._functional:\n\u001b[32m--> \u001b[39m\u001b[32m221\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m self._functional.call(inputs, training=training, mask=mask)\n\u001b[32m    222\u001b[39m \n\u001b[32m    223\u001b[39m         \u001b[38;5;66;03m# Fallback: Just apply the layer sequence.\u001b[39;00m\n\u001b[32m    224\u001b[39m         \u001b[38;5;66;03m# This typically happens if `inputs` is a nested struct.\u001b[39;00m\n",
      "\u001b[32m~/carrera/3/2/ma2/ma2Python12/lib/python3.12/site-packages/keras/src/models/functional.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, inputs, training, mask)\u001b[39m\n\u001b[32m    179\u001b[39m             masks = tree.flatten(mask)\n\u001b[32m    180\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m x, mask \u001b[38;5;28;01min\u001b[39;00m zip(inputs, masks):\n\u001b[32m    181\u001b[39m                 \u001b[38;5;28;01mif\u001b[39;00m mask \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    182\u001b[39m                     backend.set_keras_mask(x, mask)\n\u001b[32m--> \u001b[39m\u001b[32m183\u001b[39m         outputs = self._run_through_graph(\n\u001b[32m    184\u001b[39m             inputs, operation_fn=\u001b[38;5;28;01mlambda\u001b[39;00m op: operation_fn(op, training=training)\n\u001b[32m    185\u001b[39m         )\n\u001b[32m    186\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m unpack_singleton(outputs)\n",
      "\u001b[32m~/carrera/3/2/ma2/ma2Python12/lib/python3.12/site-packages/keras/src/ops/function.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, inputs, operation_fn, call_fn)\u001b[39m\n\u001b[32m    167\u001b[39m                 op = operation_fn(node.operation)\n\u001b[32m    168\u001b[39m                 \u001b[38;5;28;01mif\u001b[39;00m call_fn \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    169\u001b[39m                     outputs = call_fn(op, *args, **kwargs)\n\u001b[32m    170\u001b[39m                 \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m171\u001b[39m                     outputs = op(*args, **kwargs)\n\u001b[32m    172\u001b[39m \n\u001b[32m    173\u001b[39m                 \u001b[38;5;66;03m# Update tensor_dict.\u001b[39;00m\n\u001b[32m    174\u001b[39m                 \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;28;01min\u001b[39;00m zip(node.outputs, tree.flatten(outputs)):\n",
      "\u001b[32m~/carrera/3/2/ma2/ma2Python12/lib/python3.12/site-packages/keras/src/models/functional.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    639\u001b[39m             \u001b[38;5;28;01mand\u001b[39;00m operation._call_has_training_arg\n\u001b[32m    640\u001b[39m             \u001b[38;5;28;01mand\u001b[39;00m training \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    641\u001b[39m         ):\n\u001b[32m    642\u001b[39m             kwargs[\u001b[33m\"training\"\u001b[39m] = training\n\u001b[32m--> \u001b[39m\u001b[32m643\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m operation(*args, **kwargs)\n",
      "\u001b[32m~/carrera/3/2/ma2/ma2Python12/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    120\u001b[39m             \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m             \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m    122\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m         \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m             \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[32m~/carrera/3/2/ma2/ma2Python12/lib/python3.12/site-packages/keras/src/layers/layer.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    944\u001b[39m                     \u001b[33m\"layers will not see the mask.\"\u001b[39m\n\u001b[32m    945\u001b[39m                 )\n\u001b[32m    946\u001b[39m         \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    947\u001b[39m             \u001b[38;5;66;03m# Destroy call context if we created it\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m948\u001b[39m             self._maybe_reset_call_context()\n\u001b[32m    949\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "\u001b[32m~/carrera/3/2/ma2/ma2Python12/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    120\u001b[39m             \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m             \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m    122\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m         \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m             \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[32m~/carrera/3/2/ma2/ma2Python12/lib/python3.12/site-packages/keras/src/ops/operation.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     48\u001b[39m             call_fn = traceback_utils.inject_argument_info_in_traceback(\n\u001b[32m     49\u001b[39m                 call_fn,\n\u001b[32m     50\u001b[39m                 object_name=(f\"{self.__class__.__name__}.call()\"),\n\u001b[32m     51\u001b[39m             )\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m call_fn(*args, **kwargs)\n\u001b[32m     53\u001b[39m \n\u001b[32m     54\u001b[39m         \u001b[38;5;66;03m# Plain flow.\u001b[39;00m\n\u001b[32m     55\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m any_symbolic_tensors(args, kwargs):\n",
      "\u001b[32m~/carrera/3/2/ma2/ma2Python12/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    213\u001b[39m                 new_e = e\n\u001b[32m    214\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m new_e.with_traceback(e.__traceback__) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    215\u001b[39m         \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    216\u001b[39m             \u001b[38;5;28;01mdel\u001b[39;00m signature\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m             \u001b[38;5;28;01mdel\u001b[39;00m bound_signature\n",
      "\u001b[32m~/carrera/3/2/ma2/ma2Python12/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, inputs)\u001b[39m\n\u001b[32m    249\u001b[39m                 bias_shape = (\u001b[32m1\u001b[39m,) * (self.rank + \u001b[32m1\u001b[39m) + (self.filters,)\n\u001b[32m    250\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    251\u001b[39m                 bias_shape = (\u001b[32m1\u001b[39m, self.filters) + (\u001b[32m1\u001b[39m,) * self.rank\n\u001b[32m    252\u001b[39m             bias = ops.reshape(self.bias, bias_shape)\n\u001b[32m--> \u001b[39m\u001b[32m253\u001b[39m             outputs = ops.add(outputs, bias)\n\u001b[32m    254\u001b[39m \n\u001b[32m    255\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m self.activation \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    256\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m self.activation(outputs)\n",
      "\u001b[32m~/carrera/3/2/ma2/ma2Python12/lib/python3.12/site-packages/keras/src/ops/numpy.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(x1, x2)\u001b[39m\n\u001b[32m    233\u001b[39m            [\u001b[32m10\u001b[39m \u001b[32m12\u001b[39m]], shape=(\u001b[32m2\u001b[39m, \u001b[32m2\u001b[39m), dtype=int32)\n\u001b[32m    234\u001b[39m     \"\"\"\n\u001b[32m    235\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m any_symbolic_tensors((x1, x2)):\n\u001b[32m    236\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m Add().symbolic_call(x1, x2)\n\u001b[32m--> \u001b[39m\u001b[32m237\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m backend.numpy.add(x1, x2)\n",
      "\u001b[32m~/carrera/3/2/ma2/ma2Python12/lib/python3.12/site-packages/keras/src/backend/tensorflow/sparse.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(x1, x2)\u001b[39m\n\u001b[32m    489\u001b[39m                     x1 = tf.convert_to_tensor(x1)\n\u001b[32m    490\u001b[39m             \u001b[38;5;28;01melif\u001b[39;00m isinstance(x2, tf.IndexedSlices):\n\u001b[32m    491\u001b[39m                 \u001b[38;5;66;03m# x2 is an IndexedSlices, densify.\u001b[39;00m\n\u001b[32m    492\u001b[39m                 x2 = tf.convert_to_tensor(x2)\n\u001b[32m--> \u001b[39m\u001b[32m493\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m func(x1, x2)\n",
      "\u001b[32m~/carrera/3/2/ma2/ma2Python12/lib/python3.12/site-packages/keras/src/backend/tensorflow/numpy.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(x1, x2)\u001b[39m\n\u001b[32m    125\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    126\u001b[39m             data_format = \u001b[33m\"NCHW\"\u001b[39m\n\u001b[32m    127\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m len(x2.shape) > \u001b[32m1\u001b[39m:\n\u001b[32m    128\u001b[39m             x2 = tf.squeeze(x2)\n\u001b[32m--> \u001b[39m\u001b[32m129\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m tf.nn.bias_add(x1, x2, data_format=data_format)\n\u001b[32m    130\u001b[39m \n\u001b[32m    131\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m tf.add(x1, x2)\n",
      "\u001b[32m~/carrera/3/2/ma2/ma2Python12/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    151\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m Exception \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m       filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    153\u001b[39m       \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    154\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m       \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[32m~/carrera/3/2/ma2/ma2Python12/lib/python3.12/site-packages/tensorflow/python/util/dispatch.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   1257\u001b[39m \n\u001b[32m   1258\u001b[39m       \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[32m   1259\u001b[39m       \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1260\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m dispatch_target(*args, **kwargs)\n\u001b[32m-> \u001b[39m\u001b[32m1261\u001b[39m       \u001b[38;5;28;01mexcept\u001b[39;00m (TypeError, ValueError):\n\u001b[32m   1262\u001b[39m         \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[32m   1263\u001b[39m         \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[32m   1264\u001b[39m         result = dispatch(op_dispatch_handler, args, kwargs)\n",
      "\u001b[32m~/carrera/3/2/ma2/ma2Python12/lib/python3.12/site-packages/tensorflow/python/ops/nn_ops.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(value, bias, data_format, name)\u001b[39m\n\u001b[32m   3556\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m context.executing_eagerly():\n\u001b[32m   3557\u001b[39m       value = ops.convert_to_tensor(value, name=\u001b[33m\"input\"\u001b[39m)\n\u001b[32m   3558\u001b[39m       bias = ops.convert_to_tensor(bias, dtype=value.dtype, name=\u001b[33m\"bias\"\u001b[39m)\n\u001b[32m   3559\u001b[39m \n\u001b[32m-> \u001b[39m\u001b[32m3560\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m gen_nn_ops.bias_add(value, bias, data_format=data_format, name=name)\n",
      "\u001b[32m~/carrera/3/2/ma2/ma2Python12/lib/python3.12/site-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(value, bias, data_format, name)\u001b[39m\n\u001b[32m    868\u001b[39m         _ctx, \u001b[33m\"BiasAdd\"\u001b[39m, name, value, bias, \u001b[33m\"data_format\"\u001b[39m, data_format)\n\u001b[32m    869\u001b[39m       \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[32m    870\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m _core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    871\u001b[39m       _ops.raise_from_not_ok_status(e, name)\n\u001b[32m--> \u001b[39m\u001b[32m872\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m _core._FallbackException:\n\u001b[32m    873\u001b[39m       \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m    874\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    875\u001b[39m       return bias_add_eager_fallback(\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.run_functions_eagerly(True)\n",
    "tf.data.experimental.enable_debug_mode()\n",
    "\n",
    "history_AE=autoencoder.fit(X_train, X_train, epochs=10, batch_size=256, validation_data=(X_dev, X_dev), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.backend' has no attribute 'function'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m backend \u001b[38;5;28;01mas\u001b[39;00m K\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m encoder = \u001b[43mK\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfunction\u001b[49m([model.layers[\u001b[32m0\u001b[39m].input], [model.layers[\u001b[32m4\u001b[39m].output])\n",
      "\u001b[31mAttributeError\u001b[39m: module 'keras.backend' has no attribute 'function'"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "#encoder = K.function([model.layers[0].input], [model.layers[4].output])\n",
    "encoder = keras.Model(input=[X_train], output=[autoencoder.layers[1], intermediate_layer2, output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/68920638/dbscan-object-has-no-attribute-predict-using-gridsearchcv-pipeline/70291704#70291704\n",
    "\n",
    "class AgglomerativeClusteringWrapper(AgglomerativeClustering):\n",
    "    def predict(self,X):\n",
    "      return self.labels_.astype(int)\n",
    "\n",
    "class DBSCANWrapper(DBSCAN):\n",
    "    def predict(self,X):\n",
    "      return self.labels_.astype(int)\n",
    "\n",
    "clustering_methods = {\n",
    "    'KMeans': KMeans(),\n",
    "    'DBSCAN': DBSCANWrapper(),\n",
    "    'Agglomerative': AgglomerativeClusteringWrapper()\n",
    "}\n",
    "\n",
    "param_grids = {\n",
    "    'KMeans': {\n",
    "        'n_clusters': [7],\n",
    "        'init': ['k-means++', 'random'],\n",
    "        #'max_iter': [300, 500]\n",
    "    },\n",
    "    'DBSCAN': {\n",
    "        'eps': [0.3],#, 0.5, 0.7],\n",
    "        'min_samples': [5]#, 10, 15, 20]\n",
    "    },\n",
    "    'Agglomerative': {\n",
    "    #    'n_clusters': [7, 8, 9, 10, 11],\n",
    "        'linkage': ['ward']#, 'complete', 'average']\n",
    "    }\n",
    "}\n",
    "\n",
    "# Function to evaluate each model and its hyperparameters\n",
    "def try_clustering(X_train, clustering_methods, param_grids):\n",
    "    results = {}\n",
    "\n",
    "    for name, model in clustering_methods.items():\n",
    "        start = time()\n",
    "        \n",
    "        grid_search = GridSearchCV(model, param_grids[name], cv=2, scoring='adjusted_mutual_info_score', n_jobs=-1, verbose = 3)\n",
    "        grid_search.fit(X_train, y_train)\n",
    "\n",
    "        \n",
    "        score = grid_search.best_score_\n",
    "        #model = grid_search.best_estimator_\n",
    "        params = grid_search.best_params_\n",
    "        end = time()\n",
    "        print(f'Modelo: {name}. \\nAdjMutualInformation: {score}. \\nParametros: {params}. \\nTiempo: {round(end-start,2)}s .\\n\\n')\n",
    "        \n",
    "        results[name] = [params, score]\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = try_clustering(X_trainPCA, clustering_methods, param_grids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analisis de Datos\n",
    "\n",
    "[x] Normalizar valores\n",
    "- Comprobar dimensionalidad -> imagenes 28x28 en escala de grises\n",
    "- Valores atipicos\n",
    "- Anadir representacion de los datos en forma de un cluster inicial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determinacion de Agrupamientos\n",
    "\n",
    "- Silhouette\n",
    "- V measure\n",
    "- Rand index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([3,4,5,6,43,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cambiar X y obsevar diferencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 20\n",
    "silhoutte_values = []\n",
    "for i in range(2, k):\n",
    "    kmeans = sklearn.cluster.KMeans(n_clusters=i)\n",
    "    kmeans.fit(X_train)\n",
    "    y_pred = kmeans.predict(X_dev)\n",
    "    silhoutte = sklearn.metrics.silhouette_score(X_dev, y_pred)\n",
    "    silhoutte_values.append(silhoutte)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1, k-1), silhoutte_values, marker='o')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Silhouette score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metodos de agrupamiento\n",
    "- k-means\n",
    "- dbscan\n",
    "- jerarquico\n",
    "- k++\n",
    "- k-medoids\n",
    "- spectral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_clusters(predictions, X): \n",
    "    plt.scatter(X[:, 0], X[:, 1], c=predictions)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Find the best number of clusters using the silhouette score\n",
    "best_k = 10\n",
    "kmeans = sklearn.cluster.KMeans(n_clusters=best_k)\n",
    "kmeans.fit(X_train)\n",
    "y_pred = kmeans.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_clusters(y_pred, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan = sklearn.cluster.DBSCAN(eps=0.5, min_samples=5)\n",
    "dbscan.fit(X_train)\n",
    "y_pred = dbscan.fit_predict(X_train)\n",
    "\n",
    "plot_clusters(y_pred, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jerarquic = sklearn.cluster.AgglomerativeClustering(n_clusters=10)\n",
    "y_pred = jerarquic.fit_predict(X_train)\n",
    "\n",
    "plot_clusters(y_pred, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medoids = sklearn_extra.cluster.KMedoids(n_clusters=10)\n",
    "y_pred = medoids.fit_predict(X_train)\n",
    "\n",
    "plot_clusters(y_pred, X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EVALUACION DE CALIDAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Utilizar metodos como matriz de confusion, f1-score, precision, recall, etc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ma2Python12",
   "language": "python",
   "name": "ma2python12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
