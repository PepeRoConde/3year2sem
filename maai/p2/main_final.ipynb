{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pablo Chantada Saborido (pablo.chantada@udc.es)\n",
    "### José Romero Conde (j.rconde@udc.es)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CARGA DE DATOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Utils import DatasetProcess, reconstruction_plot\n",
    "from ConvModel import ConvModel\n",
    "from AutoEncoder import TwoStepAutoEncoder, TwoStepClassifier, TwoStepTraining, OneStepAutoencoder, OneStepTraining\n",
    "from OneClass import AnomalyDetector\n",
    "from Contrastive import ContrastiveModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = DatasetProcess.load()\n",
    "\n",
    "\n",
    "# Aplicar la función hold_out\n",
    "(x_train_no_labeled, x_train_labeled, y_train_labeled), (x_val, y_val), (x_test, y_test) = DatasetProcess.hold_out(\n",
    "    (x_train, y_train), (x_test, y_test), validation_size=1000\n",
    ")\n",
    "\n",
    "x_train_labeled = x_train_labeled.astype('float32') / 255.0\n",
    "x_val = x_val.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "# Verificar las dimensiones\n",
    "print(f\"Datos no etiquetados: {x_train_no_labeled.shape}\")\n",
    "print(f\"Datos etiquetados entrenamiento: {x_train_labeled.shape}\")\n",
    "print(f\"Etiquetas entrenamiento: {y_train_labeled.shape}\")\n",
    "print(f\"Datos validación: {x_val.shape}\")\n",
    "print(f\"Etiquetas validación: {y_val.shape}\")\n",
    "print(f\"Datos prueba: {x_test.shape}\")\n",
    "print(f\"Etiquetas prueba: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EJERCICIO 1\n",
    "\n",
    "Entrena un modelo, creado sobre TensorFlow, haciendo uso únicamente de las instancias etiquetadas de entrenamiento. Dicho modelo debe de tener al menos cuatro capas densas y/o convolucionales.\n",
    "\n",
    "Responde a las siguientes preguntas:\n",
    "\n",
    "1. ¿Qué red has escogido? ¿Por qué? ¿Cómo la has entrenado?\n",
    "2. ¿Cuál es el rendimiento del modelo en entrenamiento? ¿Y en prueba?\n",
    "3. ¿Qué conclusiones sacas de los resultados detallados en el punto anterior?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_base = ConvModel()\n",
    "history_base = model_base.fit(\n",
    "    x_train_labeled, \n",
    "    y_train_labeled,\n",
    "    validation_data=(x_val, y_val),\n",
    "    batch_size=128,\n",
    "    epochs=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evalúa con el conjunto de prueba\n",
    "test_accuracy = model_base.score(x_test, y_test)\n",
    "print(f\"Accuracy en conjunto de prueba: {test_accuracy}\")\n",
    "\n",
    "model_base.plot(history_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EJERCICIO 2\n",
    "\n",
    "Entrena el mismo modelo, incorporando las instancias no etiquetadas de entrenamiento mediante la técnica de auto-aprendizaje. Opcionalmente, se ponderará cada instancia de entrada en función de su calidad (o certeza).\n",
    "\n",
    "Responde a las siguientes preguntas:\n",
    "1. ¿Qué parámetros has definido para el entrenamiento?\n",
    "2. ¿Cuál es el rendimiento del modelo en entrenamiento? ¿Y en prueba?\n",
    "3. ¿Se mejoran los resultados obtenidos en el Ejercicio 1?\n",
    "4. ¿Qué conclusiones sacas de los resultados detallados en los puntos anteriores?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para crear modelos consistentes durante self-training\n",
    "def create_model():\n",
    "    return ConvModel(\n",
    "        learning_rate=0.0005,  # Learning rate reducido para fine-tuning\n",
    "        dropout_prob=0.25,     \n",
    "        l2_lambda=0.005        \n",
    "    )\n",
    "\n",
    "# Normalizar datos no etiquetados\n",
    "x_train_no_labeled = x_train_no_labeled.astype('float32') / 255.0\n",
    "\n",
    "# Aplica self-training con datos no etiquetados\n",
    "final_model = ConvModel.self_training_v2(\n",
    "    model_func=create_model,\n",
    "    x_train=x_train_labeled,\n",
    "    y_train=y_train_labeled,  \n",
    "    unlabeled_data=x_train_no_labeled,\n",
    "    validation_data=(x_val, y_val),\n",
    "    thresh=0.8,             \n",
    "    train_epochs=5,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evalúa el modelo final\n",
    "final_accuracy = final_model.score(x_test, y_test)\n",
    "print(f\"Accuracy del modelo final con self-training: {final_accuracy}\")\n",
    "print(f\"Mejora respecto al modelo base: {final_accuracy - test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EJERCICIO 3\n",
    "\n",
    "Entrena un modelo de aprendizaje semisupervisado de tipo autoencoder en dos pasos (primero el autoencoder, después el clasificador). La arquitectura del encoder debe ser exactamente la misma que la definida en los Ejercicios 1 y 2, a excepción del último bloque de capas.\n",
    "\n",
    "Responde a las siguientes preguntas:\n",
    "1. ¿Cuál es la arquitectura del modelo? ¿Y sus hiperparámetros?\n",
    "2. ¿Cuál es el rendimiento del modelo en entrenamiento? ¿Y en prueba?\n",
    "3. ¿Se mejoran los resultados obtenidos en los Ejercicios 1 y 2?\n",
    "4. ¿Qué conclusiones sacas de los resultados detallados en los puntos anteriores?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabeled_train, x_train, y_train, x_val, y_val, x_test, y_test, one_hot_train, one_hot_val, one_hot_test = DatasetProcess.alt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = TwoStepAutoEncoder(\n",
    "                                input_shape=unlabeled_train[0].shape,\n",
    "                                learning_rate=0.006,\n",
    "                                l2_lambda=0.0005,\n",
    "                                dropout_prob=0.1)\n",
    "classifier = TwoStepClassifier(\n",
    "                              l2_lambda=0.0005,\n",
    "                              dropout_prob=0.05,\n",
    "                               learning_rate=0.05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "TwoStepTraining(autoencoder=autoencoder, \n",
    "                classifier=classifier, \n",
    "                x_train=x_train, \n",
    "                y_train=one_hot_train, \n",
    "                unlabeled_train=unlabeled_train, \n",
    "                validation_data=(x_val, one_hot_val),\n",
    "                batch_size_autoencoder=256,\n",
    "                epochs_autoencoder=1,\n",
    "                batch_size_classifier=4096,\n",
    "                epochs_classifier=405)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruction_plot(autoencoder, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.score(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EJERCICIO 4\n",
    "\n",
    "Entrena un modelo de aprendizaje semisupervisado de tipo autoencoder en un paso (autoencoder y clasificador al mismo tiempo). La arquitectura del autoencoder será la misma que la definida en el Ejercicio 3, y la combinación de encoder y clasificador será igual a la arquitectura definida en el\n",
    "Ejercicio 1.\n",
    "\n",
    "Responde a las siguientes preguntas:\n",
    "1. ¿Cuál es la arquitectura del modelo? ¿Y sus hiperparámetros?\n",
    "2. ¿Cuál es el rendimiento del modelo en entrenamiento? ¿Y en prueba?\n",
    "3. ¿Se mejoran los resultados obtenidos en los ejercicios anteriores?\n",
    "4. ¿Qué conclusiones sacas de los resultados detallados en los puntos anteriores?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "one_step_autoencoder = OneStepAutoencoder(input_shape=unlabeled_train[0].shape,\n",
    "                                learning_rate=0.0015,\n",
    "                                decoder_extra_loss_weight = 0.45,\n",
    "                                l2_lambda=0.00005,\n",
    "                                dropout_prob=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "h = OneStepTraining(one_step_autoencoder, \n",
    "                    x_train=x_train, \n",
    "                    y_train=one_hot_train, \n",
    "                    unlabeled_train=unlabeled_train,\n",
    "                    batch_size=256,\n",
    "                    epochs=1000,\n",
    "                    patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reconstruction_plot(one_step_autoencoder, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_step_autoencoder.score(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EJERCICIO 5\n",
    "\n",
    "Repite el mismo entrenamiento de los Ejercicios 1-4, pero eliminando las instancias no etiquetadas\n",
    "más atípicas con respecto a los datos etiquetados. Se cumplirán los siguientes puntos:\n",
    "- La arquitectura de la red de clasificación en una clase será la misma a la utilizada en el\n",
    "clasificador del Ejercicio 1, a excepción de la capa de salida.\n",
    "- Utiliza la técnica explicada en el Notebook 5, usando un valor de 𝑣 = 0,9.\n",
    "\n",
    "Responde a la siguiente pregunta:\n",
    "1. ¿Se mejoran los resultados con respecto a los anteriores ejercicios? ¿Qué conclusiones sacas de estos resultados?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = AnomalyDetector(input_shape=(32,32,3), \n",
    "                        nu=.9,\n",
    "                        l2_lambda=0.0,\n",
    "                        learning_rate=0.0001,\n",
    "                        dropout_prob=0.05)\n",
    "model.fit(x_train, \n",
    "          batch_size=256, \n",
    "          epochs=50, \n",
    "          delta=.025, \n",
    "          steps=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DE AQUI HASTA EL 6 LO QUE PUSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primero predecimos qué datos son típicos en el conjunto no etiquetado\n",
    "unlabeled_predictions = model.predict(unlabeled_train)\n",
    "r_value = model.model.r.numpy()\n",
    "is_typical = unlabeled_predictions > r_value\n",
    "\n",
    "# Filtramos para obtener solo los datos típicos\n",
    "filtered_unlabeled_train = unlabeled_train[is_typical]\n",
    "percetage = np.mean(is_typical) * 100\n",
    "print(f\"Porcentaje de datos no etiquetados etiquetados como típicos: {percetage:.2f}%\")\n",
    "print(f\"Porcentaje de datos no etiquetados etiquetados como atípicos: {100 - percetage:.2f}%\")\n",
    "print(f\"Datos originales no etiquetados: {unlabeled_train.shape}\")\n",
    "print(f\"Datos filtrados no etiquetados (solo típicos): {filtered_unlabeled_train.shape}\")\n",
    "print(f\"Se eliminaron {unlabeled_train.shape[0] - filtered_unlabeled_train.shape[0]} muestras atípicas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora entrenamos los modelos con los datos filtrados\n",
    "\n",
    "# Ejercicio 2 con datos filtrados\n",
    "model_self_filtered = ConvModel.self_training_v2(\n",
    "    model_func=create_model,\n",
    "    x_train=x_train_labeled,\n",
    "    y_train=y_train_labeled,\n",
    "    unlabeled_data=filtered_unlabeled_train,\n",
    "    validation_data=(x_val, y_val),\n",
    "    thresh=0.8,\n",
    "    train_epochs=5\n",
    ")\n",
    "\n",
    "# Evaluar los modelos filtrados\n",
    "test_accuracy_self_filtered = model_self_filtered.score(x_test, y_test)\n",
    "print(f\"Accuracy en conjunto de prueba (self-training filtrado): {test_accuracy_self_filtered}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejercicio 3 con datos filtrados\n",
    "autoencoder_filtered = TwoStepAutoEncoder(\n",
    "    input_shape=filtered_unlabeled_train[0].shape,\n",
    "    learning_rate=0.006,\n",
    "    l2_lambda=0.0005,\n",
    "    dropout_prob=0.1\n",
    ")\n",
    "\n",
    "classifier_filtered = TwoStepClassifier(\n",
    "    l2_lambda=0.0005,\n",
    "    dropout_prob=0.05,\n",
    "    learning_rate=0.05\n",
    ")\n",
    "\n",
    "history_two_step_filtered = TwoStepTraining(\n",
    "    autoencoder=autoencoder_filtered, \n",
    "    classifier=classifier_filtered, \n",
    "    x_train=x_train, \n",
    "    y_train=one_hot_train, \n",
    "    unlabeled_train=filtered_unlabeled_train, \n",
    "    validation_data=(x_val, one_hot_val),\n",
    "    batch_size_autoencoder=256,\n",
    "    epochs_autoencoder=50,\n",
    "    batch_size_classifier=256,\n",
    "    epochs_classifier=100\n",
    ")\n",
    "\n",
    "# Evaluar modelos\n",
    "test_accuracy_two_step_filtered = classifier_filtered.score(x_test, y_test)  # No se si es asi como se evaluaria este la verdad supongo que si\n",
    "print(f\"Accuracy del modelo one-step filtrado: {test_accuracy_two_step_filtered}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejercicio 4 con datos filtrados\n",
    "one_step_autoencoder_filtered = OneStepAutoencoder(\n",
    "    input_shape=filtered_unlabeled_train[0].shape,\n",
    "    learning_rate=0.0015,\n",
    "    decoder_extra_loss_weight=0.45,\n",
    "    l2_lambda=0.00005,\n",
    "    dropout_prob=0.05\n",
    ")\n",
    "\n",
    "history_one_step_filtered = OneStepTraining(\n",
    "    one_step_autoencoder_filtered, \n",
    "    x_train=x_train, \n",
    "    y_train=one_hot_train, \n",
    "    unlabeled_train=filtered_unlabeled_train,\n",
    "    batch_size=256,\n",
    "    epochs=100,\n",
    "    patience=10\n",
    ")\n",
    "# Evaluar modelos\n",
    "test_accuracy_one_step_filtered = one_step_autoencoder_filtered.score(x_test, y_test)\n",
    "print(f\"Accuracy del modelo one-step filtrado: {test_accuracy_one_step_filtered}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EJERCICIO 6\n",
    "\n",
    "Repite los Ejercicios 3-5 cambiando el autencoder por la técnica definida en el apartado “Hay vida más allá del autoencoder” del Notebook 4. Contesta a las preguntas de dichos ejercicios. Se cumplirán los siguientes puntos:\n",
    "\n",
    "1. La arquitectura de la red será igual a la parte encoder del autencoder definido en los\n",
    "ejercicios anteriores.\n",
    "2. El modelo debe entrenar correctamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cModel = ContrastiveModel(unlabeled_train[0].shape, \n",
    "                          learning_rate=0.05, \n",
    "                          lambda_param=.9,\n",
    "                          l2_lambda=0.001)\n",
    "cModel.train(unlabeled_train, \n",
    "             epochs=5, \n",
    "             batch_size=2048)\n",
    "cModel.plot_training_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 100\n",
    "test_samples = x_test[:n_samples].reshape(n_samples,32,32,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 100\n",
    "test_samples = x_test[:n_samples].reshape(n_samples,32,32,3)\n",
    "\n",
    "cModel.plot_similarity_matrix(test_samples, n_samples=n_samples);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Echale un vistazo q no se como ira"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejercicio 6 - Implementación con técnica contrastiva\n",
    "\n",
    "# Primero filtrar datos atípicos \n",
    "unlabeled_predictions = model.predict(unlabeled_train)\n",
    "r_value = model.model.r.numpy()\n",
    "is_typical = unlabeled_predictions > r_value\n",
    "filtered_unlabeled_train = unlabeled_train[is_typical]\n",
    "\n",
    "# Entrenar modelo contrastivo con datos completos\n",
    "contrastive_full = ContrastiveModel(\n",
    "    unlabeled_train[0].shape, \n",
    "    learning_rate=0.05, \n",
    "    lambda_param=0.9,\n",
    "    l2_lambda=0.001\n",
    ")\n",
    "contrastive_full.train(\n",
    "    unlabeled_train, \n",
    "    epochs=5, \n",
    "    batch_size=2048\n",
    ")\n",
    "\n",
    "# Entrenar modelo contrastivo con datos filtrados\n",
    "contrastive_filtered = ContrastiveModel(\n",
    "    filtered_unlabeled_train[0].shape, \n",
    "    learning_rate=0.05, \n",
    "    lambda_param=0.9,\n",
    "    l2_lambda=0.001\n",
    ")\n",
    "contrastive_filtered.train(\n",
    "    filtered_unlabeled_train, \n",
    "    epochs=5, \n",
    "    batch_size=2048\n",
    ")\n",
    "\n",
    "# Extraer características para clasificación\n",
    "train_features_full = contrastive_full.get_features(x_train)\n",
    "val_features_full = contrastive_full.get_features(x_val)\n",
    "test_features_full = contrastive_full.get_features(x_test)\n",
    "\n",
    "train_features_filtered = contrastive_filtered.get_features(x_train)\n",
    "val_features_filtered = contrastive_filtered.get_features(x_val)\n",
    "test_features_filtered = contrastive_filtered.get_features(x_test)\n",
    "\n",
    "# Entrenar clasificadores con estas características\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Clasificador para características del modelo contrastivo completo\n",
    "classifier_contrastive_full = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(train_features_full.shape[1],)),\n",
    "    Dropout(0.2),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "classifier_contrastive_full.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history_clf_full = classifier_contrastive_full.fit(\n",
    "    train_features_full, one_hot_train,\n",
    "    validation_data=(val_features_full, one_hot_val),\n",
    "    epochs=50,\n",
    "    batch_size=256,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Clasificador para características del modelo contrastivo filtrado\n",
    "classifier_contrastive_filtered = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(train_features_filtered.shape[1],)),\n",
    "    Dropout(0.2),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "classifier_contrastive_filtered.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history_clf_filtered = classifier_contrastive_filtered.fit(\n",
    "    train_features_filtered, one_hot_train,\n",
    "    validation_data=(val_features_filtered, one_hot_val),\n",
    "    epochs=50,\n",
    "    batch_size=256,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluar modelos\n",
    "test_loss_full, test_acc_full = classifier_contrastive_full.evaluate(test_features_full, one_hot_test)\n",
    "test_loss_filtered, test_acc_filtered = classifier_contrastive_filtered.evaluate(test_features_filtered, one_hot_test)\n",
    "\n",
    "print(f\"Accuracy del clasificador contrastivo completo: {test_acc_full}\")\n",
    "print(f\"Accuracy del clasificador contrastivo filtrado: {test_acc_filtered}\")\n",
    "\n",
    "# Visualizar matrices de similitud para ambos modelos\n",
    "n_samples = 100\n",
    "test_samples = x_test[:n_samples].reshape(n_samples, 32, 32, 3)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(18, 8))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "contrastive_full.plot_similarity_matrix(test_samples, n_samples=n_samples)\n",
    "plt.title(\"Matriz de similitud - Modelo contrastivo con datos completos\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "contrastive_filtered.plot_similarity_matrix(test_samples, n_samples=n_samples)\n",
    "plt.title(\"Matriz de similitud - Modelo contrastivo con datos filtrados\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "maai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
