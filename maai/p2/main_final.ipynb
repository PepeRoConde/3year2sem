{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CARGA DE DATOS\n",
    "\n",
    "__TODO__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Utils import DatasetProcess, reconstruction_plot\n",
    "from ConvModel import ConvModel\n",
    "from AutoEncoder import TwoStepAutoEncoder, TwoStepClassifier, TwoStepTraining, OneStepAutoencoder, OneStepTraining\n",
    "from OneClass import AnomalyDetector\n",
    "from Contrastive import ContrastiveModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = DatasetProcess.load()\n",
    "\n",
    "\n",
    "# Aplicar la funci√≥n hold_out\n",
    "(x_train_no_labeled, x_train_labeled, y_train_labeled), (x_val, y_val), (x_test, y_test) = DatasetProcess.hold_out(\n",
    "    (x_train, y_train), (x_test, y_test), validation_size=1000\n",
    ")\n",
    "\n",
    "x_train_labeled = x_train_labeled.astype('float32') / 255.0\n",
    "x_val = x_val.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "# Verificar las dimensiones\n",
    "print(f\"Datos no etiquetados: {x_train_no_labeled.shape}\")\n",
    "print(f\"Datos etiquetados entrenamiento: {x_train_labeled.shape}\")\n",
    "print(f\"Etiquetas entrenamiento: {y_train_labeled.shape}\")\n",
    "print(f\"Datos validaci√≥n: {x_val.shape}\")\n",
    "print(f\"Etiquetas validaci√≥n: {y_val.shape}\")\n",
    "print(f\"Datos prueba: {x_test.shape}\")\n",
    "print(f\"Etiquetas prueba: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EJERCICIO 1\n",
    "\n",
    "Entrena un modelo, creado sobre TensorFlow, haciendo uso √∫nicamente de las instancias etiquetadas de entrenamiento. Dicho modelo debe de tener al menos cuatro capas densas y/o convolucionales.\n",
    "\n",
    "Responde a las siguientes preguntas:\n",
    "\n",
    "1. ¬øQu√© red has escogido? ¬øPor qu√©? ¬øC√≥mo la has entrenado?\n",
    "2. ¬øCu√°l es el rendimiento del modelo en entrenamiento? ¬øY en prueba?\n",
    "3. ¬øQu√© conclusiones sacas de los resultados detallados en el punto anterior?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_base = ConvModel()\n",
    "history_base = model_base.fit(\n",
    "    x_train_labeled, \n",
    "    y_train_labeled,\n",
    "    validation_data=(x_val, y_val),\n",
    "    batch_size=64,\n",
    "    epochs=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eval√∫a con el conjunto de prueba\n",
    "test_accuracy = model_base.score(x_test, y_test)\n",
    "print(f\"Accuracy en conjunto de prueba: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.unique(np.argmax(model_base(x_test),axis=1)) # >> array([60]) # solo predice la clase 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_base.plot(history_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EJERCICIO 2\n",
    "\n",
    "Entrena el mismo modelo, incorporando las instancias no etiquetadas de entrenamiento mediante la t√©cnica de auto-aprendizaje. Opcionalmente, se ponderar√° cada instancia de entrada en funci√≥n de su calidad (o certeza).\n",
    "\n",
    "Responde a las siguientes preguntas:\n",
    "1. ¬øQu√© par√°metros has definido para el entrenamiento?\n",
    "2. ¬øCu√°l es el rendimiento del modelo en entrenamiento? ¬øY en prueba?\n",
    "3. ¬øSe mejoran los resultados obtenidos en el Ejercicio 1?\n",
    "4. ¬øQu√© conclusiones sacas de los resultados detallados en los puntos anteriores?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funci√≥n para crear modelos consistentes durante self-training\n",
    "def create_model():\n",
    "    return ConvModel(\n",
    "        learning_rate=0.0005,  # Learning rate reducido para fine-tuning\n",
    "        dropout_prob=0.25,     \n",
    "        l2_lambda=0.005        \n",
    "    )\n",
    "\n",
    "# Normalizar datos no etiquetados\n",
    "x_train_no_labeled = x_train_no_labeled.astype('float32') / 255.0\n",
    "\n",
    "# Aplica self-training con datos no etiquetados\n",
    "final_model = ConvModel.self_training_v2(\n",
    "    model_func=create_model,\n",
    "    x_train=x_train_labeled,\n",
    "    y_train=y_train_labeled,  \n",
    "    unlabeled_data=x_train_no_labeled,\n",
    "    validation_data=(x_val, y_val),\n",
    "    thresh=0.9,             # Umbral ligeramente m√°s bajo para incluir m√°s ejemplos\n",
    "    train_epochs=5           # 5 iteraciones de self-training\n",
    ")\n",
    "\n",
    "# Eval√∫a el modelo final\n",
    "final_accuracy = final_model.score(x_test, y_test)\n",
    "print(f\"Accuracy del modelo final con self-training: {final_accuracy}\")\n",
    "print(f\"Mejora respecto al modelo base: {final_accuracy - test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EJERCICIO 3\n",
    "\n",
    "Entrena un modelo de aprendizaje semisupervisado de tipo autoencoder en dos pasos (primero el autoencoder, despu√©s el clasificador). La arquitectura del encoder debe ser exactamente la misma que la definida en los Ejercicios 1 y 2, a excepci√≥n del √∫ltimo bloque de capas.\n",
    "\n",
    "Responde a las siguientes preguntas:\n",
    "1. ¬øCu√°l es la arquitectura del modelo? ¬øY sus hiperpar√°metros?\n",
    "2. ¬øCu√°l es el rendimiento del modelo en entrenamiento? ¬øY en prueba?\n",
    "3. ¬øSe mejoran los resultados obtenidos en los Ejercicios 1 y 2?\n",
    "4. ¬øQu√© conclusiones sacas de los resultados detallados en los puntos anteriores?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = TwoStepAutoEncoder(input_shape=unlabeled_train[0].shape,\n",
    "                                learning_rate=0.0015)\n",
    "classifier = TwoStepClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "TwoStepTraining(autoencoder=autoencoder, \n",
    "                classifier=classifier, \n",
    "                x_train=x_train, \n",
    "                y_train=one_hot_train, \n",
    "                unlabeled_train=unlabeled_train, \n",
    "                batch_size_autoencoder=256,\n",
    "                epochs_autoencoder=15,\n",
    "                batch_size_classifier=4096,\n",
    "                epochs_classifier=405)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruction_plot(autoencoder, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.score(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EJERCICIO 4\n",
    "\n",
    "Entrena un modelo de aprendizaje semisupervisado de tipo autoencoder en un paso (autoencoder y clasificador al mismo tiempo). La arquitectura del autoencoder ser√° la misma que la definida en el Ejercicio 3, y la combinaci√≥n de encoder y clasificador ser√° igual a la arquitectura definida en el\n",
    "Ejercicio 1.\n",
    "\n",
    "Responde a las siguientes preguntas:\n",
    "1. ¬øCu√°l es la arquitectura del modelo? ¬øY sus hiperpar√°metros?\n",
    "2. ¬øCu√°l es el rendimiento del modelo en entrenamiento? ¬øY en prueba?\n",
    "3. ¬øSe mejoran los resultados obtenidos en los ejercicios anteriores?\n",
    "4. ¬øQu√© conclusiones sacas de los resultados detallados en los puntos anteriores?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "one_step_autoencoder = OneStepAutoencoder(input_shape=unlabeled_train[0].shape,\n",
    "                                learning_rate=0.0015,\n",
    "                                decoder_extra_loss_weight = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "h = OneStepTraining(one_step_autoencoder, \n",
    "                    x_train=x_train, \n",
    "                    y_train=one_hot_train, \n",
    "                    unlabeled_train=unlabeled_train,\n",
    "                    batch_size=256,\n",
    "                    epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reconstruction_plot(one_step_autoencoder, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_step_autoencoder.score(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EJERCICIO 5\n",
    "\n",
    "Repite el mismo entrenamiento de los Ejercicios 1-4, pero eliminando las instancias no etiquetadas\n",
    "m√°s at√≠picas con respecto a los datos etiquetados. Se cumplir√°n los siguientes puntos:\n",
    "- La arquitectura de la red de clasificaci√≥n en una clase ser√° la misma a la utilizada en el\n",
    "clasificador del Ejercicio 1, a excepci√≥n de la capa de salida.\n",
    "- Utiliza la t√©cnica explicada en el Notebook 5, usando un valor de ùë£ = 0,9.\n",
    "\n",
    "Responde a la siguiente pregunta:\n",
    "1. ¬øSe mejoran los resultados con respecto a los anteriores ejercicios? ¬øQu√© conclusiones sacas de estos resultados?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = AnomalyDetector(input_shape=(32,32,3), \n",
    "                        nu=.9,\n",
    "                        l2_lambda=0.0,\n",
    "                        learning_rate=0.0001,\n",
    "                        dropout_prob=0.1)\n",
    "model.fit(x_train, \n",
    "          batch_size=256, \n",
    "          epochs=50, \n",
    "          delta=.025, \n",
    "          steps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# TODO: Eval√∫a el modelo con los datos del conjunto de test. Indica el porcentaje de datos etiquetados como t√≠picos, y visualiza los datos\n",
    "predicciones = model.predict(x_test)\n",
    "\n",
    "# Determinamos qu√© datos son t√≠picos (normales) y cu√°les son anomal√≠as\n",
    "# Un dato es t√≠pico si su predicci√≥n es mayor que r\n",
    "r_valor = model.model.r.numpy()\n",
    "es_tipico = predicciones > r_valor\n",
    "\n",
    "# Calculamos el porcentaje de datos etiquetados como t√≠picos\n",
    "porcentaje_tipicos = np.mean(es_tipico) * 100\n",
    "\n",
    "print(f\"Valor de r: {r_valor:.4f}\")\n",
    "print(f\"Porcentaje de datos etiquetados como t√≠picos: {porcentaje_tipicos:.2f}%\")\n",
    "print(f\"Porcentaje de datos etiquetados como anomal√≠as: {100 - porcentaje_tipicos:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(predicciones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Eval√∫a el modelo con los datos del conjunto de outliers. Indica el porcentaje de datos etiquetados como at√≠picos, y visualiza los datos en conjunto con los de test\n",
    "predicciones_outliers = model.predict(x_outliers)\n",
    "r_valor = model.model.r.numpy()\n",
    "es_atipico_outliers = predicciones_outliers <= r_valor\n",
    "porcentaje_atipicos_outliers = np.mean(es_atipico_outliers) * 100\n",
    "\n",
    "# Evaluamos tambi√©n los datos de test para comparar\n",
    "predicciones_test = model.predict(x_test)\n",
    "es_atipico_test = predicciones_test <= r_valor\n",
    "\n",
    "print(f\"Porcentaje de outliers etiquetados como at√≠picos: {porcentaje_atipicos_outliers:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EJERCICIO 6\n",
    "\n",
    "Repite los Ejercicios 3-5 cambiando el autencoder por la t√©cnica definida en el apartado ‚ÄúHay vida m√°s all√° del autoencoder‚Äù del Notebook 4. Contesta a las preguntas de dichos ejercicios. Se cumplir√°n los siguientes puntos:\n",
    "\n",
    "1. La arquitectura de la red ser√° igual a la parte encoder del autencoder definido en los\n",
    "ejercicios anteriores.\n",
    "2. El modelo debe entrenar correctamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cModel = ContrastiveModel(unlabeled_train[0].shape, \n",
    "                          learning_rate=0.05, \n",
    "                          lambda_param=.9,\n",
    "                          l2_lambda=0.001)\n",
    "cModel.train(unlabeled_train, \n",
    "             epochs=5, \n",
    "             batch_size=2048)\n",
    "cModel.plot_training_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 100\n",
    "test_samples = x_test[:n_samples].reshape(n_samples,32,32,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 100\n",
    "test_samples = x_test[:n_samples].reshape(n_samples,32,32,3)\n",
    "\n",
    "cModel.plot_similarity_matrix(test_samples, n_samples=n_samples);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "maai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
