{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pablo Chantada Saborido (pablo.chantada@udc.es)\n",
    "### Jos√© Romero Conde (j.rconde@udc.es)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CARGA DE DATOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Utils import DatasetProcess, reconstruction_plot\n",
    "from ConvModel import ConvModel\n",
    "from AutoEncoder import TwoStepAutoEncoder, TwoStepClassifier, TwoStepTraining, OneStepAutoencoder, OneStepTraining\n",
    "from OneClass import AnomalyDetector\n",
    "from Contrastive import ContrastiveModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = DatasetProcess.load()\n",
    "\n",
    "\n",
    "# Aplicar la funci√≥n hold_out\n",
    "(x_train_no_labeled, x_train_labeled, y_train_labeled), (x_val, y_val), (x_test, y_test) = DatasetProcess.hold_out(\n",
    "    (x_train, y_train), (x_test, y_test), validation_size=1000\n",
    ")\n",
    "\n",
    "x_train_labeled = x_train_labeled.astype('float32') / 255.0\n",
    "x_val = x_val.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "# Verificar las dimensiones\n",
    "print(f\"Datos no etiquetados: {x_train_no_labeled.shape}\")\n",
    "print(f\"Datos etiquetados entrenamiento: {x_train_labeled.shape}\")\n",
    "print(f\"Etiquetas entrenamiento: {y_train_labeled.shape}\")\n",
    "print(f\"Datos validaci√≥n: {x_val.shape}\")\n",
    "print(f\"Etiquetas validaci√≥n: {y_val.shape}\")\n",
    "print(f\"Datos prueba: {x_test.shape}\")\n",
    "print(f\"Etiquetas prueba: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EJERCICIO 1\n",
    "\n",
    "Entrena un modelo, creado sobre TensorFlow, haciendo uso √∫nicamente de las instancias etiquetadas de entrenamiento. Dicho modelo debe de tener al menos cuatro capas densas y/o convolucionales.\n",
    "\n",
    "Responde a las siguientes preguntas:\n",
    "\n",
    "1. ¬øQu√© red has escogido? ¬øPor qu√©? ¬øC√≥mo la has entrenado?\n",
    "2. ¬øCu√°l es el rendimiento del modelo en entrenamiento? ¬øY en prueba?\n",
    "3. ¬øQu√© conclusiones sacas de los resultados detallados en el punto anterior?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_base = ConvModel()\n",
    "history_base = model_base.fit(\n",
    "    x_train_labeled, \n",
    "    y_train_labeled,\n",
    "    validation_data=(x_val, y_val),\n",
    "    batch_size=128,\n",
    "    epochs=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eval√∫a con el conjunto de prueba\n",
    "test_accuracy = model_base.score(x_test, y_test)\n",
    "print(f\"Accuracy en conjunto de prueba: {test_accuracy}\")\n",
    "\n",
    "model_base.plot(history_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EJERCICIO 2\n",
    "\n",
    "Entrena el mismo modelo, incorporando las instancias no etiquetadas de entrenamiento mediante la t√©cnica de auto-aprendizaje. Opcionalmente, se ponderar√° cada instancia de entrada en funci√≥n de su calidad (o certeza).\n",
    "\n",
    "Responde a las siguientes preguntas:\n",
    "1. ¬øQu√© par√°metros has definido para el entrenamiento?\n",
    "2. ¬øCu√°l es el rendimiento del modelo en entrenamiento? ¬øY en prueba?\n",
    "3. ¬øSe mejoran los resultados obtenidos en el Ejercicio 1?\n",
    "4. ¬øQu√© conclusiones sacas de los resultados detallados en los puntos anteriores?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funci√≥n para crear modelos consistentes durante self-training\n",
    "def create_model():\n",
    "    return ConvModel(\n",
    "        learning_rate=0.0005,  # Learning rate reducido para fine-tuning\n",
    "        dropout_prob=0.25,     \n",
    "        l2_lambda=0.005        \n",
    "    )\n",
    "\n",
    "# Normalizar datos no etiquetados\n",
    "x_train_no_labeled = x_train_no_labeled.astype('float32') / 255.0\n",
    "\n",
    "# Aplica self-training con datos no etiquetados\n",
    "final_model = ConvModel.self_training_v2(\n",
    "    model_func=create_model,\n",
    "    x_train=x_train_labeled,\n",
    "    y_train=y_train_labeled,  \n",
    "    unlabeled_data=x_train_no_labeled,\n",
    "    validation_data=(x_val, y_val),\n",
    "    thresh=0.8,             \n",
    "    train_epochs=5,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Eval√∫a el modelo final\n",
    "final_accuracy = final_model.score(x_test, y_test)\n",
    "print(f\"Accuracy del modelo final con self-training: {final_accuracy}\")\n",
    "print(f\"Mejora respecto al modelo base: {final_accuracy - test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EJERCICIO 3\n",
    "\n",
    "Entrena un modelo de aprendizaje semisupervisado de tipo autoencoder en dos pasos (primero el autoencoder, despu√©s el clasificador). La arquitectura del encoder debe ser exactamente la misma que la definida en los Ejercicios 1 y 2, a excepci√≥n del √∫ltimo bloque de capas.\n",
    "\n",
    "Responde a las siguientes preguntas:\n",
    "1. ¬øCu√°l es la arquitectura del modelo? ¬øY sus hiperpar√°metros?\n",
    "2. ¬øCu√°l es el rendimiento del modelo en entrenamiento? ¬øY en prueba?\n",
    "3. ¬øSe mejoran los resultados obtenidos en los Ejercicios 1 y 2?\n",
    "4. ¬øQu√© conclusiones sacas de los resultados detallados en los puntos anteriores?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabeled_train, x_train, y_train, x_val, y_val, x_test, y_test, one_hot_train, one_hot_val, one_hot_test = DatasetProcess.alt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = TwoStepAutoEncoder(\n",
    "                                input_shape=unlabeled_train[0].shape,\n",
    "                                learning_rate=0.006,\n",
    "                                l2_lambda=0.0005,\n",
    "                                dropout_prob=0.1)\n",
    "classifier = TwoStepClassifier(\n",
    "                              l2_lambda=0.0005,\n",
    "                              dropout_prob=0.05,\n",
    "                               learning_rate=0.05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "TwoStepTraining(autoencoder=autoencoder, \n",
    "                classifier=classifier, \n",
    "                x_train=x_train, \n",
    "                y_train=one_hot_train, \n",
    "                unlabeled_train=unlabeled_train, \n",
    "                validation_data=(x_val, one_hot_val),\n",
    "                batch_size_autoencoder=256,\n",
    "                epochs_autoencoder=1,\n",
    "                batch_size_classifier=4096,\n",
    "                epochs_classifier=405)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruction_plot(autoencoder, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.score(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EJERCICIO 4\n",
    "\n",
    "Entrena un modelo de aprendizaje semisupervisado de tipo autoencoder en un paso (autoencoder y clasificador al mismo tiempo). La arquitectura del autoencoder ser√° la misma que la definida en el Ejercicio 3, y la combinaci√≥n de encoder y clasificador ser√° igual a la arquitectura definida en el\n",
    "Ejercicio 1.\n",
    "\n",
    "Responde a las siguientes preguntas:\n",
    "1. ¬øCu√°l es la arquitectura del modelo? ¬øY sus hiperpar√°metros?\n",
    "2. ¬øCu√°l es el rendimiento del modelo en entrenamiento? ¬øY en prueba?\n",
    "3. ¬øSe mejoran los resultados obtenidos en los ejercicios anteriores?\n",
    "4. ¬øQu√© conclusiones sacas de los resultados detallados en los puntos anteriores?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "one_step_autoencoder = OneStepAutoencoder(input_shape=unlabeled_train[0].shape,\n",
    "                                learning_rate=0.0015,\n",
    "                                decoder_extra_loss_weight = 0.45,\n",
    "                                l2_lambda=0.00005,\n",
    "                                dropout_prob=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "h = OneStepTraining(one_step_autoencoder, \n",
    "                    x_train=x_train, \n",
    "                    y_train=one_hot_train, \n",
    "                    unlabeled_train=unlabeled_train,\n",
    "                    batch_size=256,\n",
    "                    epochs=1000,\n",
    "                    patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reconstruction_plot(one_step_autoencoder, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_step_autoencoder.score(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EJERCICIO 5\n",
    "\n",
    "Repite el mismo entrenamiento de los Ejercicios 1-4, pero eliminando las instancias no etiquetadas\n",
    "m√°s at√≠picas con respecto a los datos etiquetados. Se cumplir√°n los siguientes puntos:\n",
    "- La arquitectura de la red de clasificaci√≥n en una clase ser√° la misma a la utilizada en el\n",
    "clasificador del Ejercicio 1, a excepci√≥n de la capa de salida.\n",
    "- Utiliza la t√©cnica explicada en el Notebook 5, usando un valor de ùë£ = 0,9.\n",
    "\n",
    "Responde a la siguiente pregunta:\n",
    "1. ¬øSe mejoran los resultados con respecto a los anteriores ejercicios? ¬øQu√© conclusiones sacas de estos resultados?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = AnomalyDetector(input_shape=(32,32,3), \n",
    "                        nu=.9,\n",
    "                        l2_lambda=0.0,\n",
    "                        learning_rate=0.0001,\n",
    "                        dropout_prob=0.05)\n",
    "model.fit(x_train, \n",
    "          batch_size=256, \n",
    "          epochs=50, \n",
    "          delta=.025, \n",
    "          steps=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DE AQUI HASTA EL 6 LO QUE PUSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primero predecimos qu√© datos son t√≠picos en el conjunto no etiquetado\n",
    "unlabeled_predictions = model.predict(unlabeled_train)\n",
    "r_value = model.model.r.numpy()\n",
    "is_typical = unlabeled_predictions > r_value\n",
    "\n",
    "# Filtramos para obtener solo los datos t√≠picos\n",
    "filtered_unlabeled_train = unlabeled_train[is_typical]\n",
    "percetage = np.mean(is_typical) * 100\n",
    "print(f\"Porcentaje de datos no etiquetados etiquetados como t√≠picos: {percetage:.2f}%\")\n",
    "print(f\"Porcentaje de datos no etiquetados etiquetados como at√≠picos: {100 - percetage:.2f}%\")\n",
    "print(f\"Datos originales no etiquetados: {unlabeled_train.shape}\")\n",
    "print(f\"Datos filtrados no etiquetados (solo t√≠picos): {filtered_unlabeled_train.shape}\")\n",
    "print(f\"Se eliminaron {unlabeled_train.shape[0] - filtered_unlabeled_train.shape[0]} muestras at√≠picas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora entrenamos los modelos con los datos filtrados\n",
    "\n",
    "# Ejercicio 2 con datos filtrados\n",
    "model_self_filtered = ConvModel.self_training_v2(\n",
    "    model_func=create_model,\n",
    "    x_train=x_train_labeled,\n",
    "    y_train=y_train_labeled,\n",
    "    unlabeled_data=filtered_unlabeled_train,\n",
    "    validation_data=(x_val, y_val),\n",
    "    thresh=0.8,\n",
    "    train_epochs=5\n",
    ")\n",
    "\n",
    "# Evaluar los modelos filtrados\n",
    "test_accuracy_self_filtered = model_self_filtered.score(x_test, y_test)\n",
    "print(f\"Accuracy en conjunto de prueba (self-training filtrado): {test_accuracy_self_filtered}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejercicio 3 con datos filtrados\n",
    "autoencoder_filtered = TwoStepAutoEncoder(\n",
    "    input_shape=filtered_unlabeled_train[0].shape,\n",
    "    learning_rate=0.006,\n",
    "    l2_lambda=0.0005,\n",
    "    dropout_prob=0.1\n",
    ")\n",
    "\n",
    "classifier_filtered = TwoStepClassifier(\n",
    "    l2_lambda=0.0005,\n",
    "    dropout_prob=0.05,\n",
    "    learning_rate=0.05\n",
    ")\n",
    "\n",
    "history_two_step_filtered = TwoStepTraining(\n",
    "    autoencoder=autoencoder_filtered, \n",
    "    classifier=classifier_filtered, \n",
    "    x_train=x_train, \n",
    "    y_train=one_hot_train, \n",
    "    unlabeled_train=filtered_unlabeled_train, \n",
    "    validation_data=(x_val, one_hot_val),\n",
    "    batch_size_autoencoder=256,\n",
    "    epochs_autoencoder=50,\n",
    "    batch_size_classifier=256,\n",
    "    epochs_classifier=100\n",
    ")\n",
    "\n",
    "# Evaluar modelos\n",
    "test_accuracy_two_step_filtered = classifier_filtered.score(x_test, y_test)  # No se si es asi como se evaluaria este la verdad supongo que si\n",
    "print(f\"Accuracy del modelo one-step filtrado: {test_accuracy_two_step_filtered}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejercicio 4 con datos filtrados\n",
    "one_step_autoencoder_filtered = OneStepAutoencoder(\n",
    "    input_shape=filtered_unlabeled_train[0].shape,\n",
    "    learning_rate=0.0015,\n",
    "    decoder_extra_loss_weight=0.45,\n",
    "    l2_lambda=0.00005,\n",
    "    dropout_prob=0.05\n",
    ")\n",
    "\n",
    "history_one_step_filtered = OneStepTraining(\n",
    "    one_step_autoencoder_filtered, \n",
    "    x_train=x_train, \n",
    "    y_train=one_hot_train, \n",
    "    unlabeled_train=filtered_unlabeled_train,\n",
    "    batch_size=256,\n",
    "    epochs=100,\n",
    "    patience=10\n",
    ")\n",
    "# Evaluar modelos\n",
    "test_accuracy_one_step_filtered = one_step_autoencoder_filtered.score(x_test, y_test)\n",
    "print(f\"Accuracy del modelo one-step filtrado: {test_accuracy_one_step_filtered}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EJERCICIO 6\n",
    "\n",
    "Repite los Ejercicios 3-5 cambiando el autencoder por la t√©cnica definida en el apartado ‚ÄúHay vida m√°s all√° del autoencoder‚Äù del Notebook 4. Contesta a las preguntas de dichos ejercicios. Se cumplir√°n los siguientes puntos:\n",
    "\n",
    "1. La arquitectura de la red ser√° igual a la parte encoder del autencoder definido en los\n",
    "ejercicios anteriores.\n",
    "2. El modelo debe entrenar correctamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cModel = ContrastiveModel(unlabeled_train[0].shape, \n",
    "                          learning_rate=0.05, \n",
    "                          lambda_param=.9,\n",
    "                          l2_lambda=0.001)\n",
    "cModel.train(unlabeled_train, \n",
    "             epochs=5, \n",
    "             batch_size=2048)\n",
    "cModel.plot_training_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 100\n",
    "test_samples = x_test[:n_samples].reshape(n_samples,32,32,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 100\n",
    "test_samples = x_test[:n_samples].reshape(n_samples,32,32,3)\n",
    "\n",
    "cModel.plot_similarity_matrix(test_samples, n_samples=n_samples);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Echale un vistazo q no se como ira"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejercicio 6 - Implementaci√≥n con t√©cnica contrastiva\n",
    "\n",
    "# Primero filtrar datos at√≠picos \n",
    "unlabeled_predictions = model.predict(unlabeled_train)\n",
    "r_value = model.model.r.numpy()\n",
    "is_typical = unlabeled_predictions > r_value\n",
    "filtered_unlabeled_train = unlabeled_train[is_typical]\n",
    "\n",
    "# Entrenar modelo contrastivo con datos completos\n",
    "contrastive_full = ContrastiveModel(\n",
    "    unlabeled_train[0].shape, \n",
    "    learning_rate=0.05, \n",
    "    lambda_param=0.9,\n",
    "    l2_lambda=0.001\n",
    ")\n",
    "contrastive_full.train(\n",
    "    unlabeled_train, \n",
    "    epochs=5, \n",
    "    batch_size=2048\n",
    ")\n",
    "\n",
    "# Entrenar modelo contrastivo con datos filtrados\n",
    "contrastive_filtered = ContrastiveModel(\n",
    "    filtered_unlabeled_train[0].shape, \n",
    "    learning_rate=0.05, \n",
    "    lambda_param=0.9,\n",
    "    l2_lambda=0.001\n",
    ")\n",
    "contrastive_filtered.train(\n",
    "    filtered_unlabeled_train, \n",
    "    epochs=5, \n",
    "    batch_size=2048\n",
    ")\n",
    "\n",
    "# Extraer caracter√≠sticas para clasificaci√≥n\n",
    "train_features_full = contrastive_full.get_features(x_train)\n",
    "val_features_full = contrastive_full.get_features(x_val)\n",
    "test_features_full = contrastive_full.get_features(x_test)\n",
    "\n",
    "train_features_filtered = contrastive_filtered.get_features(x_train)\n",
    "val_features_filtered = contrastive_filtered.get_features(x_val)\n",
    "test_features_filtered = contrastive_filtered.get_features(x_test)\n",
    "\n",
    "# Entrenar clasificadores con estas caracter√≠sticas\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Clasificador para caracter√≠sticas del modelo contrastivo completo\n",
    "classifier_contrastive_full = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(train_features_full.shape[1],)),\n",
    "    Dropout(0.2),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "classifier_contrastive_full.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history_clf_full = classifier_contrastive_full.fit(\n",
    "    train_features_full, one_hot_train,\n",
    "    validation_data=(val_features_full, one_hot_val),\n",
    "    epochs=50,\n",
    "    batch_size=256,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Clasificador para caracter√≠sticas del modelo contrastivo filtrado\n",
    "classifier_contrastive_filtered = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(train_features_filtered.shape[1],)),\n",
    "    Dropout(0.2),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "classifier_contrastive_filtered.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history_clf_filtered = classifier_contrastive_filtered.fit(\n",
    "    train_features_filtered, one_hot_train,\n",
    "    validation_data=(val_features_filtered, one_hot_val),\n",
    "    epochs=50,\n",
    "    batch_size=256,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluar modelos\n",
    "test_loss_full, test_acc_full = classifier_contrastive_full.evaluate(test_features_full, one_hot_test)\n",
    "test_loss_filtered, test_acc_filtered = classifier_contrastive_filtered.evaluate(test_features_filtered, one_hot_test)\n",
    "\n",
    "print(f\"Accuracy del clasificador contrastivo completo: {test_acc_full}\")\n",
    "print(f\"Accuracy del clasificador contrastivo filtrado: {test_acc_filtered}\")\n",
    "\n",
    "# Visualizar matrices de similitud para ambos modelos\n",
    "n_samples = 100\n",
    "test_samples = x_test[:n_samples].reshape(n_samples, 32, 32, 3)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(18, 8))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "contrastive_full.plot_similarity_matrix(test_samples, n_samples=n_samples)\n",
    "plt.title(\"Matriz de similitud - Modelo contrastivo con datos completos\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "contrastive_filtered.plot_similarity_matrix(test_samples, n_samples=n_samples)\n",
    "plt.title(\"Matriz de similitud - Modelo contrastivo con datos filtrados\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "maai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
