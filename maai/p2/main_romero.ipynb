{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CARGA DE DATOS\n",
    "\n",
    "__TODO__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from Utils import DatasetProcess, reconstruction_plot\n",
    "from AutoEncoder import TwoStepAutoEncoder, TwoStepClassifier, TwoStepTraining, OneStepAutoencoder, OneStepTraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabeled_train, x_train, y_train, x_test, y_test, one_hot_train, one_hot_test = DatasetProcess.alt()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EJERCICIO 1\n",
    "\n",
    "Entrena un modelo, creado sobre TensorFlow, haciendo uso √∫nicamente de las instancias etiquetadas de entrenamiento. Dicho modelo debe de tener al menos cuatro capas densas y/o convolucionales.\n",
    "\n",
    "Responde a las siguientes preguntas:\n",
    "\n",
    "1. ¬øQu√© red has escogido? ¬øPor qu√©? ¬øC√≥mo la has entrenado?\n",
    "2. ¬øCu√°l es el rendimiento del modelo en entrenamiento? ¬øY en prueba?\n",
    "3. ¬øQu√© conclusiones sacas de los resultados detallados en el punto anterior?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EJERCICIO 2\n",
    "\n",
    "Entrena el mismo modelo, incorporando las instancias no etiquetadas de entrenamiento mediante la t√©cnica de auto-aprendizaje. Opcionalmente, se ponderar√° cada instancia de entrada en funci√≥n de su calidad (o certeza).\n",
    "\n",
    "Responde a las siguientes preguntas:\n",
    "1. ¬øQu√© par√°metros has definido para el entrenamiento?\n",
    "2. ¬øCu√°l es el rendimiento del modelo en entrenamiento? ¬øY en prueba?\n",
    "3. ¬øSe mejoran los resultados obtenidos en el Ejercicio 1?\n",
    "4. ¬øQu√© conclusiones sacas de los resultados detallados en los puntos anteriores?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EJERCICIO 3\n",
    "\n",
    "Entrena un modelo de aprendizaje semisupervisado de tipo autoencoder en dos pasos (primero el autoencoder, despu√©s el clasificador). La arquitectura del encoder debe ser exactamente la misma que la definida en los Ejercicios 1 y 2, a excepci√≥n del √∫ltimo bloque de capas.\n",
    "\n",
    "Responde a las siguientes preguntas:\n",
    "1. ¬øCu√°l es la arquitectura del modelo? ¬øY sus hiperpar√°metros?\n",
    "2. ¬øCu√°l es el rendimiento del modelo en entrenamiento? ¬øY en prueba?\n",
    "3. ¬øSe mejoran los resultados obtenidos en los Ejercicios 1 y 2?\n",
    "4. ¬øQu√© conclusiones sacas de los resultados detallados en los puntos anteriores?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pepe/carrera/3/2/ma2/ma2Python12/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2025-04-01 02:16:43.521095: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1\n",
      "2025-04-01 02:16:43.521123: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 8.00 GB\n",
      "2025-04-01 02:16:43.521127: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 2.67 GB\n",
      "2025-04-01 02:16:43.521142: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-04-01 02:16:43.521152: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "autoencoder = TwoStepAutoEncoder(input_shape=unlabeled_train[0].shape,\n",
    "                                learning_rate=0.0015)\n",
    "classifier = TwoStepClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-01 02:16:52.008092: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m196/196\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 733ms/step - loss: 0.0231\n",
      "Epoch 2/15\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 738ms/step - loss: 0.0092\n",
      "Epoch 3/15\n",
      "\u001b[1m 30/196\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[1m2:05\u001b[0m 755ms/step - loss: 0.0074"
     ]
    }
   ],
   "source": [
    "TwoStepTraining(autoencoder=autoencoder, \n",
    "                classifier=classifier, \n",
    "                x_train=x_train, \n",
    "                y_train=one_hot_train, \n",
    "                unlabeled_train=unlabeled_train, \n",
    "                batch_size_autoencoder=256,\n",
    "                epochs_autoencoder=15,\n",
    "                batch_size_classifier=4096,\n",
    "                epochs_classifier=405)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruction_plot(autoencoder, x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EJERCICIO 4\n",
    "\n",
    "Entrena un modelo de aprendizaje semisupervisado de tipo autoencoder en un paso (autoencoder y clasificador al mismo tiempo). La arquitectura del autoencoder ser√° la misma que la definida en el Ejercicio 3, y la combinaci√≥n de encoder y clasificador ser√° igual a la arquitectura definida en el\n",
    "Ejercicio 1.\n",
    "\n",
    "Responde a las siguientes preguntas:\n",
    "1. ¬øCu√°l es la arquitectura del modelo? ¬øY sus hiperpar√°metros?\n",
    "2. ¬øCu√°l es el rendimiento del modelo en entrenamiento? ¬øY en prueba?\n",
    "3. ¬øSe mejoran los resultados obtenidos en los ejercicios anteriores?\n",
    "4. ¬øQu√© conclusiones sacas de los resultados detallados en los puntos anteriores?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true,
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-01 00:45:37.892338: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1\n",
      "2025-04-01 00:45:37.892829: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 8.00 GB\n",
      "2025-04-01 00:45:37.892847: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 2.67 GB\n",
      "2025-04-01 00:45:37.892879: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-04-01 00:45:37.892910: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "one_step_autoencoder = OneStepAutoencoder(input_shape=unlabeled_train[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Dimensions must be equal, but are 3 and 32 for '{{node compile_loss/mse/sub}} = Sub[T=DT_FLOAT](data_1, functional_2_1/autoencoder_1/Sigmoid)' with input shapes: [?,32,32,3], [?,32,32,32].",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m h = \u001b[43mOneStepTraining\u001b[49m\u001b[43m(\u001b[49m\u001b[43mone_step_autoencoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mone_hot_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munlabeled_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repositorios/3year2sem/maai/p2/AutoEncoder.py:255\u001b[39m, in \u001b[36mOneStepTraining\u001b[39m\u001b[34m(model, x_train, y_train, unlabeled_data, batch_size, epochs)\u001b[39m\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mOneStepTraining\u001b[39m(model, x_train, y_train, unlabeled_data, batch_size=\u001b[32m60_000\u001b[39m, epochs = \u001b[32m1000\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m255\u001b[39m     h = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munlabeled_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    256\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m h\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repositorios/3year2sem/maai/p2/AutoEncoder.py:216\u001b[39m, in \u001b[36mOneStepAutoencoder.fit\u001b[39m\u001b[34m(self, X, y, unlabeled_train, batch_size, epochs)\u001b[39m\n\u001b[32m    213\u001b[39m weight_autoencoder = np.ones(\u001b[38;5;28mlen\u001b[39m(all_x))\n\u001b[32m    214\u001b[39m weight_classifier = np.array([\u001b[32m1\u001b[39m]*\u001b[38;5;28mlen\u001b[39m(X) + [\u001b[32m0\u001b[39m]*\u001b[38;5;28mlen\u001b[39m(unlabeled_train))\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m h = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    217\u001b[39m \u001b[43m               \u001b[49m\u001b[43m[\u001b[49m\u001b[43mall_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_y\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m               \u001b[49m\u001b[38;5;66;43;03m#all_y,\u001b[39;49;00m\n\u001b[32m    219\u001b[39m \u001b[43m               \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mweight_autoencoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight_classifier\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    220\u001b[39m \u001b[43m               \u001b[49m\u001b[38;5;66;43;03m#sample_weight=sample_weight,\u001b[39;49;00m\n\u001b[32m    221\u001b[39m \u001b[43m               \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    222\u001b[39m \u001b[43m               \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    223\u001b[39m \u001b[43m               \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    224\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m h\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/carrera/3/2/ma2/ma2Python12/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/carrera/3/2/ma2/ma2Python12/lib/python3.12/site-packages/keras/src/losses/losses.py:1679\u001b[39m, in \u001b[36mmean_squared_error\u001b[39m\u001b[34m(y_true, y_pred)\u001b[39m\n\u001b[32m   1677\u001b[39m y_true = ops.convert_to_tensor(y_true, dtype=y_pred.dtype)\n\u001b[32m   1678\u001b[39m y_true, y_pred = squeeze_or_expand_to_same_rank(y_true, y_pred)\n\u001b[32m-> \u001b[39m\u001b[32m1679\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m ops.mean(ops.square(\u001b[43my_true\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m), axis=-\u001b[32m1\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: Dimensions must be equal, but are 3 and 32 for '{{node compile_loss/mse/sub}} = Sub[T=DT_FLOAT](data_1, functional_2_1/autoencoder_1/Sigmoid)' with input shapes: [?,32,32,3], [?,32,32,32]."
     ]
    }
   ],
   "source": [
    "h = OneStepTraining(one_step_autoencoder, x_train, one_hot_train, unlabeled_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EJERCICIO 5\n",
    "\n",
    "Repite el mismo entrenamiento de los Ejercicios 1-4, pero eliminando las instancias no etiquetadas\n",
    "m√°s at√≠picas con respecto a los datos etiquetados. Se cumplir√°n los siguientes puntos:\n",
    "- La arquitectura de la red de clasificaci√≥n en una clase ser√° la misma a la utilizada en el\n",
    "clasificador del Ejercicio 1, a excepci√≥n de la capa de salida.\n",
    "- Utiliza la t√©cnica explicada en el Notebook 5, usando un valor de ùë£ = 0,9.\n",
    "\n",
    "Responde a la siguiente pregunta:\n",
    "1. ¬øSe mejoran los resultados con respecto a los anteriores ejercicios? ¬øQu√© conclusiones sacas de estos resultados?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "unlabeled_train[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EJERCICIO 6\n",
    "\n",
    "Repite los Ejercicios 3-5 cambiando el autencoder por la t√©cnica definida en el apartado ‚ÄúHay vida m√°s all√° del autoencoder‚Äù del Notebook 4. Contesta a las preguntas de dichos ejercicios. Se cumplir√°n los siguientes puntos:\n",
    "\n",
    "1. La arquitectura de la red ser√° igual a la parte encoder del autencoder definido en los\n",
    "ejercicios anteriores.\n",
    "2. El modelo debe entrenar correctamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ma2Python12",
   "language": "python",
   "name": "ma2python12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
