{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "57knM8jrYZ2t"
   },
   "source": [
    "# Notebook 4: Modelos generativos\n",
    "\n",
    "## Pre-requisitos\n",
    "\n",
    "### Instalar paquetes\n",
    "\n",
    "Si la práctica requiere algún paquete de Python, habrá que incluir una celda en la que se instalen. Si usamos un paquete que se ha utilizado en prácticas anteriores, podríamos dar por supuesto que está instalado pero no cuesta nada satisfacer todas las dependencias en la propia práctica para reducir las dependencias entre ellas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "LkaimNJfYZ2w"
   },
   "outputs": [],
   "source": [
    "# Ejemplo de instalación de tensorflow 2.0\n",
    "#%tensorflow_version 2.x\n",
    "# !pip3 install tensorflow  # NECESARIO SOLO SI SE EJECUTA EN LOCAL\n",
    "import tensorflow as tf\n",
    "\n",
    "# Hacemos los imports que sean necesarios\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SOch-CnwQttl"
   },
   "source": [
    "# Modelos generativos sobre MNIST\n",
    "\n",
    "Lo primero que tenemos que hacer es cargar el dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "1gXdWDBIEKel"
   },
   "outputs": [],
   "source": [
    "labeled_data = 0.01 # Vamos a usar el etiquetado de sólo el 1% de los datos\n",
    "np.random.seed(42)\n",
    "\n",
    "(x_train, y_train), (x_test, y_test), = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "indexes = np.arange(len(x_train))\n",
    "np.random.shuffle(indexes)\n",
    "ntrain_data = int(labeled_data*len(x_train))\n",
    "unlabeled_train = x_train[indexes[ntrain_data:]]\n",
    "x_train = x_train[indexes[:ntrain_data]] \n",
    "y_train = y_train[indexes[:ntrain_data]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "8XsZIqV8TmSc"
   },
   "outputs": [],
   "source": [
    "# TODO: Haz el preprocesado que necesites aquí (si lo necesitas)\n",
    "\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1]*x_train.shape[2])) \n",
    "x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1]*x_test.shape[2])) /255\n",
    "unlabeled_train = np.reshape(unlabeled_train, (unlabeled_train.shape[0], unlabeled_train.shape[1]*unlabeled_train.shape[2])) /255\n",
    "\n",
    "one_hot_train = np.zeros((y_train.size, len(set(y_train))), dtype=int)\n",
    "one_hot_train[np.arange(y_train.size), y_train ] = 1\n",
    "\n",
    "one_hot_test = np.zeros((y_test.size, len(set(y_test))), dtype=int)\n",
    "one_hot_test[np.arange(y_test.size), y_test ] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wkaCDOGapMyl"
   },
   "source": [
    "## Modelo generativo\n",
    "\n",
    "Vamos a crear nuestro propio modelo generativo. En clase de teoría has visto muchas versiones distintas:\n",
    "\n",
    "1. Mezcla de distribuciones de Gaussianas (GMM)\n",
    "1. Mezcla de distribuciones multinomiales (Naive Bayes)\n",
    "1. Modelos de Markov ocultos (HMM)\n",
    "\n",
    "Tal y como se os apunta en teoría, los modelos generativos abordan un problema más general, y aprenden realmente cómo se estructuran y distribuyen los datos de entrada. \n",
    "\n",
    "En nuestro caso, vamos a distribuír los datos de entrada mediante el uso de **Autoencoders**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pxf_lSC1HsYh"
   },
   "source": [
    "# Autoencoders\n",
    "\n",
    "El autoencoder es un tipo de red que se utiliza para aprender codificaciones eficientes de datos sin etiquetar (lo que se conoce como aprendizaje no supervisado). Es una red que tiene el mismo tamaño en la entrada como en la salida, puesto que el objetivo de la red es reconstruír la entrada con la menor pérdida posible.\n",
    "\n",
    "Si lo que hacemos es reconstruír la entrada, ¿qué sentido tiene el usar la red? Habitualmente, **la red consta, a su mitad, de una capa con menos elementos que los datos de entrada**. Por tanto, al reconstruír los datos de la entrada a la salida, en esa capa tendremos una versión *comprimida* de la entrada, que contendrá la mayor parte de su información.\n",
    "\n",
    "Por tanto, podemos dividir un autoencoder en 3 secciones diferentes, tal y como se ve en la siguiente figura:\n",
    "\n",
    "![autoencoder](https://drive.google.com/uc?export=view&id=1yxkKZV0J0YplQAGPGJxQ2Z80Ad6L94eu)\n",
    "\n",
    "\n",
    "1. **Encoder:** es la parte inicial de la red, encargada de comprimir los datos de la entrada.\n",
    "1. **Code:** es la salida del encoder, contiene la versión *comprimida* de los datos de entrada.\n",
    "1. **Decoder:** se encarga de, partiendo de la salida del *Encoder*, reconstruír la red."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7-mBCsDXJX3M"
   },
   "source": [
    "## Crea tu propio Autoencoder\n",
    "\n",
    "El diseño del autoencoder es libre (capas densas, convolucionales, ...), puedes crearlo como quieras. **El único requisito es que tiene que mantener los nombres (y parámetros) de las funciones descritas abajo.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "M95R6t1pJW3f"
   },
   "outputs": [],
   "source": [
    "# TODO: crea tu propio autoencoder\n",
    "\n",
    "\n",
    "class MiAutoencoder:\n",
    "\n",
    "    def __init__(self, input_shape):\n",
    "        \n",
    "        self.input_shape = input_shape\n",
    "        \n",
    "        self.encoder = models.Sequential()\n",
    "        self.encoder.add(layers.InputLayer(shape=self.input_shape))\n",
    "        self.encoder.add(layers.Dense(512, activation='relu'))\n",
    "        self.encoder.add(layers.Dense(128, activation='relu'))\n",
    "        self.encoder.add(layers.Dense(64, activation='relu'))\n",
    "        self.encoder.add(layers.Dense(32, activation='relu'))\n",
    "        self.encoder.add(layers.Dense(32, activation='relu'))  # Latent space\n",
    "\n",
    "        self.decoder = models.Sequential()\n",
    "        self.decoder.add(layers.InputLayer(shape=(32,)))\n",
    "        self.decoder.add(layers.Dense(32, activation='relu'))\n",
    "        self.decoder.add(layers.Dense(64, activation='relu'))\n",
    "        self.decoder.add(layers.Dense(128, activation='relu'))\n",
    "        self.decoder.add(layers.Dense(512, activation='relu'))\n",
    "        self.decoder.add(layers.Dense(self.input_shape[0], activation='sigmoid'))  # Output should match input\n",
    "\n",
    "        self.autoencoder = models.Sequential([self.encoder, self.decoder])\n",
    "\n",
    "        self.optimicer = tf.keras.optimizers.AdamW(\n",
    "            learning_rate=0.001,\n",
    "            clipnorm=1,\n",
    "        )\n",
    "\n",
    "\n",
    "        self.autoencoder.compile(optimizer=self.optimicer, loss='mse')\n",
    "    \n",
    "    def fit(self, X, y=None, sample_weight=None, batch_size=60_000, epochs=100):\n",
    "        # TODO: entrena el modelo. Escoge el tamaño de batch y el número de epochs que quieras\n",
    "        \n",
    "        self.autoencoder.fit(X, X, \n",
    "                             batch_size=batch_size, \n",
    "                             epochs=epochs, \n",
    "                             sample_weight=sample_weight)\n",
    "\n",
    "    def get_encoded_data(self, X):\n",
    "        # TODO: devuelve la salida del encoder (code)\n",
    "        return self.encoder.predict(X)\n",
    "\n",
    "\n",
    "    def __call__(self, X):\n",
    "        return self.autoencoder.predict(X)\n",
    "        \n",
    "    def __del__(self):\n",
    "        # elimina todos los modelos que hayas creado\n",
    "        tf.keras.backend.clear_session() # Necesario para liberar la memoria en GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6tt0L2yCMdmb"
   },
   "source": [
    "## Crea tu propio Clasificador\n",
    "\n",
    "El diseño del clasificador es libre, pero recuerda que tiene que ser simple (máximo dos capas). **El único requisito es que tiene que mantener los nombres (y parámetros) de las funciones descritas abajo.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "1mh0yzbKMuhk"
   },
   "outputs": [],
   "source": [
    "# TODO: crea tu propio clasificador\n",
    "\n",
    "class MiClasificador:\n",
    "\n",
    "    def __init__(self):\n",
    "        # TODO : define el modelo y compílalo\n",
    "        \n",
    "        self.input_shape = (32,)\n",
    "        \n",
    "        self.classifier = models.Sequential()\n",
    "        self.classifier.add(layers.InputLayer(shape=self.input_shape))\n",
    "        self.classifier.add(layers.Dense(32, activation='relu'))\n",
    "        self.classifier.add(layers.Dense(10, activation='sigmoid'))\n",
    "\n",
    "        self.optimicer = tf.keras.optimizers.AdamW(\n",
    "            learning_rate=0.001,\n",
    "            clipnorm=1,\n",
    "        )\n",
    "\n",
    "        self.classifier.compile(optimizer=self.optimicer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    def fit(self, X, y, sample_weight=None, batch_size=60_000, epochs=350):\n",
    "        # TODO: entrena el modelo. Escoge el tamaño de batch y el número de epochs que quieras\n",
    "        self.classifier.fit(X, y, \n",
    "                             batch_size=batch_size, \n",
    "                             epochs=epochs, \n",
    "                             sample_weight=sample_weight)\n",
    "\n",
    "    def predict(self, X):\n",
    "        # TODO: devuelve la clase ganadora\n",
    "\n",
    "        return np.argmax(self.predict_proba(X)) + 1\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \n",
    "        return self.classifier.predict(X)\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        \n",
    "        return self.classifier.evaluate(X, y)[1]\n",
    "\n",
    "    def __del__(self):\n",
    "        # elimina todos los modelos que hayas creado\n",
    "        tf.keras.backend.clear_session() # Necesario para liberar la memoria en GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w1-v4D6VH3Qq"
   },
   "source": [
    "### Entrenamiendo del modelo semisupervisado\n",
    "\n",
    "El entrenamiento del sistema semisupervisado se realiza en dos pasos.\n",
    "\n",
    "1. Se entrena el autoencoder con todos los datos (etiquetados y sin etiquetar).\n",
    "1. Se entrena un clasificador simple (una o dos capas), teniendo como entrada la salida del encoder (**code**) de los datos etiquetados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vqT2nuCspfE_"
   },
   "source": [
    "<font color='red'>NOTA:</font> para entrenar (y predecir) vamos a utilizar los nombres de las funciones que hemos definido en el autoencoder y en el clasificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "5xjcLa21EKen"
   },
   "outputs": [],
   "source": [
    "# TODO: implementa el algoritmo semisupervised_training.\n",
    "\n",
    "def semisupervised_training(autoencoder, classifier, x_train, y_train, unlabeled_data):\n",
    "\n",
    "    all_x = np.vstack((x_train, unlabeled_train))\n",
    "    autoencoder.fit(all_x)\n",
    "    x_coded = autoencoder.get_encoded_data(x_train)\n",
    "    classifier.fit(x_coded, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qjFXe6EiYfRg"
   },
   "source": [
    "### Entrenamos nuestro modelo\n",
    "\n",
    "Usa lo hecho anteriormente para entrenar tu clasificador de una manera semi-supervisada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "lNC1s2Wmqx4x"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-31 23:36:17.458837: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1\n",
      "2025-03-31 23:36:17.458919: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 8.00 GB\n",
      "2025-03-31 23:36:17.458948: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 2.67 GB\n",
      "2025-03-31 23:36:17.458987: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-03-31 23:36:17.459016: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "# Crea tu autoencoder y tu clasificador\n",
    "\n",
    "autoencoder = MiAutoencoder(input_shape=x_train[0].shape)\n",
    "classifier = MiClasificador()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "hN2zd3DEYnKI",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-31 23:36:21.935447: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - loss: 71.5394\n",
      "Epoch 2/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 796ms/step - loss: 71.4639\n",
      "Epoch 3/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500ms/step - loss: 71.3724\n",
      "Epoch 4/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445ms/step - loss: 71.2990\n",
      "Epoch 5/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 443ms/step - loss: 71.2545\n",
      "Epoch 6/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 430ms/step - loss: 71.2296\n",
      "Epoch 7/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425ms/step - loss: 71.2136\n",
      "Epoch 8/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 438ms/step - loss: 71.2041\n",
      "Epoch 9/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473ms/step - loss: 71.1965\n",
      "Epoch 10/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 545ms/step - loss: 71.1943\n",
      "Epoch 11/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480ms/step - loss: 71.1877\n",
      "Epoch 12/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 442ms/step - loss: 71.1811\n",
      "Epoch 13/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 437ms/step - loss: 71.1793\n",
      "Epoch 14/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 435ms/step - loss: 71.1788\n",
      "Epoch 15/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491ms/step - loss: 71.1721\n",
      "Epoch 16/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 504ms/step - loss: 71.1700\n",
      "Epoch 17/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 519ms/step - loss: 71.1677\n",
      "Epoch 18/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 518ms/step - loss: 71.1656\n",
      "Epoch 19/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487ms/step - loss: 71.1636\n",
      "Epoch 20/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449ms/step - loss: 71.1611\n",
      "Epoch 21/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451ms/step - loss: 71.1581\n",
      "Epoch 22/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 426ms/step - loss: 71.1562\n",
      "Epoch 23/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 423ms/step - loss: 71.1537\n",
      "Epoch 24/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 443ms/step - loss: 71.1512\n",
      "Epoch 25/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486ms/step - loss: 71.1479\n",
      "Epoch 26/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 516ms/step - loss: 71.1449\n",
      "Epoch 27/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475ms/step - loss: 71.1440\n",
      "Epoch 28/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 505ms/step - loss: 71.1438\n",
      "Epoch 29/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 512ms/step - loss: 71.1426\n",
      "Epoch 30/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456ms/step - loss: 71.1388\n",
      "Epoch 31/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 440ms/step - loss: 71.1377\n",
      "Epoch 32/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 427ms/step - loss: 71.1359\n",
      "Epoch 33/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 422ms/step - loss: 71.1338\n",
      "Epoch 34/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 443ms/step - loss: 71.1320\n",
      "Epoch 35/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446ms/step - loss: 71.1302\n",
      "Epoch 36/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420ms/step - loss: 71.1284\n",
      "Epoch 37/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 423ms/step - loss: 71.1264\n",
      "Epoch 38/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 428ms/step - loss: 71.1237\n",
      "Epoch 39/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 432ms/step - loss: 71.1221\n",
      "Epoch 40/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462ms/step - loss: 71.1233\n",
      "Epoch 41/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474ms/step - loss: 71.1197\n",
      "Epoch 42/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460ms/step - loss: 71.1189\n",
      "Epoch 43/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449ms/step - loss: 71.1186\n",
      "Epoch 44/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 430ms/step - loss: 71.1176\n",
      "Epoch 45/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 444ms/step - loss: 71.1164\n",
      "Epoch 46/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 427ms/step - loss: 71.1146\n",
      "Epoch 47/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462ms/step - loss: 71.1127\n",
      "Epoch 48/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 541ms/step - loss: 71.1108\n",
      "Epoch 49/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 517ms/step - loss: 71.1091\n",
      "Epoch 50/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 437ms/step - loss: 71.1086\n",
      "Epoch 51/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474ms/step - loss: 71.1074\n",
      "Epoch 52/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477ms/step - loss: 71.1063\n",
      "Epoch 53/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496ms/step - loss: 71.1047\n",
      "Epoch 54/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466ms/step - loss: 71.1042\n",
      "Epoch 55/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 428ms/step - loss: 71.1038\n",
      "Epoch 56/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 436ms/step - loss: 71.1022\n",
      "Epoch 57/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446ms/step - loss: 71.1014\n",
      "Epoch 58/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452ms/step - loss: 71.0993\n",
      "Epoch 59/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425ms/step - loss: 71.0984\n",
      "Epoch 60/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 432ms/step - loss: 71.0976\n",
      "Epoch 61/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 436ms/step - loss: 71.0974\n",
      "Epoch 62/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 444ms/step - loss: 71.0952\n",
      "Epoch 63/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479ms/step - loss: 71.0947\n",
      "Epoch 64/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 500ms/step - loss: 71.0925\n",
      "Epoch 65/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472ms/step - loss: 71.0918\n",
      "Epoch 66/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 432ms/step - loss: 71.0915\n",
      "Epoch 67/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 435ms/step - loss: 71.0911\n",
      "Epoch 68/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 429ms/step - loss: 71.0890\n",
      "Epoch 69/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 429ms/step - loss: 71.0875\n",
      "Epoch 70/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 442ms/step - loss: 71.0872\n",
      "Epoch 71/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 424ms/step - loss: 71.0866\n",
      "Epoch 72/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425ms/step - loss: 71.0853\n",
      "Epoch 73/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 431ms/step - loss: 71.0870\n",
      "Epoch 74/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 432ms/step - loss: 71.0825\n",
      "Epoch 75/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 426ms/step - loss: 71.0806\n",
      "Epoch 76/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454ms/step - loss: 71.0823\n",
      "Epoch 77/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 555ms/step - loss: 71.0823\n",
      "Epoch 78/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 647ms/step - loss: 71.0784\n",
      "Epoch 79/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 512ms/step - loss: 71.0980\n",
      "Epoch 80/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459ms/step - loss: 71.1099\n",
      "Epoch 81/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - loss: 71.1481\n",
      "Epoch 82/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 468ms/step - loss: 71.1524\n",
      "Epoch 83/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 529ms/step - loss: 71.1339\n",
      "Epoch 84/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 521ms/step - loss: 71.1024\n",
      "Epoch 85/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455ms/step - loss: 71.0957\n",
      "Epoch 86/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 521ms/step - loss: 71.1196\n",
      "Epoch 87/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473ms/step - loss: 71.0819\n",
      "Epoch 88/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 432ms/step - loss: 71.0751\n",
      "Epoch 89/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 424ms/step - loss: 71.0780\n",
      "Epoch 90/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 429ms/step - loss: 71.0807\n",
      "Epoch 91/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 426ms/step - loss: 71.0805\n",
      "Epoch 92/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 429ms/step - loss: 71.0779\n",
      "Epoch 93/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463ms/step - loss: 71.0753\n",
      "Epoch 94/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 434ms/step - loss: 71.0738\n",
      "Epoch 95/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457ms/step - loss: 71.0722\n",
      "Epoch 96/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 507ms/step - loss: 71.0698\n",
      "Epoch 97/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 535ms/step - loss: 71.0667\n",
      "Epoch 98/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 587ms/step - loss: 71.0644\n",
      "Epoch 99/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 631ms/step - loss: 71.0630\n",
      "Epoch 100/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490ms/step - loss: 71.0617\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step  \n",
      "Epoch 1/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.0900 - loss: 1397.1637\n",
      "Epoch 2/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.0867 - loss: 1312.1133\n",
      "Epoch 3/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.0867 - loss: 1239.3304\n",
      "Epoch 4/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.0833 - loss: 1178.6244\n",
      "Epoch 5/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.0783 - loss: 1121.1644\n",
      "Epoch 6/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.0783 - loss: 1063.4427\n",
      "Epoch 7/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.0700 - loss: 1006.2294\n",
      "Epoch 8/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.0633 - loss: 953.2740\n",
      "Epoch 9/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.0683 - loss: 910.8041\n",
      "Epoch 10/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.0650 - loss: 882.3644\n",
      "Epoch 11/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.0650 - loss: 860.1843\n",
      "Epoch 12/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.0650 - loss: 833.6529\n",
      "Epoch 13/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.0650 - loss: 802.7247\n",
      "Epoch 14/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.0800 - loss: 768.9641\n",
      "Epoch 15/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.0783 - loss: 735.1561\n",
      "Epoch 16/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.0917 - loss: 704.6005\n",
      "Epoch 17/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.0983 - loss: 678.5394\n",
      "Epoch 18/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.1000 - loss: 655.8394\n",
      "Epoch 19/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.1017 - loss: 635.6038\n",
      "Epoch 20/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.1067 - loss: 616.7831\n",
      "Epoch 21/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.1050 - loss: 598.8525\n",
      "Epoch 22/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.1050 - loss: 581.7367\n",
      "Epoch 23/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.1050 - loss: 565.5253\n",
      "Epoch 24/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.1050 - loss: 549.8178\n",
      "Epoch 25/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.1067 - loss: 534.0887\n",
      "Epoch 26/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.1067 - loss: 518.3021\n",
      "Epoch 27/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.1067 - loss: 501.9050\n",
      "Epoch 28/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.1067 - loss: 485.0006\n",
      "Epoch 29/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.1067 - loss: 467.9550\n",
      "Epoch 30/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.1067 - loss: 450.8593\n",
      "Epoch 31/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.1067 - loss: 434.6382\n",
      "Epoch 32/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.1067 - loss: 420.0388\n",
      "Epoch 33/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.1067 - loss: 407.3231\n",
      "Epoch 34/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.1033 - loss: 395.3228\n",
      "Epoch 35/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.1050 - loss: 383.9630\n",
      "Epoch 36/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.1017 - loss: 373.9183\n",
      "Epoch 37/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.1017 - loss: 365.1388\n",
      "Epoch 38/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.1017 - loss: 357.1755\n",
      "Epoch 39/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.1050 - loss: 348.9270\n",
      "Epoch 40/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.1050 - loss: 340.0301\n",
      "Epoch 41/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.1100 - loss: 330.3871\n",
      "Epoch 42/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.1117 - loss: 320.2466\n",
      "Epoch 43/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.1117 - loss: 310.1669\n",
      "Epoch 44/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.1117 - loss: 300.1450\n",
      "Epoch 45/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.1133 - loss: 290.2730\n",
      "Epoch 46/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.1100 - loss: 280.9395\n",
      "Epoch 47/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.1100 - loss: 271.8476\n",
      "Epoch 48/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.1100 - loss: 263.2164\n",
      "Epoch 49/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.1100 - loss: 254.2491\n",
      "Epoch 50/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.1100 - loss: 244.6761\n",
      "Epoch 51/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.1133 - loss: 234.8632\n",
      "Epoch 52/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.1133 - loss: 225.2551\n",
      "Epoch 53/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.1133 - loss: 216.4288\n",
      "Epoch 54/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.1133 - loss: 208.2012\n",
      "Epoch 55/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.1150 - loss: 199.9703\n",
      "Epoch 56/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.1183 - loss: 191.5226\n",
      "Epoch 57/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.1183 - loss: 182.9550\n",
      "Epoch 58/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.1200 - loss: 174.4214\n",
      "Epoch 59/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.1200 - loss: 166.1586\n",
      "Epoch 60/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.1417 - loss: 158.1679\n",
      "Epoch 61/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.1483 - loss: 150.1083\n",
      "Epoch 62/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.1583 - loss: 142.1428\n",
      "Epoch 63/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.1750 - loss: 134.5576\n",
      "Epoch 64/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.1967 - loss: 127.7906\n",
      "Epoch 65/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.2133 - loss: 123.3092\n",
      "Epoch 66/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.2150 - loss: 121.7706\n",
      "Epoch 67/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.2167 - loss: 123.5678\n",
      "Epoch 68/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.2150 - loss: 126.4221\n",
      "Epoch 69/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.2150 - loss: 128.1565\n",
      "Epoch 70/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2150 - loss: 127.7648\n",
      "Epoch 71/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2150 - loss: 125.3009\n",
      "Epoch 72/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.2150 - loss: 121.2925\n",
      "Epoch 73/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2183 - loss: 116.6105\n",
      "Epoch 74/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.2167 - loss: 112.2967\n",
      "Epoch 75/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2200 - loss: 108.7276\n",
      "Epoch 76/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2200 - loss: 105.6469\n",
      "Epoch 77/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.2200 - loss: 103.6558\n",
      "Epoch 78/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.2267 - loss: 102.5159\n",
      "Epoch 79/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2217 - loss: 101.7107\n",
      "Epoch 80/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2217 - loss: 100.8819\n",
      "Epoch 81/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2167 - loss: 99.6066\n",
      "Epoch 82/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.2200 - loss: 97.9844\n",
      "Epoch 83/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2217 - loss: 96.1599\n",
      "Epoch 84/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.2250 - loss: 94.2487\n",
      "Epoch 85/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2250 - loss: 92.0945\n",
      "Epoch 86/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.2250 - loss: 90.0061\n",
      "Epoch 87/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2233 - loss: 88.1209\n",
      "Epoch 88/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2233 - loss: 86.7598\n",
      "Epoch 89/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.2233 - loss: 85.3461\n",
      "Epoch 90/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.2233 - loss: 83.8426\n",
      "Epoch 91/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.2233 - loss: 82.2456\n",
      "Epoch 92/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2217 - loss: 80.5239\n",
      "Epoch 93/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.2217 - loss: 78.7241\n",
      "Epoch 94/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2250 - loss: 77.1031\n",
      "Epoch 95/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2233 - loss: 75.5967\n",
      "Epoch 96/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2250 - loss: 74.1812\n",
      "Epoch 97/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.2250 - loss: 72.7884\n",
      "Epoch 98/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2250 - loss: 71.2772\n",
      "Epoch 99/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.2250 - loss: 69.7087\n",
      "Epoch 100/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.2250 - loss: 68.2616\n",
      "Epoch 101/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2250 - loss: 66.8501\n",
      "Epoch 102/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2217 - loss: 65.4966\n",
      "Epoch 103/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2217 - loss: 64.1624\n",
      "Epoch 104/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2233 - loss: 62.8392\n",
      "Epoch 105/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.2233 - loss: 61.4947\n",
      "Epoch 106/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2233 - loss: 60.1399\n",
      "Epoch 107/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2250 - loss: 58.8092\n",
      "Epoch 108/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2233 - loss: 57.5827\n",
      "Epoch 109/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2267 - loss: 56.3071\n",
      "Epoch 110/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2283 - loss: 55.0856\n",
      "Epoch 111/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.2267 - loss: 53.8238\n",
      "Epoch 112/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2300 - loss: 52.6494\n",
      "Epoch 113/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2300 - loss: 51.4790\n",
      "Epoch 114/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2300 - loss: 50.3373\n",
      "Epoch 115/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2300 - loss: 49.2575\n",
      "Epoch 116/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2300 - loss: 48.1960\n",
      "Epoch 117/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.2350 - loss: 47.1449\n",
      "Epoch 118/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2350 - loss: 46.1493\n",
      "Epoch 119/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2333 - loss: 45.1475\n",
      "Epoch 120/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2350 - loss: 44.2187\n",
      "Epoch 121/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2433 - loss: 43.2935\n",
      "Epoch 122/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2450 - loss: 42.3978\n",
      "Epoch 123/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.2467 - loss: 41.5844\n",
      "Epoch 124/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2450 - loss: 40.8245\n",
      "Epoch 125/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2450 - loss: 40.0006\n",
      "Epoch 126/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.2433 - loss: 39.3672\n",
      "Epoch 127/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2467 - loss: 38.5192\n",
      "Epoch 128/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2483 - loss: 37.9087\n",
      "Epoch 129/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2517 - loss: 37.2305\n",
      "Epoch 130/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.2450 - loss: 36.6722\n",
      "Epoch 131/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.2450 - loss: 36.1184\n",
      "Epoch 132/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2450 - loss: 35.4777\n",
      "Epoch 133/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2500 - loss: 35.0148\n",
      "Epoch 134/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.2500 - loss: 34.5866\n",
      "Epoch 135/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.2517 - loss: 33.9731\n",
      "Epoch 136/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.2550 - loss: 33.6356\n",
      "Epoch 137/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.2550 - loss: 33.1713\n",
      "Epoch 138/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2567 - loss: 32.6611\n",
      "Epoch 139/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.2533 - loss: 32.2761\n",
      "Epoch 140/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.2550 - loss: 31.8787\n",
      "Epoch 141/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.2533 - loss: 31.3972\n",
      "Epoch 142/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.2517 - loss: 31.1246\n",
      "Epoch 143/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2517 - loss: 30.7451\n",
      "Epoch 144/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2567 - loss: 30.3848\n",
      "Epoch 145/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.2533 - loss: 30.0485\n",
      "Epoch 146/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2533 - loss: 29.6290\n",
      "Epoch 147/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2533 - loss: 29.4569\n",
      "Epoch 148/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2533 - loss: 29.1332\n",
      "Epoch 149/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.2467 - loss: 28.6565\n",
      "Epoch 150/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2483 - loss: 28.4068\n",
      "Epoch 151/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.2500 - loss: 28.1597\n",
      "Epoch 152/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.2500 - loss: 27.7607\n",
      "Epoch 153/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2433 - loss: 27.4944\n",
      "Epoch 154/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2433 - loss: 27.1453\n",
      "Epoch 155/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2483 - loss: 26.9573\n",
      "Epoch 156/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2467 - loss: 26.6682\n",
      "Epoch 157/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2450 - loss: 26.3853\n",
      "Epoch 158/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2450 - loss: 26.0957\n",
      "Epoch 159/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2450 - loss: 25.8163\n",
      "Epoch 160/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.2433 - loss: 25.5216\n",
      "Epoch 161/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.2433 - loss: 25.3747\n",
      "Epoch 162/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2433 - loss: 25.1192\n",
      "Epoch 163/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2450 - loss: 24.7865\n",
      "Epoch 164/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2450 - loss: 24.5588\n",
      "Epoch 165/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.2467 - loss: 24.3543\n",
      "Epoch 166/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.2450 - loss: 24.0717\n",
      "Epoch 167/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.2467 - loss: 23.9761\n",
      "Epoch 168/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.2467 - loss: 23.7365\n",
      "Epoch 169/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.2467 - loss: 23.4295\n",
      "Epoch 170/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.2500 - loss: 23.2151\n",
      "Epoch 171/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.2467 - loss: 23.0181\n",
      "Epoch 172/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2450 - loss: 22.7622\n",
      "Epoch 173/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2450 - loss: 22.7494\n",
      "Epoch 174/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2450 - loss: 22.5273\n",
      "Epoch 175/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2433 - loss: 22.1816\n",
      "Epoch 176/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.2483 - loss: 22.0003\n",
      "Epoch 177/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2450 - loss: 21.8756\n",
      "Epoch 178/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2433 - loss: 21.6246\n",
      "Epoch 179/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2483 - loss: 21.6421\n",
      "Epoch 180/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.2483 - loss: 21.4663\n",
      "Epoch 181/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.2450 - loss: 21.0903\n",
      "Epoch 182/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.2383 - loss: 20.9720\n",
      "Epoch 183/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2433 - loss: 20.8105\n",
      "Epoch 184/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2433 - loss: 20.6121\n",
      "Epoch 185/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.2383 - loss: 20.5823\n",
      "Epoch 186/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.2383 - loss: 20.3157\n",
      "Epoch 187/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2433 - loss: 20.4168\n",
      "Epoch 188/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.2433 - loss: 20.2776\n",
      "Epoch 189/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2417 - loss: 19.9485\n",
      "Epoch 190/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2400 - loss: 19.8510\n",
      "Epoch 191/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.2367 - loss: 19.7210\n",
      "Epoch 192/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.2383 - loss: 19.5642\n",
      "Epoch 193/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.2417 - loss: 19.4483\n",
      "Epoch 194/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.2433 - loss: 19.2793\n",
      "Epoch 195/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.2417 - loss: 19.2570\n",
      "Epoch 196/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.2383 - loss: 19.0735\n",
      "Epoch 197/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.2417 - loss: 18.9878\n",
      "Epoch 198/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.2417 - loss: 18.8196\n",
      "Epoch 199/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.2433 - loss: 18.7765\n",
      "Epoch 200/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.2417 - loss: 18.5793\n",
      "Epoch 201/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2400 - loss: 18.5459\n",
      "Epoch 202/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.2400 - loss: 18.4379\n",
      "Epoch 203/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.2417 - loss: 18.1947\n",
      "Epoch 204/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2417 - loss: 18.1045\n",
      "Epoch 205/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.2400 - loss: 18.0287\n",
      "Epoch 206/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.2400 - loss: 17.8648\n",
      "Epoch 207/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.2383 - loss: 17.9765\n",
      "Epoch 208/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2400 - loss: 17.8608\n",
      "Epoch 209/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2433 - loss: 17.5162\n",
      "Epoch 210/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.2400 - loss: 17.4078\n",
      "Epoch 211/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.2400 - loss: 17.3675\n",
      "Epoch 212/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2367 - loss: 17.1992\n",
      "Epoch 213/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.2383 - loss: 17.2805\n",
      "Epoch 214/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.2367 - loss: 17.1582\n",
      "Epoch 215/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.2400 - loss: 16.9292\n",
      "Epoch 216/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.2383 - loss: 16.8754\n",
      "Epoch 217/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.2333 - loss: 16.7291\n",
      "Epoch 218/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.2333 - loss: 16.6552\n",
      "Epoch 219/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.2350 - loss: 16.5399\n",
      "Epoch 220/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2350 - loss: 16.4289\n",
      "Epoch 221/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2333 - loss: 16.4261\n",
      "Epoch 222/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2317 - loss: 16.2503\n",
      "Epoch 223/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2267 - loss: 16.3290\n",
      "Epoch 224/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2317 - loss: 16.2637\n",
      "Epoch 225/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.2350 - loss: 16.0120\n",
      "Epoch 226/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.2333 - loss: 15.8955\n",
      "Epoch 227/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.2283 - loss: 15.8825\n",
      "Epoch 228/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.2283 - loss: 15.7975\n",
      "Epoch 229/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.2300 - loss: 15.7159\n",
      "Epoch 230/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.2300 - loss: 15.6060\n",
      "Epoch 231/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.2283 - loss: 15.4917\n",
      "Epoch 232/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2300 - loss: 15.4160\n",
      "Epoch 233/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.2283 - loss: 15.2969\n",
      "Epoch 234/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.2317 - loss: 15.2550\n",
      "Epoch 235/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.2300 - loss: 15.1798\n",
      "Epoch 236/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.2317 - loss: 15.0163\n",
      "Epoch 237/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2250 - loss: 15.1729\n",
      "Epoch 238/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2233 - loss: 15.0179\n",
      "Epoch 239/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2267 - loss: 14.9578\n",
      "Epoch 240/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2283 - loss: 14.8130\n",
      "Epoch 241/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2233 - loss: 14.9528\n",
      "Epoch 242/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2217 - loss: 14.7978\n",
      "Epoch 243/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.2250 - loss: 14.7178\n",
      "Epoch 244/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.2267 - loss: 14.6227\n",
      "Epoch 245/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2250 - loss: 14.5463\n",
      "Epoch 246/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2233 - loss: 14.4410\n",
      "Epoch 247/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2250 - loss: 14.4574\n",
      "Epoch 248/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.2250 - loss: 14.2787\n",
      "Epoch 249/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2250 - loss: 14.4994\n",
      "Epoch 250/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2250 - loss: 14.4748\n",
      "Epoch 251/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2250 - loss: 14.0993\n",
      "Epoch 252/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2267 - loss: 14.0837\n",
      "Epoch 253/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2250 - loss: 14.0990\n",
      "Epoch 254/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.2233 - loss: 13.9797\n",
      "Epoch 255/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.2250 - loss: 14.0142\n",
      "Epoch 256/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.2250 - loss: 13.9158\n",
      "Epoch 257/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.2250 - loss: 13.9286\n",
      "Epoch 258/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.2233 - loss: 13.8551\n",
      "Epoch 259/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2233 - loss: 13.7212\n",
      "Epoch 260/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.2233 - loss: 13.6621\n",
      "Epoch 261/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.2233 - loss: 13.6973\n",
      "Epoch 262/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.2233 - loss: 13.5897\n",
      "Epoch 263/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.2233 - loss: 13.5647\n",
      "Epoch 264/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.2233 - loss: 13.4779\n",
      "Epoch 265/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.2233 - loss: 13.4878\n",
      "Epoch 266/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.2233 - loss: 13.3989\n",
      "Epoch 267/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.2250 - loss: 13.3621\n",
      "Epoch 268/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.2250 - loss: 13.2906\n",
      "Epoch 269/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.2233 - loss: 13.2754\n",
      "Epoch 270/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.2233 - loss: 13.1893\n",
      "Epoch 271/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.2250 - loss: 13.1904\n",
      "Epoch 272/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.2233 - loss: 13.1107\n",
      "Epoch 273/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.2233 - loss: 13.1124\n",
      "Epoch 274/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.2233 - loss: 13.0343\n",
      "Epoch 275/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.2233 - loss: 12.9671\n",
      "Epoch 276/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2233 - loss: 12.8793\n",
      "Epoch 277/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.2217 - loss: 13.0044\n",
      "Epoch 278/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2217 - loss: 12.9071\n",
      "Epoch 279/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2233 - loss: 12.7907\n",
      "Epoch 280/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2200 - loss: 12.7224\n",
      "Epoch 281/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2200 - loss: 12.7725\n",
      "Epoch 282/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.2217 - loss: 12.6562\n",
      "Epoch 283/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.2233 - loss: 12.7213\n",
      "Epoch 284/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.2200 - loss: 12.6471\n",
      "Epoch 285/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2183 - loss: 12.5263\n",
      "Epoch 286/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2200 - loss: 12.4444\n",
      "Epoch 287/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2217 - loss: 12.5132\n",
      "Epoch 288/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2183 - loss: 12.3946\n",
      "Epoch 289/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2167 - loss: 12.5066\n",
      "Epoch 290/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2167 - loss: 12.4388\n",
      "Epoch 291/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.2200 - loss: 12.2556\n",
      "Epoch 292/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.2183 - loss: 12.1830\n",
      "Epoch 293/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.2167 - loss: 12.3560\n",
      "Epoch 294/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2167 - loss: 12.2076\n",
      "Epoch 295/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2183 - loss: 12.1841\n",
      "Epoch 296/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2183 - loss: 12.1377\n",
      "Epoch 297/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2167 - loss: 12.0426\n",
      "Epoch 298/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2167 - loss: 11.9679\n",
      "Epoch 299/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2183 - loss: 12.0161\n",
      "Epoch 300/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.2183 - loss: 11.9066\n",
      "Epoch 301/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2150 - loss: 12.0691\n",
      "Epoch 302/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2167 - loss: 12.0169\n",
      "Epoch 303/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2183 - loss: 11.7705\n",
      "Epoch 304/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2183 - loss: 11.7281\n",
      "Epoch 305/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.2167 - loss: 11.8314\n",
      "Epoch 306/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.2167 - loss: 11.6590\n",
      "Epoch 307/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.2183 - loss: 11.8393\n",
      "Epoch 308/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2183 - loss: 11.8097\n",
      "Epoch 309/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.2167 - loss: 11.5649\n",
      "Epoch 310/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.2167 - loss: 11.6209\n",
      "Epoch 311/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2167 - loss: 11.5886\n",
      "Epoch 312/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2167 - loss: 11.4764\n",
      "Epoch 313/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2150 - loss: 11.5760\n",
      "Epoch 314/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.2167 - loss: 11.3990\n",
      "Epoch 315/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.2183 - loss: 11.5172\n",
      "Epoch 316/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.2167 - loss: 11.4049\n",
      "Epoch 317/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.2150 - loss: 11.5616\n",
      "Epoch 318/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.2167 - loss: 11.4937\n",
      "Epoch 319/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2167 - loss: 11.2516\n",
      "Epoch 320/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2150 - loss: 11.2548\n",
      "Epoch 321/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2150 - loss: 11.2561\n",
      "Epoch 322/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.2150 - loss: 11.1093\n",
      "Epoch 323/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.2183 - loss: 11.2739\n",
      "Epoch 324/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.2183 - loss: 11.2532\n",
      "Epoch 325/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.2167 - loss: 10.9334\n",
      "Epoch 326/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.2167 - loss: 10.9941\n",
      "Epoch 327/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.2167 - loss: 10.9385\n",
      "Epoch 328/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.2167 - loss: 10.8586\n",
      "Epoch 329/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2167 - loss: 10.8210\n",
      "Epoch 330/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2167 - loss: 10.8114\n",
      "Epoch 331/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2167 - loss: 10.7501\n",
      "Epoch 332/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.2167 - loss: 10.6548\n",
      "Epoch 333/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.2183 - loss: 10.6673\n",
      "Epoch 334/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.2167 - loss: 10.6374\n",
      "Epoch 335/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.2150 - loss: 10.5625\n",
      "Epoch 336/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.2150 - loss: 10.5494\n",
      "Epoch 337/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2150 - loss: 10.4419\n",
      "Epoch 338/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2150 - loss: 10.5415\n",
      "Epoch 339/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2150 - loss: 10.3497\n",
      "Epoch 340/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.2167 - loss: 10.8243\n",
      "Epoch 341/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.2133 - loss: 10.9033\n",
      "Epoch 342/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.2150 - loss: 10.6539\n",
      "Epoch 343/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2150 - loss: 10.3203\n",
      "Epoch 344/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2117 - loss: 10.5433\n",
      "Epoch 345/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2117 - loss: 10.5541\n",
      "Epoch 346/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2133 - loss: 10.1657\n",
      "Epoch 347/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2150 - loss: 10.2368\n",
      "Epoch 348/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2150 - loss: 10.3565\n",
      "Epoch 349/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2133 - loss: 10.0140\n",
      "Epoch 350/350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2133 - loss: 10.4854\n"
     ]
    }
   ],
   "source": [
    "# TODO: Entrena tu modelo\n",
    "\n",
    "semisupervised_training(autoencoder=autoencoder, classifier=classifier, x_train=x_train, y_train=one_hot_train, unlabeled_data=unlabeled_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "id": "n5tS8_SKOngm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7033 - loss: 0.9042\n",
      "Test accuracy : 0.730400025844574\n"
     ]
    }
   ],
   "source": [
    "# TODO: Obtén la precisión sobre el conjunto de test\n",
    "pred_data = autoencoder.get_encoded_data(x_test)\n",
    "print('Test accuracy :', classifier.score(pred_data, one_hot_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "index = 1\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "axes[0].imshow(x_test[index].reshape(28, 28), cmap='gray')\n",
    "axes[0].set_title(\"Original Image\")\n",
    "axes[0].axis('off') \n",
    "\n",
    "# Get the reconstructed image from the autoencoder\n",
    "reconstructed_image = autoencoder(x_test[index].reshape(1, 784)).reshape(28, 28)\n",
    "\n",
    "# Plot the reconstructed image on the right\n",
    "axes[1].imshow(reconstructed_image, cmap='gray')\n",
    "axes[1].set_title(\"Reconstructed Image\")\n",
    "axes[1].axis('off')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MbUKp14pPsrp"
   },
   "source": [
    "## Mejorando el código\n",
    "\n",
    "nuestro modelo actual requiere de dos pasos para entrenarse, pero podría realizarse en un único paso si **creamos un modelo con las dos salidas (autoencoder y clasificador)**. \n",
    "\n",
    "Para ello, hay que tener en cuenta que, en los datos sin etiquetar, su contribución al clasificador debería ser nula.\n",
    "\n",
    "\n",
    "### TRABAJO: Crea el nuevo modelo y modifica la función semisupervised_training para tener en cuenta todos los puntos mencionados anteriormente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "id": "xS3JLE37SqrG"
   },
   "outputs": [],
   "source": [
    "# TODO: crea el nuevo modelo\n",
    "\n",
    "# TODO: crea tu propio clasificador\n",
    "\n",
    "class MiClasificadorSemisupervisado:\n",
    "\n",
    "    def __init__(self, input_shape):\n",
    "        # TODO : define el modelo y compílalo\n",
    "        \n",
    "        self.input_shape = input_shape\n",
    "        self.num_classes = 10\n",
    "        \n",
    "        input_layer = layers.Input(shape=self.input_shape)\n",
    "        \n",
    "        # Encoder part (shared for both autoencoder and classifier)\n",
    "        encoded = layers.Dense(128, activation='relu')(input_layer)\n",
    "        encoded = layers.Dense(64, activation='relu')(encoded)\n",
    "        encoded = layers.Dense(16, activation='relu', kernel_regularizer='l2')(encoded)\n",
    "        \n",
    "        # Decoder for autoencoder part\n",
    "        decoded = layers.Dense(64, activation='relu')(encoded)\n",
    "        decoded = layers.Dense(128, activation='relu')(decoded)\n",
    "        decoded = layers.Dense(self.input_shape[0], activation='sigmoid',name='autoencoder')(decoded)\n",
    "\n",
    "        # Classifier part\n",
    "        classifier = layers.Dense(32, activation='relu')(encoded)\n",
    "        classifier = layers.Dense(16, activation='relu')(classifier)\n",
    "        classifier_output = layers.Dense(self.num_classes, activation='softmax',name='classifier')(classifier)\n",
    "\n",
    "        # Autoencoder model (for reconstructing input)\n",
    "        self.autoencoder = models.Model(input_layer, decoded)\n",
    "        #self.autoencoder.compile(optimizer='adam', loss='mse')\n",
    "        \n",
    "        # Classifier model (for predicting class labels)\n",
    "        self.classifier = models.Model(input_layer, classifier_output)\n",
    "        #self.classifier.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        \n",
    "        \n",
    "        # Combined model with two outputs: one for autoencoder (reconstruction) and one for classifier (classification)\n",
    "        self.model = models.Model(input_layer, \n",
    "                                  [decoded, classifier_output])\n",
    "                                  #classifier_output)\n",
    "\n",
    "        self.optimicer = tf.keras.optimizers.AdamW(\n",
    "            learning_rate=0.0001,\n",
    "            clipnorm=1,\n",
    "        )\n",
    "        \n",
    "        self.model.compile(optimizer=self.optimicer,\n",
    "                           loss=['mse', 'categorical_crossentropy'],\n",
    "                           #loss='categorical_crossentropy',\n",
    "                           loss_weights=[.8, 1.2],  # Adjust loss weights if needed\n",
    "                           metrics=['accuracy', 'accuracy'])\n",
    "    \n",
    "    def fit(self, X, y, unlabeled_data, batch_size,  epochs):\n",
    "        # TODO: entrena el modelo. Escoge el tamaño de batch y el número de epochs que quieras, y define bien el sample_weight\n",
    "\n",
    "        all_x = np.vstack((X, unlabeled_train))\n",
    "        y_zeros = np.zeros((unlabeled_data.shape[0],y.shape[1]))\n",
    "        all_y = np.vstack((y,y_zeros))\n",
    "        weight_autoencoder = np.ones(len(all_x))\n",
    "        weight_classifier = np.array([1]*len(X) + [0]*len(unlabeled_data))\n",
    "        \n",
    "        h = self.model.fit(all_x, \n",
    "                       [all_x, all_y], \n",
    "                       #all_y,\n",
    "                       sample_weight=[weight_autoencoder, weight_classifier], \n",
    "                       #sample_weight=sample_weight,\n",
    "                       epochs=epochs, \n",
    "                       batch_size=batch_size, \n",
    "                       verbose=1)\n",
    "        return h\n",
    "\n",
    "    def predict(self, X):\n",
    "        # TODO: devuelve la clase ganadora del clasificador\n",
    "        _, predictions = self.model.predict(X)\n",
    "        return predictions.argmax(axis=1)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        # TODO: devuelve la probabilidad del clasificador\n",
    "        _, predictions = self.model.predict(X)\n",
    "        return predictions\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        y_pred = self.predict(X)\n",
    "        return accuracy_score(y, y_pred)\n",
    "\n",
    "    def __call__(self, X):\n",
    "        return self.autoencoder.predict(X), self.classifier.predict(X)\n",
    "\n",
    "    def __del__(self):\n",
    "        # elimina todos los modelos que hayas creado\n",
    "        tf.keras.backend.clear_session() # Necesario para liberar la memoria en GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "id": "7eF_9LMeZ2J2"
   },
   "outputs": [],
   "source": [
    "# TODO: reescribe la función semisupervised_training para incorporar las mejoras mencionadas anteriormente\n",
    "\n",
    "model = MiClasificadorSemisupervisado(input_shape=x_train[0].shape)\n",
    "\n",
    "def semisupervised_training_v2(model, x_train, y_train, unlabeled_data):\n",
    "    h = model.fit(x_train, y_train, unlabeled_data, batch_size=60_000, epochs = 1000)\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "id": "YbqC0inexwHp",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - autoencoder_accuracy: 0.0017 - autoencoder_loss: 0.2327 - classifier_accuracy: 0.0037 - classifier_loss: 0.0247 - loss: 0.4767\n",
      "Epoch 2/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 535ms/step - autoencoder_accuracy: 0.0018 - autoencoder_loss: 0.2324 - classifier_accuracy: 0.0038 - classifier_loss: 0.0246 - loss: 0.4761\n",
      "Epoch 3/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376ms/step - autoencoder_accuracy: 0.0017 - autoencoder_loss: 0.2320 - classifier_accuracy: 0.0039 - classifier_loss: 0.0245 - loss: 0.4754\n",
      "Epoch 4/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 439ms/step - autoencoder_accuracy: 0.0018 - autoencoder_loss: 0.2317 - classifier_accuracy: 0.0036 - classifier_loss: 0.0244 - loss: 0.4748\n",
      "Epoch 5/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389ms/step - autoencoder_accuracy: 0.0019 - autoencoder_loss: 0.2314 - classifier_accuracy: 0.0037 - classifier_loss: 0.0244 - loss: 0.4742\n",
      "Epoch 6/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462ms/step - autoencoder_accuracy: 0.0018 - autoencoder_loss: 0.2311 - classifier_accuracy: 0.0033 - classifier_loss: 0.0243 - loss: 0.4736\n",
      "Epoch 7/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458ms/step - autoencoder_accuracy: 0.0018 - autoencoder_loss: 0.2308 - classifier_accuracy: 0.0032 - classifier_loss: 0.0243 - loss: 0.4730\n",
      "Epoch 8/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355ms/step - autoencoder_accuracy: 0.0018 - autoencoder_loss: 0.2305 - classifier_accuracy: 0.0032 - classifier_loss: 0.0242 - loss: 0.4724\n",
      "Epoch 9/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 434ms/step - autoencoder_accuracy: 0.0017 - autoencoder_loss: 0.2301 - classifier_accuracy: 0.0030 - classifier_loss: 0.0242 - loss: 0.4718\n",
      "Epoch 10/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461ms/step - autoencoder_accuracy: 0.0017 - autoencoder_loss: 0.2298 - classifier_accuracy: 0.0030 - classifier_loss: 0.0241 - loss: 0.4712\n",
      "Epoch 11/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 363ms/step - autoencoder_accuracy: 0.0016 - autoencoder_loss: 0.2294 - classifier_accuracy: 0.0030 - classifier_loss: 0.0241 - loss: 0.4705\n",
      "Epoch 12/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 540ms/step - autoencoder_accuracy: 0.0016 - autoencoder_loss: 0.2290 - classifier_accuracy: 0.0031 - classifier_loss: 0.0240 - loss: 0.4699\n",
      "Epoch 13/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459ms/step - autoencoder_accuracy: 0.0017 - autoencoder_loss: 0.2286 - classifier_accuracy: 0.0033 - classifier_loss: 0.0240 - loss: 0.4692\n",
      "Epoch 14/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 510ms/step - autoencoder_accuracy: 0.0016 - autoencoder_loss: 0.2282 - classifier_accuracy: 0.0033 - classifier_loss: 0.0239 - loss: 0.4685\n",
      "Epoch 15/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 442ms/step - autoencoder_accuracy: 0.0015 - autoencoder_loss: 0.2277 - classifier_accuracy: 0.0034 - classifier_loss: 0.0238 - loss: 0.4678\n",
      "Epoch 16/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 354ms/step - autoencoder_accuracy: 0.0015 - autoencoder_loss: 0.2273 - classifier_accuracy: 0.0036 - classifier_loss: 0.0238 - loss: 0.4671\n",
      "Epoch 17/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 343ms/step - autoencoder_accuracy: 0.0014 - autoencoder_loss: 0.2267 - classifier_accuracy: 0.0037 - classifier_loss: 0.0237 - loss: 0.4664\n",
      "Epoch 18/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 357ms/step - autoencoder_accuracy: 0.0014 - autoencoder_loss: 0.2262 - classifier_accuracy: 0.0038 - classifier_loss: 0.0237 - loss: 0.4656\n",
      "Epoch 19/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 343ms/step - autoencoder_accuracy: 0.0014 - autoencoder_loss: 0.2256 - classifier_accuracy: 0.0039 - classifier_loss: 0.0237 - loss: 0.4648\n",
      "Epoch 20/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 346ms/step - autoencoder_accuracy: 0.0014 - autoencoder_loss: 0.2250 - classifier_accuracy: 0.0038 - classifier_loss: 0.0236 - loss: 0.4640\n",
      "Epoch 21/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333ms/step - autoencoder_accuracy: 0.0014 - autoencoder_loss: 0.2244 - classifier_accuracy: 0.0039 - classifier_loss: 0.0236 - loss: 0.4632\n",
      "Epoch 22/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 348ms/step - autoencoder_accuracy: 0.0015 - autoencoder_loss: 0.2237 - classifier_accuracy: 0.0038 - classifier_loss: 0.0236 - loss: 0.4623\n",
      "Epoch 23/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 340ms/step - autoencoder_accuracy: 0.0015 - autoencoder_loss: 0.2230 - classifier_accuracy: 0.0038 - classifier_loss: 0.0235 - loss: 0.4614\n",
      "Epoch 24/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 342ms/step - autoencoder_accuracy: 0.0015 - autoencoder_loss: 0.2222 - classifier_accuracy: 0.0038 - classifier_loss: 0.0235 - loss: 0.4605\n",
      "Epoch 25/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 343ms/step - autoencoder_accuracy: 0.0016 - autoencoder_loss: 0.2214 - classifier_accuracy: 0.0037 - classifier_loss: 0.0235 - loss: 0.4596\n",
      "Epoch 26/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 344ms/step - autoencoder_accuracy: 0.0016 - autoencoder_loss: 0.2205 - classifier_accuracy: 0.0036 - classifier_loss: 0.0235 - loss: 0.4586\n",
      "Epoch 27/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 352ms/step - autoencoder_accuracy: 0.0016 - autoencoder_loss: 0.2196 - classifier_accuracy: 0.0035 - classifier_loss: 0.0235 - loss: 0.4576\n",
      "Epoch 28/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463ms/step - autoencoder_accuracy: 0.0016 - autoencoder_loss: 0.2187 - classifier_accuracy: 0.0033 - classifier_loss: 0.0235 - loss: 0.4565\n",
      "Epoch 29/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470ms/step - autoencoder_accuracy: 0.0017 - autoencoder_loss: 0.2176 - classifier_accuracy: 0.0032 - classifier_loss: 0.0235 - loss: 0.4554\n",
      "Epoch 30/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 357ms/step - autoencoder_accuracy: 0.0016 - autoencoder_loss: 0.2166 - classifier_accuracy: 0.0030 - classifier_loss: 0.0235 - loss: 0.4543\n",
      "Epoch 31/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 351ms/step - autoencoder_accuracy: 0.0017 - autoencoder_loss: 0.2154 - classifier_accuracy: 0.0028 - classifier_loss: 0.0235 - loss: 0.4531\n",
      "Epoch 32/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329ms/step - autoencoder_accuracy: 0.0017 - autoencoder_loss: 0.2142 - classifier_accuracy: 0.0026 - classifier_loss: 0.0235 - loss: 0.4519\n",
      "Epoch 33/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333ms/step - autoencoder_accuracy: 0.0018 - autoencoder_loss: 0.2130 - classifier_accuracy: 0.0025 - classifier_loss: 0.0235 - loss: 0.4506\n",
      "Epoch 34/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 346ms/step - autoencoder_accuracy: 0.0019 - autoencoder_loss: 0.2117 - classifier_accuracy: 0.0024 - classifier_loss: 0.0235 - loss: 0.4493\n",
      "Epoch 35/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331ms/step - autoencoder_accuracy: 0.0019 - autoencoder_loss: 0.2103 - classifier_accuracy: 0.0022 - classifier_loss: 0.0235 - loss: 0.4480\n",
      "Epoch 36/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 327ms/step - autoencoder_accuracy: 0.0020 - autoencoder_loss: 0.2089 - classifier_accuracy: 0.0021 - classifier_loss: 0.0235 - loss: 0.4465\n",
      "Epoch 37/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 350ms/step - autoencoder_accuracy: 0.0020 - autoencoder_loss: 0.2074 - classifier_accuracy: 0.0020 - classifier_loss: 0.0236 - loss: 0.4451\n",
      "Epoch 38/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329ms/step - autoencoder_accuracy: 0.0022 - autoencoder_loss: 0.2058 - classifier_accuracy: 0.0020 - classifier_loss: 0.0236 - loss: 0.4436\n",
      "Epoch 39/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330ms/step - autoencoder_accuracy: 0.0023 - autoencoder_loss: 0.2041 - classifier_accuracy: 0.0019 - classifier_loss: 0.0236 - loss: 0.4420\n",
      "Epoch 40/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329ms/step - autoencoder_accuracy: 0.0023 - autoencoder_loss: 0.2024 - classifier_accuracy: 0.0019 - classifier_loss: 0.0236 - loss: 0.4404\n",
      "Epoch 41/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 342ms/step - autoencoder_accuracy: 0.0024 - autoencoder_loss: 0.2006 - classifier_accuracy: 0.0018 - classifier_loss: 0.0237 - loss: 0.4388\n",
      "Epoch 42/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 357ms/step - autoencoder_accuracy: 0.0025 - autoencoder_loss: 0.1988 - classifier_accuracy: 0.0018 - classifier_loss: 0.0237 - loss: 0.4370\n",
      "Epoch 43/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392ms/step - autoencoder_accuracy: 0.0025 - autoencoder_loss: 0.1969 - classifier_accuracy: 0.0018 - classifier_loss: 0.0237 - loss: 0.4353\n",
      "Epoch 44/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 504ms/step - autoencoder_accuracy: 0.0026 - autoencoder_loss: 0.1949 - classifier_accuracy: 0.0018 - classifier_loss: 0.0238 - loss: 0.4334\n",
      "Epoch 45/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387ms/step - autoencoder_accuracy: 0.0027 - autoencoder_loss: 0.1928 - classifier_accuracy: 0.0017 - classifier_loss: 0.0238 - loss: 0.4315\n",
      "Epoch 46/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 370ms/step - autoencoder_accuracy: 0.0028 - autoencoder_loss: 0.1907 - classifier_accuracy: 0.0017 - classifier_loss: 0.0238 - loss: 0.4296\n",
      "Epoch 47/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 352ms/step - autoencoder_accuracy: 0.0029 - autoencoder_loss: 0.1885 - classifier_accuracy: 0.0018 - classifier_loss: 0.0238 - loss: 0.4276\n",
      "Epoch 48/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 360ms/step - autoencoder_accuracy: 0.0030 - autoencoder_loss: 0.1863 - classifier_accuracy: 0.0018 - classifier_loss: 0.0239 - loss: 0.4256\n",
      "Epoch 49/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 342ms/step - autoencoder_accuracy: 0.0031 - autoencoder_loss: 0.1839 - classifier_accuracy: 0.0018 - classifier_loss: 0.0239 - loss: 0.4235\n",
      "Epoch 50/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 348ms/step - autoencoder_accuracy: 0.0032 - autoencoder_loss: 0.1816 - classifier_accuracy: 0.0018 - classifier_loss: 0.0239 - loss: 0.4214\n",
      "Epoch 51/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 336ms/step - autoencoder_accuracy: 0.0032 - autoencoder_loss: 0.1791 - classifier_accuracy: 0.0018 - classifier_loss: 0.0240 - loss: 0.4192\n",
      "Epoch 52/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 341ms/step - autoencoder_accuracy: 0.0032 - autoencoder_loss: 0.1766 - classifier_accuracy: 0.0019 - classifier_loss: 0.0240 - loss: 0.4170\n",
      "Epoch 53/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 340ms/step - autoencoder_accuracy: 0.0034 - autoencoder_loss: 0.1741 - classifier_accuracy: 0.0018 - classifier_loss: 0.0240 - loss: 0.4147\n",
      "Epoch 54/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330ms/step - autoencoder_accuracy: 0.0034 - autoencoder_loss: 0.1715 - classifier_accuracy: 0.0019 - classifier_loss: 0.0241 - loss: 0.4124\n",
      "Epoch 55/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 339ms/step - autoencoder_accuracy: 0.0035 - autoencoder_loss: 0.1689 - classifier_accuracy: 0.0019 - classifier_loss: 0.0241 - loss: 0.4100\n",
      "Epoch 56/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 344ms/step - autoencoder_accuracy: 0.0036 - autoencoder_loss: 0.1662 - classifier_accuracy: 0.0019 - classifier_loss: 0.0241 - loss: 0.4077\n",
      "Epoch 57/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 336ms/step - autoencoder_accuracy: 0.0036 - autoencoder_loss: 0.1635 - classifier_accuracy: 0.0019 - classifier_loss: 0.0241 - loss: 0.4053\n",
      "Epoch 58/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 347ms/step - autoencoder_accuracy: 0.0037 - autoencoder_loss: 0.1607 - classifier_accuracy: 0.0019 - classifier_loss: 0.0241 - loss: 0.4028\n",
      "Epoch 59/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334ms/step - autoencoder_accuracy: 0.0038 - autoencoder_loss: 0.1580 - classifier_accuracy: 0.0019 - classifier_loss: 0.0242 - loss: 0.4004\n",
      "Epoch 60/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333ms/step - autoencoder_accuracy: 0.0038 - autoencoder_loss: 0.1552 - classifier_accuracy: 0.0021 - classifier_loss: 0.0242 - loss: 0.3979\n",
      "Epoch 61/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 348ms/step - autoencoder_accuracy: 0.0038 - autoencoder_loss: 0.1524 - classifier_accuracy: 0.0021 - classifier_loss: 0.0242 - loss: 0.3954\n",
      "Epoch 62/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 337ms/step - autoencoder_accuracy: 0.0038 - autoencoder_loss: 0.1496 - classifier_accuracy: 0.0022 - classifier_loss: 0.0242 - loss: 0.3930\n",
      "Epoch 63/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 324ms/step - autoencoder_accuracy: 0.0038 - autoencoder_loss: 0.1469 - classifier_accuracy: 0.0023 - classifier_loss: 0.0242 - loss: 0.3905\n",
      "Epoch 64/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 338ms/step - autoencoder_accuracy: 0.0038 - autoencoder_loss: 0.1441 - classifier_accuracy: 0.0023 - classifier_loss: 0.0242 - loss: 0.3880\n",
      "Epoch 65/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 343ms/step - autoencoder_accuracy: 0.0038 - autoencoder_loss: 0.1414 - classifier_accuracy: 0.0025 - classifier_loss: 0.0242 - loss: 0.3855\n",
      "Epoch 66/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333ms/step - autoencoder_accuracy: 0.0038 - autoencoder_loss: 0.1387 - classifier_accuracy: 0.0029 - classifier_loss: 0.0242 - loss: 0.3831\n",
      "Epoch 67/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332ms/step - autoencoder_accuracy: 0.0038 - autoencoder_loss: 0.1360 - classifier_accuracy: 0.0031 - classifier_loss: 0.0242 - loss: 0.3807\n",
      "Epoch 68/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 336ms/step - autoencoder_accuracy: 0.0038 - autoencoder_loss: 0.1333 - classifier_accuracy: 0.0034 - classifier_loss: 0.0242 - loss: 0.3783\n",
      "Epoch 69/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 336ms/step - autoencoder_accuracy: 0.0040 - autoencoder_loss: 0.1307 - classifier_accuracy: 0.0040 - classifier_loss: 0.0241 - loss: 0.3759\n",
      "Epoch 70/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 340ms/step - autoencoder_accuracy: 0.0040 - autoencoder_loss: 0.1282 - classifier_accuracy: 0.0044 - classifier_loss: 0.0241 - loss: 0.3736\n",
      "Epoch 71/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 337ms/step - autoencoder_accuracy: 0.0039 - autoencoder_loss: 0.1256 - classifier_accuracy: 0.0051 - classifier_loss: 0.0241 - loss: 0.3713\n",
      "Epoch 72/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 348ms/step - autoencoder_accuracy: 0.0039 - autoencoder_loss: 0.1232 - classifier_accuracy: 0.0063 - classifier_loss: 0.0241 - loss: 0.3690\n",
      "Epoch 73/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 350ms/step - autoencoder_accuracy: 0.0040 - autoencoder_loss: 0.1208 - classifier_accuracy: 0.0077 - classifier_loss: 0.0241 - loss: 0.3668\n",
      "Epoch 74/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 346ms/step - autoencoder_accuracy: 0.0040 - autoencoder_loss: 0.1185 - classifier_accuracy: 0.0095 - classifier_loss: 0.0240 - loss: 0.3647\n",
      "Epoch 75/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 502ms/step - autoencoder_accuracy: 0.0040 - autoencoder_loss: 0.1162 - classifier_accuracy: 0.0121 - classifier_loss: 0.0240 - loss: 0.3626\n",
      "Epoch 76/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461ms/step - autoencoder_accuracy: 0.0040 - autoencoder_loss: 0.1140 - classifier_accuracy: 0.0148 - classifier_loss: 0.0240 - loss: 0.3605\n",
      "Epoch 77/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 348ms/step - autoencoder_accuracy: 0.0039 - autoencoder_loss: 0.1119 - classifier_accuracy: 0.0188 - classifier_loss: 0.0239 - loss: 0.3585\n",
      "Epoch 78/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 341ms/step - autoencoder_accuracy: 0.0038 - autoencoder_loss: 0.1099 - classifier_accuracy: 0.0239 - classifier_loss: 0.0239 - loss: 0.3566\n",
      "Epoch 79/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 349ms/step - autoencoder_accuracy: 0.0038 - autoencoder_loss: 0.1079 - classifier_accuracy: 0.0310 - classifier_loss: 0.0239 - loss: 0.3547\n",
      "Epoch 80/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 341ms/step - autoencoder_accuracy: 0.0038 - autoencoder_loss: 0.1060 - classifier_accuracy: 0.0388 - classifier_loss: 0.0238 - loss: 0.3529\n",
      "Epoch 81/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 337ms/step - autoencoder_accuracy: 0.0039 - autoencoder_loss: 0.1042 - classifier_accuracy: 0.0476 - classifier_loss: 0.0238 - loss: 0.3512\n",
      "Epoch 82/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331ms/step - autoencoder_accuracy: 0.0039 - autoencoder_loss: 0.1025 - classifier_accuracy: 0.0575 - classifier_loss: 0.0237 - loss: 0.3495\n",
      "Epoch 83/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328ms/step - autoencoder_accuracy: 0.0040 - autoencoder_loss: 0.1009 - classifier_accuracy: 0.0679 - classifier_loss: 0.0237 - loss: 0.3479\n",
      "Epoch 84/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334ms/step - autoencoder_accuracy: 0.0039 - autoencoder_loss: 0.0993 - classifier_accuracy: 0.0795 - classifier_loss: 0.0236 - loss: 0.3463\n",
      "Epoch 85/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 343ms/step - autoencoder_accuracy: 0.0039 - autoencoder_loss: 0.0979 - classifier_accuracy: 0.0912 - classifier_loss: 0.0236 - loss: 0.3448\n",
      "Epoch 86/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 341ms/step - autoencoder_accuracy: 0.0039 - autoencoder_loss: 0.0965 - classifier_accuracy: 0.1021 - classifier_loss: 0.0235 - loss: 0.3434\n",
      "Epoch 87/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 353ms/step - autoencoder_accuracy: 0.0039 - autoencoder_loss: 0.0952 - classifier_accuracy: 0.1131 - classifier_loss: 0.0235 - loss: 0.3420\n",
      "Epoch 88/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 358ms/step - autoencoder_accuracy: 0.0039 - autoencoder_loss: 0.0939 - classifier_accuracy: 0.1233 - classifier_loss: 0.0234 - loss: 0.3407\n",
      "Epoch 89/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 351ms/step - autoencoder_accuracy: 0.0039 - autoencoder_loss: 0.0928 - classifier_accuracy: 0.1335 - classifier_loss: 0.0233 - loss: 0.3394\n",
      "Epoch 90/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 339ms/step - autoencoder_accuracy: 0.0041 - autoencoder_loss: 0.0916 - classifier_accuracy: 0.1421 - classifier_loss: 0.0233 - loss: 0.3382\n",
      "Epoch 91/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 337ms/step - autoencoder_accuracy: 0.0042 - autoencoder_loss: 0.0906 - classifier_accuracy: 0.1503 - classifier_loss: 0.0232 - loss: 0.3370\n",
      "Epoch 92/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 371ms/step - autoencoder_accuracy: 0.0045 - autoencoder_loss: 0.0896 - classifier_accuracy: 0.1569 - classifier_loss: 0.0231 - loss: 0.3358\n",
      "Epoch 93/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472ms/step - autoencoder_accuracy: 0.0046 - autoencoder_loss: 0.0887 - classifier_accuracy: 0.1622 - classifier_loss: 0.0230 - loss: 0.3348\n",
      "Epoch 94/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 437ms/step - autoencoder_accuracy: 0.0050 - autoencoder_loss: 0.0878 - classifier_accuracy: 0.1669 - classifier_loss: 0.0230 - loss: 0.3337\n",
      "Epoch 95/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 357ms/step - autoencoder_accuracy: 0.0052 - autoencoder_loss: 0.0870 - classifier_accuracy: 0.1709 - classifier_loss: 0.0229 - loss: 0.3327\n",
      "Epoch 96/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 345ms/step - autoencoder_accuracy: 0.0055 - autoencoder_loss: 0.0863 - classifier_accuracy: 0.1735 - classifier_loss: 0.0228 - loss: 0.3317\n",
      "Epoch 97/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445ms/step - autoencoder_accuracy: 0.0058 - autoencoder_loss: 0.0855 - classifier_accuracy: 0.1750 - classifier_loss: 0.0227 - loss: 0.3308\n",
      "Epoch 98/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 352ms/step - autoencoder_accuracy: 0.0062 - autoencoder_loss: 0.0849 - classifier_accuracy: 0.1756 - classifier_loss: 0.0226 - loss: 0.3299\n",
      "Epoch 99/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 339ms/step - autoencoder_accuracy: 0.0068 - autoencoder_loss: 0.0842 - classifier_accuracy: 0.1753 - classifier_loss: 0.0225 - loss: 0.3290\n",
      "Epoch 100/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 339ms/step - autoencoder_accuracy: 0.0071 - autoencoder_loss: 0.0836 - classifier_accuracy: 0.1742 - classifier_loss: 0.0224 - loss: 0.3282\n",
      "Epoch 101/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 350ms/step - autoencoder_accuracy: 0.0073 - autoencoder_loss: 0.0831 - classifier_accuracy: 0.1731 - classifier_loss: 0.0224 - loss: 0.3274\n",
      "Epoch 102/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355ms/step - autoencoder_accuracy: 0.0077 - autoencoder_loss: 0.0825 - classifier_accuracy: 0.1713 - classifier_loss: 0.0223 - loss: 0.3266\n",
      "Epoch 103/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 339ms/step - autoencoder_accuracy: 0.0080 - autoencoder_loss: 0.0820 - classifier_accuracy: 0.1693 - classifier_loss: 0.0222 - loss: 0.3259\n",
      "Epoch 104/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334ms/step - autoencoder_accuracy: 0.0080 - autoencoder_loss: 0.0816 - classifier_accuracy: 0.1674 - classifier_loss: 0.0221 - loss: 0.3251\n",
      "Epoch 105/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 341ms/step - autoencoder_accuracy: 0.0080 - autoencoder_loss: 0.0811 - classifier_accuracy: 0.1649 - classifier_loss: 0.0221 - loss: 0.3244\n",
      "Epoch 106/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 340ms/step - autoencoder_accuracy: 0.0083 - autoencoder_loss: 0.0807 - classifier_accuracy: 0.1628 - classifier_loss: 0.0220 - loss: 0.3237\n",
      "Epoch 107/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 345ms/step - autoencoder_accuracy: 0.0082 - autoencoder_loss: 0.0802 - classifier_accuracy: 0.1606 - classifier_loss: 0.0219 - loss: 0.3230\n",
      "Epoch 108/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 327ms/step - autoencoder_accuracy: 0.0083 - autoencoder_loss: 0.0798 - classifier_accuracy: 0.1591 - classifier_loss: 0.0219 - loss: 0.3224\n",
      "Epoch 109/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330ms/step - autoencoder_accuracy: 0.0083 - autoencoder_loss: 0.0794 - classifier_accuracy: 0.1566 - classifier_loss: 0.0218 - loss: 0.3217\n",
      "Epoch 110/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330ms/step - autoencoder_accuracy: 0.0083 - autoencoder_loss: 0.0790 - classifier_accuracy: 0.1547 - classifier_loss: 0.0217 - loss: 0.3211\n",
      "Epoch 111/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 344ms/step - autoencoder_accuracy: 0.0082 - autoencoder_loss: 0.0786 - classifier_accuracy: 0.1529 - classifier_loss: 0.0217 - loss: 0.3205\n",
      "Epoch 112/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 350ms/step - autoencoder_accuracy: 0.0082 - autoencoder_loss: 0.0783 - classifier_accuracy: 0.1511 - classifier_loss: 0.0217 - loss: 0.3199\n",
      "Epoch 113/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 344ms/step - autoencoder_accuracy: 0.0083 - autoencoder_loss: 0.0779 - classifier_accuracy: 0.1488 - classifier_loss: 0.0216 - loss: 0.3193\n",
      "Epoch 114/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388ms/step - autoencoder_accuracy: 0.0083 - autoencoder_loss: 0.0775 - classifier_accuracy: 0.1462 - classifier_loss: 0.0216 - loss: 0.3187\n",
      "Epoch 115/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 509ms/step - autoencoder_accuracy: 0.0084 - autoencoder_loss: 0.0772 - classifier_accuracy: 0.1437 - classifier_loss: 0.0215 - loss: 0.3181\n",
      "Epoch 116/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 464ms/step - autoencoder_accuracy: 0.0084 - autoencoder_loss: 0.0769 - classifier_accuracy: 0.1412 - classifier_loss: 0.0215 - loss: 0.3176\n",
      "Epoch 117/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 348ms/step - autoencoder_accuracy: 0.0084 - autoencoder_loss: 0.0766 - classifier_accuracy: 0.1390 - classifier_loss: 0.0214 - loss: 0.3170\n",
      "Epoch 118/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 336ms/step - autoencoder_accuracy: 0.0083 - autoencoder_loss: 0.0762 - classifier_accuracy: 0.1363 - classifier_loss: 0.0214 - loss: 0.3165\n",
      "Epoch 119/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 337ms/step - autoencoder_accuracy: 0.0083 - autoencoder_loss: 0.0759 - classifier_accuracy: 0.1338 - classifier_loss: 0.0214 - loss: 0.3159\n",
      "Epoch 120/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 339ms/step - autoencoder_accuracy: 0.0083 - autoencoder_loss: 0.0756 - classifier_accuracy: 0.1315 - classifier_loss: 0.0213 - loss: 0.3154\n",
      "Epoch 121/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334ms/step - autoencoder_accuracy: 0.0084 - autoencoder_loss: 0.0754 - classifier_accuracy: 0.1289 - classifier_loss: 0.0213 - loss: 0.3149\n",
      "Epoch 122/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 343ms/step - autoencoder_accuracy: 0.0084 - autoencoder_loss: 0.0751 - classifier_accuracy: 0.1266 - classifier_loss: 0.0212 - loss: 0.3143\n",
      "Epoch 123/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333ms/step - autoencoder_accuracy: 0.0085 - autoencoder_loss: 0.0748 - classifier_accuracy: 0.1245 - classifier_loss: 0.0212 - loss: 0.3138\n",
      "Epoch 124/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 337ms/step - autoencoder_accuracy: 0.0086 - autoencoder_loss: 0.0745 - classifier_accuracy: 0.1226 - classifier_loss: 0.0211 - loss: 0.3133\n",
      "Epoch 125/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 342ms/step - autoencoder_accuracy: 0.0086 - autoencoder_loss: 0.0743 - classifier_accuracy: 0.1205 - classifier_loss: 0.0211 - loss: 0.3128\n",
      "Epoch 126/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 336ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0740 - classifier_accuracy: 0.1188 - classifier_loss: 0.0210 - loss: 0.3123\n",
      "Epoch 127/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 338ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0738 - classifier_accuracy: 0.1171 - classifier_loss: 0.0210 - loss: 0.3118\n",
      "Epoch 128/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 338ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0736 - classifier_accuracy: 0.1159 - classifier_loss: 0.0209 - loss: 0.3113\n",
      "Epoch 129/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0733 - classifier_accuracy: 0.1145 - classifier_loss: 0.0209 - loss: 0.3108\n",
      "Epoch 130/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 341ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0731 - classifier_accuracy: 0.1138 - classifier_loss: 0.0208 - loss: 0.3103\n",
      "Epoch 131/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0729 - classifier_accuracy: 0.1129 - classifier_loss: 0.0208 - loss: 0.3098\n",
      "Epoch 132/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0727 - classifier_accuracy: 0.1126 - classifier_loss: 0.0207 - loss: 0.3093\n",
      "Epoch 133/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 356ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0725 - classifier_accuracy: 0.1125 - classifier_loss: 0.0207 - loss: 0.3088\n",
      "Epoch 134/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 370ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0723 - classifier_accuracy: 0.1126 - classifier_loss: 0.0206 - loss: 0.3084\n",
      "Epoch 135/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 352ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0721 - classifier_accuracy: 0.1128 - classifier_loss: 0.0206 - loss: 0.3079\n",
      "Epoch 136/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 347ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0719 - classifier_accuracy: 0.1132 - classifier_loss: 0.0205 - loss: 0.3075\n",
      "Epoch 137/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 343ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0717 - classifier_accuracy: 0.1140 - classifier_loss: 0.0205 - loss: 0.3070\n",
      "Epoch 138/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 349ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0715 - classifier_accuracy: 0.1147 - classifier_loss: 0.0204 - loss: 0.3065\n",
      "Epoch 139/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 361ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0713 - classifier_accuracy: 0.1153 - classifier_loss: 0.0204 - loss: 0.3061\n",
      "Epoch 140/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 365ms/step - autoencoder_accuracy: 0.0085 - autoencoder_loss: 0.0712 - classifier_accuracy: 0.1161 - classifier_loss: 0.0203 - loss: 0.3057\n",
      "Epoch 141/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 360ms/step - autoencoder_accuracy: 0.0085 - autoencoder_loss: 0.0710 - classifier_accuracy: 0.1170 - classifier_loss: 0.0203 - loss: 0.3052\n",
      "Epoch 142/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387ms/step - autoencoder_accuracy: 0.0086 - autoencoder_loss: 0.0708 - classifier_accuracy: 0.1179 - classifier_loss: 0.0202 - loss: 0.3048\n",
      "Epoch 143/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 438ms/step - autoencoder_accuracy: 0.0085 - autoencoder_loss: 0.0707 - classifier_accuracy: 0.1192 - classifier_loss: 0.0202 - loss: 0.3044\n",
      "Epoch 144/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476ms/step - autoencoder_accuracy: 0.0085 - autoencoder_loss: 0.0705 - classifier_accuracy: 0.1205 - classifier_loss: 0.0201 - loss: 0.3039\n",
      "Epoch 145/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 611ms/step - autoencoder_accuracy: 0.0086 - autoencoder_loss: 0.0704 - classifier_accuracy: 0.1221 - classifier_loss: 0.0201 - loss: 0.3035\n",
      "Epoch 146/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458ms/step - autoencoder_accuracy: 0.0086 - autoencoder_loss: 0.0702 - classifier_accuracy: 0.1237 - classifier_loss: 0.0201 - loss: 0.3031\n",
      "Epoch 147/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 467ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0701 - classifier_accuracy: 0.1252 - classifier_loss: 0.0200 - loss: 0.3027\n",
      "Epoch 148/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 352ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0699 - classifier_accuracy: 0.1268 - classifier_loss: 0.0200 - loss: 0.3022\n",
      "Epoch 149/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 358ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0698 - classifier_accuracy: 0.1285 - classifier_loss: 0.0199 - loss: 0.3018\n",
      "Epoch 150/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 465ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0696 - classifier_accuracy: 0.1303 - classifier_loss: 0.0199 - loss: 0.3014\n",
      "Epoch 151/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 504ms/step - autoencoder_accuracy: 0.0090 - autoencoder_loss: 0.0695 - classifier_accuracy: 0.1317 - classifier_loss: 0.0198 - loss: 0.3010\n",
      "Epoch 152/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 364ms/step - autoencoder_accuracy: 0.0090 - autoencoder_loss: 0.0694 - classifier_accuracy: 0.1327 - classifier_loss: 0.0198 - loss: 0.3006\n",
      "Epoch 153/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 351ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0692 - classifier_accuracy: 0.1340 - classifier_loss: 0.0197 - loss: 0.3002\n",
      "Epoch 154/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 356ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0691 - classifier_accuracy: 0.1348 - classifier_loss: 0.0197 - loss: 0.2998\n",
      "Epoch 155/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 353ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0690 - classifier_accuracy: 0.1356 - classifier_loss: 0.0196 - loss: 0.2994\n",
      "Epoch 156/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 362ms/step - autoencoder_accuracy: 0.0092 - autoencoder_loss: 0.0688 - classifier_accuracy: 0.1356 - classifier_loss: 0.0196 - loss: 0.2990\n",
      "Epoch 157/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0687 - classifier_accuracy: 0.1359 - classifier_loss: 0.0195 - loss: 0.2986\n",
      "Epoch 158/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 514ms/step - autoencoder_accuracy: 0.0092 - autoencoder_loss: 0.0686 - classifier_accuracy: 0.1356 - classifier_loss: 0.0195 - loss: 0.2982\n",
      "Epoch 159/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0685 - classifier_accuracy: 0.1353 - classifier_loss: 0.0194 - loss: 0.2978\n",
      "Epoch 160/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 345ms/step - autoencoder_accuracy: 0.0092 - autoencoder_loss: 0.0684 - classifier_accuracy: 0.1346 - classifier_loss: 0.0194 - loss: 0.2974\n",
      "Epoch 161/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 352ms/step - autoencoder_accuracy: 0.0092 - autoencoder_loss: 0.0682 - classifier_accuracy: 0.1337 - classifier_loss: 0.0193 - loss: 0.2970\n",
      "Epoch 162/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0681 - classifier_accuracy: 0.1325 - classifier_loss: 0.0193 - loss: 0.2966\n",
      "Epoch 163/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0680 - classifier_accuracy: 0.1315 - classifier_loss: 0.0192 - loss: 0.2962\n",
      "Epoch 164/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0679 - classifier_accuracy: 0.1304 - classifier_loss: 0.0192 - loss: 0.2958\n",
      "Epoch 165/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 357ms/step - autoencoder_accuracy: 0.0095 - autoencoder_loss: 0.0678 - classifier_accuracy: 0.1286 - classifier_loss: 0.0191 - loss: 0.2954\n",
      "Epoch 166/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0677 - classifier_accuracy: 0.1271 - classifier_loss: 0.0191 - loss: 0.2951\n",
      "Epoch 167/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 353ms/step - autoencoder_accuracy: 0.0095 - autoencoder_loss: 0.0676 - classifier_accuracy: 0.1255 - classifier_loss: 0.0190 - loss: 0.2947\n",
      "Epoch 168/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 345ms/step - autoencoder_accuracy: 0.0096 - autoencoder_loss: 0.0674 - classifier_accuracy: 0.1241 - classifier_loss: 0.0190 - loss: 0.2943\n",
      "Epoch 169/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376ms/step - autoencoder_accuracy: 0.0097 - autoencoder_loss: 0.0673 - classifier_accuracy: 0.1227 - classifier_loss: 0.0190 - loss: 0.2939\n",
      "Epoch 170/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 364ms/step - autoencoder_accuracy: 0.0098 - autoencoder_loss: 0.0672 - classifier_accuracy: 0.1212 - classifier_loss: 0.0189 - loss: 0.2936\n",
      "Epoch 171/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 347ms/step - autoencoder_accuracy: 0.0099 - autoencoder_loss: 0.0671 - classifier_accuracy: 0.1198 - classifier_loss: 0.0189 - loss: 0.2932\n",
      "Epoch 172/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 358ms/step - autoencoder_accuracy: 0.0098 - autoencoder_loss: 0.0670 - classifier_accuracy: 0.1189 - classifier_loss: 0.0189 - loss: 0.2928\n",
      "Epoch 173/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 369ms/step - autoencoder_accuracy: 0.0099 - autoencoder_loss: 0.0669 - classifier_accuracy: 0.1180 - classifier_loss: 0.0188 - loss: 0.2924\n",
      "Epoch 174/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 347ms/step - autoencoder_accuracy: 0.0097 - autoencoder_loss: 0.0668 - classifier_accuracy: 0.1173 - classifier_loss: 0.0188 - loss: 0.2921\n",
      "Epoch 175/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 353ms/step - autoencoder_accuracy: 0.0099 - autoencoder_loss: 0.0667 - classifier_accuracy: 0.1174 - classifier_loss: 0.0188 - loss: 0.2917\n",
      "Epoch 176/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403ms/step - autoencoder_accuracy: 0.0099 - autoencoder_loss: 0.0666 - classifier_accuracy: 0.1177 - classifier_loss: 0.0187 - loss: 0.2914\n",
      "Epoch 177/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386ms/step - autoencoder_accuracy: 0.0102 - autoencoder_loss: 0.0664 - classifier_accuracy: 0.1179 - classifier_loss: 0.0187 - loss: 0.2910\n",
      "Epoch 178/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402ms/step - autoencoder_accuracy: 0.0103 - autoencoder_loss: 0.0663 - classifier_accuracy: 0.1183 - classifier_loss: 0.0187 - loss: 0.2907\n",
      "Epoch 179/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376ms/step - autoencoder_accuracy: 0.0104 - autoencoder_loss: 0.0662 - classifier_accuracy: 0.1189 - classifier_loss: 0.0187 - loss: 0.2903\n",
      "Epoch 180/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366ms/step - autoencoder_accuracy: 0.0105 - autoencoder_loss: 0.0662 - classifier_accuracy: 0.1196 - classifier_loss: 0.0186 - loss: 0.2900\n",
      "Epoch 181/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 427ms/step - autoencoder_accuracy: 0.0105 - autoencoder_loss: 0.0661 - classifier_accuracy: 0.1200 - classifier_loss: 0.0186 - loss: 0.2896\n",
      "Epoch 182/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388ms/step - autoencoder_accuracy: 0.0105 - autoencoder_loss: 0.0660 - classifier_accuracy: 0.1202 - classifier_loss: 0.0186 - loss: 0.2893\n",
      "Epoch 183/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490ms/step - autoencoder_accuracy: 0.0106 - autoencoder_loss: 0.0659 - classifier_accuracy: 0.1203 - classifier_loss: 0.0186 - loss: 0.2890\n",
      "Epoch 184/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 358ms/step - autoencoder_accuracy: 0.0109 - autoencoder_loss: 0.0658 - classifier_accuracy: 0.1202 - classifier_loss: 0.0185 - loss: 0.2886\n",
      "Epoch 185/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 412ms/step - autoencoder_accuracy: 0.0110 - autoencoder_loss: 0.0657 - classifier_accuracy: 0.1196 - classifier_loss: 0.0185 - loss: 0.2883\n",
      "Epoch 186/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 360ms/step - autoencoder_accuracy: 0.0113 - autoencoder_loss: 0.0656 - classifier_accuracy: 0.1191 - classifier_loss: 0.0185 - loss: 0.2880\n",
      "Epoch 187/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 360ms/step - autoencoder_accuracy: 0.0114 - autoencoder_loss: 0.0655 - classifier_accuracy: 0.1185 - classifier_loss: 0.0184 - loss: 0.2876\n",
      "Epoch 188/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 364ms/step - autoencoder_accuracy: 0.0115 - autoencoder_loss: 0.0655 - classifier_accuracy: 0.1178 - classifier_loss: 0.0184 - loss: 0.2873\n",
      "Epoch 189/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 370ms/step - autoencoder_accuracy: 0.0115 - autoencoder_loss: 0.0654 - classifier_accuracy: 0.1170 - classifier_loss: 0.0184 - loss: 0.2869\n",
      "Epoch 190/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473ms/step - autoencoder_accuracy: 0.0115 - autoencoder_loss: 0.0653 - classifier_accuracy: 0.1160 - classifier_loss: 0.0184 - loss: 0.2866\n",
      "Epoch 191/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 440ms/step - autoencoder_accuracy: 0.0114 - autoencoder_loss: 0.0652 - classifier_accuracy: 0.1151 - classifier_loss: 0.0183 - loss: 0.2863\n",
      "Epoch 192/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494ms/step - autoencoder_accuracy: 0.0111 - autoencoder_loss: 0.0651 - classifier_accuracy: 0.1143 - classifier_loss: 0.0183 - loss: 0.2859\n",
      "Epoch 193/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 352ms/step - autoencoder_accuracy: 0.0109 - autoencoder_loss: 0.0650 - classifier_accuracy: 0.1138 - classifier_loss: 0.0183 - loss: 0.2856\n",
      "Epoch 194/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 347ms/step - autoencoder_accuracy: 0.0108 - autoencoder_loss: 0.0649 - classifier_accuracy: 0.1133 - classifier_loss: 0.0183 - loss: 0.2853\n",
      "Epoch 195/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 422ms/step - autoencoder_accuracy: 0.0107 - autoencoder_loss: 0.0648 - classifier_accuracy: 0.1127 - classifier_loss: 0.0183 - loss: 0.2849\n",
      "Epoch 196/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 549ms/step - autoencoder_accuracy: 0.0106 - autoencoder_loss: 0.0647 - classifier_accuracy: 0.1122 - classifier_loss: 0.0182 - loss: 0.2846\n",
      "Epoch 197/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 504ms/step - autoencoder_accuracy: 0.0106 - autoencoder_loss: 0.0646 - classifier_accuracy: 0.1116 - classifier_loss: 0.0182 - loss: 0.2843\n",
      "Epoch 198/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452ms/step - autoencoder_accuracy: 0.0106 - autoencoder_loss: 0.0645 - classifier_accuracy: 0.1114 - classifier_loss: 0.0182 - loss: 0.2840\n",
      "Epoch 199/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 572ms/step - autoencoder_accuracy: 0.0107 - autoencoder_loss: 0.0644 - classifier_accuracy: 0.1107 - classifier_loss: 0.0182 - loss: 0.2836\n",
      "Epoch 200/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476ms/step - autoencoder_accuracy: 0.0108 - autoencoder_loss: 0.0644 - classifier_accuracy: 0.1098 - classifier_loss: 0.0182 - loss: 0.2833\n",
      "Epoch 201/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454ms/step - autoencoder_accuracy: 0.0109 - autoencoder_loss: 0.0643 - classifier_accuracy: 0.1092 - classifier_loss: 0.0182 - loss: 0.2830\n",
      "Epoch 202/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 440ms/step - autoencoder_accuracy: 0.0109 - autoencoder_loss: 0.0642 - classifier_accuracy: 0.1086 - classifier_loss: 0.0181 - loss: 0.2827\n",
      "Epoch 203/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492ms/step - autoencoder_accuracy: 0.0112 - autoencoder_loss: 0.0641 - classifier_accuracy: 0.1082 - classifier_loss: 0.0181 - loss: 0.2824\n",
      "Epoch 204/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 528ms/step - autoencoder_accuracy: 0.0113 - autoencoder_loss: 0.0640 - classifier_accuracy: 0.1076 - classifier_loss: 0.0181 - loss: 0.2820\n",
      "Epoch 205/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 527ms/step - autoencoder_accuracy: 0.0114 - autoencoder_loss: 0.0639 - classifier_accuracy: 0.1069 - classifier_loss: 0.0181 - loss: 0.2817\n",
      "Epoch 206/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 469ms/step - autoencoder_accuracy: 0.0114 - autoencoder_loss: 0.0638 - classifier_accuracy: 0.1063 - classifier_loss: 0.0181 - loss: 0.2814\n",
      "Epoch 207/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407ms/step - autoencoder_accuracy: 0.0114 - autoencoder_loss: 0.0637 - classifier_accuracy: 0.1057 - classifier_loss: 0.0180 - loss: 0.2810\n",
      "Epoch 208/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 554ms/step - autoencoder_accuracy: 0.0114 - autoencoder_loss: 0.0637 - classifier_accuracy: 0.1050 - classifier_loss: 0.0180 - loss: 0.2807\n",
      "Epoch 209/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 427ms/step - autoencoder_accuracy: 0.0113 - autoencoder_loss: 0.0636 - classifier_accuracy: 0.1043 - classifier_loss: 0.0180 - loss: 0.2804\n",
      "Epoch 210/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398ms/step - autoencoder_accuracy: 0.0113 - autoencoder_loss: 0.0635 - classifier_accuracy: 0.1041 - classifier_loss: 0.0179 - loss: 0.2800\n",
      "Epoch 211/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 337ms/step - autoencoder_accuracy: 0.0112 - autoencoder_loss: 0.0634 - classifier_accuracy: 0.1042 - classifier_loss: 0.0179 - loss: 0.2797\n",
      "Epoch 212/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366ms/step - autoencoder_accuracy: 0.0110 - autoencoder_loss: 0.0633 - classifier_accuracy: 0.1043 - classifier_loss: 0.0179 - loss: 0.2794\n",
      "Epoch 213/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 442ms/step - autoencoder_accuracy: 0.0110 - autoencoder_loss: 0.0632 - classifier_accuracy: 0.1046 - classifier_loss: 0.0178 - loss: 0.2790\n",
      "Epoch 214/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479ms/step - autoencoder_accuracy: 0.0108 - autoencoder_loss: 0.0631 - classifier_accuracy: 0.1053 - classifier_loss: 0.0178 - loss: 0.2787\n",
      "Epoch 215/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445ms/step - autoencoder_accuracy: 0.0106 - autoencoder_loss: 0.0630 - classifier_accuracy: 0.1064 - classifier_loss: 0.0178 - loss: 0.2783\n",
      "Epoch 216/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 524ms/step - autoencoder_accuracy: 0.0104 - autoencoder_loss: 0.0629 - classifier_accuracy: 0.1072 - classifier_loss: 0.0178 - loss: 0.2780\n",
      "Epoch 217/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 514ms/step - autoencoder_accuracy: 0.0105 - autoencoder_loss: 0.0628 - classifier_accuracy: 0.1081 - classifier_loss: 0.0177 - loss: 0.2777\n",
      "Epoch 218/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 513ms/step - autoencoder_accuracy: 0.0104 - autoencoder_loss: 0.0627 - classifier_accuracy: 0.1093 - classifier_loss: 0.0177 - loss: 0.2773\n",
      "Epoch 219/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 353ms/step - autoencoder_accuracy: 0.0104 - autoencoder_loss: 0.0626 - classifier_accuracy: 0.1104 - classifier_loss: 0.0177 - loss: 0.2770\n",
      "Epoch 220/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 356ms/step - autoencoder_accuracy: 0.0104 - autoencoder_loss: 0.0625 - classifier_accuracy: 0.1116 - classifier_loss: 0.0176 - loss: 0.2766\n",
      "Epoch 221/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457ms/step - autoencoder_accuracy: 0.0104 - autoencoder_loss: 0.0625 - classifier_accuracy: 0.1128 - classifier_loss: 0.0176 - loss: 0.2763\n",
      "Epoch 222/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451ms/step - autoencoder_accuracy: 0.0103 - autoencoder_loss: 0.0624 - classifier_accuracy: 0.1141 - classifier_loss: 0.0175 - loss: 0.2759\n",
      "Epoch 223/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 435ms/step - autoencoder_accuracy: 0.0103 - autoencoder_loss: 0.0623 - classifier_accuracy: 0.1153 - classifier_loss: 0.0175 - loss: 0.2756\n",
      "Epoch 224/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384ms/step - autoencoder_accuracy: 0.0103 - autoencoder_loss: 0.0622 - classifier_accuracy: 0.1162 - classifier_loss: 0.0175 - loss: 0.2753\n",
      "Epoch 225/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 367ms/step - autoencoder_accuracy: 0.0102 - autoencoder_loss: 0.0621 - classifier_accuracy: 0.1172 - classifier_loss: 0.0174 - loss: 0.2749\n",
      "Epoch 226/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 515ms/step - autoencoder_accuracy: 0.0100 - autoencoder_loss: 0.0620 - classifier_accuracy: 0.1179 - classifier_loss: 0.0174 - loss: 0.2746\n",
      "Epoch 227/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 437ms/step - autoencoder_accuracy: 0.0099 - autoencoder_loss: 0.0619 - classifier_accuracy: 0.1190 - classifier_loss: 0.0173 - loss: 0.2742\n",
      "Epoch 228/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 364ms/step - autoencoder_accuracy: 0.0098 - autoencoder_loss: 0.0619 - classifier_accuracy: 0.1202 - classifier_loss: 0.0173 - loss: 0.2739\n",
      "Epoch 229/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397ms/step - autoencoder_accuracy: 0.0097 - autoencoder_loss: 0.0618 - classifier_accuracy: 0.1212 - classifier_loss: 0.0173 - loss: 0.2736\n",
      "Epoch 230/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0617 - classifier_accuracy: 0.1222 - classifier_loss: 0.0172 - loss: 0.2732\n",
      "Epoch 231/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 362ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0616 - classifier_accuracy: 0.1236 - classifier_loss: 0.0172 - loss: 0.2729\n",
      "Epoch 232/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0615 - classifier_accuracy: 0.1249 - classifier_loss: 0.0171 - loss: 0.2725\n",
      "Epoch 233/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 560ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0614 - classifier_accuracy: 0.1259 - classifier_loss: 0.0171 - loss: 0.2722\n",
      "Epoch 234/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 527ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0614 - classifier_accuracy: 0.1273 - classifier_loss: 0.0171 - loss: 0.2719\n",
      "Epoch 235/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 586ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0613 - classifier_accuracy: 0.1287 - classifier_loss: 0.0170 - loss: 0.2715\n",
      "Epoch 236/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 516ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0612 - classifier_accuracy: 0.1299 - classifier_loss: 0.0170 - loss: 0.2712\n",
      "Epoch 237/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 506ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0611 - classifier_accuracy: 0.1313 - classifier_loss: 0.0169 - loss: 0.2709\n",
      "Epoch 238/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0610 - classifier_accuracy: 0.1324 - classifier_loss: 0.0169 - loss: 0.2706\n",
      "Epoch 239/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0610 - classifier_accuracy: 0.1338 - classifier_loss: 0.0169 - loss: 0.2702\n",
      "Epoch 240/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0609 - classifier_accuracy: 0.1348 - classifier_loss: 0.0168 - loss: 0.2699\n",
      "Epoch 241/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 548ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0608 - classifier_accuracy: 0.1358 - classifier_loss: 0.0168 - loss: 0.2696\n",
      "Epoch 242/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 507ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0607 - classifier_accuracy: 0.1368 - classifier_loss: 0.0167 - loss: 0.2692\n",
      "Epoch 243/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 592ms/step - autoencoder_accuracy: 0.0086 - autoencoder_loss: 0.0607 - classifier_accuracy: 0.1376 - classifier_loss: 0.0167 - loss: 0.2689\n",
      "Epoch 244/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 521ms/step - autoencoder_accuracy: 0.0086 - autoencoder_loss: 0.0606 - classifier_accuracy: 0.1383 - classifier_loss: 0.0167 - loss: 0.2686\n",
      "Epoch 245/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485ms/step - autoencoder_accuracy: 0.0086 - autoencoder_loss: 0.0605 - classifier_accuracy: 0.1392 - classifier_loss: 0.0166 - loss: 0.2683\n",
      "Epoch 246/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step - autoencoder_accuracy: 0.0084 - autoencoder_loss: 0.0604 - classifier_accuracy: 0.1403 - classifier_loss: 0.0166 - loss: 0.2679\n",
      "Epoch 247/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 535ms/step - autoencoder_accuracy: 0.0084 - autoencoder_loss: 0.0604 - classifier_accuracy: 0.1412 - classifier_loss: 0.0166 - loss: 0.2676\n",
      "Epoch 248/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 616ms/step - autoencoder_accuracy: 0.0083 - autoencoder_loss: 0.0603 - classifier_accuracy: 0.1426 - classifier_loss: 0.0165 - loss: 0.2673\n",
      "Epoch 249/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 634ms/step - autoencoder_accuracy: 0.0082 - autoencoder_loss: 0.0602 - classifier_accuracy: 0.1440 - classifier_loss: 0.0165 - loss: 0.2670\n",
      "Epoch 250/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 524ms/step - autoencoder_accuracy: 0.0081 - autoencoder_loss: 0.0601 - classifier_accuracy: 0.1454 - classifier_loss: 0.0164 - loss: 0.2666\n",
      "Epoch 251/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 648ms/step - autoencoder_accuracy: 0.0081 - autoencoder_loss: 0.0601 - classifier_accuracy: 0.1469 - classifier_loss: 0.0164 - loss: 0.2663\n",
      "Epoch 252/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 581ms/step - autoencoder_accuracy: 0.0081 - autoencoder_loss: 0.0600 - classifier_accuracy: 0.1482 - classifier_loss: 0.0164 - loss: 0.2660\n",
      "Epoch 253/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 519ms/step - autoencoder_accuracy: 0.0080 - autoencoder_loss: 0.0599 - classifier_accuracy: 0.1492 - classifier_loss: 0.0163 - loss: 0.2657\n",
      "Epoch 254/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496ms/step - autoencoder_accuracy: 0.0080 - autoencoder_loss: 0.0599 - classifier_accuracy: 0.1505 - classifier_loss: 0.0163 - loss: 0.2654\n",
      "Epoch 255/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 519ms/step - autoencoder_accuracy: 0.0080 - autoencoder_loss: 0.0598 - classifier_accuracy: 0.1514 - classifier_loss: 0.0163 - loss: 0.2651\n",
      "Epoch 256/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 549ms/step - autoencoder_accuracy: 0.0079 - autoencoder_loss: 0.0597 - classifier_accuracy: 0.1522 - classifier_loss: 0.0162 - loss: 0.2647\n",
      "Epoch 257/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 681ms/step - autoencoder_accuracy: 0.0079 - autoencoder_loss: 0.0597 - classifier_accuracy: 0.1530 - classifier_loss: 0.0162 - loss: 0.2644\n",
      "Epoch 258/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 660ms/step - autoencoder_accuracy: 0.0078 - autoencoder_loss: 0.0596 - classifier_accuracy: 0.1535 - classifier_loss: 0.0161 - loss: 0.2641\n",
      "Epoch 259/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 649ms/step - autoencoder_accuracy: 0.0079 - autoencoder_loss: 0.0595 - classifier_accuracy: 0.1539 - classifier_loss: 0.0161 - loss: 0.2638\n",
      "Epoch 260/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 620ms/step - autoencoder_accuracy: 0.0079 - autoencoder_loss: 0.0594 - classifier_accuracy: 0.1542 - classifier_loss: 0.0161 - loss: 0.2635\n",
      "Epoch 261/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 529ms/step - autoencoder_accuracy: 0.0078 - autoencoder_loss: 0.0594 - classifier_accuracy: 0.1547 - classifier_loss: 0.0160 - loss: 0.2631\n",
      "Epoch 262/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 368ms/step - autoencoder_accuracy: 0.0078 - autoencoder_loss: 0.0593 - classifier_accuracy: 0.1547 - classifier_loss: 0.0160 - loss: 0.2628\n",
      "Epoch 263/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 514ms/step - autoencoder_accuracy: 0.0078 - autoencoder_loss: 0.0592 - classifier_accuracy: 0.1547 - classifier_loss: 0.0159 - loss: 0.2625\n",
      "Epoch 264/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 405ms/step - autoencoder_accuracy: 0.0078 - autoencoder_loss: 0.0592 - classifier_accuracy: 0.1551 - classifier_loss: 0.0159 - loss: 0.2622\n",
      "Epoch 265/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379ms/step - autoencoder_accuracy: 0.0078 - autoencoder_loss: 0.0591 - classifier_accuracy: 0.1551 - classifier_loss: 0.0159 - loss: 0.2619\n",
      "Epoch 266/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382ms/step - autoencoder_accuracy: 0.0077 - autoencoder_loss: 0.0590 - classifier_accuracy: 0.1550 - classifier_loss: 0.0158 - loss: 0.2616\n",
      "Epoch 267/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393ms/step - autoencoder_accuracy: 0.0079 - autoencoder_loss: 0.0590 - classifier_accuracy: 0.1551 - classifier_loss: 0.0158 - loss: 0.2613\n",
      "Epoch 268/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 511ms/step - autoencoder_accuracy: 0.0080 - autoencoder_loss: 0.0589 - classifier_accuracy: 0.1551 - classifier_loss: 0.0158 - loss: 0.2609\n",
      "Epoch 269/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493ms/step - autoencoder_accuracy: 0.0080 - autoencoder_loss: 0.0588 - classifier_accuracy: 0.1551 - classifier_loss: 0.0157 - loss: 0.2606\n",
      "Epoch 270/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476ms/step - autoencoder_accuracy: 0.0079 - autoencoder_loss: 0.0588 - classifier_accuracy: 0.1552 - classifier_loss: 0.0157 - loss: 0.2603\n",
      "Epoch 271/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481ms/step - autoencoder_accuracy: 0.0078 - autoencoder_loss: 0.0587 - classifier_accuracy: 0.1553 - classifier_loss: 0.0156 - loss: 0.2600\n",
      "Epoch 272/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393ms/step - autoencoder_accuracy: 0.0079 - autoencoder_loss: 0.0586 - classifier_accuracy: 0.1553 - classifier_loss: 0.0156 - loss: 0.2597\n",
      "Epoch 273/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - autoencoder_accuracy: 0.0079 - autoencoder_loss: 0.0585 - classifier_accuracy: 0.1552 - classifier_loss: 0.0155 - loss: 0.2593\n",
      "Epoch 274/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492ms/step - autoencoder_accuracy: 0.0079 - autoencoder_loss: 0.0585 - classifier_accuracy: 0.1552 - classifier_loss: 0.0155 - loss: 0.2590\n",
      "Epoch 275/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455ms/step - autoencoder_accuracy: 0.0078 - autoencoder_loss: 0.0584 - classifier_accuracy: 0.1553 - classifier_loss: 0.0155 - loss: 0.2587\n",
      "Epoch 276/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473ms/step - autoencoder_accuracy: 0.0079 - autoencoder_loss: 0.0583 - classifier_accuracy: 0.1556 - classifier_loss: 0.0154 - loss: 0.2584\n",
      "Epoch 277/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484ms/step - autoencoder_accuracy: 0.0079 - autoencoder_loss: 0.0583 - classifier_accuracy: 0.1559 - classifier_loss: 0.0154 - loss: 0.2581\n",
      "Epoch 278/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 505ms/step - autoencoder_accuracy: 0.0080 - autoencoder_loss: 0.0582 - classifier_accuracy: 0.1562 - classifier_loss: 0.0154 - loss: 0.2578\n",
      "Epoch 279/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 627ms/step - autoencoder_accuracy: 0.0080 - autoencoder_loss: 0.0581 - classifier_accuracy: 0.1567 - classifier_loss: 0.0153 - loss: 0.2574\n",
      "Epoch 280/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 358ms/step - autoencoder_accuracy: 0.0080 - autoencoder_loss: 0.0580 - classifier_accuracy: 0.1570 - classifier_loss: 0.0153 - loss: 0.2571\n",
      "Epoch 281/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451ms/step - autoencoder_accuracy: 0.0081 - autoencoder_loss: 0.0580 - classifier_accuracy: 0.1572 - classifier_loss: 0.0153 - loss: 0.2568\n",
      "Epoch 282/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466ms/step - autoencoder_accuracy: 0.0081 - autoencoder_loss: 0.0579 - classifier_accuracy: 0.1572 - classifier_loss: 0.0152 - loss: 0.2565\n",
      "Epoch 283/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384ms/step - autoencoder_accuracy: 0.0082 - autoencoder_loss: 0.0578 - classifier_accuracy: 0.1574 - classifier_loss: 0.0152 - loss: 0.2562\n",
      "Epoch 284/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388ms/step - autoencoder_accuracy: 0.0082 - autoencoder_loss: 0.0577 - classifier_accuracy: 0.1578 - classifier_loss: 0.0152 - loss: 0.2559\n",
      "Epoch 285/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377ms/step - autoencoder_accuracy: 0.0082 - autoencoder_loss: 0.0577 - classifier_accuracy: 0.1577 - classifier_loss: 0.0151 - loss: 0.2556\n",
      "Epoch 286/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355ms/step - autoencoder_accuracy: 0.0083 - autoencoder_loss: 0.0576 - classifier_accuracy: 0.1576 - classifier_loss: 0.0151 - loss: 0.2553\n",
      "Epoch 287/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457ms/step - autoencoder_accuracy: 0.0084 - autoencoder_loss: 0.0575 - classifier_accuracy: 0.1574 - classifier_loss: 0.0151 - loss: 0.2550\n",
      "Epoch 288/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 522ms/step - autoencoder_accuracy: 0.0085 - autoencoder_loss: 0.0575 - classifier_accuracy: 0.1571 - classifier_loss: 0.0150 - loss: 0.2547\n",
      "Epoch 289/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 536ms/step - autoencoder_accuracy: 0.0084 - autoencoder_loss: 0.0574 - classifier_accuracy: 0.1565 - classifier_loss: 0.0150 - loss: 0.2544\n",
      "Epoch 290/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448ms/step - autoencoder_accuracy: 0.0084 - autoencoder_loss: 0.0573 - classifier_accuracy: 0.1559 - classifier_loss: 0.0150 - loss: 0.2541\n",
      "Epoch 291/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0572 - classifier_accuracy: 0.1555 - classifier_loss: 0.0149 - loss: 0.2537\n",
      "Epoch 292/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0572 - classifier_accuracy: 0.1549 - classifier_loss: 0.0149 - loss: 0.2534\n",
      "Epoch 293/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0571 - classifier_accuracy: 0.1541 - classifier_loss: 0.0148 - loss: 0.2531\n",
      "Epoch 294/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0570 - classifier_accuracy: 0.1533 - classifier_loss: 0.0148 - loss: 0.2528\n",
      "Epoch 295/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0570 - classifier_accuracy: 0.1527 - classifier_loss: 0.0148 - loss: 0.2525\n",
      "Epoch 296/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 440ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0569 - classifier_accuracy: 0.1523 - classifier_loss: 0.0147 - loss: 0.2522\n",
      "Epoch 297/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0568 - classifier_accuracy: 0.1517 - classifier_loss: 0.0147 - loss: 0.2519\n",
      "Epoch 298/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0568 - classifier_accuracy: 0.1512 - classifier_loss: 0.0146 - loss: 0.2516\n",
      "Epoch 299/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 357ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0567 - classifier_accuracy: 0.1507 - classifier_loss: 0.0146 - loss: 0.2513\n",
      "Epoch 300/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 344ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0566 - classifier_accuracy: 0.1505 - classifier_loss: 0.0146 - loss: 0.2509\n",
      "Epoch 301/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 347ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0566 - classifier_accuracy: 0.1503 - classifier_loss: 0.0145 - loss: 0.2506\n",
      "Epoch 302/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0565 - classifier_accuracy: 0.1502 - classifier_loss: 0.0145 - loss: 0.2503\n",
      "Epoch 303/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 371ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0564 - classifier_accuracy: 0.1499 - classifier_loss: 0.0144 - loss: 0.2500\n",
      "Epoch 304/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 367ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0563 - classifier_accuracy: 0.1499 - classifier_loss: 0.0144 - loss: 0.2497\n",
      "Epoch 305/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 435ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0563 - classifier_accuracy: 0.1500 - classifier_loss: 0.0143 - loss: 0.2494\n",
      "Epoch 306/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0562 - classifier_accuracy: 0.1500 - classifier_loss: 0.0143 - loss: 0.2491\n",
      "Epoch 307/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0562 - classifier_accuracy: 0.1498 - classifier_loss: 0.0143 - loss: 0.2488\n",
      "Epoch 308/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 360ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0561 - classifier_accuracy: 0.1492 - classifier_loss: 0.0142 - loss: 0.2485\n",
      "Epoch 309/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0560 - classifier_accuracy: 0.1489 - classifier_loss: 0.0142 - loss: 0.2482\n",
      "Epoch 310/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 341ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0560 - classifier_accuracy: 0.1484 - classifier_loss: 0.0141 - loss: 0.2478\n",
      "Epoch 311/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 365ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0559 - classifier_accuracy: 0.1477 - classifier_loss: 0.0141 - loss: 0.2475\n",
      "Epoch 312/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0558 - classifier_accuracy: 0.1468 - classifier_loss: 0.0140 - loss: 0.2472\n",
      "Epoch 313/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0558 - classifier_accuracy: 0.1460 - classifier_loss: 0.0140 - loss: 0.2469\n",
      "Epoch 314/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0557 - classifier_accuracy: 0.1452 - classifier_loss: 0.0139 - loss: 0.2466\n",
      "Epoch 315/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 504ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0557 - classifier_accuracy: 0.1444 - classifier_loss: 0.0139 - loss: 0.2463\n",
      "Epoch 316/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402ms/step - autoencoder_accuracy: 0.0090 - autoencoder_loss: 0.0556 - classifier_accuracy: 0.1435 - classifier_loss: 0.0138 - loss: 0.2460\n",
      "Epoch 317/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384ms/step - autoencoder_accuracy: 0.0090 - autoencoder_loss: 0.0555 - classifier_accuracy: 0.1427 - classifier_loss: 0.0138 - loss: 0.2456\n",
      "Epoch 318/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0555 - classifier_accuracy: 0.1421 - classifier_loss: 0.0137 - loss: 0.2453\n",
      "Epoch 319/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382ms/step - autoencoder_accuracy: 0.0090 - autoencoder_loss: 0.0554 - classifier_accuracy: 0.1414 - classifier_loss: 0.0137 - loss: 0.2450\n",
      "Epoch 320/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0554 - classifier_accuracy: 0.1408 - classifier_loss: 0.0136 - loss: 0.2447\n",
      "Epoch 321/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460ms/step - autoencoder_accuracy: 0.0092 - autoencoder_loss: 0.0553 - classifier_accuracy: 0.1402 - classifier_loss: 0.0136 - loss: 0.2444\n",
      "Epoch 322/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 426ms/step - autoencoder_accuracy: 0.0092 - autoencoder_loss: 0.0552 - classifier_accuracy: 0.1398 - classifier_loss: 0.0135 - loss: 0.2441\n",
      "Epoch 323/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 348ms/step - autoencoder_accuracy: 0.0092 - autoencoder_loss: 0.0552 - classifier_accuracy: 0.1393 - classifier_loss: 0.0135 - loss: 0.2438\n",
      "Epoch 324/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 370ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0551 - classifier_accuracy: 0.1389 - classifier_loss: 0.0134 - loss: 0.2434\n",
      "Epoch 325/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0550 - classifier_accuracy: 0.1384 - classifier_loss: 0.0134 - loss: 0.2431\n",
      "Epoch 326/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 351ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0550 - classifier_accuracy: 0.1378 - classifier_loss: 0.0133 - loss: 0.2428\n",
      "Epoch 327/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 363ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0549 - classifier_accuracy: 0.1370 - classifier_loss: 0.0133 - loss: 0.2425\n",
      "Epoch 328/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 361ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0548 - classifier_accuracy: 0.1364 - classifier_loss: 0.0132 - loss: 0.2422\n",
      "Epoch 329/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0548 - classifier_accuracy: 0.1357 - classifier_loss: 0.0132 - loss: 0.2419\n",
      "Epoch 330/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0547 - classifier_accuracy: 0.1348 - classifier_loss: 0.0131 - loss: 0.2416\n",
      "Epoch 331/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0547 - classifier_accuracy: 0.1340 - classifier_loss: 0.0131 - loss: 0.2413\n",
      "Epoch 332/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 356ms/step - autoencoder_accuracy: 0.0095 - autoencoder_loss: 0.0546 - classifier_accuracy: 0.1332 - classifier_loss: 0.0130 - loss: 0.2409\n",
      "Epoch 333/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 345ms/step - autoencoder_accuracy: 0.0095 - autoencoder_loss: 0.0545 - classifier_accuracy: 0.1325 - classifier_loss: 0.0130 - loss: 0.2406\n",
      "Epoch 334/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 412ms/step - autoencoder_accuracy: 0.0095 - autoencoder_loss: 0.0545 - classifier_accuracy: 0.1316 - classifier_loss: 0.0129 - loss: 0.2403\n",
      "Epoch 335/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 423ms/step - autoencoder_accuracy: 0.0095 - autoencoder_loss: 0.0544 - classifier_accuracy: 0.1308 - classifier_loss: 0.0129 - loss: 0.2400\n",
      "Epoch 336/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 471ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0544 - classifier_accuracy: 0.1302 - classifier_loss: 0.0128 - loss: 0.2397\n",
      "Epoch 337/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0543 - classifier_accuracy: 0.1295 - classifier_loss: 0.0128 - loss: 0.2394\n",
      "Epoch 338/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477ms/step - autoencoder_accuracy: 0.0095 - autoencoder_loss: 0.0542 - classifier_accuracy: 0.1290 - classifier_loss: 0.0127 - loss: 0.2391\n",
      "Epoch 339/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 567ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0542 - classifier_accuracy: 0.1285 - classifier_loss: 0.0127 - loss: 0.2388\n",
      "Epoch 340/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 541ms/step - autoencoder_accuracy: 0.0096 - autoencoder_loss: 0.0541 - classifier_accuracy: 0.1280 - classifier_loss: 0.0126 - loss: 0.2385\n",
      "Epoch 341/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 521ms/step - autoencoder_accuracy: 0.0096 - autoencoder_loss: 0.0540 - classifier_accuracy: 0.1276 - classifier_loss: 0.0126 - loss: 0.2382\n",
      "Epoch 342/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 519ms/step - autoencoder_accuracy: 0.0097 - autoencoder_loss: 0.0540 - classifier_accuracy: 0.1270 - classifier_loss: 0.0125 - loss: 0.2379\n",
      "Epoch 343/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486ms/step - autoencoder_accuracy: 0.0098 - autoencoder_loss: 0.0539 - classifier_accuracy: 0.1263 - classifier_loss: 0.0125 - loss: 0.2376\n",
      "Epoch 344/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 421ms/step - autoencoder_accuracy: 0.0097 - autoencoder_loss: 0.0539 - classifier_accuracy: 0.1259 - classifier_loss: 0.0124 - loss: 0.2372\n",
      "Epoch 345/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 569ms/step - autoencoder_accuracy: 0.0097 - autoencoder_loss: 0.0538 - classifier_accuracy: 0.1255 - classifier_loss: 0.0124 - loss: 0.2369\n",
      "Epoch 346/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490ms/step - autoencoder_accuracy: 0.0096 - autoencoder_loss: 0.0537 - classifier_accuracy: 0.1250 - classifier_loss: 0.0123 - loss: 0.2366\n",
      "Epoch 347/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 540ms/step - autoencoder_accuracy: 0.0095 - autoencoder_loss: 0.0537 - classifier_accuracy: 0.1247 - classifier_loss: 0.0123 - loss: 0.2363\n",
      "Epoch 348/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470ms/step - autoencoder_accuracy: 0.0095 - autoencoder_loss: 0.0536 - classifier_accuracy: 0.1245 - classifier_loss: 0.0122 - loss: 0.2360\n",
      "Epoch 349/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 508ms/step - autoencoder_accuracy: 0.0096 - autoencoder_loss: 0.0535 - classifier_accuracy: 0.1244 - classifier_loss: 0.0122 - loss: 0.2357\n",
      "Epoch 350/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 529ms/step - autoencoder_accuracy: 0.0096 - autoencoder_loss: 0.0535 - classifier_accuracy: 0.1239 - classifier_loss: 0.0121 - loss: 0.2354\n",
      "Epoch 351/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 522ms/step - autoencoder_accuracy: 0.0095 - autoencoder_loss: 0.0534 - classifier_accuracy: 0.1236 - classifier_loss: 0.0121 - loss: 0.2351\n",
      "Epoch 352/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 543ms/step - autoencoder_accuracy: 0.0096 - autoencoder_loss: 0.0534 - classifier_accuracy: 0.1232 - classifier_loss: 0.0120 - loss: 0.2348\n",
      "Epoch 353/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493ms/step - autoencoder_accuracy: 0.0096 - autoencoder_loss: 0.0533 - classifier_accuracy: 0.1229 - classifier_loss: 0.0120 - loss: 0.2345\n",
      "Epoch 354/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 365ms/step - autoencoder_accuracy: 0.0095 - autoencoder_loss: 0.0532 - classifier_accuracy: 0.1224 - classifier_loss: 0.0119 - loss: 0.2342\n",
      "Epoch 355/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377ms/step - autoencoder_accuracy: 0.0095 - autoencoder_loss: 0.0532 - classifier_accuracy: 0.1217 - classifier_loss: 0.0119 - loss: 0.2339\n",
      "Epoch 356/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401ms/step - autoencoder_accuracy: 0.0095 - autoencoder_loss: 0.0531 - classifier_accuracy: 0.1211 - classifier_loss: 0.0118 - loss: 0.2336\n",
      "Epoch 357/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366ms/step - autoencoder_accuracy: 0.0095 - autoencoder_loss: 0.0531 - classifier_accuracy: 0.1204 - classifier_loss: 0.0118 - loss: 0.2333\n",
      "Epoch 358/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 371ms/step - autoencoder_accuracy: 0.0096 - autoencoder_loss: 0.0530 - classifier_accuracy: 0.1197 - classifier_loss: 0.0117 - loss: 0.2330\n",
      "Epoch 359/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477ms/step - autoencoder_accuracy: 0.0097 - autoencoder_loss: 0.0529 - classifier_accuracy: 0.1190 - classifier_loss: 0.0117 - loss: 0.2327\n",
      "Epoch 360/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496ms/step - autoencoder_accuracy: 0.0095 - autoencoder_loss: 0.0529 - classifier_accuracy: 0.1183 - classifier_loss: 0.0116 - loss: 0.2324\n",
      "Epoch 361/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 441ms/step - autoencoder_accuracy: 0.0096 - autoencoder_loss: 0.0528 - classifier_accuracy: 0.1177 - classifier_loss: 0.0116 - loss: 0.2321\n",
      "Epoch 362/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 352ms/step - autoencoder_accuracy: 0.0095 - autoencoder_loss: 0.0528 - classifier_accuracy: 0.1172 - classifier_loss: 0.0115 - loss: 0.2318\n",
      "Epoch 363/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 352ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0527 - classifier_accuracy: 0.1166 - classifier_loss: 0.0115 - loss: 0.2315\n",
      "Epoch 364/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 427ms/step - autoencoder_accuracy: 0.0095 - autoencoder_loss: 0.0526 - classifier_accuracy: 0.1161 - classifier_loss: 0.0114 - loss: 0.2312\n",
      "Epoch 365/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 501ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0526 - classifier_accuracy: 0.1158 - classifier_loss: 0.0114 - loss: 0.2308\n",
      "Epoch 366/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 545ms/step - autoencoder_accuracy: 0.0095 - autoencoder_loss: 0.0525 - classifier_accuracy: 0.1154 - classifier_loss: 0.0113 - loss: 0.2305\n",
      "Epoch 367/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 518ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0525 - classifier_accuracy: 0.1151 - classifier_loss: 0.0113 - loss: 0.2302\n",
      "Epoch 368/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0524 - classifier_accuracy: 0.1151 - classifier_loss: 0.0112 - loss: 0.2299\n",
      "Epoch 369/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 364ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0524 - classifier_accuracy: 0.1150 - classifier_loss: 0.0112 - loss: 0.2296\n",
      "Epoch 370/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 365ms/step - autoencoder_accuracy: 0.0095 - autoencoder_loss: 0.0523 - classifier_accuracy: 0.1151 - classifier_loss: 0.0111 - loss: 0.2293\n",
      "Epoch 371/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 351ms/step - autoencoder_accuracy: 0.0095 - autoencoder_loss: 0.0522 - classifier_accuracy: 0.1149 - classifier_loss: 0.0111 - loss: 0.2290\n",
      "Epoch 372/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 368ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0522 - classifier_accuracy: 0.1148 - classifier_loss: 0.0110 - loss: 0.2288\n",
      "Epoch 373/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 536ms/step - autoencoder_accuracy: 0.0095 - autoencoder_loss: 0.0521 - classifier_accuracy: 0.1149 - classifier_loss: 0.0110 - loss: 0.2285\n",
      "Epoch 374/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0521 - classifier_accuracy: 0.1149 - classifier_loss: 0.0109 - loss: 0.2282\n",
      "Epoch 375/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0520 - classifier_accuracy: 0.1150 - classifier_loss: 0.0109 - loss: 0.2279\n",
      "Epoch 376/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0520 - classifier_accuracy: 0.1151 - classifier_loss: 0.0108 - loss: 0.2276\n",
      "Epoch 377/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 729ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0519 - classifier_accuracy: 0.1152 - classifier_loss: 0.0108 - loss: 0.2273\n",
      "Epoch 378/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 651ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0519 - classifier_accuracy: 0.1150 - classifier_loss: 0.0108 - loss: 0.2270\n",
      "Epoch 379/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 657ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0518 - classifier_accuracy: 0.1147 - classifier_loss: 0.0107 - loss: 0.2267\n",
      "Epoch 380/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 690ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0518 - classifier_accuracy: 0.1144 - classifier_loss: 0.0107 - loss: 0.2264\n",
      "Epoch 381/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 727ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0517 - classifier_accuracy: 0.1139 - classifier_loss: 0.0106 - loss: 0.2262\n",
      "Epoch 382/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 627ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0517 - classifier_accuracy: 0.1133 - classifier_loss: 0.0106 - loss: 0.2259\n",
      "Epoch 383/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 605ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0516 - classifier_accuracy: 0.1130 - classifier_loss: 0.0105 - loss: 0.2256\n",
      "Epoch 384/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 639ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0516 - classifier_accuracy: 0.1128 - classifier_loss: 0.0105 - loss: 0.2253\n",
      "Epoch 385/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 573ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0515 - classifier_accuracy: 0.1125 - classifier_loss: 0.0104 - loss: 0.2250\n",
      "Epoch 386/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0515 - classifier_accuracy: 0.1122 - classifier_loss: 0.0104 - loss: 0.2247\n",
      "Epoch 387/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0514 - classifier_accuracy: 0.1119 - classifier_loss: 0.0104 - loss: 0.2245\n",
      "Epoch 388/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 483ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0514 - classifier_accuracy: 0.1116 - classifier_loss: 0.0103 - loss: 0.2242\n",
      "Epoch 389/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 635ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0513 - classifier_accuracy: 0.1113 - classifier_loss: 0.0103 - loss: 0.2239\n",
      "Epoch 390/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 546ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0513 - classifier_accuracy: 0.1110 - classifier_loss: 0.0102 - loss: 0.2236\n",
      "Epoch 391/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 416ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0512 - classifier_accuracy: 0.1106 - classifier_loss: 0.0102 - loss: 0.2233\n",
      "Epoch 392/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 358ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0512 - classifier_accuracy: 0.1103 - classifier_loss: 0.0102 - loss: 0.2231\n",
      "Epoch 393/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0511 - classifier_accuracy: 0.1100 - classifier_loss: 0.0101 - loss: 0.2228\n",
      "Epoch 394/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 517ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0511 - classifier_accuracy: 0.1098 - classifier_loss: 0.0101 - loss: 0.2225\n",
      "Epoch 395/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 432ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0511 - classifier_accuracy: 0.1097 - classifier_loss: 0.0100 - loss: 0.2222\n",
      "Epoch 396/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0510 - classifier_accuracy: 0.1095 - classifier_loss: 0.0100 - loss: 0.2219\n",
      "Epoch 397/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 352ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0510 - classifier_accuracy: 0.1095 - classifier_loss: 0.0099 - loss: 0.2217\n",
      "Epoch 398/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 371ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0509 - classifier_accuracy: 0.1095 - classifier_loss: 0.0099 - loss: 0.2214\n",
      "Epoch 399/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 603ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0509 - classifier_accuracy: 0.1094 - classifier_loss: 0.0099 - loss: 0.2211\n",
      "Epoch 400/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0508 - classifier_accuracy: 0.1093 - classifier_loss: 0.0098 - loss: 0.2209\n",
      "Epoch 401/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 369ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0508 - classifier_accuracy: 0.1091 - classifier_loss: 0.0098 - loss: 0.2206\n",
      "Epoch 402/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0507 - classifier_accuracy: 0.1089 - classifier_loss: 0.0097 - loss: 0.2203\n",
      "Epoch 403/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0507 - classifier_accuracy: 0.1088 - classifier_loss: 0.0097 - loss: 0.2200\n",
      "Epoch 404/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 547ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0506 - classifier_accuracy: 0.1085 - classifier_loss: 0.0097 - loss: 0.2198\n",
      "Epoch 405/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 514ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0506 - classifier_accuracy: 0.1084 - classifier_loss: 0.0096 - loss: 0.2195\n",
      "Epoch 406/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0506 - classifier_accuracy: 0.1082 - classifier_loss: 0.0096 - loss: 0.2192\n",
      "Epoch 407/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0505 - classifier_accuracy: 0.1080 - classifier_loss: 0.0096 - loss: 0.2190\n",
      "Epoch 408/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0505 - classifier_accuracy: 0.1081 - classifier_loss: 0.0095 - loss: 0.2187\n",
      "Epoch 409/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 521ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0504 - classifier_accuracy: 0.1082 - classifier_loss: 0.0095 - loss: 0.2185\n",
      "Epoch 410/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 503ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0504 - classifier_accuracy: 0.1081 - classifier_loss: 0.0095 - loss: 0.2182\n",
      "Epoch 411/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0503 - classifier_accuracy: 0.1080 - classifier_loss: 0.0094 - loss: 0.2179\n",
      "Epoch 412/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 359ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0503 - classifier_accuracy: 0.1079 - classifier_loss: 0.0094 - loss: 0.2177\n",
      "Epoch 413/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0503 - classifier_accuracy: 0.1079 - classifier_loss: 0.0094 - loss: 0.2174\n",
      "Epoch 414/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 558ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0502 - classifier_accuracy: 0.1078 - classifier_loss: 0.0093 - loss: 0.2171\n",
      "Epoch 415/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 468ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0502 - classifier_accuracy: 0.1078 - classifier_loss: 0.0093 - loss: 0.2169\n",
      "Epoch 416/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0501 - classifier_accuracy: 0.1076 - classifier_loss: 0.0093 - loss: 0.2166\n",
      "Epoch 417/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 436ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0501 - classifier_accuracy: 0.1076 - classifier_loss: 0.0092 - loss: 0.2164\n",
      "Epoch 418/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0501 - classifier_accuracy: 0.1074 - classifier_loss: 0.0092 - loss: 0.2161\n",
      "Epoch 419/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 526ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0500 - classifier_accuracy: 0.1073 - classifier_loss: 0.0092 - loss: 0.2158\n",
      "Epoch 420/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0500 - classifier_accuracy: 0.1072 - classifier_loss: 0.0091 - loss: 0.2156\n",
      "Epoch 421/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 561ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0499 - classifier_accuracy: 0.1071 - classifier_loss: 0.0091 - loss: 0.2153\n",
      "Epoch 422/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 495ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0499 - classifier_accuracy: 0.1069 - classifier_loss: 0.0091 - loss: 0.2151\n",
      "Epoch 423/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0499 - classifier_accuracy: 0.1067 - classifier_loss: 0.0090 - loss: 0.2148\n",
      "Epoch 424/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 548ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0498 - classifier_accuracy: 0.1065 - classifier_loss: 0.0090 - loss: 0.2146\n",
      "Epoch 425/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 495ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0498 - classifier_accuracy: 0.1062 - classifier_loss: 0.0090 - loss: 0.2143\n",
      "Epoch 426/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0497 - classifier_accuracy: 0.1060 - classifier_loss: 0.0089 - loss: 0.2141\n",
      "Epoch 427/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0497 - classifier_accuracy: 0.1058 - classifier_loss: 0.0089 - loss: 0.2138\n",
      "Epoch 428/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 369ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0497 - classifier_accuracy: 0.1055 - classifier_loss: 0.0089 - loss: 0.2136\n",
      "Epoch 429/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 363ms/step - autoencoder_accuracy: 0.0092 - autoencoder_loss: 0.0496 - classifier_accuracy: 0.1052 - classifier_loss: 0.0089 - loss: 0.2133\n",
      "Epoch 430/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 535ms/step - autoencoder_accuracy: 0.0092 - autoencoder_loss: 0.0496 - classifier_accuracy: 0.1050 - classifier_loss: 0.0088 - loss: 0.2131\n",
      "Epoch 431/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0495 - classifier_accuracy: 0.1048 - classifier_loss: 0.0088 - loss: 0.2128\n",
      "Epoch 432/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 367ms/step - autoencoder_accuracy: 0.0092 - autoencoder_loss: 0.0495 - classifier_accuracy: 0.1048 - classifier_loss: 0.0088 - loss: 0.2126\n",
      "Epoch 433/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 364ms/step - autoencoder_accuracy: 0.0092 - autoencoder_loss: 0.0495 - classifier_accuracy: 0.1047 - classifier_loss: 0.0087 - loss: 0.2123\n",
      "Epoch 434/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0494 - classifier_accuracy: 0.1046 - classifier_loss: 0.0087 - loss: 0.2121\n",
      "Epoch 435/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 522ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0494 - classifier_accuracy: 0.1045 - classifier_loss: 0.0087 - loss: 0.2118\n",
      "Epoch 436/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 427ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0493 - classifier_accuracy: 0.1045 - classifier_loss: 0.0087 - loss: 0.2116\n",
      "Epoch 437/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386ms/step - autoencoder_accuracy: 0.0092 - autoencoder_loss: 0.0493 - classifier_accuracy: 0.1044 - classifier_loss: 0.0086 - loss: 0.2113\n",
      "Epoch 438/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388ms/step - autoencoder_accuracy: 0.0092 - autoencoder_loss: 0.0493 - classifier_accuracy: 0.1044 - classifier_loss: 0.0086 - loss: 0.2111\n",
      "Epoch 439/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0492 - classifier_accuracy: 0.1044 - classifier_loss: 0.0086 - loss: 0.2108\n",
      "Epoch 440/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0492 - classifier_accuracy: 0.1043 - classifier_loss: 0.0085 - loss: 0.2106\n",
      "Epoch 441/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379ms/step - autoencoder_accuracy: 0.0092 - autoencoder_loss: 0.0492 - classifier_accuracy: 0.1042 - classifier_loss: 0.0085 - loss: 0.2104\n",
      "Epoch 442/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 580ms/step - autoencoder_accuracy: 0.0092 - autoencoder_loss: 0.0491 - classifier_accuracy: 0.1040 - classifier_loss: 0.0085 - loss: 0.2101\n",
      "Epoch 443/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 519ms/step - autoencoder_accuracy: 0.0092 - autoencoder_loss: 0.0491 - classifier_accuracy: 0.1037 - classifier_loss: 0.0085 - loss: 0.2099\n",
      "Epoch 444/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 370ms/step - autoencoder_accuracy: 0.0092 - autoencoder_loss: 0.0491 - classifier_accuracy: 0.1034 - classifier_loss: 0.0084 - loss: 0.2096\n",
      "Epoch 445/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0490 - classifier_accuracy: 0.1032 - classifier_loss: 0.0084 - loss: 0.2094\n",
      "Epoch 446/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 551ms/step - autoencoder_accuracy: 0.0092 - autoencoder_loss: 0.0490 - classifier_accuracy: 0.1028 - classifier_loss: 0.0084 - loss: 0.2091\n",
      "Epoch 447/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0490 - classifier_accuracy: 0.1025 - classifier_loss: 0.0084 - loss: 0.2089\n",
      "Epoch 448/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394ms/step - autoencoder_accuracy: 0.0092 - autoencoder_loss: 0.0489 - classifier_accuracy: 0.1024 - classifier_loss: 0.0083 - loss: 0.2087\n",
      "Epoch 449/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0489 - classifier_accuracy: 0.1022 - classifier_loss: 0.0083 - loss: 0.2084\n",
      "Epoch 450/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 553ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0489 - classifier_accuracy: 0.1022 - classifier_loss: 0.0083 - loss: 0.2082\n",
      "Epoch 451/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 467ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0488 - classifier_accuracy: 0.1019 - classifier_loss: 0.0083 - loss: 0.2080\n",
      "Epoch 452/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 369ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0488 - classifier_accuracy: 0.1017 - classifier_loss: 0.0082 - loss: 0.2077\n",
      "Epoch 453/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 441ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0488 - classifier_accuracy: 0.1016 - classifier_loss: 0.0082 - loss: 0.2075\n",
      "Epoch 454/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 539ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0487 - classifier_accuracy: 0.1015 - classifier_loss: 0.0082 - loss: 0.2073\n",
      "Epoch 455/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0487 - classifier_accuracy: 0.1015 - classifier_loss: 0.0082 - loss: 0.2070\n",
      "Epoch 456/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391ms/step - autoencoder_accuracy: 0.0092 - autoencoder_loss: 0.0487 - classifier_accuracy: 0.1014 - classifier_loss: 0.0081 - loss: 0.2068\n",
      "Epoch 457/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366ms/step - autoencoder_accuracy: 0.0092 - autoencoder_loss: 0.0486 - classifier_accuracy: 0.1013 - classifier_loss: 0.0081 - loss: 0.2066\n",
      "Epoch 458/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494ms/step - autoencoder_accuracy: 0.0092 - autoencoder_loss: 0.0486 - classifier_accuracy: 0.1012 - classifier_loss: 0.0081 - loss: 0.2063\n",
      "Epoch 459/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 505ms/step - autoencoder_accuracy: 0.0092 - autoencoder_loss: 0.0486 - classifier_accuracy: 0.1012 - classifier_loss: 0.0081 - loss: 0.2061\n",
      "Epoch 460/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397ms/step - autoencoder_accuracy: 0.0092 - autoencoder_loss: 0.0486 - classifier_accuracy: 0.1010 - classifier_loss: 0.0080 - loss: 0.2059\n",
      "Epoch 461/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0485 - classifier_accuracy: 0.1009 - classifier_loss: 0.0080 - loss: 0.2056\n",
      "Epoch 462/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 556ms/step - autoencoder_accuracy: 0.0092 - autoencoder_loss: 0.0485 - classifier_accuracy: 0.1006 - classifier_loss: 0.0080 - loss: 0.2054\n",
      "Epoch 463/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491ms/step - autoencoder_accuracy: 0.0092 - autoencoder_loss: 0.0485 - classifier_accuracy: 0.1004 - classifier_loss: 0.0080 - loss: 0.2052\n",
      "Epoch 464/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 356ms/step - autoencoder_accuracy: 0.0092 - autoencoder_loss: 0.0484 - classifier_accuracy: 0.1001 - classifier_loss: 0.0079 - loss: 0.2049\n",
      "Epoch 465/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 344ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0484 - classifier_accuracy: 0.0999 - classifier_loss: 0.0079 - loss: 0.2047\n",
      "Epoch 466/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 507ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0484 - classifier_accuracy: 0.0997 - classifier_loss: 0.0079 - loss: 0.2045\n",
      "Epoch 467/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 497ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0483 - classifier_accuracy: 0.0997 - classifier_loss: 0.0079 - loss: 0.2042\n",
      "Epoch 468/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0483 - classifier_accuracy: 0.0995 - classifier_loss: 0.0078 - loss: 0.2040\n",
      "Epoch 469/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0483 - classifier_accuracy: 0.0995 - classifier_loss: 0.0078 - loss: 0.2038\n",
      "Epoch 470/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 560ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0483 - classifier_accuracy: 0.0995 - classifier_loss: 0.0078 - loss: 0.2035\n",
      "Epoch 471/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0482 - classifier_accuracy: 0.0994 - classifier_loss: 0.0078 - loss: 0.2033\n",
      "Epoch 472/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408ms/step - autoencoder_accuracy: 0.0092 - autoencoder_loss: 0.0482 - classifier_accuracy: 0.0994 - classifier_loss: 0.0077 - loss: 0.2031\n",
      "Epoch 473/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388ms/step - autoencoder_accuracy: 0.0092 - autoencoder_loss: 0.0482 - classifier_accuracy: 0.0993 - classifier_loss: 0.0077 - loss: 0.2029\n",
      "Epoch 474/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 538ms/step - autoencoder_accuracy: 0.0092 - autoencoder_loss: 0.0481 - classifier_accuracy: 0.0992 - classifier_loss: 0.0077 - loss: 0.2026\n",
      "Epoch 475/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0481 - classifier_accuracy: 0.0992 - classifier_loss: 0.0077 - loss: 0.2024\n",
      "Epoch 476/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0481 - classifier_accuracy: 0.0991 - classifier_loss: 0.0076 - loss: 0.2022\n",
      "Epoch 477/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0481 - classifier_accuracy: 0.0989 - classifier_loss: 0.0076 - loss: 0.2020\n",
      "Epoch 478/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 517ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0480 - classifier_accuracy: 0.0988 - classifier_loss: 0.0076 - loss: 0.2017\n",
      "Epoch 479/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 441ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0480 - classifier_accuracy: 0.0987 - classifier_loss: 0.0076 - loss: 0.2015\n",
      "Epoch 480/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 372ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0480 - classifier_accuracy: 0.0985 - classifier_loss: 0.0076 - loss: 0.2013\n",
      "Epoch 481/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0480 - classifier_accuracy: 0.0984 - classifier_loss: 0.0075 - loss: 0.2011\n",
      "Epoch 482/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 530ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0479 - classifier_accuracy: 0.0984 - classifier_loss: 0.0075 - loss: 0.2008\n",
      "Epoch 483/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0479 - classifier_accuracy: 0.0983 - classifier_loss: 0.0075 - loss: 0.2006\n",
      "Epoch 484/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 369ms/step - autoencoder_accuracy: 0.0092 - autoencoder_loss: 0.0479 - classifier_accuracy: 0.0982 - classifier_loss: 0.0075 - loss: 0.2004\n",
      "Epoch 485/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375ms/step - autoencoder_accuracy: 0.0092 - autoencoder_loss: 0.0479 - classifier_accuracy: 0.0981 - classifier_loss: 0.0074 - loss: 0.2002\n",
      "Epoch 486/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 508ms/step - autoencoder_accuracy: 0.0092 - autoencoder_loss: 0.0478 - classifier_accuracy: 0.0980 - classifier_loss: 0.0074 - loss: 0.1999\n",
      "Epoch 487/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 429ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0478 - classifier_accuracy: 0.0978 - classifier_loss: 0.0074 - loss: 0.1997\n",
      "Epoch 488/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 426ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0478 - classifier_accuracy: 0.0977 - classifier_loss: 0.0074 - loss: 0.1995\n",
      "Epoch 489/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 371ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0477 - classifier_accuracy: 0.0977 - classifier_loss: 0.0074 - loss: 0.1993\n",
      "Epoch 490/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0477 - classifier_accuracy: 0.0977 - classifier_loss: 0.0073 - loss: 0.1991\n",
      "Epoch 491/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0477 - classifier_accuracy: 0.0976 - classifier_loss: 0.0073 - loss: 0.1988\n",
      "Epoch 492/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0477 - classifier_accuracy: 0.0976 - classifier_loss: 0.0073 - loss: 0.1986\n",
      "Epoch 493/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 546ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0476 - classifier_accuracy: 0.0977 - classifier_loss: 0.0073 - loss: 0.1984\n",
      "Epoch 494/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0476 - classifier_accuracy: 0.0977 - classifier_loss: 0.0072 - loss: 0.1982\n",
      "Epoch 495/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449ms/step - autoencoder_accuracy: 0.0090 - autoencoder_loss: 0.0476 - classifier_accuracy: 0.0977 - classifier_loss: 0.0072 - loss: 0.1980\n",
      "Epoch 496/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411ms/step - autoencoder_accuracy: 0.0090 - autoencoder_loss: 0.0476 - classifier_accuracy: 0.0978 - classifier_loss: 0.0072 - loss: 0.1977\n",
      "Epoch 497/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 547ms/step - autoencoder_accuracy: 0.0090 - autoencoder_loss: 0.0475 - classifier_accuracy: 0.0978 - classifier_loss: 0.0072 - loss: 0.1975\n",
      "Epoch 498/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 426ms/step - autoencoder_accuracy: 0.0090 - autoencoder_loss: 0.0475 - classifier_accuracy: 0.0979 - classifier_loss: 0.0072 - loss: 0.1973\n",
      "Epoch 499/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382ms/step - autoencoder_accuracy: 0.0090 - autoencoder_loss: 0.0475 - classifier_accuracy: 0.0980 - classifier_loss: 0.0071 - loss: 0.1971\n",
      "Epoch 500/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486ms/step - autoencoder_accuracy: 0.0090 - autoencoder_loss: 0.0475 - classifier_accuracy: 0.0980 - classifier_loss: 0.0071 - loss: 0.1969\n",
      "Epoch 501/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466ms/step - autoencoder_accuracy: 0.0090 - autoencoder_loss: 0.0474 - classifier_accuracy: 0.0981 - classifier_loss: 0.0071 - loss: 0.1967\n",
      "Epoch 502/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 513ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0474 - classifier_accuracy: 0.0982 - classifier_loss: 0.0071 - loss: 0.1964\n",
      "Epoch 503/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475ms/step - autoencoder_accuracy: 0.0090 - autoencoder_loss: 0.0474 - classifier_accuracy: 0.0983 - classifier_loss: 0.0071 - loss: 0.1962\n",
      "Epoch 504/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - autoencoder_accuracy: 0.0090 - autoencoder_loss: 0.0474 - classifier_accuracy: 0.0983 - classifier_loss: 0.0070 - loss: 0.1960\n",
      "Epoch 505/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 421ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0473 - classifier_accuracy: 0.0984 - classifier_loss: 0.0070 - loss: 0.1958\n",
      "Epoch 506/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 532ms/step - autoencoder_accuracy: 0.0090 - autoencoder_loss: 0.0473 - classifier_accuracy: 0.0984 - classifier_loss: 0.0070 - loss: 0.1956\n",
      "Epoch 507/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 431ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0473 - classifier_accuracy: 0.0984 - classifier_loss: 0.0070 - loss: 0.1954\n",
      "Epoch 508/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0473 - classifier_accuracy: 0.0984 - classifier_loss: 0.0069 - loss: 0.1951\n",
      "Epoch 509/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 405ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0472 - classifier_accuracy: 0.0983 - classifier_loss: 0.0069 - loss: 0.1949\n",
      "Epoch 510/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0472 - classifier_accuracy: 0.0983 - classifier_loss: 0.0069 - loss: 0.1947\n",
      "Epoch 511/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0472 - classifier_accuracy: 0.0982 - classifier_loss: 0.0069 - loss: 0.1945\n",
      "Epoch 512/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 438ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0472 - classifier_accuracy: 0.0981 - classifier_loss: 0.0069 - loss: 0.1943\n",
      "Epoch 513/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 503ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0471 - classifier_accuracy: 0.0981 - classifier_loss: 0.0068 - loss: 0.1941\n",
      "Epoch 514/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0471 - classifier_accuracy: 0.0981 - classifier_loss: 0.0068 - loss: 0.1939\n",
      "Epoch 515/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 505ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0471 - classifier_accuracy: 0.0981 - classifier_loss: 0.0068 - loss: 0.1936\n",
      "Epoch 516/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 560ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0471 - classifier_accuracy: 0.0979 - classifier_loss: 0.0068 - loss: 0.1934\n",
      "Epoch 517/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0471 - classifier_accuracy: 0.0978 - classifier_loss: 0.0068 - loss: 0.1932\n",
      "Epoch 518/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0470 - classifier_accuracy: 0.0978 - classifier_loss: 0.0067 - loss: 0.1930\n",
      "Epoch 519/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0470 - classifier_accuracy: 0.0976 - classifier_loss: 0.0067 - loss: 0.1928\n",
      "Epoch 520/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 540ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0470 - classifier_accuracy: 0.0975 - classifier_loss: 0.0067 - loss: 0.1926\n",
      "Epoch 521/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0470 - classifier_accuracy: 0.0974 - classifier_loss: 0.0067 - loss: 0.1924\n",
      "Epoch 522/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0469 - classifier_accuracy: 0.0973 - classifier_loss: 0.0067 - loss: 0.1922\n",
      "Epoch 523/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0469 - classifier_accuracy: 0.0973 - classifier_loss: 0.0066 - loss: 0.1919\n",
      "Epoch 524/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 526ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0469 - classifier_accuracy: 0.0972 - classifier_loss: 0.0066 - loss: 0.1917\n",
      "Epoch 525/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 502ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0469 - classifier_accuracy: 0.0972 - classifier_loss: 0.0066 - loss: 0.1915\n",
      "Epoch 526/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 372ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0469 - classifier_accuracy: 0.0971 - classifier_loss: 0.0066 - loss: 0.1913\n",
      "Epoch 527/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0468 - classifier_accuracy: 0.0971 - classifier_loss: 0.0065 - loss: 0.1911\n",
      "Epoch 528/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 551ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0468 - classifier_accuracy: 0.0972 - classifier_loss: 0.0065 - loss: 0.1909\n",
      "Epoch 529/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 502ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0468 - classifier_accuracy: 0.0972 - classifier_loss: 0.0065 - loss: 0.1907\n",
      "Epoch 530/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0468 - classifier_accuracy: 0.0972 - classifier_loss: 0.0065 - loss: 0.1905\n",
      "Epoch 531/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0467 - classifier_accuracy: 0.0973 - classifier_loss: 0.0065 - loss: 0.1903\n",
      "Epoch 532/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 568ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0467 - classifier_accuracy: 0.0972 - classifier_loss: 0.0064 - loss: 0.1901\n",
      "Epoch 533/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 518ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0467 - classifier_accuracy: 0.0972 - classifier_loss: 0.0064 - loss: 0.1898\n",
      "Epoch 534/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 465ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0467 - classifier_accuracy: 0.0972 - classifier_loss: 0.0064 - loss: 0.1896\n",
      "Epoch 535/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 543ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0466 - classifier_accuracy: 0.0973 - classifier_loss: 0.0064 - loss: 0.1894\n",
      "Epoch 536/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 535ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0466 - classifier_accuracy: 0.0972 - classifier_loss: 0.0064 - loss: 0.1892\n",
      "Epoch 537/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0466 - classifier_accuracy: 0.0972 - classifier_loss: 0.0063 - loss: 0.1890\n",
      "Epoch 538/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 352ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0466 - classifier_accuracy: 0.0971 - classifier_loss: 0.0063 - loss: 0.1888\n",
      "Epoch 539/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 362ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0466 - classifier_accuracy: 0.0970 - classifier_loss: 0.0063 - loss: 0.1886\n",
      "Epoch 540/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 525ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0465 - classifier_accuracy: 0.0970 - classifier_loss: 0.0063 - loss: 0.1884\n",
      "Epoch 541/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0465 - classifier_accuracy: 0.0970 - classifier_loss: 0.0063 - loss: 0.1882\n",
      "Epoch 542/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 364ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0465 - classifier_accuracy: 0.0969 - classifier_loss: 0.0063 - loss: 0.1880\n",
      "Epoch 543/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 363ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0465 - classifier_accuracy: 0.0969 - classifier_loss: 0.0062 - loss: 0.1878\n",
      "Epoch 544/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0464 - classifier_accuracy: 0.0969 - classifier_loss: 0.0062 - loss: 0.1876\n",
      "Epoch 545/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0464 - classifier_accuracy: 0.0967 - classifier_loss: 0.0062 - loss: 0.1874\n",
      "Epoch 546/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 359ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0464 - classifier_accuracy: 0.0967 - classifier_loss: 0.0062 - loss: 0.1872\n",
      "Epoch 547/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0464 - classifier_accuracy: 0.0966 - classifier_loss: 0.0062 - loss: 0.1870\n",
      "Epoch 548/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0464 - classifier_accuracy: 0.0966 - classifier_loss: 0.0061 - loss: 0.1868\n",
      "Epoch 549/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 427ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0463 - classifier_accuracy: 0.0966 - classifier_loss: 0.0061 - loss: 0.1866\n",
      "Epoch 550/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 361ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0463 - classifier_accuracy: 0.0967 - classifier_loss: 0.0061 - loss: 0.1864\n",
      "Epoch 551/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0463 - classifier_accuracy: 0.0967 - classifier_loss: 0.0061 - loss: 0.1862\n",
      "Epoch 552/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 422ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0463 - classifier_accuracy: 0.0967 - classifier_loss: 0.0061 - loss: 0.1860\n",
      "Epoch 553/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 429ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0463 - classifier_accuracy: 0.0967 - classifier_loss: 0.0061 - loss: 0.1858\n",
      "Epoch 554/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0462 - classifier_accuracy: 0.0968 - classifier_loss: 0.0060 - loss: 0.1856\n",
      "Epoch 555/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 427ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0462 - classifier_accuracy: 0.0969 - classifier_loss: 0.0060 - loss: 0.1854\n",
      "Epoch 556/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0462 - classifier_accuracy: 0.0969 - classifier_loss: 0.0060 - loss: 0.1852\n",
      "Epoch 557/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0462 - classifier_accuracy: 0.0969 - classifier_loss: 0.0060 - loss: 0.1850\n",
      "Epoch 558/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0461 - classifier_accuracy: 0.0968 - classifier_loss: 0.0060 - loss: 0.1848\n",
      "Epoch 559/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0461 - classifier_accuracy: 0.0968 - classifier_loss: 0.0060 - loss: 0.1846\n",
      "Epoch 560/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0461 - classifier_accuracy: 0.0969 - classifier_loss: 0.0059 - loss: 0.1844\n",
      "Epoch 561/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 514ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0461 - classifier_accuracy: 0.0970 - classifier_loss: 0.0059 - loss: 0.1842\n",
      "Epoch 562/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0461 - classifier_accuracy: 0.0970 - classifier_loss: 0.0059 - loss: 0.1840\n",
      "Epoch 563/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0460 - classifier_accuracy: 0.0969 - classifier_loss: 0.0059 - loss: 0.1838\n",
      "Epoch 564/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 465ms/step - autoencoder_accuracy: 0.0090 - autoencoder_loss: 0.0460 - classifier_accuracy: 0.0969 - classifier_loss: 0.0059 - loss: 0.1836\n",
      "Epoch 565/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473ms/step - autoencoder_accuracy: 0.0090 - autoencoder_loss: 0.0460 - classifier_accuracy: 0.0969 - classifier_loss: 0.0059 - loss: 0.1834\n",
      "Epoch 566/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400ms/step - autoencoder_accuracy: 0.0090 - autoencoder_loss: 0.0460 - classifier_accuracy: 0.0970 - classifier_loss: 0.0058 - loss: 0.1832\n",
      "Epoch 567/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0460 - classifier_accuracy: 0.0970 - classifier_loss: 0.0058 - loss: 0.1830\n",
      "Epoch 568/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0459 - classifier_accuracy: 0.0970 - classifier_loss: 0.0058 - loss: 0.1828\n",
      "Epoch 569/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 344ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0459 - classifier_accuracy: 0.0971 - classifier_loss: 0.0058 - loss: 0.1826\n",
      "Epoch 570/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 512ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0459 - classifier_accuracy: 0.0971 - classifier_loss: 0.0058 - loss: 0.1824\n",
      "Epoch 571/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 438ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0459 - classifier_accuracy: 0.0972 - classifier_loss: 0.0058 - loss: 0.1822\n",
      "Epoch 572/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 367ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0459 - classifier_accuracy: 0.0972 - classifier_loss: 0.0057 - loss: 0.1820\n",
      "Epoch 573/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0458 - classifier_accuracy: 0.0973 - classifier_loss: 0.0057 - loss: 0.1818\n",
      "Epoch 574/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 441ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0458 - classifier_accuracy: 0.0973 - classifier_loss: 0.0057 - loss: 0.1816\n",
      "Epoch 575/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0458 - classifier_accuracy: 0.0973 - classifier_loss: 0.0057 - loss: 0.1814\n",
      "Epoch 576/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0458 - classifier_accuracy: 0.0973 - classifier_loss: 0.0057 - loss: 0.1812\n",
      "Epoch 577/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0458 - classifier_accuracy: 0.0973 - classifier_loss: 0.0057 - loss: 0.1810\n",
      "Epoch 578/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 368ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0457 - classifier_accuracy: 0.0974 - classifier_loss: 0.0056 - loss: 0.1808\n",
      "Epoch 579/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 517ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0457 - classifier_accuracy: 0.0974 - classifier_loss: 0.0056 - loss: 0.1806\n",
      "Epoch 580/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 502ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0457 - classifier_accuracy: 0.0974 - classifier_loss: 0.0056 - loss: 0.1804\n",
      "Epoch 581/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0457 - classifier_accuracy: 0.0973 - classifier_loss: 0.0056 - loss: 0.1802\n",
      "Epoch 582/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0457 - classifier_accuracy: 0.0974 - classifier_loss: 0.0056 - loss: 0.1800\n",
      "Epoch 583/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0456 - classifier_accuracy: 0.0974 - classifier_loss: 0.0056 - loss: 0.1799\n",
      "Epoch 584/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0456 - classifier_accuracy: 0.0974 - classifier_loss: 0.0056 - loss: 0.1797\n",
      "Epoch 585/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 412ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0456 - classifier_accuracy: 0.0973 - classifier_loss: 0.0055 - loss: 0.1795\n",
      "Epoch 586/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 437ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0456 - classifier_accuracy: 0.0973 - classifier_loss: 0.0055 - loss: 0.1793\n",
      "Epoch 587/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0455 - classifier_accuracy: 0.0974 - classifier_loss: 0.0055 - loss: 0.1791\n",
      "Epoch 588/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0455 - classifier_accuracy: 0.0974 - classifier_loss: 0.0055 - loss: 0.1789\n",
      "Epoch 589/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0455 - classifier_accuracy: 0.0975 - classifier_loss: 0.0055 - loss: 0.1787\n",
      "Epoch 590/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 524ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0455 - classifier_accuracy: 0.0975 - classifier_loss: 0.0055 - loss: 0.1785\n",
      "Epoch 591/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 467ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0455 - classifier_accuracy: 0.0975 - classifier_loss: 0.0054 - loss: 0.1783\n",
      "Epoch 592/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0454 - classifier_accuracy: 0.0975 - classifier_loss: 0.0054 - loss: 0.1781\n",
      "Epoch 593/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0454 - classifier_accuracy: 0.0975 - classifier_loss: 0.0054 - loss: 0.1779\n",
      "Epoch 594/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0454 - classifier_accuracy: 0.0976 - classifier_loss: 0.0054 - loss: 0.1777\n",
      "Epoch 595/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0454 - classifier_accuracy: 0.0976 - classifier_loss: 0.0054 - loss: 0.1775\n",
      "Epoch 596/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 468ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0454 - classifier_accuracy: 0.0976 - classifier_loss: 0.0054 - loss: 0.1774\n",
      "Epoch 597/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 544ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0453 - classifier_accuracy: 0.0977 - classifier_loss: 0.0054 - loss: 0.1772\n",
      "Epoch 598/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0453 - classifier_accuracy: 0.0978 - classifier_loss: 0.0053 - loss: 0.1770\n",
      "Epoch 599/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 372ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0453 - classifier_accuracy: 0.0979 - classifier_loss: 0.0053 - loss: 0.1768\n",
      "Epoch 600/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 426ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0453 - classifier_accuracy: 0.0979 - classifier_loss: 0.0053 - loss: 0.1766\n",
      "Epoch 601/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0453 - classifier_accuracy: 0.0980 - classifier_loss: 0.0053 - loss: 0.1764\n",
      "Epoch 602/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 357ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0452 - classifier_accuracy: 0.0981 - classifier_loss: 0.0053 - loss: 0.1762\n",
      "Epoch 603/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0452 - classifier_accuracy: 0.0982 - classifier_loss: 0.0053 - loss: 0.1760\n",
      "Epoch 604/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 436ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0452 - classifier_accuracy: 0.0983 - classifier_loss: 0.0053 - loss: 0.1758\n",
      "Epoch 605/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0452 - classifier_accuracy: 0.0983 - classifier_loss: 0.0052 - loss: 0.1757\n",
      "Epoch 606/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 344ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0452 - classifier_accuracy: 0.0984 - classifier_loss: 0.0052 - loss: 0.1755\n",
      "Epoch 607/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 354ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0451 - classifier_accuracy: 0.0984 - classifier_loss: 0.0052 - loss: 0.1753\n",
      "Epoch 608/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 370ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0451 - classifier_accuracy: 0.0984 - classifier_loss: 0.0052 - loss: 0.1751\n",
      "Epoch 609/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0451 - classifier_accuracy: 0.0984 - classifier_loss: 0.0052 - loss: 0.1749\n",
      "Epoch 610/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 369ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0451 - classifier_accuracy: 0.0984 - classifier_loss: 0.0052 - loss: 0.1747\n",
      "Epoch 611/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 362ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0451 - classifier_accuracy: 0.0984 - classifier_loss: 0.0051 - loss: 0.1745\n",
      "Epoch 612/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0450 - classifier_accuracy: 0.0984 - classifier_loss: 0.0051 - loss: 0.1743\n",
      "Epoch 613/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379ms/step - autoencoder_accuracy: 0.0090 - autoencoder_loss: 0.0450 - classifier_accuracy: 0.0984 - classifier_loss: 0.0051 - loss: 0.1742\n",
      "Epoch 614/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 359ms/step - autoencoder_accuracy: 0.0090 - autoencoder_loss: 0.0450 - classifier_accuracy: 0.0984 - classifier_loss: 0.0051 - loss: 0.1740\n",
      "Epoch 615/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366ms/step - autoencoder_accuracy: 0.0090 - autoencoder_loss: 0.0450 - classifier_accuracy: 0.0984 - classifier_loss: 0.0051 - loss: 0.1738\n",
      "Epoch 616/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 369ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0450 - classifier_accuracy: 0.0985 - classifier_loss: 0.0051 - loss: 0.1736\n",
      "Epoch 617/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 405ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0449 - classifier_accuracy: 0.0985 - classifier_loss: 0.0051 - loss: 0.1734\n",
      "Epoch 618/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456ms/step - autoencoder_accuracy: 0.0090 - autoencoder_loss: 0.0449 - classifier_accuracy: 0.0985 - classifier_loss: 0.0051 - loss: 0.1732\n",
      "Epoch 619/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0449 - classifier_accuracy: 0.0984 - classifier_loss: 0.0050 - loss: 0.1730\n",
      "Epoch 620/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 424ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0449 - classifier_accuracy: 0.0984 - classifier_loss: 0.0050 - loss: 0.1728\n",
      "Epoch 621/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0449 - classifier_accuracy: 0.0985 - classifier_loss: 0.0050 - loss: 0.1727\n",
      "Epoch 622/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0448 - classifier_accuracy: 0.0985 - classifier_loss: 0.0050 - loss: 0.1725\n",
      "Epoch 623/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 358ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0448 - classifier_accuracy: 0.0985 - classifier_loss: 0.0050 - loss: 0.1723\n",
      "Epoch 624/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 439ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0448 - classifier_accuracy: 0.0985 - classifier_loss: 0.0050 - loss: 0.1721\n",
      "Epoch 625/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0448 - classifier_accuracy: 0.0985 - classifier_loss: 0.0050 - loss: 0.1719\n",
      "Epoch 626/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 438ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0447 - classifier_accuracy: 0.0985 - classifier_loss: 0.0049 - loss: 0.1717\n",
      "Epoch 627/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0447 - classifier_accuracy: 0.0985 - classifier_loss: 0.0049 - loss: 0.1716\n",
      "Epoch 628/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 468ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0447 - classifier_accuracy: 0.0985 - classifier_loss: 0.0049 - loss: 0.1714\n",
      "Epoch 629/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 467ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0447 - classifier_accuracy: 0.0985 - classifier_loss: 0.0049 - loss: 0.1712\n",
      "Epoch 630/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 519ms/step - autoencoder_accuracy: 0.0090 - autoencoder_loss: 0.0447 - classifier_accuracy: 0.0985 - classifier_loss: 0.0049 - loss: 0.1710\n",
      "Epoch 631/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425ms/step - autoencoder_accuracy: 0.0090 - autoencoder_loss: 0.0446 - classifier_accuracy: 0.0984 - classifier_loss: 0.0049 - loss: 0.1708\n",
      "Epoch 632/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0446 - classifier_accuracy: 0.0985 - classifier_loss: 0.0049 - loss: 0.1706\n",
      "Epoch 633/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0446 - classifier_accuracy: 0.0984 - classifier_loss: 0.0048 - loss: 0.1704\n",
      "Epoch 634/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0446 - classifier_accuracy: 0.0985 - classifier_loss: 0.0048 - loss: 0.1703\n",
      "Epoch 635/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 525ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0446 - classifier_accuracy: 0.0985 - classifier_loss: 0.0048 - loss: 0.1701\n",
      "Epoch 636/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 662ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0445 - classifier_accuracy: 0.0984 - classifier_loss: 0.0048 - loss: 0.1699\n",
      "Epoch 637/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 563ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0445 - classifier_accuracy: 0.0984 - classifier_loss: 0.0048 - loss: 0.1697\n",
      "Epoch 638/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 537ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0445 - classifier_accuracy: 0.0984 - classifier_loss: 0.0048 - loss: 0.1695\n",
      "Epoch 639/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 567ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0445 - classifier_accuracy: 0.0984 - classifier_loss: 0.0048 - loss: 0.1693\n",
      "Epoch 640/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 579ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0444 - classifier_accuracy: 0.0984 - classifier_loss: 0.0048 - loss: 0.1692\n",
      "Epoch 641/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 530ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0444 - classifier_accuracy: 0.0985 - classifier_loss: 0.0047 - loss: 0.1690\n",
      "Epoch 642/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 598ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0444 - classifier_accuracy: 0.0986 - classifier_loss: 0.0047 - loss: 0.1688\n",
      "Epoch 643/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 587ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0444 - classifier_accuracy: 0.0985 - classifier_loss: 0.0047 - loss: 0.1686\n",
      "Epoch 644/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 471ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0444 - classifier_accuracy: 0.0985 - classifier_loss: 0.0047 - loss: 0.1684\n",
      "Epoch 645/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 662ms/step - autoencoder_accuracy: 0.0090 - autoencoder_loss: 0.0443 - classifier_accuracy: 0.0984 - classifier_loss: 0.0047 - loss: 0.1683\n",
      "Epoch 646/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 516ms/step - autoencoder_accuracy: 0.0090 - autoencoder_loss: 0.0443 - classifier_accuracy: 0.0984 - classifier_loss: 0.0047 - loss: 0.1681\n",
      "Epoch 647/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478ms/step - autoencoder_accuracy: 0.0090 - autoencoder_loss: 0.0443 - classifier_accuracy: 0.0985 - classifier_loss: 0.0047 - loss: 0.1679\n",
      "Epoch 648/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 660ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0443 - classifier_accuracy: 0.0985 - classifier_loss: 0.0047 - loss: 0.1677\n",
      "Epoch 649/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 558ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0443 - classifier_accuracy: 0.0986 - classifier_loss: 0.0046 - loss: 0.1675\n",
      "Epoch 650/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 469ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0442 - classifier_accuracy: 0.0986 - classifier_loss: 0.0046 - loss: 0.1674\n",
      "Epoch 651/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 607ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0442 - classifier_accuracy: 0.0986 - classifier_loss: 0.0046 - loss: 0.1672\n",
      "Epoch 652/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 516ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0442 - classifier_accuracy: 0.0987 - classifier_loss: 0.0046 - loss: 0.1670\n",
      "Epoch 653/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0442 - classifier_accuracy: 0.0987 - classifier_loss: 0.0046 - loss: 0.1668\n",
      "Epoch 654/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 653ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0441 - classifier_accuracy: 0.0988 - classifier_loss: 0.0046 - loss: 0.1667\n",
      "Epoch 655/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 527ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0441 - classifier_accuracy: 0.0989 - classifier_loss: 0.0046 - loss: 0.1665\n",
      "Epoch 656/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 483ms/step - autoencoder_accuracy: 0.0090 - autoencoder_loss: 0.0441 - classifier_accuracy: 0.0989 - classifier_loss: 0.0046 - loss: 0.1663\n",
      "Epoch 657/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 642ms/step - autoencoder_accuracy: 0.0090 - autoencoder_loss: 0.0441 - classifier_accuracy: 0.0990 - classifier_loss: 0.0046 - loss: 0.1661\n",
      "Epoch 658/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 529ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0441 - classifier_accuracy: 0.0990 - classifier_loss: 0.0045 - loss: 0.1659\n",
      "Epoch 659/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 534ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0440 - classifier_accuracy: 0.0991 - classifier_loss: 0.0045 - loss: 0.1658\n",
      "Epoch 660/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 636ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0440 - classifier_accuracy: 0.0992 - classifier_loss: 0.0045 - loss: 0.1656\n",
      "Epoch 661/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 552ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0440 - classifier_accuracy: 0.0993 - classifier_loss: 0.0045 - loss: 0.1654\n",
      "Epoch 662/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 599ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0440 - classifier_accuracy: 0.0994 - classifier_loss: 0.0045 - loss: 0.1652\n",
      "Epoch 663/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 538ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0440 - classifier_accuracy: 0.0995 - classifier_loss: 0.0045 - loss: 0.1651\n",
      "Epoch 664/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0439 - classifier_accuracy: 0.0995 - classifier_loss: 0.0045 - loss: 0.1649\n",
      "Epoch 665/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 561ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0439 - classifier_accuracy: 0.0995 - classifier_loss: 0.0045 - loss: 0.1647\n",
      "Epoch 666/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 515ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0439 - classifier_accuracy: 0.0996 - classifier_loss: 0.0045 - loss: 0.1645\n",
      "Epoch 667/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 517ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0439 - classifier_accuracy: 0.0997 - classifier_loss: 0.0044 - loss: 0.1644\n",
      "Epoch 668/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 531ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0438 - classifier_accuracy: 0.0997 - classifier_loss: 0.0044 - loss: 0.1642\n",
      "Epoch 669/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 495ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0438 - classifier_accuracy: 0.0997 - classifier_loss: 0.0044 - loss: 0.1640\n",
      "Epoch 670/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0438 - classifier_accuracy: 0.0997 - classifier_loss: 0.0044 - loss: 0.1638\n",
      "Epoch 671/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0438 - classifier_accuracy: 0.0997 - classifier_loss: 0.0044 - loss: 0.1637\n",
      "Epoch 672/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 510ms/step - autoencoder_accuracy: 0.0090 - autoencoder_loss: 0.0438 - classifier_accuracy: 0.0997 - classifier_loss: 0.0044 - loss: 0.1635\n",
      "Epoch 673/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 599ms/step - autoencoder_accuracy: 0.0090 - autoencoder_loss: 0.0437 - classifier_accuracy: 0.0997 - classifier_loss: 0.0044 - loss: 0.1633\n",
      "Epoch 674/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482ms/step - autoencoder_accuracy: 0.0090 - autoencoder_loss: 0.0437 - classifier_accuracy: 0.0997 - classifier_loss: 0.0044 - loss: 0.1631\n",
      "Epoch 675/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0437 - classifier_accuracy: 0.0997 - classifier_loss: 0.0044 - loss: 0.1630\n",
      "Epoch 676/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 637ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0437 - classifier_accuracy: 0.0997 - classifier_loss: 0.0043 - loss: 0.1628\n",
      "Epoch 677/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 544ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0436 - classifier_accuracy: 0.0997 - classifier_loss: 0.0043 - loss: 0.1626\n",
      "Epoch 678/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 464ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0436 - classifier_accuracy: 0.0997 - classifier_loss: 0.0043 - loss: 0.1624\n",
      "Epoch 679/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 601ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0436 - classifier_accuracy: 0.0997 - classifier_loss: 0.0043 - loss: 0.1623\n",
      "Epoch 680/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475ms/step - autoencoder_accuracy: 0.0090 - autoencoder_loss: 0.0436 - classifier_accuracy: 0.0998 - classifier_loss: 0.0043 - loss: 0.1621\n",
      "Epoch 681/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485ms/step - autoencoder_accuracy: 0.0090 - autoencoder_loss: 0.0436 - classifier_accuracy: 0.0997 - classifier_loss: 0.0043 - loss: 0.1619\n",
      "Epoch 682/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 606ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0435 - classifier_accuracy: 0.0998 - classifier_loss: 0.0043 - loss: 0.1617\n",
      "Epoch 683/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 500ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0435 - classifier_accuracy: 0.0998 - classifier_loss: 0.0043 - loss: 0.1616\n",
      "Epoch 684/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479ms/step - autoencoder_accuracy: 0.0090 - autoencoder_loss: 0.0435 - classifier_accuracy: 0.0998 - classifier_loss: 0.0043 - loss: 0.1614\n",
      "Epoch 685/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 595ms/step - autoencoder_accuracy: 0.0090 - autoencoder_loss: 0.0435 - classifier_accuracy: 0.0999 - classifier_loss: 0.0043 - loss: 0.1612\n",
      "Epoch 686/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 504ms/step - autoencoder_accuracy: 0.0090 - autoencoder_loss: 0.0434 - classifier_accuracy: 0.0998 - classifier_loss: 0.0042 - loss: 0.1611\n",
      "Epoch 687/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 517ms/step - autoencoder_accuracy: 0.0090 - autoencoder_loss: 0.0434 - classifier_accuracy: 0.0998 - classifier_loss: 0.0042 - loss: 0.1609\n",
      "Epoch 688/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 586ms/step - autoencoder_accuracy: 0.0090 - autoencoder_loss: 0.0434 - classifier_accuracy: 0.0998 - classifier_loss: 0.0042 - loss: 0.1607\n",
      "Epoch 689/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0434 - classifier_accuracy: 0.0999 - classifier_loss: 0.0042 - loss: 0.1605\n",
      "Epoch 690/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 515ms/step - autoencoder_accuracy: 0.0092 - autoencoder_loss: 0.0434 - classifier_accuracy: 0.1000 - classifier_loss: 0.0042 - loss: 0.1604\n",
      "Epoch 691/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 585ms/step - autoencoder_accuracy: 0.0092 - autoencoder_loss: 0.0433 - classifier_accuracy: 0.1000 - classifier_loss: 0.0042 - loss: 0.1602\n",
      "Epoch 692/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0433 - classifier_accuracy: 0.1000 - classifier_loss: 0.0042 - loss: 0.1600\n",
      "Epoch 693/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 579ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0433 - classifier_accuracy: 0.1001 - classifier_loss: 0.0042 - loss: 0.1599\n",
      "Epoch 694/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 438ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0433 - classifier_accuracy: 0.1001 - classifier_loss: 0.0042 - loss: 0.1597\n",
      "Epoch 695/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0432 - classifier_accuracy: 0.1001 - classifier_loss: 0.0042 - loss: 0.1595\n",
      "Epoch 696/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 521ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0432 - classifier_accuracy: 0.1002 - classifier_loss: 0.0042 - loss: 0.1593\n",
      "Epoch 697/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 468ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0432 - classifier_accuracy: 0.1002 - classifier_loss: 0.0041 - loss: 0.1592\n",
      "Epoch 698/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0432 - classifier_accuracy: 0.1002 - classifier_loss: 0.0041 - loss: 0.1590\n",
      "Epoch 699/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0432 - classifier_accuracy: 0.1003 - classifier_loss: 0.0041 - loss: 0.1588\n",
      "Epoch 700/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0431 - classifier_accuracy: 0.1003 - classifier_loss: 0.0041 - loss: 0.1587\n",
      "Epoch 701/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 521ms/step - autoencoder_accuracy: 0.0092 - autoencoder_loss: 0.0431 - classifier_accuracy: 0.1003 - classifier_loss: 0.0041 - loss: 0.1585\n",
      "Epoch 702/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475ms/step - autoencoder_accuracy: 0.0092 - autoencoder_loss: 0.0431 - classifier_accuracy: 0.1003 - classifier_loss: 0.0041 - loss: 0.1583\n",
      "Epoch 703/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 546ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0431 - classifier_accuracy: 0.1004 - classifier_loss: 0.0041 - loss: 0.1582\n",
      "Epoch 704/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 563ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0430 - classifier_accuracy: 0.1003 - classifier_loss: 0.0041 - loss: 0.1580\n",
      "Epoch 705/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0430 - classifier_accuracy: 0.1003 - classifier_loss: 0.0041 - loss: 0.1578\n",
      "Epoch 706/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 594ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0430 - classifier_accuracy: 0.1003 - classifier_loss: 0.0041 - loss: 0.1577\n",
      "Epoch 707/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 519ms/step - autoencoder_accuracy: 0.0092 - autoencoder_loss: 0.0430 - classifier_accuracy: 0.1003 - classifier_loss: 0.0041 - loss: 0.1575\n",
      "Epoch 708/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478ms/step - autoencoder_accuracy: 0.0092 - autoencoder_loss: 0.0430 - classifier_accuracy: 0.1003 - classifier_loss: 0.0040 - loss: 0.1573\n",
      "Epoch 709/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 693ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0429 - classifier_accuracy: 0.1004 - classifier_loss: 0.0040 - loss: 0.1572\n",
      "Epoch 710/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 601ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0429 - classifier_accuracy: 0.1003 - classifier_loss: 0.0040 - loss: 0.1570\n",
      "Epoch 711/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 621ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0429 - classifier_accuracy: 0.1003 - classifier_loss: 0.0040 - loss: 0.1568\n",
      "Epoch 712/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 568ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0429 - classifier_accuracy: 0.1003 - classifier_loss: 0.0040 - loss: 0.1567\n",
      "Epoch 713/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 534ms/step - autoencoder_accuracy: 0.0092 - autoencoder_loss: 0.0428 - classifier_accuracy: 0.1002 - classifier_loss: 0.0040 - loss: 0.1565\n",
      "Epoch 714/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0428 - classifier_accuracy: 0.1003 - classifier_loss: 0.0040 - loss: 0.1563\n",
      "Epoch 715/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 593ms/step - autoencoder_accuracy: 0.0092 - autoencoder_loss: 0.0428 - classifier_accuracy: 0.1003 - classifier_loss: 0.0040 - loss: 0.1562\n",
      "Epoch 716/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 509ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0428 - classifier_accuracy: 0.1003 - classifier_loss: 0.0040 - loss: 0.1560\n",
      "Epoch 717/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0428 - classifier_accuracy: 0.1003 - classifier_loss: 0.0040 - loss: 0.1558\n",
      "Epoch 718/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 635ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0427 - classifier_accuracy: 0.1003 - classifier_loss: 0.0040 - loss: 0.1557\n",
      "Epoch 719/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 426ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0427 - classifier_accuracy: 0.1003 - classifier_loss: 0.0040 - loss: 0.1555\n",
      "Epoch 720/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0427 - classifier_accuracy: 0.1003 - classifier_loss: 0.0039 - loss: 0.1553\n",
      "Epoch 721/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 522ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0427 - classifier_accuracy: 0.1004 - classifier_loss: 0.0039 - loss: 0.1552\n",
      "Epoch 722/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0426 - classifier_accuracy: 0.1004 - classifier_loss: 0.0039 - loss: 0.1550\n",
      "Epoch 723/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 497ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0426 - classifier_accuracy: 0.1004 - classifier_loss: 0.0039 - loss: 0.1549\n",
      "Epoch 724/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 581ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0426 - classifier_accuracy: 0.1004 - classifier_loss: 0.0039 - loss: 0.1547\n",
      "Epoch 725/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0426 - classifier_accuracy: 0.1004 - classifier_loss: 0.0039 - loss: 0.1545\n",
      "Epoch 726/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 568ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0426 - classifier_accuracy: 0.1005 - classifier_loss: 0.0039 - loss: 0.1544\n",
      "Epoch 727/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 510ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0425 - classifier_accuracy: 0.1006 - classifier_loss: 0.0039 - loss: 0.1542\n",
      "Epoch 728/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 599ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0425 - classifier_accuracy: 0.1006 - classifier_loss: 0.0039 - loss: 0.1540\n",
      "Epoch 729/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0425 - classifier_accuracy: 0.1006 - classifier_loss: 0.0039 - loss: 0.1539\n",
      "Epoch 730/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488ms/step - autoencoder_accuracy: 0.0092 - autoencoder_loss: 0.0425 - classifier_accuracy: 0.1006 - classifier_loss: 0.0039 - loss: 0.1537\n",
      "Epoch 731/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477ms/step - autoencoder_accuracy: 0.0092 - autoencoder_loss: 0.0425 - classifier_accuracy: 0.1007 - classifier_loss: 0.0039 - loss: 0.1536\n",
      "Epoch 732/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 524ms/step - autoencoder_accuracy: 0.0092 - autoencoder_loss: 0.0424 - classifier_accuracy: 0.1007 - classifier_loss: 0.0038 - loss: 0.1534\n",
      "Epoch 733/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473ms/step - autoencoder_accuracy: 0.0092 - autoencoder_loss: 0.0424 - classifier_accuracy: 0.1008 - classifier_loss: 0.0038 - loss: 0.1532\n",
      "Epoch 734/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 471ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0424 - classifier_accuracy: 0.1008 - classifier_loss: 0.0038 - loss: 0.1531\n",
      "Epoch 735/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 558ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0424 - classifier_accuracy: 0.1008 - classifier_loss: 0.0038 - loss: 0.1529\n",
      "Epoch 736/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 431ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0424 - classifier_accuracy: 0.1007 - classifier_loss: 0.0038 - loss: 0.1527\n",
      "Epoch 737/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 430ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0423 - classifier_accuracy: 0.1007 - classifier_loss: 0.0038 - loss: 0.1526\n",
      "Epoch 738/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0423 - classifier_accuracy: 0.1007 - classifier_loss: 0.0038 - loss: 0.1524\n",
      "Epoch 739/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 358ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0423 - classifier_accuracy: 0.1006 - classifier_loss: 0.0038 - loss: 0.1523\n",
      "Epoch 740/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 571ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0423 - classifier_accuracy: 0.1006 - classifier_loss: 0.0038 - loss: 0.1521\n",
      "Epoch 741/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0423 - classifier_accuracy: 0.1007 - classifier_loss: 0.0038 - loss: 0.1519\n",
      "Epoch 742/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0422 - classifier_accuracy: 0.1007 - classifier_loss: 0.0038 - loss: 0.1518\n",
      "Epoch 743/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 503ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0422 - classifier_accuracy: 0.1007 - classifier_loss: 0.0038 - loss: 0.1516\n",
      "Epoch 744/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0422 - classifier_accuracy: 0.1007 - classifier_loss: 0.0038 - loss: 0.1515\n",
      "Epoch 745/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 574ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0422 - classifier_accuracy: 0.1007 - classifier_loss: 0.0037 - loss: 0.1513\n",
      "Epoch 746/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 622ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0422 - classifier_accuracy: 0.1007 - classifier_loss: 0.0037 - loss: 0.1512\n",
      "Epoch 747/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 520ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0421 - classifier_accuracy: 0.1007 - classifier_loss: 0.0037 - loss: 0.1510\n",
      "Epoch 748/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 586ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0421 - classifier_accuracy: 0.1007 - classifier_loss: 0.0037 - loss: 0.1508\n",
      "Epoch 749/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 500ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0421 - classifier_accuracy: 0.1008 - classifier_loss: 0.0037 - loss: 0.1507\n",
      "Epoch 750/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0421 - classifier_accuracy: 0.1008 - classifier_loss: 0.0037 - loss: 0.1505\n",
      "Epoch 751/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 613ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0421 - classifier_accuracy: 0.1007 - classifier_loss: 0.0037 - loss: 0.1504\n",
      "Epoch 752/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 540ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0421 - classifier_accuracy: 0.1008 - classifier_loss: 0.0037 - loss: 0.1502\n",
      "Epoch 753/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0420 - classifier_accuracy: 0.1007 - classifier_loss: 0.0037 - loss: 0.1501\n",
      "Epoch 754/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479ms/step - autoencoder_accuracy: 0.0095 - autoencoder_loss: 0.0420 - classifier_accuracy: 0.1008 - classifier_loss: 0.0037 - loss: 0.1499\n",
      "Epoch 755/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 510ms/step - autoencoder_accuracy: 0.0095 - autoencoder_loss: 0.0420 - classifier_accuracy: 0.1008 - classifier_loss: 0.0037 - loss: 0.1497\n",
      "Epoch 756/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 553ms/step - autoencoder_accuracy: 0.0095 - autoencoder_loss: 0.0420 - classifier_accuracy: 0.1008 - classifier_loss: 0.0037 - loss: 0.1496\n",
      "Epoch 757/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 516ms/step - autoencoder_accuracy: 0.0095 - autoencoder_loss: 0.0420 - classifier_accuracy: 0.1007 - classifier_loss: 0.0037 - loss: 0.1494\n",
      "Epoch 758/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 568ms/step - autoencoder_accuracy: 0.0095 - autoencoder_loss: 0.0419 - classifier_accuracy: 0.1007 - classifier_loss: 0.0037 - loss: 0.1493\n",
      "Epoch 759/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 527ms/step - autoencoder_accuracy: 0.0095 - autoencoder_loss: 0.0419 - classifier_accuracy: 0.1007 - classifier_loss: 0.0036 - loss: 0.1491\n",
      "Epoch 760/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 371ms/step - autoencoder_accuracy: 0.0095 - autoencoder_loss: 0.0419 - classifier_accuracy: 0.1007 - classifier_loss: 0.0036 - loss: 0.1490\n",
      "Epoch 761/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 506ms/step - autoencoder_accuracy: 0.0095 - autoencoder_loss: 0.0419 - classifier_accuracy: 0.1007 - classifier_loss: 0.0036 - loss: 0.1488\n",
      "Epoch 762/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453ms/step - autoencoder_accuracy: 0.0095 - autoencoder_loss: 0.0419 - classifier_accuracy: 0.1006 - classifier_loss: 0.0036 - loss: 0.1487\n",
      "Epoch 763/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 517ms/step - autoencoder_accuracy: 0.0095 - autoencoder_loss: 0.0419 - classifier_accuracy: 0.1006 - classifier_loss: 0.0036 - loss: 0.1485\n",
      "Epoch 764/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 532ms/step - autoencoder_accuracy: 0.0095 - autoencoder_loss: 0.0418 - classifier_accuracy: 0.1006 - classifier_loss: 0.0036 - loss: 0.1484\n",
      "Epoch 765/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488ms/step - autoencoder_accuracy: 0.0096 - autoencoder_loss: 0.0418 - classifier_accuracy: 0.1006 - classifier_loss: 0.0036 - loss: 0.1482\n",
      "Epoch 766/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 624ms/step - autoencoder_accuracy: 0.0097 - autoencoder_loss: 0.0418 - classifier_accuracy: 0.1006 - classifier_loss: 0.0036 - loss: 0.1480\n",
      "Epoch 767/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473ms/step - autoencoder_accuracy: 0.0096 - autoencoder_loss: 0.0418 - classifier_accuracy: 0.1006 - classifier_loss: 0.0036 - loss: 0.1479\n",
      "Epoch 768/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491ms/step - autoencoder_accuracy: 0.0097 - autoencoder_loss: 0.0418 - classifier_accuracy: 0.1006 - classifier_loss: 0.0036 - loss: 0.1477\n",
      "Epoch 769/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 641ms/step - autoencoder_accuracy: 0.0097 - autoencoder_loss: 0.0417 - classifier_accuracy: 0.1007 - classifier_loss: 0.0036 - loss: 0.1476\n",
      "Epoch 770/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 519ms/step - autoencoder_accuracy: 0.0097 - autoencoder_loss: 0.0417 - classifier_accuracy: 0.1007 - classifier_loss: 0.0036 - loss: 0.1474\n",
      "Epoch 771/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484ms/step - autoencoder_accuracy: 0.0097 - autoencoder_loss: 0.0417 - classifier_accuracy: 0.1006 - classifier_loss: 0.0036 - loss: 0.1473\n",
      "Epoch 772/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 554ms/step - autoencoder_accuracy: 0.0097 - autoencoder_loss: 0.0417 - classifier_accuracy: 0.1006 - classifier_loss: 0.0036 - loss: 0.1471\n",
      "Epoch 773/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452ms/step - autoencoder_accuracy: 0.0098 - autoencoder_loss: 0.0417 - classifier_accuracy: 0.1006 - classifier_loss: 0.0036 - loss: 0.1470\n",
      "Epoch 774/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452ms/step - autoencoder_accuracy: 0.0098 - autoencoder_loss: 0.0417 - classifier_accuracy: 0.1005 - classifier_loss: 0.0035 - loss: 0.1468\n",
      "Epoch 775/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 518ms/step - autoencoder_accuracy: 0.0098 - autoencoder_loss: 0.0416 - classifier_accuracy: 0.1005 - classifier_loss: 0.0035 - loss: 0.1467\n",
      "Epoch 776/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384ms/step - autoencoder_accuracy: 0.0098 - autoencoder_loss: 0.0416 - classifier_accuracy: 0.1005 - classifier_loss: 0.0035 - loss: 0.1465\n",
      "Epoch 777/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 548ms/step - autoencoder_accuracy: 0.0098 - autoencoder_loss: 0.0416 - classifier_accuracy: 0.1005 - classifier_loss: 0.0035 - loss: 0.1464\n",
      "Epoch 778/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455ms/step - autoencoder_accuracy: 0.0098 - autoencoder_loss: 0.0416 - classifier_accuracy: 0.1006 - classifier_loss: 0.0035 - loss: 0.1462\n",
      "Epoch 779/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 565ms/step - autoencoder_accuracy: 0.0098 - autoencoder_loss: 0.0416 - classifier_accuracy: 0.1007 - classifier_loss: 0.0035 - loss: 0.1461\n",
      "Epoch 780/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 502ms/step - autoencoder_accuracy: 0.0098 - autoencoder_loss: 0.0416 - classifier_accuracy: 0.1007 - classifier_loss: 0.0035 - loss: 0.1459\n",
      "Epoch 781/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 508ms/step - autoencoder_accuracy: 0.0098 - autoencoder_loss: 0.0415 - classifier_accuracy: 0.1008 - classifier_loss: 0.0035 - loss: 0.1458\n",
      "Epoch 782/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 590ms/step - autoencoder_accuracy: 0.0098 - autoencoder_loss: 0.0415 - classifier_accuracy: 0.1007 - classifier_loss: 0.0035 - loss: 0.1456\n",
      "Epoch 783/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 442ms/step - autoencoder_accuracy: 0.0098 - autoencoder_loss: 0.0415 - classifier_accuracy: 0.1008 - classifier_loss: 0.0035 - loss: 0.1455\n",
      "Epoch 784/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 531ms/step - autoencoder_accuracy: 0.0098 - autoencoder_loss: 0.0415 - classifier_accuracy: 0.1008 - classifier_loss: 0.0035 - loss: 0.1453\n",
      "Epoch 785/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402ms/step - autoencoder_accuracy: 0.0098 - autoencoder_loss: 0.0415 - classifier_accuracy: 0.1008 - classifier_loss: 0.0035 - loss: 0.1452\n",
      "Epoch 786/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 429ms/step - autoencoder_accuracy: 0.0098 - autoencoder_loss: 0.0415 - classifier_accuracy: 0.1009 - classifier_loss: 0.0035 - loss: 0.1450\n",
      "Epoch 787/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 527ms/step - autoencoder_accuracy: 0.0098 - autoencoder_loss: 0.0414 - classifier_accuracy: 0.1009 - classifier_loss: 0.0035 - loss: 0.1449\n",
      "Epoch 788/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 467ms/step - autoencoder_accuracy: 0.0098 - autoencoder_loss: 0.0414 - classifier_accuracy: 0.1009 - classifier_loss: 0.0035 - loss: 0.1447\n",
      "Epoch 789/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389ms/step - autoencoder_accuracy: 0.0098 - autoencoder_loss: 0.0414 - classifier_accuracy: 0.1009 - classifier_loss: 0.0034 - loss: 0.1446\n",
      "Epoch 790/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 365ms/step - autoencoder_accuracy: 0.0098 - autoencoder_loss: 0.0414 - classifier_accuracy: 0.1009 - classifier_loss: 0.0034 - loss: 0.1444\n",
      "Epoch 791/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490ms/step - autoencoder_accuracy: 0.0098 - autoencoder_loss: 0.0414 - classifier_accuracy: 0.1009 - classifier_loss: 0.0034 - loss: 0.1443\n",
      "Epoch 792/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498ms/step - autoencoder_accuracy: 0.0098 - autoencoder_loss: 0.0414 - classifier_accuracy: 0.1009 - classifier_loss: 0.0034 - loss: 0.1441\n",
      "Epoch 793/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484ms/step - autoencoder_accuracy: 0.0098 - autoencoder_loss: 0.0413 - classifier_accuracy: 0.1010 - classifier_loss: 0.0034 - loss: 0.1440\n",
      "Epoch 794/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384ms/step - autoencoder_accuracy: 0.0097 - autoencoder_loss: 0.0413 - classifier_accuracy: 0.1010 - classifier_loss: 0.0034 - loss: 0.1438\n",
      "Epoch 795/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480ms/step - autoencoder_accuracy: 0.0097 - autoencoder_loss: 0.0413 - classifier_accuracy: 0.1010 - classifier_loss: 0.0034 - loss: 0.1437\n",
      "Epoch 796/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461ms/step - autoencoder_accuracy: 0.0097 - autoencoder_loss: 0.0413 - classifier_accuracy: 0.1010 - classifier_loss: 0.0034 - loss: 0.1435\n",
      "Epoch 797/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 540ms/step - autoencoder_accuracy: 0.0097 - autoencoder_loss: 0.0413 - classifier_accuracy: 0.1010 - classifier_loss: 0.0034 - loss: 0.1434\n",
      "Epoch 798/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481ms/step - autoencoder_accuracy: 0.0098 - autoencoder_loss: 0.0413 - classifier_accuracy: 0.1010 - classifier_loss: 0.0034 - loss: 0.1432\n",
      "Epoch 799/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420ms/step - autoencoder_accuracy: 0.0098 - autoencoder_loss: 0.0412 - classifier_accuracy: 0.1010 - classifier_loss: 0.0034 - loss: 0.1431\n",
      "Epoch 800/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 537ms/step - autoencoder_accuracy: 0.0098 - autoencoder_loss: 0.0412 - classifier_accuracy: 0.1010 - classifier_loss: 0.0034 - loss: 0.1429\n",
      "Epoch 801/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473ms/step - autoencoder_accuracy: 0.0098 - autoencoder_loss: 0.0412 - classifier_accuracy: 0.1010 - classifier_loss: 0.0034 - loss: 0.1428\n",
      "Epoch 802/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394ms/step - autoencoder_accuracy: 0.0097 - autoencoder_loss: 0.0412 - classifier_accuracy: 0.1011 - classifier_loss: 0.0034 - loss: 0.1426\n",
      "Epoch 803/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 520ms/step - autoencoder_accuracy: 0.0097 - autoencoder_loss: 0.0412 - classifier_accuracy: 0.1011 - classifier_loss: 0.0034 - loss: 0.1425\n",
      "Epoch 804/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499ms/step - autoencoder_accuracy: 0.0097 - autoencoder_loss: 0.0412 - classifier_accuracy: 0.1011 - classifier_loss: 0.0033 - loss: 0.1424\n",
      "Epoch 805/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454ms/step - autoencoder_accuracy: 0.0097 - autoencoder_loss: 0.0411 - classifier_accuracy: 0.1012 - classifier_loss: 0.0033 - loss: 0.1422\n",
      "Epoch 806/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 442ms/step - autoencoder_accuracy: 0.0097 - autoencoder_loss: 0.0411 - classifier_accuracy: 0.1012 - classifier_loss: 0.0033 - loss: 0.1421\n",
      "Epoch 807/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 526ms/step - autoencoder_accuracy: 0.0098 - autoencoder_loss: 0.0411 - classifier_accuracy: 0.1012 - classifier_loss: 0.0033 - loss: 0.1419\n",
      "Epoch 808/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 623ms/step - autoencoder_accuracy: 0.0097 - autoencoder_loss: 0.0411 - classifier_accuracy: 0.1013 - classifier_loss: 0.0033 - loss: 0.1418\n",
      "Epoch 809/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491ms/step - autoencoder_accuracy: 0.0097 - autoencoder_loss: 0.0411 - classifier_accuracy: 0.1013 - classifier_loss: 0.0033 - loss: 0.1416\n",
      "Epoch 810/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 563ms/step - autoencoder_accuracy: 0.0098 - autoencoder_loss: 0.0411 - classifier_accuracy: 0.1014 - classifier_loss: 0.0033 - loss: 0.1415\n",
      "Epoch 811/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 518ms/step - autoencoder_accuracy: 0.0097 - autoencoder_loss: 0.0411 - classifier_accuracy: 0.1015 - classifier_loss: 0.0033 - loss: 0.1413\n",
      "Epoch 812/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 608ms/step - autoencoder_accuracy: 0.0098 - autoencoder_loss: 0.0410 - classifier_accuracy: 0.1015 - classifier_loss: 0.0033 - loss: 0.1412\n",
      "Epoch 813/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 654ms/step - autoencoder_accuracy: 0.0098 - autoencoder_loss: 0.0410 - classifier_accuracy: 0.1015 - classifier_loss: 0.0033 - loss: 0.1411\n",
      "Epoch 814/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 540ms/step - autoencoder_accuracy: 0.0098 - autoencoder_loss: 0.0410 - classifier_accuracy: 0.1015 - classifier_loss: 0.0033 - loss: 0.1409\n",
      "Epoch 815/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 501ms/step - autoencoder_accuracy: 0.0098 - autoencoder_loss: 0.0410 - classifier_accuracy: 0.1016 - classifier_loss: 0.0033 - loss: 0.1408\n",
      "Epoch 816/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 526ms/step - autoencoder_accuracy: 0.0097 - autoencoder_loss: 0.0410 - classifier_accuracy: 0.1017 - classifier_loss: 0.0033 - loss: 0.1406\n",
      "Epoch 817/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 535ms/step - autoencoder_accuracy: 0.0097 - autoencoder_loss: 0.0410 - classifier_accuracy: 0.1018 - classifier_loss: 0.0033 - loss: 0.1405\n",
      "Epoch 818/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 603ms/step - autoencoder_accuracy: 0.0097 - autoencoder_loss: 0.0409 - classifier_accuracy: 0.1019 - classifier_loss: 0.0033 - loss: 0.1403\n",
      "Epoch 819/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 523ms/step - autoencoder_accuracy: 0.0097 - autoencoder_loss: 0.0409 - classifier_accuracy: 0.1020 - classifier_loss: 0.0033 - loss: 0.1402\n",
      "Epoch 820/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 527ms/step - autoencoder_accuracy: 0.0097 - autoencoder_loss: 0.0409 - classifier_accuracy: 0.1020 - classifier_loss: 0.0033 - loss: 0.1401\n",
      "Epoch 821/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 543ms/step - autoencoder_accuracy: 0.0097 - autoencoder_loss: 0.0409 - classifier_accuracy: 0.1021 - classifier_loss: 0.0033 - loss: 0.1399\n",
      "Epoch 822/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 615ms/step - autoencoder_accuracy: 0.0096 - autoencoder_loss: 0.0409 - classifier_accuracy: 0.1021 - classifier_loss: 0.0032 - loss: 0.1398\n",
      "Epoch 823/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 584ms/step - autoencoder_accuracy: 0.0096 - autoencoder_loss: 0.0409 - classifier_accuracy: 0.1022 - classifier_loss: 0.0032 - loss: 0.1396\n",
      "Epoch 824/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 536ms/step - autoencoder_accuracy: 0.0096 - autoencoder_loss: 0.0408 - classifier_accuracy: 0.1022 - classifier_loss: 0.0032 - loss: 0.1395\n",
      "Epoch 825/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445ms/step - autoencoder_accuracy: 0.0096 - autoencoder_loss: 0.0408 - classifier_accuracy: 0.1023 - classifier_loss: 0.0032 - loss: 0.1393\n",
      "Epoch 826/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 633ms/step - autoencoder_accuracy: 0.0096 - autoencoder_loss: 0.0408 - classifier_accuracy: 0.1023 - classifier_loss: 0.0032 - loss: 0.1392\n",
      "Epoch 827/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 687ms/step - autoencoder_accuracy: 0.0096 - autoencoder_loss: 0.0408 - classifier_accuracy: 0.1024 - classifier_loss: 0.0032 - loss: 0.1391\n",
      "Epoch 828/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 713ms/step - autoencoder_accuracy: 0.0096 - autoencoder_loss: 0.0408 - classifier_accuracy: 0.1024 - classifier_loss: 0.0032 - loss: 0.1389\n",
      "Epoch 829/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 638ms/step - autoencoder_accuracy: 0.0096 - autoencoder_loss: 0.0408 - classifier_accuracy: 0.1026 - classifier_loss: 0.0032 - loss: 0.1388\n",
      "Epoch 830/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 539ms/step - autoencoder_accuracy: 0.0096 - autoencoder_loss: 0.0408 - classifier_accuracy: 0.1027 - classifier_loss: 0.0032 - loss: 0.1386\n",
      "Epoch 831/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 622ms/step - autoencoder_accuracy: 0.0096 - autoencoder_loss: 0.0407 - classifier_accuracy: 0.1027 - classifier_loss: 0.0032 - loss: 0.1385\n",
      "Epoch 832/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 629ms/step - autoencoder_accuracy: 0.0096 - autoencoder_loss: 0.0407 - classifier_accuracy: 0.1027 - classifier_loss: 0.0032 - loss: 0.1384\n",
      "Epoch 833/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 504ms/step - autoencoder_accuracy: 0.0096 - autoencoder_loss: 0.0407 - classifier_accuracy: 0.1025 - classifier_loss: 0.0032 - loss: 0.1382\n",
      "Epoch 834/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 563ms/step - autoencoder_accuracy: 0.0096 - autoencoder_loss: 0.0407 - classifier_accuracy: 0.1025 - classifier_loss: 0.0032 - loss: 0.1381\n",
      "Epoch 835/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 501ms/step - autoencoder_accuracy: 0.0096 - autoencoder_loss: 0.0407 - classifier_accuracy: 0.1025 - classifier_loss: 0.0032 - loss: 0.1379\n",
      "Epoch 836/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448ms/step - autoencoder_accuracy: 0.0095 - autoencoder_loss: 0.0407 - classifier_accuracy: 0.1025 - classifier_loss: 0.0032 - loss: 0.1378\n",
      "Epoch 837/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 631ms/step - autoencoder_accuracy: 0.0095 - autoencoder_loss: 0.0407 - classifier_accuracy: 0.1025 - classifier_loss: 0.0032 - loss: 0.1377\n",
      "Epoch 838/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 556ms/step - autoencoder_accuracy: 0.0096 - autoencoder_loss: 0.0406 - classifier_accuracy: 0.1025 - classifier_loss: 0.0032 - loss: 0.1375\n",
      "Epoch 839/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496ms/step - autoencoder_accuracy: 0.0096 - autoencoder_loss: 0.0406 - classifier_accuracy: 0.1025 - classifier_loss: 0.0032 - loss: 0.1374\n",
      "Epoch 840/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 587ms/step - autoencoder_accuracy: 0.0096 - autoencoder_loss: 0.0406 - classifier_accuracy: 0.1025 - classifier_loss: 0.0032 - loss: 0.1372\n",
      "Epoch 841/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481ms/step - autoencoder_accuracy: 0.0096 - autoencoder_loss: 0.0406 - classifier_accuracy: 0.1025 - classifier_loss: 0.0031 - loss: 0.1371\n",
      "Epoch 842/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463ms/step - autoencoder_accuracy: 0.0095 - autoencoder_loss: 0.0406 - classifier_accuracy: 0.1024 - classifier_loss: 0.0031 - loss: 0.1370\n",
      "Epoch 843/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 471ms/step - autoencoder_accuracy: 0.0095 - autoencoder_loss: 0.0406 - classifier_accuracy: 0.1024 - classifier_loss: 0.0031 - loss: 0.1368\n",
      "Epoch 844/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384ms/step - autoencoder_accuracy: 0.0095 - autoencoder_loss: 0.0405 - classifier_accuracy: 0.1024 - classifier_loss: 0.0031 - loss: 0.1367\n",
      "Epoch 845/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 497ms/step - autoencoder_accuracy: 0.0095 - autoencoder_loss: 0.0405 - classifier_accuracy: 0.1024 - classifier_loss: 0.0031 - loss: 0.1365\n",
      "Epoch 846/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487ms/step - autoencoder_accuracy: 0.0096 - autoencoder_loss: 0.0405 - classifier_accuracy: 0.1025 - classifier_loss: 0.0031 - loss: 0.1364\n",
      "Epoch 847/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400ms/step - autoencoder_accuracy: 0.0096 - autoencoder_loss: 0.0405 - classifier_accuracy: 0.1024 - classifier_loss: 0.0031 - loss: 0.1363\n",
      "Epoch 848/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 510ms/step - autoencoder_accuracy: 0.0096 - autoencoder_loss: 0.0405 - classifier_accuracy: 0.1023 - classifier_loss: 0.0031 - loss: 0.1361\n",
      "Epoch 849/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499ms/step - autoencoder_accuracy: 0.0096 - autoencoder_loss: 0.0405 - classifier_accuracy: 0.1024 - classifier_loss: 0.0031 - loss: 0.1360\n",
      "Epoch 850/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 351ms/step - autoencoder_accuracy: 0.0096 - autoencoder_loss: 0.0405 - classifier_accuracy: 0.1025 - classifier_loss: 0.0031 - loss: 0.1358\n",
      "Epoch 851/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 511ms/step - autoencoder_accuracy: 0.0095 - autoencoder_loss: 0.0404 - classifier_accuracy: 0.1025 - classifier_loss: 0.0031 - loss: 0.1357\n",
      "Epoch 852/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 508ms/step - autoencoder_accuracy: 0.0095 - autoencoder_loss: 0.0404 - classifier_accuracy: 0.1026 - classifier_loss: 0.0031 - loss: 0.1356\n",
      "Epoch 853/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 361ms/step - autoencoder_accuracy: 0.0095 - autoencoder_loss: 0.0404 - classifier_accuracy: 0.1026 - classifier_loss: 0.0031 - loss: 0.1354\n",
      "Epoch 854/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409ms/step - autoencoder_accuracy: 0.0095 - autoencoder_loss: 0.0404 - classifier_accuracy: 0.1026 - classifier_loss: 0.0031 - loss: 0.1353\n",
      "Epoch 855/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0404 - classifier_accuracy: 0.1026 - classifier_loss: 0.0031 - loss: 0.1352\n",
      "Epoch 856/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 468ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0404 - classifier_accuracy: 0.1026 - classifier_loss: 0.0031 - loss: 0.1350\n",
      "Epoch 857/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 500ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0404 - classifier_accuracy: 0.1026 - classifier_loss: 0.0031 - loss: 0.1349\n",
      "Epoch 858/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 545ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0403 - classifier_accuracy: 0.1027 - classifier_loss: 0.0031 - loss: 0.1348\n",
      "Epoch 859/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 523ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0403 - classifier_accuracy: 0.1026 - classifier_loss: 0.0031 - loss: 0.1346\n",
      "Epoch 860/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 505ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0403 - classifier_accuracy: 0.1026 - classifier_loss: 0.0031 - loss: 0.1345\n",
      "Epoch 861/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 667ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0403 - classifier_accuracy: 0.1025 - classifier_loss: 0.0031 - loss: 0.1343\n",
      "Epoch 862/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 588ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0403 - classifier_accuracy: 0.1025 - classifier_loss: 0.0030 - loss: 0.1342\n",
      "Epoch 863/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 568ms/step - autoencoder_accuracy: 0.0094 - autoencoder_loss: 0.0403 - classifier_accuracy: 0.1025 - classifier_loss: 0.0030 - loss: 0.1341\n",
      "Epoch 864/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 653ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0403 - classifier_accuracy: 0.1025 - classifier_loss: 0.0030 - loss: 0.1339\n",
      "Epoch 865/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 525ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0402 - classifier_accuracy: 0.1025 - classifier_loss: 0.0030 - loss: 0.1338\n",
      "Epoch 866/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0402 - classifier_accuracy: 0.1025 - classifier_loss: 0.0030 - loss: 0.1337\n",
      "Epoch 867/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 608ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0402 - classifier_accuracy: 0.1024 - classifier_loss: 0.0030 - loss: 0.1335\n",
      "Epoch 868/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 512ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0402 - classifier_accuracy: 0.1024 - classifier_loss: 0.0030 - loss: 0.1334\n",
      "Epoch 869/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393ms/step - autoencoder_accuracy: 0.0092 - autoencoder_loss: 0.0402 - classifier_accuracy: 0.1025 - classifier_loss: 0.0030 - loss: 0.1333\n",
      "Epoch 870/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 560ms/step - autoencoder_accuracy: 0.0092 - autoencoder_loss: 0.0402 - classifier_accuracy: 0.1025 - classifier_loss: 0.0030 - loss: 0.1331\n",
      "Epoch 871/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 501ms/step - autoencoder_accuracy: 0.0092 - autoencoder_loss: 0.0402 - classifier_accuracy: 0.1024 - classifier_loss: 0.0030 - loss: 0.1330\n",
      "Epoch 872/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374ms/step - autoencoder_accuracy: 0.0092 - autoencoder_loss: 0.0401 - classifier_accuracy: 0.1023 - classifier_loss: 0.0030 - loss: 0.1329\n",
      "Epoch 873/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 551ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0401 - classifier_accuracy: 0.1025 - classifier_loss: 0.0030 - loss: 0.1327\n",
      "Epoch 874/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 554ms/step - autoencoder_accuracy: 0.0093 - autoencoder_loss: 0.0401 - classifier_accuracy: 0.1025 - classifier_loss: 0.0030 - loss: 0.1326\n",
      "Epoch 875/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 598ms/step - autoencoder_accuracy: 0.0092 - autoencoder_loss: 0.0401 - classifier_accuracy: 0.1025 - classifier_loss: 0.0030 - loss: 0.1325\n",
      "Epoch 876/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493ms/step - autoencoder_accuracy: 0.0092 - autoencoder_loss: 0.0401 - classifier_accuracy: 0.1024 - classifier_loss: 0.0030 - loss: 0.1323\n",
      "Epoch 877/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 467ms/step - autoencoder_accuracy: 0.0092 - autoencoder_loss: 0.0401 - classifier_accuracy: 0.1024 - classifier_loss: 0.0030 - loss: 0.1322\n",
      "Epoch 878/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459ms/step - autoencoder_accuracy: 0.0092 - autoencoder_loss: 0.0401 - classifier_accuracy: 0.1024 - classifier_loss: 0.0030 - loss: 0.1321\n",
      "Epoch 879/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 503ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0400 - classifier_accuracy: 0.1025 - classifier_loss: 0.0030 - loss: 0.1319\n",
      "Epoch 880/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 545ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0400 - classifier_accuracy: 0.1025 - classifier_loss: 0.0030 - loss: 0.1318\n",
      "Epoch 881/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 524ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0400 - classifier_accuracy: 0.1024 - classifier_loss: 0.0030 - loss: 0.1317\n",
      "Epoch 882/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0400 - classifier_accuracy: 0.1024 - classifier_loss: 0.0030 - loss: 0.1315\n",
      "Epoch 883/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 552ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0400 - classifier_accuracy: 0.1024 - classifier_loss: 0.0030 - loss: 0.1314\n",
      "Epoch 884/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 515ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0400 - classifier_accuracy: 0.1023 - classifier_loss: 0.0029 - loss: 0.1313\n",
      "Epoch 885/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413ms/step - autoencoder_accuracy: 0.0091 - autoencoder_loss: 0.0400 - classifier_accuracy: 0.1023 - classifier_loss: 0.0029 - loss: 0.1311\n",
      "Epoch 886/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 502ms/step - autoencoder_accuracy: 0.0090 - autoencoder_loss: 0.0399 - classifier_accuracy: 0.1023 - classifier_loss: 0.0029 - loss: 0.1310\n",
      "Epoch 887/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496ms/step - autoencoder_accuracy: 0.0090 - autoencoder_loss: 0.0399 - classifier_accuracy: 0.1023 - classifier_loss: 0.0029 - loss: 0.1309\n",
      "Epoch 888/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 417ms/step - autoencoder_accuracy: 0.0090 - autoencoder_loss: 0.0399 - classifier_accuracy: 0.1023 - classifier_loss: 0.0029 - loss: 0.1307\n",
      "Epoch 889/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 551ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0399 - classifier_accuracy: 0.1022 - classifier_loss: 0.0029 - loss: 0.1306\n",
      "Epoch 890/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 508ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0399 - classifier_accuracy: 0.1022 - classifier_loss: 0.0029 - loss: 0.1305\n",
      "Epoch 891/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 527ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0399 - classifier_accuracy: 0.1023 - classifier_loss: 0.0029 - loss: 0.1303\n",
      "Epoch 892/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 571ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0399 - classifier_accuracy: 0.1022 - classifier_loss: 0.0029 - loss: 0.1302\n",
      "Epoch 893/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 635ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0398 - classifier_accuracy: 0.1023 - classifier_loss: 0.0029 - loss: 0.1301\n",
      "Epoch 894/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0398 - classifier_accuracy: 0.1023 - classifier_loss: 0.0029 - loss: 0.1300\n",
      "Epoch 895/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 553ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0398 - classifier_accuracy: 0.1024 - classifier_loss: 0.0029 - loss: 0.1298\n",
      "Epoch 896/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 526ms/step - autoencoder_accuracy: 0.0089 - autoencoder_loss: 0.0398 - classifier_accuracy: 0.1022 - classifier_loss: 0.0029 - loss: 0.1297\n",
      "Epoch 897/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0398 - classifier_accuracy: 0.1023 - classifier_loss: 0.0029 - loss: 0.1296\n",
      "Epoch 898/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0398 - classifier_accuracy: 0.1024 - classifier_loss: 0.0029 - loss: 0.1294\n",
      "Epoch 899/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0398 - classifier_accuracy: 0.1025 - classifier_loss: 0.0029 - loss: 0.1293\n",
      "Epoch 900/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 528ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0397 - classifier_accuracy: 0.1025 - classifier_loss: 0.0029 - loss: 0.1292\n",
      "Epoch 901/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 647ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0397 - classifier_accuracy: 0.1025 - classifier_loss: 0.0029 - loss: 0.1290\n",
      "Epoch 902/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 580ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0397 - classifier_accuracy: 0.1025 - classifier_loss: 0.0029 - loss: 0.1289\n",
      "Epoch 903/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 605ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0397 - classifier_accuracy: 0.1025 - classifier_loss: 0.0029 - loss: 0.1288\n",
      "Epoch 904/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 568ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0397 - classifier_accuracy: 0.1026 - classifier_loss: 0.0029 - loss: 0.1287\n",
      "Epoch 905/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 597ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0397 - classifier_accuracy: 0.1025 - classifier_loss: 0.0029 - loss: 0.1285\n",
      "Epoch 906/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 593ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0397 - classifier_accuracy: 0.1025 - classifier_loss: 0.0029 - loss: 0.1284\n",
      "Epoch 907/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 534ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0397 - classifier_accuracy: 0.1026 - classifier_loss: 0.0029 - loss: 0.1283\n",
      "Epoch 908/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 617ms/step - autoencoder_accuracy: 0.0086 - autoencoder_loss: 0.0396 - classifier_accuracy: 0.1027 - classifier_loss: 0.0029 - loss: 0.1281\n",
      "Epoch 909/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 543ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0396 - classifier_accuracy: 0.1027 - classifier_loss: 0.0029 - loss: 0.1280\n",
      "Epoch 910/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 368ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0396 - classifier_accuracy: 0.1027 - classifier_loss: 0.0029 - loss: 0.1279\n",
      "Epoch 911/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 595ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0396 - classifier_accuracy: 0.1027 - classifier_loss: 0.0028 - loss: 0.1278\n",
      "Epoch 912/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 516ms/step - autoencoder_accuracy: 0.0086 - autoencoder_loss: 0.0396 - classifier_accuracy: 0.1027 - classifier_loss: 0.0028 - loss: 0.1276\n",
      "Epoch 913/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0396 - classifier_accuracy: 0.1027 - classifier_loss: 0.0028 - loss: 0.1275\n",
      "Epoch 914/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 602ms/step - autoencoder_accuracy: 0.0086 - autoencoder_loss: 0.0396 - classifier_accuracy: 0.1028 - classifier_loss: 0.0028 - loss: 0.1274\n",
      "Epoch 915/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411ms/step - autoencoder_accuracy: 0.0086 - autoencoder_loss: 0.0395 - classifier_accuracy: 0.1027 - classifier_loss: 0.0028 - loss: 0.1273\n",
      "Epoch 916/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 596ms/step - autoencoder_accuracy: 0.0086 - autoencoder_loss: 0.0395 - classifier_accuracy: 0.1027 - classifier_loss: 0.0028 - loss: 0.1271\n",
      "Epoch 917/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409ms/step - autoencoder_accuracy: 0.0086 - autoencoder_loss: 0.0395 - classifier_accuracy: 0.1026 - classifier_loss: 0.0028 - loss: 0.1270\n",
      "Epoch 918/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 569ms/step - autoencoder_accuracy: 0.0086 - autoencoder_loss: 0.0395 - classifier_accuracy: 0.1025 - classifier_loss: 0.0028 - loss: 0.1269\n",
      "Epoch 919/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484ms/step - autoencoder_accuracy: 0.0086 - autoencoder_loss: 0.0395 - classifier_accuracy: 0.1025 - classifier_loss: 0.0028 - loss: 0.1267\n",
      "Epoch 920/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487ms/step - autoencoder_accuracy: 0.0086 - autoencoder_loss: 0.0395 - classifier_accuracy: 0.1026 - classifier_loss: 0.0028 - loss: 0.1266\n",
      "Epoch 921/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 577ms/step - autoencoder_accuracy: 0.0086 - autoencoder_loss: 0.0395 - classifier_accuracy: 0.1026 - classifier_loss: 0.0028 - loss: 0.1265\n",
      "Epoch 922/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 542ms/step - autoencoder_accuracy: 0.0086 - autoencoder_loss: 0.0395 - classifier_accuracy: 0.1026 - classifier_loss: 0.0028 - loss: 0.1264\n",
      "Epoch 923/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 440ms/step - autoencoder_accuracy: 0.0086 - autoencoder_loss: 0.0394 - classifier_accuracy: 0.1026 - classifier_loss: 0.0028 - loss: 0.1262\n",
      "Epoch 924/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 542ms/step - autoencoder_accuracy: 0.0086 - autoencoder_loss: 0.0394 - classifier_accuracy: 0.1025 - classifier_loss: 0.0028 - loss: 0.1261\n",
      "Epoch 925/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456ms/step - autoencoder_accuracy: 0.0086 - autoencoder_loss: 0.0394 - classifier_accuracy: 0.1025 - classifier_loss: 0.0028 - loss: 0.1260\n",
      "Epoch 926/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 584ms/step - autoencoder_accuracy: 0.0086 - autoencoder_loss: 0.0394 - classifier_accuracy: 0.1024 - classifier_loss: 0.0028 - loss: 0.1258\n",
      "Epoch 927/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420ms/step - autoencoder_accuracy: 0.0086 - autoencoder_loss: 0.0394 - classifier_accuracy: 0.1023 - classifier_loss: 0.0028 - loss: 0.1257\n",
      "Epoch 928/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 586ms/step - autoencoder_accuracy: 0.0086 - autoencoder_loss: 0.0394 - classifier_accuracy: 0.1023 - classifier_loss: 0.0028 - loss: 0.1256\n",
      "Epoch 929/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466ms/step - autoencoder_accuracy: 0.0085 - autoencoder_loss: 0.0394 - classifier_accuracy: 0.1024 - classifier_loss: 0.0028 - loss: 0.1255\n",
      "Epoch 930/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 517ms/step - autoencoder_accuracy: 0.0086 - autoencoder_loss: 0.0393 - classifier_accuracy: 0.1025 - classifier_loss: 0.0028 - loss: 0.1253\n",
      "Epoch 931/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 500ms/step - autoencoder_accuracy: 0.0085 - autoencoder_loss: 0.0393 - classifier_accuracy: 0.1027 - classifier_loss: 0.0028 - loss: 0.1252\n",
      "Epoch 932/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 529ms/step - autoencoder_accuracy: 0.0086 - autoencoder_loss: 0.0393 - classifier_accuracy: 0.1027 - classifier_loss: 0.0028 - loss: 0.1251\n",
      "Epoch 933/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 580ms/step - autoencoder_accuracy: 0.0085 - autoencoder_loss: 0.0393 - classifier_accuracy: 0.1026 - classifier_loss: 0.0028 - loss: 0.1250\n",
      "Epoch 934/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480ms/step - autoencoder_accuracy: 0.0085 - autoencoder_loss: 0.0393 - classifier_accuracy: 0.1025 - classifier_loss: 0.0027 - loss: 0.1248\n",
      "Epoch 935/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 662ms/step - autoencoder_accuracy: 0.0085 - autoencoder_loss: 0.0393 - classifier_accuracy: 0.1025 - classifier_loss: 0.0027 - loss: 0.1247\n",
      "Epoch 936/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 583ms/step - autoencoder_accuracy: 0.0086 - autoencoder_loss: 0.0393 - classifier_accuracy: 0.1025 - classifier_loss: 0.0027 - loss: 0.1246\n",
      "Epoch 937/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492ms/step - autoencoder_accuracy: 0.0086 - autoencoder_loss: 0.0393 - classifier_accuracy: 0.1025 - classifier_loss: 0.0027 - loss: 0.1245\n",
      "Epoch 938/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 538ms/step - autoencoder_accuracy: 0.0086 - autoencoder_loss: 0.0392 - classifier_accuracy: 0.1025 - classifier_loss: 0.0027 - loss: 0.1243\n",
      "Epoch 939/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 511ms/step - autoencoder_accuracy: 0.0085 - autoencoder_loss: 0.0392 - classifier_accuracy: 0.1024 - classifier_loss: 0.0027 - loss: 0.1242\n",
      "Epoch 940/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 559ms/step - autoencoder_accuracy: 0.0085 - autoencoder_loss: 0.0392 - classifier_accuracy: 0.1024 - classifier_loss: 0.0027 - loss: 0.1241\n",
      "Epoch 941/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474ms/step - autoencoder_accuracy: 0.0085 - autoencoder_loss: 0.0392 - classifier_accuracy: 0.1024 - classifier_loss: 0.0027 - loss: 0.1240\n",
      "Epoch 942/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388ms/step - autoencoder_accuracy: 0.0086 - autoencoder_loss: 0.0392 - classifier_accuracy: 0.1024 - classifier_loss: 0.0027 - loss: 0.1238\n",
      "Epoch 943/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 574ms/step - autoencoder_accuracy: 0.0086 - autoencoder_loss: 0.0392 - classifier_accuracy: 0.1024 - classifier_loss: 0.0027 - loss: 0.1237\n",
      "Epoch 944/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490ms/step - autoencoder_accuracy: 0.0086 - autoencoder_loss: 0.0392 - classifier_accuracy: 0.1024 - classifier_loss: 0.0027 - loss: 0.1236\n",
      "Epoch 945/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 501ms/step - autoencoder_accuracy: 0.0086 - autoencoder_loss: 0.0391 - classifier_accuracy: 0.1024 - classifier_loss: 0.0027 - loss: 0.1235\n",
      "Epoch 946/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 524ms/step - autoencoder_accuracy: 0.0086 - autoencoder_loss: 0.0391 - classifier_accuracy: 0.1023 - classifier_loss: 0.0027 - loss: 0.1233\n",
      "Epoch 947/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 501ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0391 - classifier_accuracy: 0.1023 - classifier_loss: 0.0027 - loss: 0.1232\n",
      "Epoch 948/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 544ms/step - autoencoder_accuracy: 0.0086 - autoencoder_loss: 0.0391 - classifier_accuracy: 0.1023 - classifier_loss: 0.0027 - loss: 0.1231\n",
      "Epoch 949/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 561ms/step - autoencoder_accuracy: 0.0086 - autoencoder_loss: 0.0391 - classifier_accuracy: 0.1023 - classifier_loss: 0.0027 - loss: 0.1230\n",
      "Epoch 950/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473ms/step - autoencoder_accuracy: 0.0086 - autoencoder_loss: 0.0391 - classifier_accuracy: 0.1023 - classifier_loss: 0.0027 - loss: 0.1229\n",
      "Epoch 951/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 549ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0391 - classifier_accuracy: 0.1023 - classifier_loss: 0.0027 - loss: 0.1227\n",
      "Epoch 952/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 573ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0391 - classifier_accuracy: 0.1023 - classifier_loss: 0.0027 - loss: 0.1226\n",
      "Epoch 953/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0390 - classifier_accuracy: 0.1023 - classifier_loss: 0.0027 - loss: 0.1225\n",
      "Epoch 954/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 405ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0390 - classifier_accuracy: 0.1023 - classifier_loss: 0.0027 - loss: 0.1224\n",
      "Epoch 955/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 554ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0390 - classifier_accuracy: 0.1023 - classifier_loss: 0.0027 - loss: 0.1222\n",
      "Epoch 956/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0390 - classifier_accuracy: 0.1023 - classifier_loss: 0.0027 - loss: 0.1221\n",
      "Epoch 957/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 522ms/step - autoencoder_accuracy: 0.0086 - autoencoder_loss: 0.0390 - classifier_accuracy: 0.1023 - classifier_loss: 0.0027 - loss: 0.1220\n",
      "Epoch 958/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 603ms/step - autoencoder_accuracy: 0.0086 - autoencoder_loss: 0.0390 - classifier_accuracy: 0.1024 - classifier_loss: 0.0027 - loss: 0.1219\n",
      "Epoch 959/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 529ms/step - autoencoder_accuracy: 0.0086 - autoencoder_loss: 0.0390 - classifier_accuracy: 0.1023 - classifier_loss: 0.0027 - loss: 0.1218\n",
      "Epoch 960/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 468ms/step - autoencoder_accuracy: 0.0086 - autoencoder_loss: 0.0389 - classifier_accuracy: 0.1023 - classifier_loss: 0.0026 - loss: 0.1216\n",
      "Epoch 961/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 560ms/step - autoencoder_accuracy: 0.0086 - autoencoder_loss: 0.0389 - classifier_accuracy: 0.1023 - classifier_loss: 0.0026 - loss: 0.1215\n",
      "Epoch 962/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 612ms/step - autoencoder_accuracy: 0.0086 - autoencoder_loss: 0.0389 - classifier_accuracy: 0.1023 - classifier_loss: 0.0026 - loss: 0.1214\n",
      "Epoch 963/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 523ms/step - autoencoder_accuracy: 0.0086 - autoencoder_loss: 0.0389 - classifier_accuracy: 0.1023 - classifier_loss: 0.0026 - loss: 0.1213\n",
      "Epoch 964/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 610ms/step - autoencoder_accuracy: 0.0086 - autoencoder_loss: 0.0389 - classifier_accuracy: 0.1023 - classifier_loss: 0.0026 - loss: 0.1211\n",
      "Epoch 965/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 542ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0389 - classifier_accuracy: 0.1023 - classifier_loss: 0.0026 - loss: 0.1210\n",
      "Epoch 966/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 590ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0389 - classifier_accuracy: 0.1023 - classifier_loss: 0.0026 - loss: 0.1209\n",
      "Epoch 967/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 546ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0389 - classifier_accuracy: 0.1023 - classifier_loss: 0.0026 - loss: 0.1208\n",
      "Epoch 968/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 437ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0388 - classifier_accuracy: 0.1022 - classifier_loss: 0.0026 - loss: 0.1207\n",
      "Epoch 969/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0388 - classifier_accuracy: 0.1022 - classifier_loss: 0.0026 - loss: 0.1205\n",
      "Epoch 970/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 543ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0388 - classifier_accuracy: 0.1022 - classifier_loss: 0.0026 - loss: 0.1204\n",
      "Epoch 971/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 567ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0388 - classifier_accuracy: 0.1022 - classifier_loss: 0.0026 - loss: 0.1203\n",
      "Epoch 972/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 510ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0388 - classifier_accuracy: 0.1022 - classifier_loss: 0.0026 - loss: 0.1202\n",
      "Epoch 973/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 619ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0388 - classifier_accuracy: 0.1022 - classifier_loss: 0.0026 - loss: 0.1201\n",
      "Epoch 974/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 639ms/step - autoencoder_accuracy: 0.0088 - autoencoder_loss: 0.0388 - classifier_accuracy: 0.1021 - classifier_loss: 0.0026 - loss: 0.1199\n",
      "Epoch 975/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 566ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0387 - classifier_accuracy: 0.1021 - classifier_loss: 0.0026 - loss: 0.1198\n",
      "Epoch 976/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 575ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0387 - classifier_accuracy: 0.1021 - classifier_loss: 0.0026 - loss: 0.1197\n",
      "Epoch 977/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 557ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0387 - classifier_accuracy: 0.1022 - classifier_loss: 0.0026 - loss: 0.1196\n",
      "Epoch 978/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 576ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0387 - classifier_accuracy: 0.1022 - classifier_loss: 0.0026 - loss: 0.1195\n",
      "Epoch 979/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 529ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0387 - classifier_accuracy: 0.1022 - classifier_loss: 0.0026 - loss: 0.1193\n",
      "Epoch 980/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 539ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0387 - classifier_accuracy: 0.1022 - classifier_loss: 0.0026 - loss: 0.1192\n",
      "Epoch 981/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 558ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0387 - classifier_accuracy: 0.1022 - classifier_loss: 0.0026 - loss: 0.1191\n",
      "Epoch 982/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 514ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0387 - classifier_accuracy: 0.1021 - classifier_loss: 0.0026 - loss: 0.1190\n",
      "Epoch 983/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 525ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0386 - classifier_accuracy: 0.1021 - classifier_loss: 0.0026 - loss: 0.1189\n",
      "Epoch 984/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 538ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0386 - classifier_accuracy: 0.1021 - classifier_loss: 0.0026 - loss: 0.1188\n",
      "Epoch 985/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0386 - classifier_accuracy: 0.1020 - classifier_loss: 0.0026 - loss: 0.1186\n",
      "Epoch 986/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 513ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0386 - classifier_accuracy: 0.1020 - classifier_loss: 0.0026 - loss: 0.1185\n",
      "Epoch 987/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0386 - classifier_accuracy: 0.1020 - classifier_loss: 0.0026 - loss: 0.1184\n",
      "Epoch 988/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 592ms/step - autoencoder_accuracy: 0.0086 - autoencoder_loss: 0.0386 - classifier_accuracy: 0.1020 - classifier_loss: 0.0026 - loss: 0.1183\n",
      "Epoch 989/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 533ms/step - autoencoder_accuracy: 0.0086 - autoencoder_loss: 0.0386 - classifier_accuracy: 0.1021 - classifier_loss: 0.0026 - loss: 0.1182\n",
      "Epoch 990/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 435ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0385 - classifier_accuracy: 0.1021 - classifier_loss: 0.0025 - loss: 0.1180\n",
      "Epoch 991/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 566ms/step - autoencoder_accuracy: 0.0086 - autoencoder_loss: 0.0385 - classifier_accuracy: 0.1021 - classifier_loss: 0.0025 - loss: 0.1179\n",
      "Epoch 992/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 535ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0385 - classifier_accuracy: 0.1021 - classifier_loss: 0.0025 - loss: 0.1178\n",
      "Epoch 993/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 570ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0385 - classifier_accuracy: 0.1021 - classifier_loss: 0.0025 - loss: 0.1177\n",
      "Epoch 994/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 514ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0385 - classifier_accuracy: 0.1022 - classifier_loss: 0.0025 - loss: 0.1176\n",
      "Epoch 995/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0385 - classifier_accuracy: 0.1022 - classifier_loss: 0.0025 - loss: 0.1175\n",
      "Epoch 996/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 552ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0385 - classifier_accuracy: 0.1022 - classifier_loss: 0.0025 - loss: 0.1173\n",
      "Epoch 997/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 501ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0385 - classifier_accuracy: 0.1022 - classifier_loss: 0.0025 - loss: 0.1172\n",
      "Epoch 998/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 581ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0384 - classifier_accuracy: 0.1022 - classifier_loss: 0.0025 - loss: 0.1171\n",
      "Epoch 999/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 637ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0384 - classifier_accuracy: 0.1022 - classifier_loss: 0.0025 - loss: 0.1170\n",
      "Epoch 1000/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 524ms/step - autoencoder_accuracy: 0.0087 - autoencoder_loss: 0.0384 - classifier_accuracy: 0.1022 - classifier_loss: 0.0025 - loss: 0.1169\n"
     ]
    }
   ],
   "source": [
    "# TODO: Crea y entrena tu clasificador\n",
    "\n",
    "model = MiClasificadorSemisupervisado(input_shape=x_train[0].shape)\n",
    "\n",
    "h = semisupervised_training_v2(model, x_train, one_hot_train, unlabeled_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "id": "JSVVW8fZXWGs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 318 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x345c25d00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n",
      "Test accuracy : 0.816\n"
     ]
    }
   ],
   "source": [
    "# TODO: Obtén la precisión sobre el conjunto de test\n",
    "print('Test accuracy :', model.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "index = 32\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "axes[0].imshow(x_test[index].reshape(28, 28), cmap='gray')\n",
    "axes[0].set_title(\"Original Image\")\n",
    "axes[0].axis('off') \n",
    "\n",
    "# Get the reconstructed image from the autoencoder\n",
    "reconstructed_image, label = model(x_test[index].reshape(1, 784))\n",
    "\n",
    "# Plot the reconstructed image on the right\n",
    "axes[1].imshow(reconstructed_image.reshape(28, 28), cmap='gray')\n",
    "axes[1].set_title(f\"Reconstructed Image, predicted {np.argmax(label)}\")\n",
    "axes[1].axis('off')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(h.history['classifier_accuracy'], label='Classifier Accuracy')\n",
    "plt.plot(h.history['autoencoder_accuracy'], label='Autoencoder Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mPGRXmHXptYW"
   },
   "source": [
    "# Hay vida más allá del autoencoder\n",
    "\n",
    "¿Has probado a utilizar otro método distinto del autoencoder para obtener una respresentación similar a la salida del encoder? La idea es la siguiente:\n",
    "\n",
    "1. Define un modelo $model$ convolucional similar al encoder de un autoencoder (la entrada es el tamaño de la imagen, la salida el vector de representación)\n",
    "1. Define una capa de salida $cluster$ que, partiendo de la salida de model, nos devuelva una salida con el mismo número de clases que el dataset a utilizar (la entrada es el vector de representación), usando softmax como activación de salida\n",
    "1. Para cada batch de entrenamiento $X$:  # Usa un batch alto, mínimo 128\n",
    "  1. Modifica las imágenes de entrada con [data_augmentation](https://www.tensorflow.org/tutorials/images/data_augmentation?hl=es-419), llámala $augX_1$.\n",
    "  1. Modifica otra vez las imágenes de entrada con [data_augmentation_2](https://www.tensorflow.org/tutorials/images/data_augmentation?hl=es-419), llámala $augX_2$.\n",
    "  1. $augX_{1comp} \\leftarrow model(augX_1)$\n",
    "  1. $augX_{2comp} \\leftarrow model(augX_2)$\n",
    "  1. $cX_{1comp} \\leftarrow cluster(augX_{1comp})$\n",
    "  1. $cX_{2comp} \\leftarrow cluster(augX_{2comp})$\n",
    "  1. $M \\leftarrow augX_{1comp} ~ augX_{2comp}^T$\n",
    "  1. $loss_C \\leftarrow cX_{1comp}(1 - cX_{1comp}) + cX_{2comp}(1 - cX_{2comp})$ # Puede que tengas que crear tu [propia función de coste](https://keras.io/api/losses/#creating-custom-losses)\n",
    "  1. $loss_M \\leftarrow crossentropy(I, softmax(M/\\tau, axis=1)))$ # Puede que tengas que crear tu [propia función de coste](https://keras.io/api/losses/#creating-custom-losses)\n",
    "  1. $\\tau$ es un hiperparámetro que se suele definir a 5.0\n",
    "  1. $loss \\leftarrow loss_M + \\lambda~loss_C$\n",
    "    1. $\\lambda$ es un hiperparámetro (puedes probar con 0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "7cXegrUWtiFW"
   },
   "outputs": [],
   "source": [
    "# Escribe aquí la solución. Crea tantos bloques de código como necesites. Puedes utilizar la siguiente red para generar distorsiones\n",
    "\n",
    "\n",
    "class ContrastiveLoss():\n",
    "    def __init__(self, temperature=0.5):\n",
    "        self.temperature = temperature\n",
    "        \n",
    "    def __call__(self, M):\n",
    "        # y_true es la matriz identidad (no la usamos directamente)\n",
    "        # y_pred es la matriz de similitud M\n",
    "        \n",
    "        # Aplicamos softmax con temperatura\n",
    "        logits = M / self.temperature\n",
    "        logits_max = tf.reduce_max(logits, axis=1, keepdims=True)\n",
    "        logits = logits - logits_max\n",
    "        exp_logits = tf.exp(logits)\n",
    "        exp_logits_sum = tf.reduce_sum(exp_logits, axis=1, keepdims=True)\n",
    "        probs = exp_logits / exp_logits_sum # softmax\n",
    "        \n",
    "        # Creamos matriz identidad como objetivo\n",
    "        batch_size = tf.shape(M)[0]\n",
    "        I = tf.eye(batch_size)\n",
    "\n",
    "        # Seleccionamos las probabilidades de la clase correcta (diagonal de y_true)\n",
    "        correct_class_probs = tf.matmul(I, probs)   \n",
    "        # Calculamos entropia cruzada\n",
    "        loss = -tf.reduce_mean(tf.math.log(correct_class_probs + 1e-10))\n",
    "        \n",
    "        return loss\n",
    "\n",
    "# Función de pérdida para el clustering\n",
    "class ClusteringLoss():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def __call__(self, cX_1comp, cX_2comp):\n",
    "\n",
    "        # loss_C = cX_1comp(1 - cX_1comp) + cX_2comp(1 - cX_2comp)\n",
    "        loss_1 = tf.reduce_mean(cX_1comp * (1 - cX_1comp))\n",
    "        loss_2 = tf.reduce_mean(cX_2comp * (1 - cX_2comp))\n",
    "        \n",
    "        return loss_1 + loss_2\n",
    "\n",
    "\n",
    "class ContrastiveModel():\n",
    "    def __init__(self, input_shape, lambda_param = 0.5, temperature = 0.5, learning_rate=0.0005):\n",
    "\n",
    "        self.lambda_param = lambda_param\n",
    "        self.contrastive_loss = ContrastiveLoss(temperature=temperature)\n",
    "        self.clustering_loss = ClusteringLoss()\n",
    "        self.optimicer = tf.keras.optimizers.AdamW(\n",
    "            learning_rate=learning_rate,\n",
    "            clipnorm=1,\n",
    "        )\n",
    "\n",
    "        self.data_augmentation_1 = tf.keras.models.Sequential([\n",
    "                # tf.keras.layers.RandomFlip(\"horizontal\"),  # Puede ser util en otros casos\n",
    "                tf.keras.layers.RandomRotation(0.05),\n",
    "                tf.keras.layers.RandomTranslation(0.15, 0.15),\n",
    "                tf.keras.layers.RandomZoom(.15),\n",
    "            ])\n",
    "    \n",
    "        self.data_augmentation_2 = tf.keras.models.Sequential([\n",
    "                # tf.keras.layers.RandomFlip(\"horizontal\"),  # Puede ser util en otros casos\n",
    "                tf.keras.layers.RandomTranslation(0.15, 0.15),\n",
    "                tf.keras.layers.RandomRotation(.2)\n",
    "                #tf.keras.layers.Resizing(40, 40), # para CIFAR, para MNIST usar 40 en lugar de 48\n",
    "                #tf.keras.layers.RandomCrop(28, 28), # para CIFAR, para MNIST usar 28 en lugar de 32\n",
    "            ])\n",
    "            \n",
    "        # Definir modelo convolucional\n",
    "        input_layer = tf.keras.layers.Input(batch_shape=(None, 28, 28,1))  # Tamaño de imagen\n",
    "        conv_layer = tf.keras.layers.Conv2D(8, (3, 3), activation='relu')(input_layer)\n",
    "        conv_layer = tf.keras.layers.Conv2D(8, (3, 3), activation='relu')(conv_layer)\n",
    "        conv_layer = tf.keras.layers.Conv2D(8, (3, 3), activation='relu')(conv_layer)\n",
    "        conv_layer = tf.keras.layers.Conv2D(16, (3, 3), activation='relu')(conv_layer)\n",
    "        conv_layer = tf.keras.layers.Conv2D(32, (3, 3), activation='relu')(conv_layer)\n",
    "        flatten_layer = tf.keras.layers.Flatten()(conv_layer)\n",
    "        \n",
    "        # Capa de clustering\n",
    "        cluster_layer = tf.keras.layers.Dense(10, activation='softmax')(flatten_layer)\n",
    "        \n",
    "        # Modelo final\n",
    "        self.encoder = tf.keras.Model(input_layer, outputs=flatten_layer)\n",
    "        self.cluster = tf.keras.Model(flatten_layer, outputs=cluster_layer)\n",
    "        \n",
    "        #model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    \n",
    "    def train_step(self, data):\n",
    "        if isinstance(data, tuple):\n",
    "            X = data[0]\n",
    "        else:\n",
    "            X = data\n",
    "            \n",
    "        batch_size = tf.shape(X)[0]\n",
    "        \n",
    "        # Aplicar las dos transformaciones de data augmentation\n",
    "        augX_1 = self.data_augmentation_1(X)\n",
    "        augX_2 = self.data_augmentation_2(X)\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            #print(f'< 1 {augX_1.shape}, 2 {augX_2.shape}')\n",
    "            # Obtener representaciones del encoder\n",
    "            augX_1comp = self.encoder(augX_1)\n",
    "            #augX_1comp = self.encoder(X)\n",
    "            augX_2comp = self.encoder(augX_2)\n",
    "            #augX_2comp = self.encoder(X)\n",
    "            #print(f'<< 1 {augX_1comp.shape}, 2 {augX_2comp.shape}')\n",
    "            # Obtener salidas del clustering\n",
    "            #augX_1comp = tf.keras.layers.Flatten('channels_last')(augX_1comp)\n",
    "            cX_1comp = self.cluster(augX_1comp)\n",
    "            cX_2comp = self.cluster(augX_2comp)\n",
    "\n",
    "            \n",
    "            # Calcular matriz de similitud M\n",
    "            M = tf.matmul(augX_1comp, augX_2comp, transpose_b=True)\n",
    "            #print(f'm {M.shape}, 1 {augX_1comp.shape}, 2 {augX_2comp.shape}')\n",
    "            \n",
    "            plt.imshow(M.numpy())\n",
    "            \n",
    "            # Calcular pérdida de contraste\n",
    "            loss_M = self.contrastive_loss(M)\n",
    "            \n",
    "            # Calcular pérdida de clustering\n",
    "            loss_C = self.clustering_loss(cX_1comp, cX_2comp)\n",
    "            \n",
    "            # Pérdida total\n",
    "            total_loss = loss_M + self.lambda_param * loss_C\n",
    "            \n",
    "        # Calcular gradientes y actualizar pesos\n",
    "        gradients = tape.gradient(total_loss, self.cluster.trainable_variables)\n",
    "        self.optimicer.apply_gradients(zip(gradients, self.cluster.trainable_variables))\n",
    "        \n",
    "        return {\"loss\": total_loss, \"contrastive_loss\": loss_M, \"clustering_loss\": loss_C}\n",
    "\n",
    "    def mini_batches(self, X, batch_size):\n",
    "        for start in range(0, X.shape[0], batch_size):\n",
    "            # Yield each mini-batch\n",
    "            end = min(start + batch_size, X.shape[0])\n",
    "            yield X[start:end]\n",
    "\n",
    "    def train(self, dataset, epochs=10, batch_size=128):\n",
    "        for epoch in range(epochs):\n",
    "            total_loss = 0\n",
    "            for data in self.mini_batches(dataset, batch_size=batch_size):\n",
    "                loss_dict = self.train_step(data)\n",
    "                total_loss += loss_dict[\"loss\"]\n",
    "            \n",
    "           \n",
    "            print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss_dict[\"loss\"]}\")\n",
    "\n",
    "    def __call__(self, X):\n",
    "        return self.encoder.predict(X), self.clusters.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastiveLoss():\n",
    "    def __init__(self, temperature=0.5):\n",
    "        self.temperature = temperature\n",
    "        \n",
    "    def __call__(self, M):\n",
    "        # y_true es la matriz identidad (no la usamos directamente)\n",
    "        # y_pred es la matriz de similitud M\n",
    "        \n",
    "        # Aplicamos softmax con temperatura\n",
    "        logits = M / self.temperature\n",
    "        logits_max = tf.reduce_max(logits, axis=1, keepdims=True)\n",
    "        logits = logits - logits_max\n",
    "        exp_logits = tf.exp(logits)\n",
    "        exp_logits_sum = tf.reduce_sum(exp_logits, axis=1, keepdims=True)\n",
    "        probs = exp_logits / exp_logits_sum # softmax\n",
    "        \n",
    "        # Creamos matriz identidad como objetivo\n",
    "        batch_size = tf.shape(M)[0]\n",
    "        I = tf.eye(batch_size)\n",
    "        # Seleccionamos las probabilidades de la clase correcta (diagonal de y_true)\n",
    "        correct_class_probs = tf.matmul(I, probs)   \n",
    "        # Calculamos entropia cruzada\n",
    "        loss = -tf.reduce_mean(tf.math.log(correct_class_probs + 1e-10))\n",
    "        \n",
    "        return loss\n",
    "\n",
    "# Función de pérdida para el clustering\n",
    "class ClusteringLoss():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def __call__(self, cX_1comp, cX_2comp):\n",
    "        # loss_C = cX_1comp(1 - cX_1comp) + cX_2comp(1 - cX_2comp)\n",
    "        loss_1 = tf.reduce_mean(cX_1comp * (1 - cX_1comp))\n",
    "        loss_2 = tf.reduce_mean(cX_2comp * (1 - cX_2comp))\n",
    "        \n",
    "        return loss_1 + loss_2\n",
    "\n",
    "class ContrastiveModel():\n",
    "    def __init__(self, input_shape, lambda_param = 0.5, temperature = 0.5, learning_rate=0.0005):\n",
    "        self.lambda_param = lambda_param\n",
    "        self.contrastive_loss = ContrastiveLoss(temperature=temperature)\n",
    "        self.clustering_loss = ClusteringLoss()\n",
    "        self.optimicer = tf.keras.optimizers.AdamW(\n",
    "            learning_rate=learning_rate,\n",
    "            clipnorm=1,\n",
    "        )\n",
    "        self.data_augmentation_1 = tf.keras.models.Sequential([\n",
    "                # tf.keras.layers.RandomFlip(\"horizontal\"),  # Puede ser util en otros casos\n",
    "                tf.keras.layers.RandomRotation(0.05),\n",
    "                tf.keras.layers.RandomTranslation(0.15, 0.15),\n",
    "                tf.keras.layers.RandomZoom(.15),\n",
    "            ])\n",
    "    \n",
    "        self.data_augmentation_2 = tf.keras.models.Sequential([\n",
    "                # tf.keras.layers.RandomFlip(\"horizontal\"),  # Puede ser util en otros casos\n",
    "                tf.keras.layers.RandomTranslation(0.15, 0.15),\n",
    "                tf.keras.layers.RandomRotation(.2),\n",
    "                tf.keras.layers.Resizing(40, 40), # para CIFAR, para MNIST usar 40 en lugar de 48\n",
    "                tf.keras.layers.RandomCrop(28, 28), # para CIFAR, para MNIST usar 28 en lugar de 32\n",
    "            ])\n",
    "            \n",
    "        # Definir modelo convolucional\n",
    "        input_layer = tf.keras.layers.Input(batch_shape=(None, 28, 28,1))  # Tamaño de imagen\n",
    "        conv_layer = tf.keras.layers.Conv2D(8, (3, 3), activation='relu')(input_layer)\n",
    "        conv_layer = tf.keras.layers.Conv2D(8, (3, 3), activation='relu')(conv_layer)\n",
    "        conv_layer = tf.keras.layers.Conv2D(8, (3, 3), activation='relu')(conv_layer)\n",
    "        conv_layer = tf.keras.layers.Conv2D(16, (3, 3), activation='relu')(conv_layer)\n",
    "        conv_layer = tf.keras.layers.Conv2D(32, (3, 3), activation='relu')(conv_layer)\n",
    "        flatten_layer = tf.keras.layers.Flatten()(conv_layer)\n",
    "        \n",
    "        # Capa de clustering\n",
    "        cluster_layer = tf.keras.layers.Dense(10, activation='softmax')(flatten_layer)\n",
    "        \n",
    "        # Modelo final\n",
    "        self.encoder = tf.keras.Model(input_layer, outputs=flatten_layer)\n",
    "        self.cluster = tf.keras.Model(flatten_layer, outputs=cluster_layer)\n",
    "        \n",
    "        # Historial de pérdidas para graficar\n",
    "        self.loss_history = {\n",
    "            'total_loss': [],\n",
    "            'contrastive_loss': [],\n",
    "            'clustering_loss': []\n",
    "        }\n",
    "        \n",
    "        #model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    def train_step(self, data):\n",
    "        if isinstance(data, tuple):\n",
    "            X = data[0]\n",
    "        else:\n",
    "            X = data\n",
    "            \n",
    "        batch_size = tf.shape(X)[0]\n",
    "        \n",
    "        # Aplicar las dos transformaciones de data augmentation\n",
    "        augX_1 = self.data_augmentation_1(X)\n",
    "        augX_2 = self.data_augmentation_2(X)\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            #print(f'< 1 {augX_1.shape}, 2 {augX_2.shape}')\n",
    "            # Obtener representaciones del encoder\n",
    "            augX_1comp = self.encoder(augX_1)\n",
    "            #augX_1comp = self.encoder(X)\n",
    "            augX_2comp = self.encoder(augX_2)\n",
    "            #augX_2comp = self.encoder(X)\n",
    "            #print(f'<< 1 {augX_1comp.shape}, 2 {augX_2comp.shape}')\n",
    "            # Obtener salidas del clustering\n",
    "            #augX_1comp = tf.keras.layers.Flatten('channels_last')(augX_1comp)\n",
    "            cX_1comp = self.cluster(augX_1comp)\n",
    "            cX_2comp = self.cluster(augX_2comp)\n",
    "            \n",
    "            # Calcular matriz de similitud M\n",
    "            M = tf.matmul(augX_1comp, augX_2comp, transpose_b=True)\n",
    "            #print(f'm {M.shape}, 1 {augX_1comp.shape}, 2 {augX_2comp.shape}')\n",
    "            \n",
    "            # Calcular pérdida de contraste\n",
    "            loss_M = self.contrastive_loss(M)\n",
    "            \n",
    "            # Calcular pérdida de clustering\n",
    "            loss_C = self.clustering_loss(cX_1comp, cX_2comp)\n",
    "            \n",
    "            # Pérdida total\n",
    "            total_loss = loss_M + self.lambda_param * loss_C\n",
    "            \n",
    "        # Calcular gradientes y actualizar pesos\n",
    "        gradients = tape.gradient(total_loss, self.encoder.trainable_variables + self.cluster.trainable_variables)\n",
    "        self.optimicer.apply_gradients(zip(gradients, self.encoder.trainable_variables + self.cluster.trainable_variables))\n",
    "        \n",
    "        return {\"loss\": total_loss, \"contrastive_loss\": loss_M, \"clustering_loss\": loss_C}\n",
    "    \n",
    "    def mini_batches(self, X, batch_size):\n",
    "        for start in range(0, X.shape[0], batch_size):\n",
    "            # Yield each mini-batch\n",
    "            end = min(start + batch_size, X.shape[0])\n",
    "            yield X[start:end]\n",
    "    \n",
    "    def train(self, dataset, epochs=10, batch_size=128):\n",
    "        # Reiniciar el historial de pérdida si comenzamos un nuevo entrenamiento\n",
    "        self.loss_history = {\n",
    "            'total_loss': [],\n",
    "            'contrastive_loss': [],\n",
    "            'clustering_loss': []\n",
    "        }\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            epoch_total_loss = 0\n",
    "            epoch_contrastive_loss = 0\n",
    "            epoch_clustering_loss = 0\n",
    "            batch_count = 0\n",
    "            \n",
    "            for data in self.mini_batches(dataset, batch_size=batch_size):\n",
    "                loss_dict = self.train_step(data)\n",
    "                epoch_total_loss += loss_dict[\"loss\"]\n",
    "                epoch_contrastive_loss += loss_dict[\"contrastive_loss\"]\n",
    "                epoch_clustering_loss += loss_dict[\"clustering_loss\"]\n",
    "                batch_count += 1\n",
    "            \n",
    "            # Calcular promedios para la época\n",
    "            avg_total_loss = epoch_total_loss / batch_count\n",
    "            avg_contrastive_loss = epoch_contrastive_loss / batch_count\n",
    "            avg_clustering_loss = epoch_clustering_loss / batch_count\n",
    "            \n",
    "            # Guardar en el historial\n",
    "            self.loss_history['total_loss'].append(avg_total_loss.numpy())\n",
    "            self.loss_history['contrastive_loss'].append(avg_contrastive_loss.numpy())\n",
    "            self.loss_history['clustering_loss'].append(avg_clustering_loss.numpy())\n",
    "            \n",
    "            print(f\"Epoch {epoch+1}/{epochs}, Total Loss: {avg_total_loss:.4f}, \"\n",
    "                  f\"Contrastive Loss: {avg_contrastive_loss:.4f}, \"\n",
    "                  f\"Clustering Loss: {avg_clustering_loss:.4f}\")\n",
    "    \n",
    "    def plot_training_history(self, figsize=(12, 6)):\n",
    "        \"\"\"\n",
    "        Visualiza el historial de pérdidas durante el entrenamiento.\n",
    "        \"\"\"\n",
    "        import matplotlib.pyplot as plt\n",
    "        \n",
    "        epochs = range(1, len(self.loss_history['total_loss']) + 1)\n",
    "        \n",
    "        plt.figure(figsize=figsize)\n",
    "        \n",
    "        # Gráfico de pérdida total\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(epochs, self.loss_history['total_loss'], 'b-', label='Total Loss')\n",
    "        plt.title('Total Loss')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        \n",
    "        # Gráfico comparativo de pérdidas\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(epochs, self.loss_history['contrastive_loss'], 'r-', label='Contrastive Loss')\n",
    "        plt.plot(epochs, self.loss_history['clustering_loss'], 'g-', label='Clustering Loss')\n",
    "        plt.title('Component Losses')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def __call__(self, X):\n",
    "        features = self.encoder(X)\n",
    "        clusters = self.cluster(features)\n",
    "        return features, clusters\n",
    "\n",
    "    def plot_similarity_matrix(self, X, n_samples=10):\n",
    "        \"\"\"\n",
    "        Visualiza la matriz de similitud para un conjunto de muestras.\n",
    "        \"\"\"\n",
    "        import matplotlib.pyplot as plt\n",
    "        import numpy as np\n",
    "        \n",
    "        # Seleccionar n_samples aleatorias\n",
    "        if n_samples < X.shape[0]:\n",
    "            indices = np.random.choice(X.shape[0], n_samples, replace=False)\n",
    "            samples = X[indices]\n",
    "        else:\n",
    "            samples = X\n",
    "            \n",
    "        # Aplicar data augmentation\n",
    "        augX_1 = self.data_augmentation_1(samples)\n",
    "        augX_2 = self.data_augmentation_2(samples)\n",
    "        \n",
    "        # Obtener representaciones\n",
    "        augX_1comp = self.encoder(augX_1)\n",
    "        augX_2comp = self.encoder(augX_2)\n",
    "        \n",
    "        # Calcular matriz de similitud\n",
    "        M = tf.matmul(augX_1comp, augX_2comp, transpose_b=True).numpy()\n",
    "        \n",
    "        # Visualizar\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.imshow(M, cmap='viridis')\n",
    "        plt.colorbar()\n",
    "        plt.title('Similarity Matrix')\n",
    "        plt.xlabel('Augmentation 2')\n",
    "        plt.ylabel('Augmentation 1')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_data = 0.01 # Vamos a usar el etiquetado de sólo el 1% de los datos\n",
    "np.random.seed(42)\n",
    "\n",
    "(x_train, y_train), (x_test, y_test), = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "indexes = np.arange(len(x_train))\n",
    "np.random.shuffle(indexes)\n",
    "ntrain_data = int(labeled_data*len(x_train))\n",
    "unlabeled_train = x_train[indexes[ntrain_data:]]\n",
    "x_train = x_train[indexes[:ntrain_data]] \n",
    "y_train = y_train[indexes[:ntrain_data]]\n",
    "\n",
    "\n",
    "# TODO: Haz el preprocesado que necesites aquí (si lo necesitas)\n",
    "\n",
    "x_train = x_train /255\n",
    "x_test = x_test /255\n",
    "unlabeled_train = unlabeled_train /255\n",
    "\n",
    "one_hot_train = np.zeros((y_train.size, len(set(y_train))), dtype=int)\n",
    "one_hot_train[np.arange(y_train.size), y_train ] = 1\n",
    "\n",
    "one_hot_test = np.zeros((y_test.size, len(set(y_test))), dtype=int)\n",
    "one_hot_test[np.arange(y_test.size), y_test ] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-02 15:35:52.102051: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1\n",
      "2025-04-02 15:35:52.102391: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 8.00 GB\n",
      "2025-04-02 15:35:52.102423: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 2.67 GB\n",
      "2025-04-02 15:35:52.102836: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-04-02 15:35:52.102885: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Total Loss: 12.3804, Contrastive Loss: 3.3822, Clustering Loss: 0.1800\n",
      "Epoch 2/20, Total Loss: 12.3248, Contrastive Loss: 3.3337, Clustering Loss: 0.1798\n",
      "Epoch 3/20, Total Loss: 12.0602, Contrastive Loss: 3.3419, Clustering Loss: 0.1744\n",
      "Epoch 4/20, Total Loss: 11.0825, Contrastive Loss: 3.4184, Clustering Loss: 0.1533\n",
      "Epoch 5/20, Total Loss: 8.1181, Contrastive Loss: 3.4712, Clustering Loss: 0.0929\n",
      "Epoch 6/20, Total Loss: 3.6234, Contrastive Loss: 3.5483, Clustering Loss: 0.0015\n",
      "Epoch 7/20, Total Loss: 3.4023, Contrastive Loss: 3.3860, Clustering Loss: 0.0003\n",
      "Epoch 8/20, Total Loss: 3.3680, Contrastive Loss: 3.3599, Clustering Loss: 0.0002\n",
      "Epoch 9/20, Total Loss: 3.3560, Contrastive Loss: 3.3515, Clustering Loss: 0.0001\n",
      "Epoch 10/20, Total Loss: 3.3515, Contrastive Loss: 3.3481, Clustering Loss: 0.0001\n",
      "Epoch 11/20, Total Loss: 3.3479, Contrastive Loss: 3.3450, Clustering Loss: 0.0001\n",
      "Epoch 12/20, Total Loss: 3.3450, Contrastive Loss: 3.3427, Clustering Loss: 0.0000\n",
      "Epoch 13/20, Total Loss: 3.3426, Contrastive Loss: 3.3407, Clustering Loss: 0.0000\n",
      "Epoch 14/20, Total Loss: 3.3414, Contrastive Loss: 3.3398, Clustering Loss: 0.0000\n",
      "Epoch 15/20, Total Loss: 3.3398, Contrastive Loss: 3.3385, Clustering Loss: 0.0000\n",
      "Epoch 16/20, Total Loss: 3.3388, Contrastive Loss: 3.3376, Clustering Loss: 0.0000\n",
      "Epoch 17/20, Total Loss: 3.3384, Contrastive Loss: 3.3374, Clustering Loss: 0.0000\n",
      "Epoch 18/20, Total Loss: 3.3369, Contrastive Loss: 3.3361, Clustering Loss: 0.0000\n",
      "Epoch 19/20, Total Loss: 3.3366, Contrastive Loss: 3.3359, Clustering Loss: 0.0000\n",
      "Epoch 20/20, Total Loss: 3.3365, Contrastive Loss: 3.3359, Clustering Loss: 0.0000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cModel = ContrastiveModel(unlabeled_train[0].shape, learning_rate=0.0001, lambda_param=50)\n",
    "#unlabeled_train = np.expand_dims(unlabeled_train, axis=-1)\n",
    "cModel.train(unlabeled_train, epochs=20, batch_size=2048)\n",
    "cModel.plot_training_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 100\n",
    "test_samples = x_test[:n_samples].reshape(n_samples,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cModel.plot_similarity_matrix(test_samples, n_samples=n_samples);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'Contrastive'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mContrastive\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ContrastiveModel\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mUtils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DatasetProcess\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'Contrastive'"
     ]
    }
   ],
   "source": [
    "from Contrastive import ContrastiveModel\n",
    "from Utils import DatasetProcess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cModel = ContrastiveModel(unlabeled_train[0].shape, \n",
    "                          learning_rate=0.005, \n",
    "                          lambda_param=.1,\n",
    "                          l2_lambda=0.0001)\n",
    "cModel.train(unlabeled_train, \n",
    "             epochs=5, \n",
    "             batch_size=128)\n",
    "cModel.plot_training_history()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vEZfd7iVX94s"
   },
   "source": [
    "# Trabajo extra\n",
    "\n",
    "¿Has probado a hacer el autoencoder totalmente convolucional? Para el *decoder* puedes usar las funciones [UpSampling2D](https://www.tensorflow.org/api_docs/python/tf/keras/layers/UpSampling2D) o [Conv2DTranspose](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2DTranspose)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: crea el nuevo modelo\n",
    "\n",
    "# TODO: crea tu propio clasificador\n",
    "\n",
    "class MiClasificadorSemisupervisado:\n",
    "\n",
    "    def __init__(self, input_shape):\n",
    "        # TODO : define el modelo y compílalo\n",
    "        \n",
    "        self.input_shape = (28,28,1)\n",
    "        self.num_classes = 10\n",
    "        \n",
    "        input_layer = layers.Input(shape=self.input_shape)\n",
    "        \n",
    "        # Encoder part (shared for both autoencoder and classifier)\n",
    "        # Convolutional layers instead of dense layers\n",
    "        x = layers.Conv2D(32, (3, 3), activation='relu')(input_layer)\n",
    "        x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "        x = layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
    "        x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "        x = layers.Conv2D(128, (3, 3), activation='relu')(x)\n",
    "        x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "        \n",
    "        # Encoder output (encoded features for classifier)\n",
    "        encoded = layers.Flatten()(x)\n",
    "        encoded = layers.Dense(64, activation='relu', kernel_regularizer='l2')(encoded)\n",
    "        \n",
    "        # Decoder for autoencoder part (using Conv2DTranspose layers)\n",
    "        decoded = layers.Dense(8 * 8 * 128, activation='relu', kernel_regularizer='l2')(encoded)\n",
    "        decoded = layers.Reshape((8, 8, 128))(decoded)\n",
    "        decoded = layers.Conv2DTranspose(128, (3, 3), activation='relu')(decoded)\n",
    "        decoded = layers.UpSampling2D((2, 2))(decoded)\n",
    "        decoded = layers.Conv2DTranspose(64, (3, 3), activation='relu')(decoded)\n",
    "        #decoded = layers.UpSampling2D((2, 2))(decoded)\n",
    "        decoded = layers.Conv2DTranspose(32, (3, 3), activation='relu', padding=(1,1))(decoded)\n",
    "        #decoded = layers.UpSampling2D((2, 2))(decoded)\n",
    "        decoded = layers.Conv2DTranspose(self.input_shape[2], (3, 3), activation='sigmoid', name='autoencoder')(decoded)\n",
    "\n",
    "\n",
    "        # Classifier part\n",
    "        classifier = layers.Dense(64, activation='relu', kernel_regularizer='l2')(encoded)\n",
    "        classifier = layers.Dense(32, activation='relu', kernel_regularizer='l2')(classifier)\n",
    "        classifier_output = layers.Dense(self.num_classes, activation='softmax',name='classifier')(classifier)\n",
    "\n",
    "        # Autoencoder model (for reconstructing input)\n",
    "        self.autoencoder = models.Model(input_layer, decoded)\n",
    "        self.autoencoder.compile(optimizer='adam', loss='mse')\n",
    "        \n",
    "        # Classifier model (for predicting class labels)\n",
    "        self.classifier = models.Model(input_layer, classifier_output)\n",
    "        self.classifier.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        # Combined model with two outputs: one for autoencoder (reconstruction) and one for classifier (classification)\n",
    "        self.model = models.Model(input_layer, \n",
    "                                  [decoded, classifier_output])\n",
    "                                  #classifier_output)\n",
    "        self.model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "                           loss=['mse', 'categorical_crossentropy'],\n",
    "                           #loss='categorical_crossentropy',\n",
    "                           loss_weights=[.5, 1.5],  # Adjust loss weights if needed\n",
    "                           metrics=['accuracy', 'accuracy'])\n",
    "    \n",
    "    def fit(self, X, y, unlabeled_data, batch_size,  epochs):\n",
    "        # TODO: entrena el modelo. Escoge el tamaño de batch y el número de epochs que quieras, y define bien el sample_weight\n",
    "\n",
    "        all_x = np.vstack((X, unlabeled_train))\n",
    "        y_zeros = np.zeros((unlabeled_data.shape[0],y.shape[1]))\n",
    "        all_y = np.vstack((y,y_zeros))\n",
    "        weight_autoencoder = np.ones(len(all_x))\n",
    "        weight_classifier = np.array([1]*len(X) + [0]*len(unlabeled_data))\n",
    "        \n",
    "        h = self.model.fit(all_x, \n",
    "                       [all_x, all_y], \n",
    "                       #all_y,\n",
    "                       sample_weight=[weight_autoencoder, weight_classifier], \n",
    "                       #sample_weight=sample_weight,\n",
    "                       epochs=epochs, \n",
    "                       batch_size=batch_size, \n",
    "                       verbose=1)\n",
    "        return h\n",
    "\n",
    "    def predict(self, X):\n",
    "        # TODO: devuelve la clase ganadora del clasificador\n",
    "        _, predictions = self.model.predict(X)\n",
    "        return predictions.argmax(axis=1)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        # TODO: devuelve la probabilidad del clasificador\n",
    "        _, predictions = self.model.predict(X)\n",
    "        return predictions\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        y_pred = self.predict(X)\n",
    "        return accuracy_score(y, y_pred)\n",
    "\n",
    "    def __del__(self):\n",
    "        # elimina todos los modelos que hayas creado\n",
    "        tf.keras.backend.clear_session() # Necesario para liberar la memoria en GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Exception encountered when calling Conv2DTranspose.call().\n\n\u001b[1m'tuple' object has no attribute 'lower'\u001b[0m\n\nArguments received by Conv2DTranspose.call():\n  • args=('<KerasTensor shape=(None, 22, 22, 64), dtype=float32, sparse=False, ragged=False, name=keras_tensor_163>',)\n  • kwargs=<class 'inspect._empty'>",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[243]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m model = \u001b[43mMiClasificadorSemisupervisado\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m=\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m h = model.fit(x_train, one_hot_train, unlabeled_train, batch_size=\u001b[32m60_000\u001b[39m, epochs = \u001b[32m100\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[242]\u001b[39m\u001b[32m, line 35\u001b[39m, in \u001b[36mMiClasificadorSemisupervisado.__init__\u001b[39m\u001b[34m(self, input_shape)\u001b[39m\n\u001b[32m     33\u001b[39m decoded = layers.Conv2DTranspose(\u001b[32m64\u001b[39m, (\u001b[32m3\u001b[39m, \u001b[32m3\u001b[39m), activation=\u001b[33m'\u001b[39m\u001b[33mrelu\u001b[39m\u001b[33m'\u001b[39m)(decoded)\n\u001b[32m     34\u001b[39m \u001b[38;5;66;03m#decoded = layers.UpSampling2D((2, 2))(decoded)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m decoded = \u001b[43mlayers\u001b[49m\u001b[43m.\u001b[49m\u001b[43mConv2DTranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrelu\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdecoded\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[38;5;66;03m#decoded = layers.UpSampling2D((2, 2))(decoded)\u001b[39;00m\n\u001b[32m     37\u001b[39m decoded = layers.Conv2DTranspose(\u001b[38;5;28mself\u001b[39m.input_shape[\u001b[32m2\u001b[39m], (\u001b[32m3\u001b[39m, \u001b[32m3\u001b[39m), activation=\u001b[33m'\u001b[39m\u001b[33msigmoid\u001b[39m\u001b[33m'\u001b[39m, name=\u001b[33m'\u001b[39m\u001b[33mautoencoder\u001b[39m\u001b[33m'\u001b[39m)(decoded)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/carrera/3/2/ma2/ma2Python12/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/carrera/3/2/ma2/ma2Python12/lib/python3.12/site-packages/keras/src/backend/common/backend_utils.py:196\u001b[39m, in \u001b[36m_get_output_shape_given_tf_padding\u001b[39m\u001b[34m(input_size, kernel_size, strides, padding, output_padding, dilation_rate)\u001b[39m\n\u001b[32m    193\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m input_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    194\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m196\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[43mpadding\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlower\u001b[49m() \u001b[38;5;129;01min\u001b[39;00m {\u001b[33m\"\u001b[39m\u001b[33mvalid\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33msame\u001b[39m\u001b[33m\"\u001b[39m}\n\u001b[32m    198\u001b[39m kernel_size = (kernel_size - \u001b[32m1\u001b[39m) * dilation_rate + \u001b[32m1\u001b[39m\n\u001b[32m    200\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m padding.lower() == \u001b[33m\"\u001b[39m\u001b[33mvalid\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[31mAttributeError\u001b[39m: Exception encountered when calling Conv2DTranspose.call().\n\n\u001b[1m'tuple' object has no attribute 'lower'\u001b[0m\n\nArguments received by Conv2DTranspose.call():\n  • args=('<KerasTensor shape=(None, 22, 22, 64), dtype=float32, sparse=False, ragged=False, name=keras_tensor_163>',)\n  • kwargs=<class 'inspect._empty'>"
     ]
    }
   ],
   "source": [
    "model = MiClasificadorSemisupervisado(input_shape=x_train[0].shape)\n",
    "h = model.fit(x_train, one_hot_train, unlabeled_train, batch_size=60_000, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(h.history['classifier_accuracy']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, losses\n",
    "import numpy as np\n",
    "\n",
    "# Hiperparámetros\n",
    "BATCH_SIZE = 128\n",
    "EMBEDDING_DIM = 128\n",
    "NUM_CLASSES = 10  # Ajustar según el dataset\n",
    "TEMPERATURE = 5.0\n",
    "LAMBDA = 0.5\n",
    "\n",
    "# Función para crear el modelo CNN (similar al encoder)\n",
    "def create_encoder_model(input_shape=(32, 32, 3)):\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(EMBEDDING_DIM)\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Función para crear la capa de cluster\n",
    "def create_cluster_model(embedding_dim=EMBEDDING_DIM, num_classes=NUM_CLASSES):\n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=(embedding_dim,)),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Data augmentation para imágenes\n",
    "def get_data_augmentation():\n",
    "    data_augmentation = keras.Sequential([\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomRotation(0.1),\n",
    "        layers.RandomZoom(0.1),\n",
    "    ])\n",
    "    return data_augmentation\n",
    "\n",
    "# Data augmentation diferente para segundo conjunto\n",
    "def get_data_augmentation_2():\n",
    "    data_augmentation = keras.Sequential([\n",
    "        layers.RandomFlip(\"vertical\"),\n",
    "        layers.RandomContrast(0.2),\n",
    "        layers.RandomTranslation(0.1, 0.1),\n",
    "    ])\n",
    "    return data_augmentation\n",
    "\n",
    "# Función de pérdida para la matriz de similitud\n",
    "class ContrastiveLoss():\n",
    "    def __init__(self, temperature=TEMPERATURE):\n",
    "        self.temperature = temperature\n",
    "        \n",
    "    def __call__(self, y_pred):\n",
    "        # y_true es la matriz identidad (no la usamos directamente)\n",
    "        # y_pred es la matriz de similitud M\n",
    "        \n",
    "        # Aplicamos softmax con temperatura\n",
    "        logits = y_pred / self.temperature\n",
    "        logits_max = tf.reduce_max(logits, axis=1, keepdims=True)\n",
    "        logits = logits - logits_max\n",
    "        exp_logits = tf.exp(logits)\n",
    "        exp_logits_sum = tf.reduce_sum(exp_logits, axis=1, keepdims=True)\n",
    "        probs = exp_logits / exp_logits_sum\n",
    "        \n",
    "        # Creamos matriz identidad como objetivo\n",
    "        batch_size = tf.shape(y_pred)[0]\n",
    "        y_true = tf.eye(batch_size)\n",
    "        \n",
    "        # Calculamos entropia cruzada\n",
    "        loss = -tf.reduce_sum(y_true * tf.math.log(probs + 1e-10)) / tf.cast(batch_size, tf.float32)\n",
    "        return loss\n",
    "\n",
    "# Función de pérdida para el clustering\n",
    "class ClusteringLoss():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def __call__(self, cX_1comp, cX_2comp):\n",
    "\n",
    "        # loss_C = cX_1comp(1 - cX_1comp) + cX_2comp(1 - cX_2comp)\n",
    "        loss_1 = tf.reduce_mean(cX_1comp * (1 - cX_1comp))\n",
    "        loss_2 = tf.reduce_mean(cX_2comp * (1 - cX_2comp))\n",
    "        \n",
    "        return loss_1 + loss_2\n",
    "\n",
    "# Modelo combinado para entrenamiento\n",
    "class ContrastiveModel(tf.keras.Model):\n",
    "    def __init__(self, input_shape=(32, 32, 3), embedding_dim=EMBEDDING_DIM, num_classes=NUM_CLASSES):\n",
    "        super(ContrastiveModel, self).__init__()\n",
    "        self.encoder = create_encoder_model(input_shape)\n",
    "        self.cluster = create_cluster_model(embedding_dim, num_classes)\n",
    "        self.data_aug1 = get_data_augmentation()\n",
    "        self.data_aug2 = get_data_augmentation_2()\n",
    "        self.contrastive_loss = ContrastiveLoss()\n",
    "        self.clustering_loss = ClusteringLoss()\n",
    "        self.lambda_param = LAMBDA\n",
    "        \n",
    "    def compile(self, optimizer):\n",
    "        super(ContrastiveModel, self).compile()\n",
    "        self.optimizer = optimizer\n",
    "        \n",
    "    def train_step(self, data):\n",
    "        # Desempaquetar los datos\n",
    "        if isinstance(data, tuple):\n",
    "            X = data[0]\n",
    "        else:\n",
    "            X = data\n",
    "            \n",
    "        batch_size = tf.shape(X)[0]\n",
    "        \n",
    "        # Aplicar las dos transformaciones de data augmentation\n",
    "        augX_1 = self.data_aug1(X)\n",
    "        augX_2 = self.data_aug2(X)\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            # Obtener representaciones del encoder\n",
    "            augX_1comp = self.encoder(augX_1)\n",
    "            augX_2comp = self.encoder(augX_2)\n",
    "            \n",
    "            # Obtener salidas del clustering\n",
    "            cX_1comp = self.cluster(augX_1comp)\n",
    "            cX_2comp = self.cluster(augX_2comp)\n",
    "            \n",
    "            # Calcular matriz de similitud M\n",
    "            M = tf.matmul(augX_1comp, augX_2comp, transpose_b=True)\n",
    "            \n",
    "            # Calcular pérdida de contraste\n",
    "            loss_M = self.contrastive_loss(M)\n",
    "            \n",
    "            # Calcular pérdida de clustering\n",
    "            loss_C = self.clustering_loss(cX_1comp, cX_2comp)\n",
    "            \n",
    "            # Pérdida total\n",
    "            total_loss = loss_M + self.lambda_param * loss_C\n",
    "            \n",
    "        # Calcular gradientes y actualizar pesos\n",
    "        gradients = tape.gradient(total_loss, self.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "        \n",
    "        return {\"loss\": total_loss, \"contrastive_loss\": loss_M, \"clustering_loss\": loss_C}\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        # Para inferencia, solo devolvemos la representación del encoder\n",
    "        return self.encoder(inputs)\n",
    "\n",
    "# Función de utilidad para cargar y preparar dataset (ej. CIFAR-10)\n",
    "def load_dataset():\n",
    "    (x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "    x_train = x_train.astype(\"float32\") / 255.0\n",
    "    x_test = x_test.astype(\"float32\") / 255.0\n",
    "    return (x_train, y_train), (x_test, y_test)\n",
    "\n",
    "def dummy_loss(y_true, y_pred):\n",
    "    return tf.constant(0.0)\n",
    "\n",
    "# Entrenamiento del modelo\n",
    "def train_model():\n",
    "    # Cargar dataset\n",
    "    (x_train, y_train), (x_test, y_test) = load_dataset()\n",
    "    \n",
    "    # Crear modelo\n",
    "    input_shape = x_train.shape[1:]\n",
    "    model = ContrastiveModel(input_shape=input_shape)\n",
    "    \n",
    "    # Compilar el modelo\n",
    "    model.compile(optimizer=keras.optimizers.Adam(1e-4))\n",
    "    \n",
    "    # Entrenar modelo\n",
    "    model.fit(\n",
    "        x_train,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        epochs=20,\n",
    "        validation_data=(x_test, None),\n",
    "        loss=dummy_loss\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Para usar el modelo entrenado para extraer representaciones:\n",
    "def extract_features(model, images):\n",
    "    return model.encoder(images).numpy()\n",
    "\n",
    "# Para clasificación, se puede entrenar un clasificador sobre las características extraídas\n",
    "def train_classifier(X_features, y_labels):\n",
    "    classifier = keras.Sequential([\n",
    "        layers.Input(shape=(EMBEDDING_DIM,)),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(NUM_CLASSES, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    classifier.compile(\n",
    "        optimizer=keras.optimizers.Adam(1e-3),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    classifier.fit(X_features, y_labels, batch_size=32, epochs=10, validation_split=0.1)\n",
    "    return classifier\n",
    "\n",
    "# Ejemplo de uso completo\n",
    "if __name__ == \"__main__\":\n",
    "    # Entrenar el modelo contrastivo\n",
    "    contrastive_model = train_model()\n",
    "    \n",
    "    # Cargar datos\n",
    "    (x_train, y_train), (x_test, y_test) = load_dataset()\n",
    "    \n",
    "    # Extraer características\n",
    "    train_features = extract_features(contrastive_model, x_train)\n",
    "    test_features = extract_features(contrastive_model, x_test)\n",
    "    \n",
    "    # Entrenar clasificador\n",
    "    classifier = train_classifier(train_features, y_train)\n",
    "    \n",
    "    # Evaluar\n",
    "    test_loss, test_acc = classifier.evaluate(test_features, y_test)\n",
    "    print(f\"Test accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabeled_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 1, 0])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_train[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ma2Python12",
   "language": "python",
   "name": "ma2python12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
